[
    {
        "class": "YouTubeVideo",
        "title": "Exploring Data-Driven Equation Discovery to Model Moisture Flux by Rebecca Porter",
        "videoId": "p9TLA9hTLGo",
        "url": "https://www.youtube.com/watch?v=p9TLA9hTLGo",
        "publishedAt": "2023-08-02T18:17:59Z",
        "transcript": "4.56s: okay hello everyone my name is Rebecca\n7.5s: Porter I come from the University of\n9.0s: Saint Mary and I'm the interdisciplinary\n10.92s: study student that they talked about\n12.3s: earlier\n13.38s: um and so today I'm going to talk to you\n14.46s: a little bit about modeling moisture\n16.02s: flux using equation Discovery and so if\n18.48s: you don't know what moisture flux is\n20.82s: this image on the left here is a good\n22.74s: visualization uh you can sort of it's\n24.96s: the rate at which moisture flows through\n26.699s: a given area so you can sort of Imagine\n28.439s: these lines these arrows pointing\n30.48s: upwards as particles of moisture moving\n32.64s: through the atmosphere and when you get\n34.32s: a vertical movement that generally means\n36.18s: that you're also going to get like these\n38.82s: beautiful clouds\n40.44s: um that you see on the right\n42.42s: um so yeah anytime you have moisture\n43.739s: moving upward in the air you generally\n45.12s: get Cloud development and precipitation\n46.98s: development and that's why I want to\n48.48s: study and improve the modeling\n51.059s: of this variable because of the impact\n54.719s: that moisture flux has on cloud\n56.699s: development and precipitation\n58.379s: and so a little bit about traditional\n60.96s: and new climate modeling methods that we\n63.48s: have today\n64.799s: um if you as you just saw from the\n67.02s: presentation like two seconds ago uh we\n69.54s: have sort of a grid in equations within\n71.4s: that grid that model atmospheric\n73.08s: processes and it's great except for when\n75.479s: you want to model things that are\n77.88s: subgrid scale processes which means that\n80.04s: they're smaller than the original grid\n81.6s: size moisture flux is one of these\n83.759s: processes that is much smaller than the\n85.5s: grid size and so\n87.54s: um it it is not as accurate when you\n90.6s: take it in a larger scale\n92.759s: um you sort of have to generalize a\n94.2s: little too much for it to be accurate\n95.64s: and so to sort of overcome that issue\n99.0s: and the computational expense from\n101.159s: modeling these smaller subgrid scale\n103.38s: processes people are looking into\n104.64s: machine learning and that's great as\n107.22s: well because it's a lot more accurate\n109.38s: more efficient but the problem with\n111.659s: machine learning is sometimes the models\n113.28s: aren't always interpretable you can ask\n114.96s: the machine learning model how'd you get\n116.7s: that answer and I won't be able to tell\n118.02s: you what like it it just knows the\n120.78s: pattern it doesn't know the why behind\n122.159s: it and so a way to overcome both of\n124.92s: these issues is equation Discovery it's\n128.16s: what I did my research on this summer\n129.8s: and a it's basically a way to discover\n132.78s: equations of this graph here on the left\n135.84s: side is a basic example of that it's\n138.3s: linear regression where you have your\n139.98s: input and your output variables and\n141.3s: you're trying to map a relationship\n142.68s: between the two and so uh if it there's\n145.739s: a linear relationship linear regression\n147.66s: is great but if there it looks a little\n149.64s: bit more like this thing on the right\n151.2s: with all the ways and whatnot it doesn't\n153.599s: work so great a line's not going to help\n155.099s: you there\n156.18s: um so I use something called symbolic\n158.459s: regression that's one of the methods I\n159.84s: use where you input your data and it\n162.599s: tries to map like I said a relationship\n164.7s: between your input and output and it\n167.519s: will basically search through this space\n169.319s: of mathematical operators like uh as\n172.379s: subtract multiply divide log all that\n174.18s: stuff and it creates an equation that\n176.4s: shows the relationship between your and\n178.08s: put it output and so the equation might\n179.94s: look something a little bit more like uh\n181.739s: I should be pointing with this shouldn't\n183.36s: I this\n185.22s: this one here the equation tree\n188.22s: um where at the bottom the you see okay\n190.379s: well I have and X here to next here and\n193.2s: it's telling me I need to add those two\n194.58s: x's so now I know it's 2x but then I'll\n196.98s: instill we may need to add the sign\n198.18s: apply that sign to the 2x so then I then\n201.42s: know that my equation is y equals sine\n203.519s: 2X and so that's how symbolic regression\n205.5s: works and I also use another method\n207.659s: called piecewise regression where you\n209.64s: have something called a break point and\n211.379s: it essentially tells us where the slope\n214.2s: in your data changes that's where your\n216.0s: breakpoint is and then it fits two\n217.62s: different linear lines around that\n220.26s: breakpoint and you can have multiple\n221.34s: breakpoints but I only used one\n223.68s: um so it outputs an equation like this\n226.08s: on the screen here and it looks nasty\n228.54s: and it kind of is if you don't know\n229.92s: what's going on here but really what it\n232.62s: is is this part y equals ax plus C is\n235.019s: really just a y equals MX plus b but for\n237.48s: your first segment here on the left\n239.64s: um and then to account for the second\n240.9s: segment you have this chunk here the\n243.239s: Plus\n244.14s: all that stuff\n245.76s: um and so this first term here the beta\n248.58s: that just accounts for the change in\n250.26s: slope between segment one and segment\n251.879s: two so it's not the slope of segment two\n253.739s: it's a change in slope between the two\n255.959s: um and then the this symbol here that is\n259.26s: going to be where the break point or\n260.82s: where the change in slope occurs and\n262.68s: then the H of x minus this symbol\n266.46s: um that is the it essentially is zero\n269.58s: when X is less than zero and it is one\n271.68s: when X is greater than or equal to zero\n273.72s: and um then we also have a noise term\n277.139s: here because not everything's perfect\n279.78s: um and so\n281.759s: before uh I could apply any of this I\n285.0s: first want to talk about like the\n287.04s: equation that I was hoping to get I used\n288.78s: the real world uh or real geography data\n291.36s: at the low res as uh mentioned\n294.24s: um and then I just wanted to focus on\n295.88s: where moisture would be most abundant\n298.68s: and so I I thought that July would be a\n300.479s: good month to look at because that's our\n302.04s: summer month here and then I looked\n304.259s: specifically over the near the Caribbean\n306.479s: islands over the ocean because moisture\n308.699s: is off but quite obviously abundant\n310.74s: there\n311.639s: um and then I focused just on the lowest\n313.8s: three levels in the atmosphere so uh 723\n316.74s: meters above the surface and Below\n318.96s: um because that's where I found when I\n321.12s: was sort of mapping out the moisture\n322.38s: that's where it was most abundant and so\n324.72s: I was hoping to find an equation\n326.94s: um kind of like this with my equation\n329.22s: Discovery where W Prime Q Prime is the\n331.62s: moisture flux that's what we're trying\n333.0s: to predict and then dqd that is what\n336.06s: we're inputting into the model\n338.039s: um that is the vertical rating of\n339.3s: moisture or how moisture changes\n340.8s: throughout the the vertical movement in\n344.039s: the atmosphere uh and then I was hoping\n346.8s: to find this any diffusivity constant\n349.919s: um using equation Discovery but before I\n353.039s: could do any of this I had to do some\n355.08s: background math of course\n356.639s: um because in the data set there was\n358.8s: actually no DZ in there outputted there\n361.02s: was no W Prime Q Prime unfortunately for\n363.539s: my course self and so I uh I had to\n367.44s: with the help of you I had to figure out\n370.68s: um how I can find these these data uh\n373.56s: this data basically so I use R for dry\n376.08s: air which is uh coming from the ideal\n378.18s: gas law virtual temperature gravity and\n380.46s: then this is the change in the log of\n382.44s: pressure\n383.46s: and then for Adobe Prime Q Prime at a\n385.74s: specific layer in the atmosphere I use\n387.66s: moistening tendency at that layer times\n390.3s: the change in height of that layer then\n392.34s: I added all the layers below it plus the\n394.38s: latent heat flux going upward into the\n396.24s: air generally I think and um that found\n399.0s: my w Prime Q Prime doctor I did all this\n401.58s: data pre-processing I could finally\n404.039s: um apply my modeling methods and the\n407.46s: first one I did was piecewise regression\n409.02s: and um what I first want to point out is\n411.78s: that these are all three different\n413.039s: equations one for each layer in the\n415.139s: atmosphere and\n417.12s: um what I noticed was that piecewise\n418.62s: regression had a really hard time\n419.88s: finding the break point as I said where\n422.34s: that slope changes on these two levels\n425.039s: so the middle level and the lowest level\n427.319s: closest to the atmospheric surface or I\n429.539s: mean the Earth's surface it had trouble\n431.94s: finding that breaking point but it did\n433.68s: well for the um fairly well for the\n436.02s: highest level and so because it did so\n438.66s: well on the highest level comparatively\n441.36s: um I outputted that equal equation down\n444.24s: here and like I said it looks nasty but\n447.3s: if you really bring it down to its\n448.38s: components where you have the Y equals\n450.12s: MX plus b in the beginning and all the\n452.16s: other stuff for the second equation or\n453.72s: second segment to the right\n456.18s: um it's really quite interpretable to me\n458.28s: at least I feel like\n459.84s: um so then I was also able to apply\n462.419s: symbolic regression where uh I just put\n466.56s: AC subtract multiply log and inverse as\n468.479s: The Operators that I could choose from\n469.979s: and what I found was really interesting\n472.199s: that\n473.16s: symbolic regression was really much\n475.259s: easier able to find the shape of the\n477.78s: data comparatively to\n480.18s: um piecewise regression now the r\n481.919s: squared values are much lower which is\n484.56s: unfortunate but I did find it\n486.18s: interesting that it could at least pick\n487.38s: up these sort of weird little tails at\n490.02s: the bottom here with piecewise where uh\n493.5s: or symbolic word with piecewise all it\n495.36s: did is just change the slope a little\n496.86s: bit lower\n498.18s: um and so for this it also did better on\n500.879s: the upmost level\n504.12s: oh there we go okay yeah I did better on\n506.28s: the utmost level so I took that equation\n508.379s: which is what you see here on the left\n510.18s: and then I simplified it for you guys\n512.099s: because I guess I'm just that nice and I\n515.099s: that is here\n517.14s: um and it's not much simpler actually so\n519.659s: that's something that I found it's\n520.86s: actually a really difficult equation to\n522.24s: understand oh and so I wanted to point\n524.339s: out that if I were to have changed this\n526.14s: inverse to a square root for example the\n529.26s: that means the equation would also\n530.76s: change and that would also mean my\n532.08s: prediction to the plot would change\n534.779s: um the r squared values have changed and\n536.399s: so what I really did was I just picked\n538.38s: the smoothest curves that looked the\n540.72s: best there was really no like actual\n543.019s: scientific reasoning behind the one that\n545.1s: I chose just it looked the best it had\n546.42s: the best r squared version\n548.339s: um so yeah\n549.959s: so summary I applied piecewise\n551.94s: regression as a small progression to\n553.32s: model moisture flux and what I learned\n556.2s: is that it needs there needs to be a bit\n558.12s: more of a accurate and interpretable\n560.519s: equation for This research to be\n561.959s: worthwhile\n563.519s: um not like the stuff you saw on the\n565.2s: last screen if that was how all of them\n566.58s: were it maybe not be that great\n568.5s: um and then I think I could do that by\n570.12s: using hyper parameter tuning so tuning\n572.16s: how many generations it runs forward I\n575.279s: um actually for symbolic regression it's\n576.779s: a genetic programming method so it I\n579.6s: didn't really actually get to use any of\n581.04s: the genetic programming features because\n582.36s: of lack of time but then I think I could\n585.42s: also add more features if it's\n586.74s: temperature pressure uh maybe hopefully\n589.019s: simplify and improve that accuracy I\n591.54s: think I could maybe try to add other\n593.399s: function possibilities and all of this\n595.38s: with an underlying understanding that I\n597.0s: want to improve computational efficiency\n598.62s: and so with that if you have any\n600.959s: questions I would be happy to take them\n603.72s: due to the time limit to a question\n606.36s: maybe anyone from audience\n613.26s: if anyone has a question online please\n615.839s: raise your hand and now I'm like I'll\n617.94s: mute you\n624.24s: sir\n634.019s: okay uh great I guess uh we don't have\n638.04s: any questions uh so let's welcome our\n640.8s: yeah thank you Rebecca\n644.34s: [Music]"
    },
    {
        "class": "YouTubeVideo",
        "title": "Investigating the Use of Neural Networks to Project Changes in Extreme Storm Surges in Europe",
        "videoId": "wR_CU-bzx4Q",
        "url": "https://www.youtube.com/watch?v=wR_CU-bzx4Q",
        "publishedAt": "2025-01-13T15:48:01Z",
        "transcript": "5.4s: all right everyone um welcome to the\n8.96s: seminar today and it's my pleasure to\n10.759s: introduce uh Tim hermans um he comes\n13.559s: from the Netherlands and is visiting uh\n15.4s: New York for a few days uh he's\n16.76s: currently a postto at the University of\n18.52s: utr um and he did his PhD at the nioz\n21.72s: Royal Netherlands Institute for sea\n23.32s: research Tim is an expert on sea level\n25.76s: change and uh extreme weather events\n28.4s: particularly flooding uh he's also a\n30.4s: chapter scientist on the uh most recent\n32.759s: ipcc um assessment report chapter nine\n36.16s: and today he's going to talk about uh\n37.68s: extrem Storm surges and uh how to work\n40.52s: on that with machine learning so I hope\n41.96s: there's a lot of overlap with folks over\n43.8s: here thanks perfect thank you uh can you\n47.039s: hear me is the microphone working okay\n49.12s: perfect well thanks a lot for having me\n50.96s: here today um by the way if you have any\n54.12s: questions for clarifications in between\n56.239s: please just feel free to ask them uh and\n58.92s: interrupt me\n60.44s: um so yeah my name is Tim uh I will talk\n62.519s: today about Computing extreme Storm\n64.32s: surges using um machine learning neural\n66.92s: network\n67.96s: specifically and julus already said it\n71.04s: um but I'm from the other side of the\n73.479s: North Atlantic uh in the Netherlands uh\n77.36s: it's very nice city if you ever visit\n78.96s: the Netherlands please go there um I did\n81.439s: a PhD on sea level change uh\n83.56s: specifically on Regional Ocean Models\n86.479s: which I use to refine the simulations of\n89.36s: uh global climate models should I yeah\n92.64s: yeah yeah yeah no problem yeah that's\n96.04s: better I think um and then I also did\n100.6s: some work on global mean sea level\n102.399s: projections and sea level variability\n105.079s: and by working on those topics I kind of\n108.04s: um was involved in uh the ipcc report in\n113.32s: 2021 where I contributed to uh sea level\n116.36s: projections and also projections of\n118.0s: extreme sea levels so that has an nice\n119.96s: link to today's presentation I'm\n122.479s: currently working on Extreme sea levels\n125.399s: uh doing extreme value analysis I did a\n127.56s: study with uh Julius on compound\n129.84s: flooding uh that's basically how we met\n132.4s: and maybe some of you were attending a\n135.319s: presentation that we gave together a\n137.36s: while ago as well and so today I will uh\n141.4s: give a bit more context on those extreme\n143.319s: sea levels uh talk about why I want to\n146.599s: use uh datadriven models and I show some\n150.239s: of the results um that I've got so\n153.4s: far so um first for some context and\n157.36s: this is not yet machine learning uh\n159.239s: related but we will get there so um\n162.56s: there are two different types of changes\n164.72s: in extreme sea levels and what's often\n167.599s: being projected are changes in extreme\n169.84s: sea levels that we call static so\n172.28s: basically you could have a distribution\n174.48s: of extreme sea levels looking like this\n177.12s: uh so depending on their return\n179.08s: frequency um they could be lower or\n181.68s: higher and um we can then assume that\n184.92s: this distribution is going to change uh\n187.84s: is going to stay the same in the future\n189.959s: which is not entirely true uh but we can\n191.879s: assume that and then add projected sea\n194.76s: level rise for a certain year for\n196.319s: instance 2100 so by doing that the whole\n199.72s: uh Baseline of those extreme sea levels\n201.76s: will be raised and then you can do some\n204.72s: calculations uh like the following so\n206.84s: for instance you could Wonder uh how\n209.239s: much more often is the extreme sea level\n211.239s: with a return frequency of once per\n213.28s: Century historically uh going to occur\n216.0s: in the future uh for instance annually\n218.84s: and that would uh result in what we call\n221.04s: an amplification Factor uh in this case\n224.599s: of\n225.64s: 100 and as I will show in a bit this is\n228.76s: a typical computation that ipcc reports\n231.319s: in the past decade or so uh have been\n235.68s: reporting um because it's relevant for\n238.28s: the machine learning work I'm going to\n240.04s: go a bit more into detail on this method\n242.64s: so how do we come come up with a a\n245.0s: distribution of extreme sea levels uh\n247.76s: basically you take an observational\n249.439s: record of those sea levels and you\n251.2s: define a certain threshold uh above\n253.64s: which you define uh sea levels to be\n255.799s: extreme uh for instance the 99\n258.28s: percentile of observations is uh often\n260.84s: used uh so you would end up with a\n263.199s: series of extreme sea levels with a\n264.96s: certain height and a certain frequency\n267.36s: of occurrence in the observational\n269.0s: period and then to say something about\n271.72s: events that you have not yet observed\n273.84s: with an even lower return frequency you\n276.44s: can fit an extreme value distribution\n279.16s: and basically that results in a a curve\n282.08s: which we call a return curve um linking\n285.72s: the return height to the return\n288.28s: frequency now in those static\n290.639s: projections that I just explained we\n292.479s: would add a certain C level rise\n294.36s: projected for an arbitrary year raise\n296.919s: that return curve up and then see uh\n299.479s: where the historical Centennial events\n302.08s: so the event with a return frequency\n303.88s: once per Century will end up in the\n306.52s: future and come up with a certain\n308.32s: amplification Factor so that's what uh\n310.84s: this looks like in\n313.56s: practice um as I said this is what the\n316.84s: ipcc did so for instance this led to\n319.24s: some headlines in uh the summary for\n321.68s: policy makers that extreme sea level\n324.24s: events that occurred once per Century in\n326.16s: the recent past are projected to occur\n328.639s: at least annually at more than half of\n330.639s: tight gauge locations in 2100 so that\n333.24s: feels quite significant um however at\n336.12s: the same time it also doesn't really say\n338.08s: a lot because how relevant is uh the\n341.08s: historical Centennial event for a\n342.759s: certain location uh maybe there's also\n344.88s: flood protection in place so as a small\n348.16s: Sid step to this presentation uh I\n350.52s: wanted to show some work that we did um\n353.28s: in the recent past uh where we replaced\n355.639s: this uh historical Centennial event with\n358.08s: flop protection standards that are\n360.24s: estimated in different places uh so for\n362.88s: instance in the Netherlands there are\n364.44s: dkes that are designed to withstand\n366.759s: events that occur once every 10,000\n369.319s: years so these are very high standards\n371.68s: uh which are also difficult to estimate\n374.0s: uh but in other locations there may be\n375.72s: relevant the uh standards uh for\n377.72s: instance once per uh decade or maybe\n380.0s: even annually so by replacing that\n382.24s: reference frequency with a more\n384.319s: meaningful um uh frequency you can uh\n388.08s: make calculations like these where we\n389.919s: were Computing uh when current flaw\n392.84s: protection standards will be exceeded 10\n394.759s: times as often uh for for instance a\n397.199s: relatively High emission scenario uh and\n399.84s: then you can uh make some conclusions\n401.759s: for instance that this will happen\n403.56s: within the coming 30 years at about a\n405.8s: quarter of tight gauge\n408.12s: locations okay so this is some\n410.36s: background uh let's get uh a bit more\n412.919s: into the machine learning aspect because\n415.12s: there may also be changes in the\n416.879s: distribution of those extreme sea levels\n419.639s: even though people often assume that\n421.52s: they're not important so there may be\n423.84s: changes due to changes in tis waves and\n426.599s: what I'm interested in uh specifically\n428.4s: is changes in storm\n431.319s: surges here you see uh projections that\n434.199s: exist at the moment for changes in storm\n436.639s: surges um apart from changes due to sea\n440.08s: level rise itself this is a map of\n443.599s: changes in the storm surge height with a\n446.639s: return frequency of once per decade and\n449.319s: this this is based on a relatively small\n451.72s: Ensemble of climate model simulations uh\n454.759s: but even still they show some um\n457.56s: patterns of change for instance\n459.68s: increases in the storm surge level here\n461.879s: and there decreases over there uh but\n464.759s: more important for this talk is that the\n466.919s: models don't really agree a lot about\n469.4s: whether these changes are positive or\n471.199s: negative so this is not the most clear\n473.759s: plot ever but um the darker the colors\n477.96s: here the more models agree about uh\n480.759s: where about the sign of the changes\n482.72s: projected uh and as you can see from the\n484.919s: light colors at many places there isn't\n487.28s: that much agreement between climate\n488.879s: models meaning these projections are\n490.879s: quite um uncertain both due to\n494.44s: differences in climate models but also\n496.039s: due to internal variability which is in\n498.319s: this specific case especially important\n500.36s: because we're looking at a period uh\n502.36s: that's quite uh close uh to the period\n505.24s: where we are in now so there's\n508.039s: uncertainty because of those uh small\n510.4s: ensembles of clim climate model\n512.08s: simulations that are being used for\n513.719s: projections like these and why uh are\n516.519s: those ensembles so small uh that's\n519.159s: because Global Climate Global Climate\n521.36s: models don't output Storm surges or at\n524.12s: least not reliably uh they simulate\n526.6s: changes in atmosphere uh wind and uh sea\n529.519s: level pressure for instance but you need\n531.68s: an offline method to transload translate\n534.64s: uh those atmospheric variables to\n537.0s: changes in storm surges and typically uh\n540.399s: a hydrodynamic model is used for that uh\n543.6s: of course that takes uh computational\n546.56s: Power therefore ensembles have been\n548.8s: limited uh in size so far so this got me\n553.32s: wondering can we do this better faster\n555.959s: more efficiently uh for instance by\n558.48s: replacing uh the hydrodynamic model with\n560.959s: a data driven model like a neural\n564.24s: network if that works it would allow us\n566.8s: to um base projections on much larger\n569.68s: ensembles of climate model simulations\n571.48s: and reduce those uncertainties that I\n573.2s: just talked\n574.519s: about however there are a few problems\n578.24s: um in the literature that I've read\n580.88s: there are quite a few examples of\n582.76s: machine learning uh to compute Storm\n585.079s: surges for specific uh events for\n588.12s: example during uh tropical Cyclones\n590.839s: using information about our path and\n593.2s: other properties uh however there have\n595.64s: been fewer applications looking at\n597.48s: reproducing whole time series of stor\n599.519s: surges based on grided atmospheric\n603.24s: data um and the studies that are there\n605.92s: they didn't really look into extreme\n607.48s: Storm surges which are in the end what\n609.72s: we are most interested in because these\n611.44s: are the ones causing flooding um and\n614.519s: they didn't really evaluate how well\n616.04s: their models are perform at simulating\n618.88s: those extreme Storm surges neither did\n620.76s: they train their models specifically to\n623.04s: predict the extremes and that's what I\n625.2s: will talk about uh on the next\n627.8s: slides Second Challenge\n630.04s: is applying those models once trained to\n632.6s: climate model simulations uh which is\n635.32s: difficult because the climate models\n636.6s: have biases and also they may uh\n639.68s: simulate changes in the atmosphere that\n641.48s: push their distributions beyond what is\n643.76s: being observed at the moment uh and that\n646.0s: may cause the neural networks to uh have\n648.32s: to extrapolate uh to compute storm\n650.56s: surges and they are not that good at it\n653.32s: any questions so\n655.68s: far\n657.24s: great Okay so let's make it a bit more\n661.04s: concrete um I'm looking the study site\n663.6s: that I'm looking at is Northwestern\n665.72s: Europe um we selected uh a few tight\n669.959s: gauges namely the ones indicated uh on a\n673.079s: figure based on their uh available data\n675.72s: and also on geographical\n678.639s: distribution and the data that we use\n681.04s: are tight gauge measurements uh and an\n683.639s: example of that is shown for Dan Helder\n686.6s: which is a city at the Dutch Coast\n689.6s: and first of all what we did through\n691.04s: those observations is to remove the ties\n693.639s: because that's not what we interested in\n695.36s: in\n696.519s: predicting so we are left with something\n698.839s: that's hopefully a non-tidal residual\n701.6s: and mainly caused by\n703.639s: storms and then uh as is common for uh\n707.32s: model training we split it up the data\n709.2s: into three different parts uh a part to\n711.92s: train the models a part to validate the\n714.24s: models and see which hyperparameters are\n716.56s: most important and work best and and a\n720.04s: third uh split of the data to evaluate\n723.24s: how well the models generalize once\n727.12s: trained and the data that we use to\n729.959s: predict those non-title residuals which\n732.16s: I will refer to as Storm surges from now\n734.36s: on uh is atmospheric data from the era 5\n737.76s: reanalysis so it's based on observations\n740.839s: uh not only at the place where the tight\n743.44s: gaug is but also in a box of 5x5 degrees\n747.959s: around it and also not only at the time\n750.68s: Step At which we want to predict the\n752.279s: search but also at multiple different\n754.32s: time steps uh\n757.72s: before so this data is available at a\n760.68s: hourly frequency um but because\n763.6s: eventually we want to apply to climate\n765.36s: models we um down sample basically the\n769.16s: data to a three-hourly frequency uh\n771.92s: because climate models uh the data of\n774.0s: the climate models is often only\n775.6s: provided at six or at best three hourly\n778.12s: frequency so we want to be as close to\n781.6s: that situation uh in training the models\n783.519s: as\n786.32s: possible and um in evaluating uh as you\n790.079s: will see in next slides uh I'm focusing\n792.44s: on exceedances of the 99 percenti\n795.079s: because this is what is typically used\n796.72s: for those extreme sea level analyses\n798.959s: that I just\n801.12s: showed okay so that uh automatically\n804.36s: also raises a problem um because those\n807.079s: exceedances the extreme Storm surges\n809.72s: uh do not happen that often they are\n811.8s: under represented in uh the observations\n815.72s: so by minimizing a certain loss function\n818.279s: for instance the mean square error uh\n820.36s: the model will be biased towards the\n822.76s: more moderate events so we wanted to\n826.24s: test something to kind of counteract\n828.079s: that uh and we did that by introducing a\n831.079s: waiting factor which is based on\n833.48s: previous work applied on a different\n836.48s: setting so that waiting Factor basically\n839.88s: puts more weight on uh observations that\n842.88s: are more rare so you can see here in\n845.519s: this figure uh these are the\n847.6s: observations on the x-axis standardized\n850.16s: and this will be the weight that is\n851.68s: given to them um and depending on this\n854.639s: hyperparameter Alpha the weights placed\n857.44s: on the more rare events uh are higher or\n860.639s: lower so uh for an alpha value of zero\n863.759s: we don't do any uh density based\n865.88s: weighting so all the observations have a\n868.36s: weight of one and the higher the alpha\n870.72s: the more severe we uh wait the extreme\n873.56s: events\n875.24s: more uh and we test it until an alpha\n877.8s: value of five uh this will come back in\n880.12s: the results as well so it's important to\n882.6s: uh\n885.0s: remember then um we tested two types of\n888.12s: neural networks and I guess that um many\n891.32s: of you will be familiar with these first\n894.56s: of all uh we used a model with an LM\n897.8s: layer long short to memory that um looks\n901.199s: at temporal features in the data um but\n904.16s: we also wanted to test um what the added\n907.12s: value is of also looking at spatial\n910.04s: temporal patterns using a convolutional\n912.36s: version of the lstm\n916.079s: model so um before I show the results um\n920.32s: let's here list the questions that we\n922.399s: wanted to answer first of all what is\n925.04s: the effect of introducing these density\n928.0s: based weights for for uh predicting\n929.959s: extreme Storm\n931.36s: surges secondly um is there any added\n934.639s: value of introducing convolutional\n936.399s: layers that look at spatial temporal\n938.639s: patterns and thirdly how well do the\n941.079s: neural networks once trained actually\n943.12s: perform uh so we have two uh different\n946.0s: benchmarks for that first of all a very\n948.8s: simple multilinear regression model uh\n951.68s: and secondly a very complex hydrodynamic\n954.199s: model uh with a very high resolution\n956.92s: which is called the global tis and\n958.399s: search model\n961.639s: gtsm so basically those two are used to\n964.68s: provide some context to the performance\n966.519s: of the neural\n968.56s: networks um okay and then uh we trained\n972.0s: those models multiple times using\n974.079s: different hyper parameters and also\n975.88s: using the same hyper\n977.6s: parameters um to see the effect of the\n980.44s: randomness in model\n982.279s: training um but uh that's not really\n986.199s: what I wanted to talk about so um let's\n988.72s: look look at the results first of all\n990.959s: how important is it to uh introduce\n993.8s: those density based weights this is a\n996.56s: quite uh complex plot I realized but I\n999.079s: will break it down for you so what we\n1001.319s: see here on the x-axis is the root mean\n1004.6s: square error uh evaluated only at places\n1008.319s: where the observation exceeds the 99\n1010.959s: percentile so basically it's the root me\n1013.12s: square error armaz of extreme\n1016.6s: observations then we have multiple\n1019.24s: locations those nine selected locations\n1021.92s: um that I mentioned here on the x-axis\n1024.64s: and we also have multiple colored\n1027.24s: circles every Circle for every location\n1030.319s: is a single lsdm model that was trained\n1034.52s: uh with different hyper\n1036.559s: parameters and depending on their color\n1038.839s: they have a different uh Alpha hyper\n1041.28s: parameter so a different degree of\n1043.52s: density based weighting either no\n1045.439s: density based weighting uh or um dens\n1048.919s: cbas waiting with a different\n1051.52s: degree so oh yeah and then a final thing\n1055.28s: those black bars uh they indicate the\n1057.919s: relative root mean Square errors so this\n1059.919s: was the absolute root mean Square errors\n1061.64s: in meter um but the 99 percentile so the\n1065.36s: extreme sea level at each location also\n1068.08s: varies um depending on the nature of the\n1071.679s: location uh so for instance for uh the\n1075.0s: Danish Coast espur the 99 percenti is\n1078.32s: fairly High high for other locations the\n1080.679s: 99 percenti is quite low so by comparing\n1083.96s: the root mean square error absolute to\n1086.72s: those color bars you can get a sense for\n1089.6s: uh the the relative error uh at every\n1093.12s: location okay so what is the effect of\n1096.159s: those hyperparameters here um basically\n1099.4s: we see that the higher the alpha value\n1102.44s: so the U more we wait extra for extreme\n1106.32s: events the lower the root means Square\n1109.32s: becomes uh which is I guess somehow\n1112.159s: expected because we uh punish the model\n1114.44s: more for being wrong at the\n1117.36s: extremes um for most locations the\n1120.32s: relative error is between 20 and 30% uh\n1124.28s: when we use an alpha value of five uh\n1126.679s: there's one location at the UK Coast\n1129.64s: where we're not so happy with yet uh and\n1132.24s: where the relative error is quite\n1134.559s: large um so this um indicates that the\n1139.0s: based waiting for the lstms is important\n1142.159s: to reduce the root mean square error but\n1144.64s: this is only for observations that are\n1146.919s: extreme it's also relevant that the\n1149.679s: model predicts the extremes at the right\n1151.72s: times uh so for that we uh introduced an\n1155.36s: another metric which is the F1 score uh\n1158.919s: that depends on uh whether the\n1161.159s: predictions uh predict extremes at the\n1163.48s: right time steps or not so basically on\n1166.159s: false negatives true negatives true\n1168.08s: positives false positives and gives an\n1170.36s: harmonic mean uh of those scores so uh\n1173.64s: it doesn't really matter if you uh don't\n1175.799s: completely follow this but just remember\n1177.679s: that the higher the F1 score the better\n1180.039s: the neural networks are at predicting\n1182.6s: the extremes at the right\n1184.919s: time so I have a similar plot as before\n1187.96s: but now for the F1 score um and there\n1191.72s: you also see quite some variation in the\n1193.84s: score per location um but the behavior\n1198.28s: depends on the density base waiting is a\n1200.48s: bit different than for the root mean\n1201.88s: square error which is interesting so by\n1205.0s: introducing uh density base waiting so\n1207.6s: from going from zero to one usually for\n1210.6s: most locations the F1 score slightly\n1212.6s: improves but then if you turn up the\n1215.039s: density base waiting even more you see\n1217.32s: that the performance in some cases also\n1219.44s: starts to drop so that is caused by uh\n1223.08s: the model um catching more true\n1226.559s: positives so predicting more extremes\n1229.24s: but also predicting more extremes at\n1231.159s: times when it shouldn't so uh the number\n1233.6s: of false positive positives also\n1236.12s: increases and the model becomes less\n1238.0s: precise\n1239.559s: so um yeah and there are three locations\n1243.039s: where you have one scores and that great\n1244.44s: in\n1246.039s: general so that means that by\n1248.64s: introducing density based waiting we can\n1251.12s: uh increase the performance but the\n1253.32s: alpha value that you need to use depends\n1255.96s: on the location and also on uh the\n1258.919s: metric that you want to\n1260.6s: optimize um so it needs to be\n1263.799s: tuned and while it increases the\n1266.28s: performance uh at predicting extremes um\n1269.88s: it worsens the performance at predicting\n1271.88s: the moderate events which I guess is\n1273.52s: expected but I'm saying that here anyway\n1276.36s: because it's important to realize that\n1278.4s: it's a trade-off between predicting\n1280.6s: extremes or predicting moderate events\n1282.44s: and it's hard to do both at the same\n1284.4s: time uh very\n1286.159s: well is this clear so far\n1290.52s: y\n1291.96s: perfect okay um yeah I also said that I\n1295.679s: was going to compare the ldm models to\n1298.24s: other neural network architectures and\n1300.84s: other models so let's make this plot a\n1304.32s: bit less complicated by taking the best\n1307.039s: performing models uh which I selected\n1309.84s: based on their joint performance of both\n1312.72s: metrics so that cleans up the plot\n1315.32s: nicely um and then I will Al also now\n1319.64s: show you the performance of the\n1321.279s: convolutional lsdm models um which are\n1325.88s: depicted uh by the red squares here I\n1328.48s: only tested this model for a\n1330.08s: hyperparameter of uh Alpha of five so\n1333.24s: the most high density based\n1335.679s: waiting um but still you can see that\n1339.159s: the convolutional neural network in\n1341.039s: general uh performs better than the lsdm\n1344.64s: models namely the red squares here are\n1347.32s: often below the the red\n1349.559s: circles and the same goes for the F1\n1352.36s: score so apparently by uh using a\n1355.44s: convolutional layer and by trying to\n1357.44s: capture those spatial temporal patterns\n1359.679s: you can get the models to uh perform\n1363.84s: better which is what I State here um and\n1368.6s: um now we still don't really know how\n1370.84s: good this is so it would be interesting\n1372.88s: to compare it to the hydrodynamic model\n1374.76s: as\n1376.2s: well so here you see\n1379.12s: uh the performance of the linear\n1380.96s: regression model uh that's the white\n1383.08s: diamonds uh in the color bars and we\n1386.679s: also have the hydrodynamic model uh\n1389.4s: abbreviated as gtsm which are the white\n1392.88s: diamonds um and then when you look at\n1395.08s: this plot you can see that the white\n1397.6s: triangles are often um performing as\n1401.44s: good as the worst performing neural\n1403.2s: network or even worse uh that goes for\n1406.679s: both the root means square error and for\n1408.6s: the F1 score so the timing of predicting\n1410.64s: the extremes um while the hydrodynamic\n1414.4s: model is often at the upper end of the\n1416.36s: performance so it has a lower error or a\n1419.2s: higher F1 score so neural networks are\n1423.2s: uh somewhere in\n1424.48s: between um however if you look at the\n1427.96s: convolutional neural network you see\n1429.799s: that in some cases at some locations the\n1432.48s: performance actually get gets pretty\n1434.36s: close to uh the hydrodynamic model which\n1437.08s: is encouraging uh especially because we\n1439.88s: trained the neural networks with three\n1441.679s: hourly frequency but those hydron damic\n1444.24s: model simulations were forced with an\n1445.919s: hourly atmospheric frequency um so in\n1449.08s: that sense the hydrodynamic model\n1450.919s: already has a bit of an advantage so the\n1452.76s: fact that we are getting that close is\n1455.32s: um quite\n1457.76s: encouraging um so basically based on\n1461.08s: this plot we conclude that things look\n1463.64s: okay at uh seven locations uh in terms\n1467.08s: of the relative performance of the Nal\n1469.0s: networks to the hydr dnamic\n1471.52s: model however um this was just based on\n1475.44s: a validation split that we used to\n1477.399s: evaluate different\n1478.96s: hyperparameters if we start looking at\n1481.039s: how well the models generalized to uh\n1483.96s: the test split uh so the data that was\n1486.44s: withheld from training and EV evaluation\n1488.919s: until this point um we see some\n1491.679s: interesting features as well so this\n1494.48s: figure shows the root mean square error\n1497.559s: um relative\n1499.159s: in a validation split against the test\n1501.36s: split and uh the different colors are\n1504.559s: different locations so what you can see\n1507.76s: from this figure is that the\n1509.44s: generalization is pretty okay for most\n1512.52s: locations uh but this location really\n1515.039s: stands out as a location in the\n1517.6s: Mediterranean Sea um and we don't know\n1521.84s: yet exactly what causes this Behavior\n1524.88s: but it may be that in the Mediterranean\n1526.799s: Sea the storm surges are are not that\n1529.399s: large to begin with so there are other\n1531.52s: factors for instance due to\n1533.64s: precipitation uh Riv discharge maybe\n1536.0s: also density driven uh bar Clinic\n1538.679s: changes in the ocean uh that may cause\n1541.799s: uh sea level to be Extreme as well and\n1545.12s: um maybe those events are not evenly\n1548.76s: distributed uh over the different uh\n1551.08s: splits which aren't that long to begin\n1554.12s: with um if we look at the generalization\n1557.679s: in terms of the F1 score um we also see\n1561.159s: this to some extent uh so here um the\n1565.2s: performances are a bit more scattered\n1566.72s: but generally fall also onto this uh one\n1569.08s: one\n1572.279s: line okay so that means that we are left\n1575.08s: with six locations because at uh the\n1577.52s: location in the Mediterranean Sea Aliant\n1579.72s: in Spain the generalization is not that\n1583.48s: good so um in the next slide I will zoom\n1586.72s: in a bit on the predictions in the test\n1588.88s: split for the remaining six locations um\n1592.6s: considering only uh the lstm and the\n1595.679s: convolutional lsdm model with the\n1597.72s: highest density based\n1600.159s: waiting so that's what you see here\n1602.76s: these are Scatter Plots of observed\n1605.919s: Storm surges higher than the 99\n1608.88s: percentile uh versus the predicted Storm\n1611.919s: surges either by the neural networks or\n1614.679s: by uh the hydrodynamic model so that's\n1617.08s: in Gray uh the orange one is the\n1619.399s: convolutional neural network and the\n1621.52s: other one the one with the lstm\n1624.36s: layer this diagonal line here is the one\n1627.32s: one line so the closer the circles are\n1629.36s: to that the better the model uh\n1632.88s: performs so um we use this plot to kind\n1637.24s: of dig into the behavior of the\n1640.12s: predictions really at the upper end of\n1642.36s: the till of the storm surges so um on\n1645.88s: the right of this um vertical line\n1648.72s: are observations that exceed the 99.9\n1651.679s: percentile so so far we were evaluating\n1654.48s: exceedences of the 99 percenti so what\n1656.88s: happens for uh even higher\n1659.48s: extremes what you can see is that uh\n1662.36s: often the hydrodynamic model is\n1665.12s: overestimating the observed extremes uh\n1668.039s: exceeding the 99.9 percenti whereas the\n1671.08s: neural networks especially the lstm\n1673.159s: model is almost always underestimating\n1676.6s: it um this is kind of alleviated by\n1680.039s: using uh a convolutional neural network\n1683.279s: but still the underestimation is uh\n1685.64s: quite\n1687.24s: visible this also has an influence on\n1689.399s: the root mean square error so uh we used\n1692.36s: in the previous figures I used the 99\n1694.6s: percentile to evaluate the root mean\n1696.64s: square error and then you saw that um\n1699.96s: the convolutional model had a comparable\n1702.08s: error to gtsm the hydrodynamic model but\n1705.279s: if you use the\n1706.919s: 99.9% which makes things very sensitive\n1709.6s: that's of course true uh but then you\n1712.08s: see that um the neural networks compare\n1715.159s: worse compared to the hydrodynamic model\n1717.279s: so apparently the further you go into\n1719.6s: the the upper taals of the distribution\n1722.0s: uh the more the neural networks start to\n1723.64s: drop off possibly because there are just\n1726.44s: not that many uh of such high Extremes\n1729.399s: in the training\n1731.399s: data um yeah and this figure kind of\n1734.24s: confirms what I just said so these are\n1736.039s: box plots um of the error distributions\n1739.32s: uh for the different neural networks and\n1740.76s: hydrodynamic models this is the relative\n1743.2s: error for the 99 percentile and for\n1746.36s: exceedences of the 99.9 percentile and\n1749.12s: then you see really for those really the\n1750.88s: most high exceedances the neural\n1753.12s: networks often underestimate uh the\n1755.64s: observations whereas the hydrodynamic\n1757.679s: model can also overestimate\n1761.08s: them okay so um first of all to answer\n1764.96s: the research questions and summarize it\n1767.039s: a bit for you\n1768.799s: um the effect of introducing density\n1771.2s: based weighting uh is positive uh in\n1774.24s: terms of both the root mean square error\n1776.48s: and the timing of predicting the\n1778.76s: extremes um however the alpha value the\n1782.76s: hyperparameter that controls the extent\n1784.64s: to which we extra weight those extremes\n1787.72s: uh needs to be tuned depending on\n1790.279s: location we see added value for uh\n1793.48s: exploiting the spatial temporal features\n1795.279s: in the data by using a convolutional\n1797.12s: lstm layer instead of an LCM layer and\n1800.279s: this is is an interesting result because\n1803.12s: previous Studies have claimed that a\n1804.799s: convolutional LCM layer doesn't really\n1806.799s: improve things um however they used\n1809.44s: atmospheric um data in only one and a\n1812.559s: half by one and a half degree box around\n1814.519s: each tight gauge and perhaps that means\n1817.679s: that to really exploit the spal temporal\n1819.679s: features you need data uh over a larger\n1822.6s: uh\n1824.0s: region finally um how well do the neural\n1827.039s: networks compared to the other models um\n1829.559s: it was clear that they outperformed the\n1831.12s: multilinear regression model which was\n1833.64s: also used in previous studies so that's\n1836.32s: good to know um especially the\n1839.279s: convolutional ldi models approximate the\n1842.159s: performance of the hydrodynamic models\n1843.799s: which is encouraging uh for application\n1846.44s: to um climate model simulations which I\n1849.0s: will talk a bit more about in the next\n1851.519s: slides however we still see an\n1853.799s: underestimation of those highest\n1855.88s: extremes and uh in the after this I\n1858.72s: would be happy to take any suggestions\n1860.48s: for how to resolve\n1863.32s: that so um based on this we have several\n1867.44s: ideas for um follow-up work next steps\n1871.84s: um first of all try to see if there if\n1875.24s: we could use other predictors besides\n1877.76s: just wind speed and uh sea level\n1879.679s: pressure uh so as I mentioned this\n1881.72s: location in a Mediterranean Sea there\n1883.36s: are all other processes that might might\n1885.639s: be relatively important for instance\n1887.399s: related to precipitation and temperature\n1890.0s: uh perhaps we could improve the\n1891.6s: performance of the neural networks by\n1893.08s: including those uh some Studies have\n1895.36s: shown that waves as a predictor are\n1897.72s: important but this uh introduces another\n1900.76s: limitation because waves are not\n1902.36s: available from Global Climate model\n1904.0s: simulations so that would kind of um\n1907.279s: bypass the the\n1909.399s: purpose uh of course there's probably a\n1911.559s: lot of room for trying different\n1913.48s: architectures again if you have ideas\n1915.72s: then um please let me know we didn't do\n1919.0s: that much hyperparameter tuning so I\n1920.679s: would expect this to improve the\n1922.039s: performance a bit more and something\n1924.48s: that I've thought about also is to try\n1926.44s: to uh test um strategies like synthetic\n1930.08s: minority oversampling in addition to uh\n1933.039s: the density based weights that we\n1934.6s: introduced however I'm not entirely\n1936.76s: clear uh yet how best to do that while\n1940.32s: also respecting the spatial temporal\n1942.279s: patterns in the input data so any help\n1944.12s: with that would be\n1946.48s: nice okay so given that the performance\n1950.559s: of especially the convolutional neural\n1952.44s: networks looks uh quite okay um will be\n1956.96s: interesting to explore trying to apply\n1958.919s: them to climate model simulations uh so\n1961.679s: there's a model inter comparison project\n1963.96s: as part of cmip 6 called highres MIP\n1966.72s: which includes high resolution uh Global\n1969.72s: Climate models with simulations until uh\n1974.24s: 2050 so we would be quite nice to apply\n1977.12s: the neural network to that come up with\n1979.48s: changes in storm surges and then there\n1981.919s: is also a benchmark data set uh to\n1984.72s: evaluate those changes um namely the\n1988.08s: same um model that I referred to earlier\n1991.88s: was used uh also forth with those High\n1994.76s: resip climate model simulations to uh\n1997.44s: compute changes in storm surges so by\n2000.159s: comparing the two against each other we\n2001.72s: could learn a bit more about those uh\n2004.159s: obstacles uh that I talked about before\n2006.799s: and see how well uh the neural networks\n2008.919s: can be used in this\n2010.799s: context um however I can't show you\n2014.2s: results yet because there are some\n2016.159s: issues here um one of them has to do\n2019.639s: with the fact that the temporal\n2021.399s: resolution of the hris MIP\n2023.88s: simulations varies some of them have a\n2026.32s: three-hourly frequency others have a six\n2028.84s: hourly frequency and to use the sixh\n2031.88s: hourly frequency I would have to retrain\n2034.48s: uh the models also on sixh hourly\n2036.519s: observational data that will probably\n2038.48s: decrease the\n2039.679s: performance uh secondly um the study\n2044.44s: that produced those simulations with the\n2045.919s: hydrodynamic models also introduced sea\n2048.359s: level rise as a forcing uh they did so\n2051.2s: by lowering the Petry of the models\n2053.44s: increasing the water depth with the\n2055.32s: projected sea level rise uh and that uh\n2058.28s: increased water depth has an effect on\n2060.0s: the Storm surges that follow extreme uh\n2062.679s: pressures and wind uh however uh I don't\n2066.159s: really see a way yet to introduce used\n2067.96s: this in training the neural networks\n2070.159s: because the sale of Rise observed so far\n2072.639s: uh has not been as large as what is\n2074.44s: projected in the\n2076.399s: future so one thing I would add to those\n2079.839s: recommendations is that we need climate\n2081.679s: model outputs at higher resolutions uh\n2084.44s: temporally so these should be available\n2086.839s: because they have uh the models are run\n2089.48s: at a much uh higher temporal resolution\n2092.52s: than uh the one that the data are\n2094.44s: provided at however they are simply not\n2096.679s: available from the data basis um well\n2099.839s: actually you can do very interesting\n2101.4s: research with them so that would be a\n2103.44s: recommendation uh from my side for the\n2106.119s: future couple model interc comparison\n2109.68s: projects and um with that I'm done and\n2113.44s: happy to uh answer any questions or hear\n2115.72s: suggestions thank\n2120.839s: you great thank you Tim does anyone have\n2124.119s: any questions in the room and if you\n2126.4s: have questions online please either use\n2129.32s: the raise hand function or PLP a\n2131.68s: question into the\n2134.92s: chat anyone in the\n2143.2s: room um do you think this has sort of\n2145.44s: implications also more on a a um\n2148.16s: operational uh basis on sort of like\n2150.319s: predicting extreme events sort of on a\n2152.4s: short Horizon to to sort of uh avoid\n2155.079s: that rather than sort of long-term risk\n2157.119s: projections\n2158.64s: yeah I think there are definitely\n2160.359s: parallels and I have the feeling that um\n2163.72s: people are way further with that than\n2166.119s: with the kind of things that we're\n2168.04s: trying to do at the moment so perhaps\n2170.24s: there are lessons to be learned there\n2172.48s: I'm not aware if they also use these\n2174.599s: schemes to weigh extremes more uh\n2177.599s: perhaps because it's also in their\n2179.76s: interest to forecast the more moderate\n2183.04s: events uh so I don't really know how how\n2186.2s: that works in that context actually\n2195.16s: any more questions in the\n2203.96s: room I have a question regarding how\n2206.8s: your data is relative to the ipcc um\n2211.359s: mitigation so um assuming that you're\n2214.56s: following an a mitigation curve how does\n2217.68s: this data relate to um those those\n2220.64s: Pathways you for example you in the\n2222.72s: beginning you said that every hundred\n2224.88s: years there would be this example of uh\n2227.28s: extreme storm surge and then that\n2229.68s: translates to once every year then now\n2232.64s: what what frame of reference is that\n2234.44s: related to in terms of mitigation\n2235.96s: according to the\n2237.48s: ipcc right um yeah I guess that's um to\n2243.079s: say something about that you would first\n2245.16s: want to calculate the Seal of\n2248.839s: uh under a uh mitigation emission\n2252.76s: scenario um that's possible of course\n2255.16s: there's this uh sea level Legacy or\n2258.319s: committed SE level rise that has already\n2260.359s: been built up by emissions that uh have\n2263.64s: been by um how you say that by what has\n2267.28s: been emitted before um so that would be\n2270.68s: one you could calculate this the\n2272.72s: difference in sealup R between uh buildt\n2275.359s: off scenarios or or maybe SSP 3.70 or\n2279.359s: something um and more related to what\n2282.319s: I'm trying to do here is you could\n2287.24s: um get atmospheric changes from Global\n2290.16s: Climate models run uh under overshoot\n2292.4s: scenarios or something like that and try\n2294.68s: to apply the neural networks to that see\n2296.88s: what uh changes in storm seches that\n2298.8s: would result to uh in comparison to uh\n2302.04s: the more regular emission scenarios that\n2305.04s: uh in which there is no mitigation and\n2306.92s: then say so something about uh the\n2308.76s: difference in the changes if that makes\n2314.48s: sense and we do have a question online\n2317.079s: from gong wo can you speak a bit more\n2320.48s: about the gtsm in terms of what\n2323.119s: atmospheric inputs they take and is it\n2325.52s: of similar spatial SLT temporal\n2327.839s: resolution to the neural network inputs\n2330.8s: great question um yeah perhaps forgot to\n2333.319s: explain that um so the data that goes\n2336.24s: into uh gtsm the hydrodynamic model is\n2340.359s: exactly the same data as what we're\n2342.359s: using to train the no networks with in\n2344.88s: the sense that it's the same variable so\n2346.96s: wind speed and sea level pressure from\n2349.319s: the same product era five um the spal\n2353.64s: resolution is also the same but the\n2355.839s: temporal resolution in their case was uh\n2358.64s: higher uh apparently they didn't bother\n2360.839s: running with a three hourly frequency\n2362.76s: when there was also a hourly frequency\n2365.119s: available which I understand but in our\n2367.16s: case it makes sense to do that if the\n2369.04s: goal is to eventually uh apply it to the\n2371.92s: global climate model simulations which\n2373.92s: are only available at a corer temporal\n2381.04s: resolution thank you any more\n2385.28s: question thank you team a bright\n2387.4s: presentation uh so my question is about\n2389.88s: the F1 score uh so as far as I know uh\n2393.079s: F1 score is a special case of the F beta\n2396.079s: score um\n2397.92s: that balance balances the Precision\n2400.96s: recall and um in your case what is more\n2404.24s: important uh the prision or the recall H\n2408.0s: because um with um so maximizing the\n2410.839s: recall means that uh you um reduces the\n2415.04s: number of false negatives okay so what\n2418.119s: is in your case and according to the\n2420.8s: application uh better so than yeah\n2424.52s: that's that's a good question that I'm\n2425.96s: actually also still bit undecided on so\n2429.0s: in a forecasting context I think that uh\n2433.92s: this is a different choice because you\n2436.04s: want to predict the extremes uh and you\n2438.839s: want to have true positives more than\n2441.04s: you care about reducing the number of\n2443.04s: false\n2444.24s: positives uh in this case it's maybe a\n2447.96s: bit different because um in a context of\n2451.839s: applying the extreme C CA level uh\n2455.52s: analysis you would then start with the\n2458.599s: predictions um calculate the 99 percenti\n2461.76s: of the predictions and use the\n2463.56s: exceedances of that 99 percentile that\n2466.4s: are predicted but those Mo could be\n2469.76s: falsely\n2471.359s: extreme um so in that sense uh it would\n2474.72s: be good to reduce the false negatives\n2476.96s: but if that comes at the cost of um\n2479.8s: simulating fewer true positives that\n2482.119s: would also be bad for the extreme sea\n2483.72s: level uh analysis so I I don't know\n2487.76s: so it's it's it's not a direct\n2490.72s: reflection of what is important for the\n2492.52s: extreme sea level analysis I think\n2499.04s: yeah any more\n2506.319s: questions um nice talk so I was\n2510.319s: wondering um if you could comment a bit\n2512.44s: on um maybe the the the nature of the\n2516.24s: invariant Coastal configurations I that\n2519.72s: depends on the site you know you have\n2521.16s: some really bendy coasts you have like\n2522.52s: islands and barriers and things and\n2524.68s: presumably that um would would impact\n2528.319s: local relationships and does that need\n2531.52s: to be taken into\n2532.96s: account yeah so that's that's a an\n2536.2s: interesting idea thanks\n2538.52s: um right now we are training the models\n2541.4s: individually individually difficult word\n2544.359s: for every location so I guess in some\n2547.24s: sense the influence of the coastal\n2549.52s: setting is taken into account by doing\n2553.0s: it in that way but I can imagine that\n2555.16s: the coastal configuration also changes\n2557.16s: over time because of sea level rise or\n2559.839s: erosion um maybe also because of\n2562.48s: channels that people make that uh affect\n2564.599s: the\n2565.48s: tithes uh so yeah definitely I mean I\n2568.68s: think for the Dutch\n2570.4s: Coast specifically uh there hasn't been\n2573.44s: that much research into changes in ties\n2576.28s: um and it's also difficult to uh to\n2579.359s: model because it requires thinking into\n2581.0s: account for your local uh uh features um\n2584.8s: I don't have concrete ideas for\n2588.2s: considering those features in the\n2590.319s: training of the neural networks to be\n2592.0s: honest but I think it will be definitely\n2593.96s: interesting uh to consider\n2599.839s: yeah great um any more\n2605.119s: questions if not another round of\n2608.2s: applause for Tim thank you"
    },
    {
        "class": "YouTubeVideo",
        "title": "LEAP: Our Story (short)",
        "videoId": "JjLcZUjnl-w",
        "url": "https://www.youtube.com/watch?v=JjLcZUjnl-w",
        "publishedAt": "2023-04-24T22:10:44Z",
        "transcript": "2.52s: we know for certain the climate is going\n4.74s: to change over the next several decades\n6.24s: and so we need to understand how we're\n8.04s: going to adapt to that\n10.5s: we know that black and brown communities\n12.96s: because of legacies of structural racism\n15.179s: and redlining and whose neighborhoods\n17.82s: have resources are already more\n20.1s: vulnerable to say extreme weather events\n25.5s: if we can have better predictions about\n28.26s: what it's going to look like in the\n29.34s: future that helps us to sort of plan\n31.14s: better today\n32.94s: New York City for instance is making\n34.8s: decisions about their transportation\n36.36s: system right now they're making\n38.16s: decisions about sea walls right now no\n41.46s: one discipline can solve the\n43.92s: complexities of the problems that we're\n45.54s: dealing with\n46.8s: leap is bringing together minds and\n49.379s: capacities that simply haven't sat in\n51.6s: the same room before\n55.199s: I'm a data Sciences Bridging the\n58.14s: expertise of climate science with the\n60.18s: expertise and knowledge of data science\n62.52s: and bringing them together our goal is\n65.04s: to use all the available data out there\n68.04s: from sensors from satellites and to help\n71.28s: better inform our climate models so that\n73.74s: we can make better predictions so we can\n75.78s: help everyone adapt to climate change if\n78.9s: we conduct science and we're not\n80.46s: effective at conveying our findings to\n83.1s: decision makers people and communities\n85.02s: who are going to be Gravely impacted by\n87.479s: the climate crisis and we haven't really\n89.46s: done our job that's really where we see\n92.4s: our role as a publicly available data\n95.579s: provider that we are trying to lower the\n97.68s: barrier so that everyone could get\n99.36s: access to climate data across the globe\n102.0s: that's a big moonshot to improve our\n104.46s: climate projections\n106.439s: but also help inform people in a way\n109.14s: that can also shift human behavior\n114.24s: what we can say is that we're heading in\n115.979s: a Direction\n117.299s: from vulnerability to resilience the\n119.399s: direction from exclusion to inclusion\n122.1s: and leap I think is a Pioneer in this\n124.2s: kind of effort you you'll be able to\n126.119s: look confidently in 10 years and say\n127.74s: we're on a path now that's fundamentally\n130.5s: different than the past we were on\n132.36s: before\n135.78s: foreign"
    },
    {
        "class": "YouTubeVideo",
        "title": "Improving Subgrid Parameterization with Causal Discovery by Amanda Sun",
        "videoId": "C9iP4VRssRU",
        "url": "https://www.youtube.com/watch?v=C9iP4VRssRU",
        "publishedAt": "2023-08-02T18:18:07Z",
        "transcript": "7.56s: is this okay\n10.32s: okay\n12.54s: so my name is Amanda and I'll be talking\n14.519s: about how we can employ causal Discovery\n17.039s: to improve subgrid parameterization in\n20.46s: our climate models\n25.32s: so for some background I'll just talk a\n27.119s: bit about what a causal graph is and\n29.939s: then talk about how it relates to\n31.8s: subgrid parameterization for a causal\n34.559s: graph essentially what I want to do and\n37.38s: what you can do with observational data\n40.26s: is you can take each variable put it\n42.54s: into a node and then create\n45.36s: um like errors between the nodes to\n47.399s: basically explain and explore how\n51.3s: different variables can causally relate\n53.28s: to one another and to give you an\n55.68s: example let's say you want to measure\n58.26s: the effect of smoking on lung cancer\n60.36s: rates but you might have like a what we\n63.719s: call confounder so another variable like\n66.06s: alcohol consumption\n67.92s: um alcohol is a carcinogen and\n70.799s: um it might affect how many people get\n72.96s: lung cancer if they consume more alcohol\n74.939s: but people who consume more alcohol\n76.619s: might also smoke more so it's hard to\n79.38s: actually measure in an observational\n80.939s: data set whether smoking actually\n83.22s: contributes to lung cancer rates if we\n85.14s: have have some sort of\n87.08s: confounder like X and um yeah so that's\n90.78s: the top right graph and then for the\n92.7s: bottom of my graph so what you want\n94.5s: ideally is um the I the C implies Y and\n98.759s: then T implies y so there is nothing\n100.979s: between C and T you can replace C and T\n103.92s: with like X and Y so there's no Arrow\n106.14s: between\n107.04s: those two nodes but in observational\n109.86s: studies we often do have that confounder\n111.84s: and\n113.579s: um I want to revisit Rebecca's slide\n116.34s: and explaining why this is helpful for\n119.22s: um\n120.72s: oh it's okay it's not in there but I do\n124.14s: want to reference that Rebecca mentioned\n126.36s: how\n127.32s: um currently our client models have like\n129.06s: grid cells right but then there's\n130.8s: sometimes an embedded subgrid\n132.9s: parameterization because we don't have\n134.819s: all the variables that we want and we're\n137.28s: going to be like kind of estimating them\n139.099s: hypothesizing about them and we're using\n141.42s: machine learning right now for that but\n143.28s: machine learning isn't always the best\n145.379s: option there's a lot of overfitting to\n147.9s: the data set and especially given that\n150.18s: climate change is impacting\n152.459s: um like how hot and cold and extreme\n154.68s: weather temperature and climate\n156.42s: temperature can be\n157.86s: um it's important that we have machine\n160.08s: learning models that are a lot more\n161.22s: robust and that rely on actual causality\n163.5s: rather than correlation\n165.48s: so um that's the point of my research\n169.14s: and\n170.519s: um yeah so here's the methodology for\n174.18s: um how I go about discovering the causal\n176.459s: graph from observational data\n178.62s: um I've seen a couple of things I assume\n180.84s: that um the data is stationary so any\n183.78s: like variance mean stays constant over\n186.78s: time I assume causal sufficiency so I\n190.08s: list most of the confounders\n192.0s: um in the causal graph and that there's\n194.28s: no instantaneous effects so there's\n195.72s: always a lag time of one day in between\n198.0s: each variable\n199.26s: and um the pcmci algorithm that I use to\n202.86s: basically take the observational data\n204.659s: and create a graph out of it is called\n206.519s: the pcmci it's composed of two parts so\n208.98s: the PC one and what the PC one does is\n212.04s: it first creates a skeleton graph as you\n213.959s: can see on the left and then um it\n216.72s: identifies immoralities so immoralities\n218.819s: are what a b and c would be right here\n221.459s: once it has immoralities discovered in\n223.98s: the graph then um it uses these\n226.14s: assumptions I referenced to create a\n228.239s: true graph\n229.319s: and then once you have that graph the\n231.299s: NCI part of the algorithm will\n233.099s: distinguish between the indirect and\n234.72s: direct causal links by using partial\n236.64s: correlation and significance level\n238.56s: testing\n241.86s: and this is just an example of what the\n244.14s: output would be you don't have to read\n245.459s: it all but you just input some\n247.5s: parameters and also values you want and\n249.659s: then you get out basically a list of\n251.64s: variables with how many links each\n253.26s: variable has\n255.48s: and then these are the data points um or\n257.519s: yeah the variables that I use\n259.62s: um so the blue ones are my inputs and\n261.359s: then I'm trying to predict brain rate so\n263.4s: that's my output you'll see on the right\n265.44s: that um two of the inputs have levels of\n268.08s: 60 because there's 60 vertical columns\n270.78s: um I'm only going to be taking 10 or\n273.479s: sorry six of each level so I'm doing a\n275.58s: step size of 10 so I would take\n278.34s: um the specific community at level 0 10\n281.22s: 20 30 40 50.\n285.479s: and then as I said before there's I\n287.759s: relied on a lot of assumptions to create\n289.44s: the causal graphs so I want to eliminate\n291.78s: like mean like I guess mean deviations\n295.08s: and seasonality so I normalize the data\n297.9s: and um removes like yeah seasonal Cycles\n303.96s: and these are more specifics about the\n305.88s: climate data processing as I said I use\n307.74s: a one day concept selected six levels\n310.08s: and\n311.58s: um for the selection process of the\n313.139s: causal graphs I retained the directed\n315.3s: links with a p-value of negative\n317.639s: um of less than .05 and then I tested a\n321.12s: range of significance levels in the\n323.46s: pcmci algorithm\n327.18s: and these are my results so I have two\n329.699s: slides and these are just the most\n331.38s: promising causal graphs that came out of\n334.8s: um yeah just came out of the algorithm I\n336.66s: used a talmin and tile Max of also one\n338.639s: so it only shows timelines of one on\n340.56s: here and\n342.72s: um I'll go through maybe what you should\n345.18s: notice in the graph because there's a\n346.979s: lot going on but out cam out precipation\n349.919s: is the rain rate that I'm trying to\n351.18s: predict and then\n353.1s: um you'll see in most of the graphs that\n354.9s: the um pbuf stolen which is\n358.8s: um\n359.759s: the solar insulation often is not\n362.16s: related it's not a parent of rain rate\n365.28s: um while you'll see that the state PS\n367.32s: which is surface pressure is often\n369.12s: related to the brain rate so here's this\n371.759s: examples again\n373.68s: um for those\n375.06s: so as you see yeah PBA you have stolen\n377.16s: is never apparent but CPS often is\n380.52s: um and then the arrows like the color of\n382.68s: the arrows just depends on like how\n384.419s: correlated they are with like closer to\n387.0s: one or negative one being a higher\n388.979s: positive or negative correlation\n390.479s: respectively\n394.919s: okay\n395.94s: some takeaways from those graphs that\n398.4s: you may have noticed like I said is that\n400.5s: surface pressure and surface heat flux\n403.02s: often directly affect precipitation\n404.94s: according to the causal graph and that\n407.52s: the strongest causal links can be found\n409.319s: at certain levels of specific humanity\n411.479s: and air temperature when combined and\n414.3s: then as I mentioned solar installation\n416.52s: never seems to predict precipitation\n419.58s: um and then some next steps from\n421.259s: creating the causal graphs would be to\n423.06s: test it on a neural network\n425.22s: um especially with those combinations of\n426.9s: inputs that identified ideally I think I\n429.6s: would try to test like maybe 60 separate\n431.819s: neural networks since I had around like\n434.34s: 60 separate outputs from my PC and pcmci\n439.68s: um and then I would like to also like\n442.68s: plot the like Alpha values I use for the\n445.979s: pcmci algorithm in comparison to the r\n448.56s: squared of the neural network so I could\n450.36s: see maybe at what what like ideal inputs\n453.3s: are like would be helpful to capture the\n456.419s: missing information in the neural\n458.46s: network\n461.46s: and yeah that's it\n468.84s: again we'll take questions from in the\n470.759s: room but we do have one online that we\n473.28s: can just get started with\n475.08s: um from Rohan fulcarney he asked what\n478.199s: seasonality did you use on the data and\n480.419s: why\n482.639s: um so to answer rohan's question I\n484.979s: didn't use seasonality but I removed it\n486.66s: from the data set so that means that the\n489.36s: data even though there's a Time step of\n491.22s: a day there isn't changes in like any of\n494.819s: these variables by\n497.039s: um whether it's winter or summer the\n499.259s: data stays constant\n504.66s: ly\n508.5s: I have a question about the assumptions\n511.08s: that you mentioned for\n513.06s: um\n513.62s: like sufficiency and things like that\n515.88s: are there ways from a data set to assess\n518.64s: like how the degree to which those\n520.68s: assumptions hold like like know whether\n522.959s: your data set is causally sufficient or\n524.76s: not um and like based on that act\n526.92s: differently or is it kind of just like\n528.42s: an assumption it's not really clear how\n530.7s: you might know that because you don't\n532.08s: know what other variables like exist in\n533.88s: the world\n535.74s: um I think some of the package I used to\n538.62s: get the color graphs is called tigermite\n540.42s: and I think there are some causal\n542.04s: sufficiency like\n544.26s: um like algorithms and functions that\n546.06s: you can use within that to test between\n548.519s: like different data but I would say that\n552.06s: a lot of the reason I picked these data\n554.04s: points was because of like background\n555.66s: research on I didn't mention this in the\n558.06s: presentation but yeah background\n559.14s: research on like which\n561.36s: um data points I absolutely Mustang food\n567.899s: hello great job presenting\n571.08s: um I was wondering so you said you\n572.88s: removed seasonality and I remember you\n575.04s: mentioned before but I couldn't remember\n576.3s: what you said um what is still that\n578.16s: oscillation in your standardization like\n580.32s: is that a diurnal cycle is like what is\n583.14s: that then if you don't have seasonality\n585.779s: um if you're off seasonality I think\n586.98s: it's noise I also added some noise to\n588.959s: the data because the research paper that\n591.12s: I based yeah my research is Summer on\n593.82s: um also added I think some noise so I\n596.22s: just wanted to make sure I was\n597.24s: reproducing it as accurately possible\n598.98s: because\n604.92s: yeah I I think based on your um thoughts\n608.399s: the seasonality still existed there\n611.459s: there a little bit but you kind of\n614.519s: was able to remove most of the cyclical\n617.58s: Cinemas\n618.839s: um thank you Amanda\n622.5s: foreign"
    },
    {
        "class": "YouTubeVideo",
        "title": "LEAP / CarbonPlan Demo (April 2023)",
        "videoId": "OPFbZAsdKz0",
        "url": "https://www.youtube.com/watch?v=OPFbZAsdKz0",
        "publishedAt": "2023-04-26T22:06:31Z",
        "transcript": "0.299s: hey I'm Kato Martin and I'm the products\n3.12s: leader carbon plan carbon plan is a\n5.46s: non-profit research organization that\n7.08s: aims to improve the transparency and\n9.3s: scientific Integrity of climate\n10.98s: Solutions through open data and tools\n13.62s: we're partnering with leap to build web\n15.24s: visualization tools to promote access\n17.22s: and exploration of climate data we're\n19.859s: hoping that these tools will be useful\n21.18s: both to the leap research Community as\n23.1s: well as a broader audience of users that\n24.9s: will consume and make decisions from\n26.58s: these data\n29.34s: first we're building a data catalog to\n31.439s: promote the easy discovery of data sets\n33.3s: being used and produced at leap this is\n35.64s: an early demo of that catalog you can\n37.8s: see a data set that was recently added\n39.54s: it's a sea surface temperature data set\n41.52s: and was added by researchers at leap\n44.879s: we also have some example data sets that\n47.1s: we created for the purposes of this demo\n49.32s: show off its data catalog and also a map\n52.079s: visualization tool which I'll show you\n53.94s: now\n57.78s: we're building this map visualization\n59.52s: tool to make it easy to explore any\n61.68s: publicly hosted geospatial data set\n64.44s: we believe that this can help during the\n66.18s: research process while scientists are\n67.799s: understanding and diagnosing their data\n69.84s: sets and it can also be used to share\n71.82s: research outputs with the broader\n73.26s: community and allow users to explore and\n75.479s: interrogate the data\n77.82s: this is a maximum air surface\n79.619s: temperature data set from cmib6 Which\n81.84s: models temperatures through the end of\n83.28s: the century\n85.38s: I can use the tool to pan through time\n87.78s: and look at the maps\n89.7s: and they're as they change\n93.36s: I can also Zoom around\n97.02s: and pan through space\n103.38s: I can also use this display panel on the\n105.6s: left to change the way the map is\n107.4s: rendered\n108.42s: so I can update the projection of the\n110.34s: map\n120.18s: I can change the color map\n129.119s: and I can change the color range\n140.04s: I can also generate time series using\n142.319s: this plots panel also on the left hand\n144.3s: side\n147.18s: but this I can drag around a point and\n149.879s: look at time series over space\n152.94s: foreign\n158.7s: grab a point of Interest\n161.76s: and look at the time series notice the\n164.58s: longitude latitude pair up here\n168.9s: I can also use I can also download the\n171.9s: Cs a CSV of the data underlying This\n174.959s: Time series\n176.879s: this would allow me to I could if I take\n179.099s: this data into\n180.72s: Excel or Google Sheets I can reproduce\n183.48s: the time series or look at the numeric\n185.459s: values underlying this plot\n197.159s: here's another data set that Maps annual\n199.379s: precipitation data also from seamup6 I'm\n202.26s: showing this to underscore that this is\n203.76s: a generic tool that can handle different\n205.56s: data sets so we can make all the cost\n207.599s: same customizations for this data set\n209.459s: that we made for the temperature data\n211.8s: set\n220.98s: and here's a final sample data set that\n223.08s: illustrates how an analysis might\n224.58s: combine multiple variables to derive a\n226.739s: metric more relevant to humans in this\n229.379s: case we're showing an index that\n230.58s: combines temperature and precipitation\n231.959s: both of which we just saw to determine\n234.659s: where agricultural corn growth is viable\n236.819s: and how that will change in the future\n239.4s: to produce this data set we look for\n241.2s: places where the minimum and maximum\n243.0s: daily temperatures are high enough to\n245.04s: support growth with more growth\n246.959s: potential shown in these brighter greens\n249.06s: and yellows\n250.62s: we also check to see to see if there's\n251.76s: enough precipitation meeting a 25 inch\n254.819s: threshold\n256.44s: in order to facilitate growth if that\n258.84s: threshold isn't met those areas get\n260.579s: massed out\n262.44s: it's not a particularly sophisticated\n264.72s: analysis compared to the kind of\n266.28s: research that will be coming from leap\n267.84s: but unlike just temperature\n269.04s: precipitation on their own it's a metric\n271.5s: that has consequences both for an\n273.0s: important business sector as well as\n275.04s: general issues of food availability\n278.94s: we can use the tool to demonstrate some\n280.919s: key trends in the data\n282.54s: namely that corn growth expands\n284.4s: northward towards the end of the century\n293.639s: we can zoom into Northern Canada\n296.1s: and see the areas that were previously\n297.84s: too cold for corn growth when\n300.32s: represented by black pixels\n305.52s: become hospitable towards the end of the\n307.56s: century when they turned green\n309.479s: this is due to\n311.04s: this is when those regions become warmer\n312.84s: due to climate change\n316.68s: we look at we can also look at the time\n318.54s: series to confirm this trend\n323.22s: and we can contextualize the trend by\n325.8s: comparing this to time series further\n327.419s: south\n331.56s: as we move South we don't see this trend\n333.84s: and instead we see growth viability stay\n336.24s: more constant\n338.82s: this is just one of many metrics that we\n340.8s: could Define using the same canonical\n342.419s: inputs we could also derive things like\n344.759s: fire and flooding into season\n350.639s: we were able to use the map\n351.84s: visualization tool to explore some\n353.759s: simple analyzes on the fly but this\n356.1s: ecosystem ecosystem of open data and\n358.5s: tools also facilitates more in-depth\n360.84s: analyzes for example in Python Computing\n363.24s: environments\n364.44s: here we have a jupyter notebook that\n366.479s: performs analyzes over the agricultural\n368.28s: data we just looked at\n370.16s: in this type of environment we have the\n372.36s: full flexibility of analytical and\n374.1s: computational choices to support more\n375.96s: advanced analyzes\n378.06s: here we're generating new maps that\n380.1s: capture the difference in growth\n381.419s: potential from the models beginning in\n383.16s: 2015 to later years in the data set\n387.12s: more positive changes in growth\n388.919s: potential are shown in red and we can\n391.139s: see the same expansion of growth\n392.639s: potential to the North in these Maps as\n394.38s: well\n395.4s: negative growth potential changes are\n397.86s: shown in blue\n399.12s: and this is where it will become harder\n401.16s: to grow corn\n404.4s: this has all been a very quick tour of\n406.5s: different views into the data that we're\n408.06s: working with at leap feel free to reach\n409.919s: out to any of us working on these tools\n411.419s: if you have ideas or want to learn more\n413.34s: thank you"
    },
    {
        "class": "YouTubeVideo",
        "title": "Ignacio Lopez Gomez",
        "videoId": "xFGLrQ-IKDA",
        "url": "https://www.youtube.com/watch?v=xFGLrQ-IKDA",
        "publishedAt": "2024-04-29T22:41:29Z",
        "transcript": "5.52s: let's get started um so thanks to all\n8.599s: for coming in person and join online\n10.519s: again and it's my great pleasure to\n13.16s: introduce our second guest speaker uh\n16.16s: for today's lecture in climate data\n17.96s: science uh ignasio Lopez Gomez uh he's a\n22.08s: research scientist at Google research\n24.8s: his research focuses on the development\n26.92s: of datadriven weather forecasting\n29.16s: systems with the emphasis on Extreme\n31.56s: events and on climate modeling and\n34.36s: Analysis he holds a PhD in environmental\n37.48s: science and engineering from the\n39.52s: California Tech uh Institute of\n41.64s: Technology where he developed models of\n44.68s: atmospheric turbulence convection and\n47.0s: clouds or climate models as well as\n50.0s: methods for parameter estimation from\n51.879s: indirect data today he's going to talk\n54.32s: about the their recent work on generated\n56.8s: weather forecast uh please join me in\n59.12s: welcome ignasio\n63.92s: thank youan and thank you everyone for\n66.119s: having me here uh it's been great so far\n68.08s: to visit Lea and hear about what uh some\n70.119s: of you are are working on um and so as\n73.96s: Jan said uh today I'm going to talk\n75.799s: about some of our latest work uh on uh\n79.36s: weather forecasting and in particular\n80.84s: I'm going to talk about how generative\n83.119s: AI Technologies can be used for uh the\n85.479s: emulation of uh weather forecast\n87.28s: ensembles and uh uh I'll be using\n90.079s: diffusion models for this uh in this\n92.0s: stock and this is work that has been\n93.6s: done together with Lisi Rob Carver uh\n96.6s: fasia and JN Anderson at Google research\n99.24s: and if there's any questions during the\n101.6s: talk just feel free to uh to interrupt\n104.56s: uh and and ask them okay so the topic of\n109.56s: this talk is Ensemble weather\n110.84s: forecasting uh what's Ensemble weather\n112.799s: forecasting this has been the dominant\n115.64s: approach to uh obtaining probabilistic\n118.479s: forecasts of weather over the last 30\n121.0s: years uh and what this method consists\n123.6s: of is uh we are going to start from an\n127.439s: initial state that we know uh from\n129.959s: observations with some level of\n131.879s: uncertainty and we're going to perturb\n134.72s: uh that initial State uh in terms of the\n137.239s: initial condition uncertainty and also\n139.2s: in terms of the structural uncertainty\n140.8s: of our forecast model and we're going to\n143.04s: uh use those uh small scale\n145.319s: perturbations in the uncertainty to\n146.92s: evolve the state of of uh Plus states of\n150.44s: weather given our initial conditions and\n153.319s: so what we end up with in this process\n155.959s: for for a given lead time and so here\n157.879s: I'm showing just an example for a lead\n159.519s: time of a week uh is uh different\n162.0s: possible weather states of of what the\n164.44s: weather could look like a week in\n166.159s: advance uh and and that gives us if the\n169.08s: emble is big enough that gives us an\n170.519s: idea of what the probability of these\n171.92s: events are so so we get we get a sense\n173.879s: of the forecast uncertainty and and what\n175.76s: are the most plausible uh feutures and\n178.44s: so once we have this information uh\n180.239s: these Ensemble uh forecasts then we can\n183.04s: use these products to um for many\n185.36s: Downstream tasks so for instance we can\n188.28s: uh ask uh what's the probability of\n190.599s: temperature exceeding a given threshold\n192.84s: over Europe a week in advance and this\n194.76s: is something that I'm showing here and\n196.799s: the schematic on the right hand side of\n198.879s: the slide um the problem is that\n202.56s: performing Ensemble forecasts is\n205.04s: expensive um and so what I'm showing\n207.799s: here is that uh if we have if we have a\n211.319s: fixed amount of compute which here I'm\n213.28s: drawing by this blue line uh and if we\n216.36s: were able to uh perform a single\n218.84s: forecast with resolution of on the order\n220.519s: of 10 kilometers in the horizontal for\n222.72s: that compute uh we would only be able to\n225.36s: afford uh to run ensembles that run at\n228.08s: significantly quer resolution so let's\n229.92s: say 30 kilometers or so uh and so\n232.76s: there's usually this dilemma um in in in\n235.4s: weather forecasting when we get more\n237.48s: compute available to us as to whether we\n240.079s: should use that compute to increase the\n242.28s: Ensemble size or increase the resolution\n244.879s: so increasing the resolution I'm sure\n247.56s: everyone knows why uh why that helps\n249.76s: because you are resolving more and more\n251.159s: processes so you have these subgrade\n252.76s: scale processes that affect not only the\n254.159s: evolution of weather but also climate in\n256.199s: longer time scales and many of you here\n257.919s: are working on on improving those uh\n260.759s: parameterizations but what does what\n263.759s: does uh increasing The Ensemble size do\n265.84s: for us what what that what does that\n267.28s: bring to the table if we already have an\n268.84s: emble um\n270.52s: so I'm just going to give an emble an\n273.0s: example of of when we would need large\n275.36s: ensembles and why they're useful and\n277.68s: essentially we're going to need large\n279.52s: ensembles whenever we're looking at high\n281.639s: impact uh rare weather events uh which\n283.919s: is something that uh that is very\n285.8s: important uh for for early warning\n287.72s: systems and so an example uh that I'm\n290.56s: giving here that is kind of related also\n292.919s: to to what we heard from from Chad uh in\n295.36s: the previous talk is uh imagine a\n297.96s: situation where there might be a\n299.84s: flooding event in New York City uh and\n302.8s: let's say that uh uh me as a user I'm\n306.32s: going to if if there was that flash\n308.08s: flooding event I would incur some losses\n309.96s: some economic losses which maybe that\n312.16s: everything that I have in my basement is\n314.28s: going to uh is going to have to get\n316.479s: thrown out uh and I'm going to have to\n318.639s: repurchase all that stuff um and then I\n322.08s: can also associate uh a given cost to\n325.0s: taking a preventive action so in this\n326.72s: case it would be maybe uh buying\n329.0s: sandbags and placing those sandbags uh\n331.639s: somewhere so that I prevent those\n333.639s: economic losses that I talked about\n336.16s: before um usually in cases where we have\n339.12s: high impact events uh the ratio between\n342.52s: the cost of taking preventive action and\n344.639s: the economic losses if we weren't take\n346.88s: if we weren't going to take preventive\n348.52s: action is is very low um and so\n352.479s: statistically it makes sense to always\n354.96s: follow preventive action if actually the\n357.039s: fraud probability is going to be higher\n359.759s: this ratio because otherwise it would\n361.6s: just be more economically viable to take\n363.72s: the losses every time this happens um\n367.36s: but the interesting thing is what\n368.919s: happens when uh when the probability is\n370.96s: kind of on the same order of magnitude\n372.56s: as this ratio so when it's actually like\n374.68s: it it's not clear whether we should\n376.52s: always take preventive action or never\n378.24s: take preventive action but we actually\n379.639s: need a forecasting system for this uh\n382.52s: and it turns out that uh if these events\n385.08s: are rare that is if the probability of\n386.88s: the order of C of the of the cost over\n389.24s: the loss\n390.12s: which as I said before is small uh then\n393.319s: we actually need systems that have a\n395.039s: probabalistic resolution comparable to\n396.759s: this ratio for their forecast to be\n398.479s: useful otherwise we cannot really\n400.16s: extract uh meaningful statistics from\n402.4s: them so if we have an ensemble uh let's\n404.759s: say of uh five or 10 members and there's\n406.96s: a probability of AR event happening of\n408.68s: 0.1% we're not going to be able to to\n411.56s: extract that likelihood uh accurately\n414.0s: from from from our emble um and so this\n417.4s: this example that I gave here on the on\n418.879s: the left hand side is is is uh more\n421.039s: quantitatively articulated uh in the in\n423.199s: the figure on the right uh which comes\n424.72s: from an article from Team Palmer in 2002\n427.759s: where he's essentially looking at the\n429.919s: added the relative added economic value\n432.52s: of two forecast systems um and the one\n436.199s: has it's basically the same system so\n438.479s: the the state of the ifs uh I guess in\n440.879s: 2002 and he's comparing the uh the added\n444.08s: value of a system with 50 Ensemble\n447.12s: members to the added value of a system\n449.12s: with 100 Ensemble members and so we can\n451.44s: see is that uh once we increase the uh\n454.759s: the number of Ensemble members the users\n456.639s: that are going to get uh the most value\n458.639s: out of it are are the user that have a\n460.4s: very low cost to loss ratio so this this\n462.96s: essentially this regime is the one where\n465.599s: uh that we would characterize as high\n467.36s: impact rare events uh for reasons before\n469.52s: so that's one reason why we need large\n471.56s: ensembles in uh in weather forecasts um\n476.199s: since many people here are also\n477.759s: interested in in working in in in\n479.68s: climate projections uh I also wanted to\n481.879s: emphasize that this is also important in\n483.759s: in climate models and even more so so\n486.199s: apart from the fact that larg and sampol\n488.159s: are going to allow us to uh to sample\n491.0s: extremes better uh in in terms of the\n494.24s: analysis of climate change uh we may ask\n496.68s: questions about whether a certain event\n499.199s: was more likely due to climate change or\n501.12s: whether Something That We're observing\n503.08s: is actually cause of a forced\n505.24s: anthropogenic response and in order to\n507.36s: do all this analysis we basically have\n508.879s: to Marginal over the internal\n511.12s: variability of the climate projection\n513.08s: and for this uh we also need large embl\n515.919s: and so here I'm showing another example\n518.399s: uh from from a paper milinski all 2020\n521.399s: where they looked at what was the\n522.88s: required Ensemble size to reduce the\n524.76s: error in the force signal for uh surface\n528.279s: temperature over over basically every\n530.279s: location on Earth and for uh\n532.399s: precipitation over the historical period\n535.16s: and they find that if if you want if we\n537.04s: want to reduce that error to about a\n539.519s: tenth of a degree uh in in in surface\n543.32s: temperature or a tenth of millimeters\n544.959s: per day in precipitation then there's\n546.6s: many regions in the world we actually\n548.0s: need uh more than 100 members uh so this\n550.76s: is another reason why we might need uh\n553.24s: large ensembles so what do we do about\n555.8s: uh about their expense how can we uh\n557.92s: reduce that um so our proposal here is\n562.32s: that we can leverage generative AI uh to\n565.36s: drastically reduce the cost of of\n566.959s: generating these ensembles uh through\n569.72s: essentially emulation techniques um and\n572.72s: in particular the method I'm going to be\n574.6s: talking about uh today is a generative\n577.8s: emulator that uh enables us to sample\n580.279s: very large weather assembles at the cost\n582.36s: of roughly on the order of one physics\n584.8s: space for so basically a handful of\n586.48s: physic space forecasts um and if you\n589.12s: think about um a con a constant cost\n592.36s: operating curve so again if we look at\n594.44s: the other at at the resolution emble\n596.32s: size straight off if we look at a\n597.48s: physics based Ensemble we basically have\n600.16s: this trade-off where uh if we increase\n602.76s: the Ensemble size we also need to force\n605.36s: and the resolution quite\n606.88s: severely um and our idea is uh to use\n610.56s: some information from a handful of these\n613.36s: physics based forecast let's say in this\n614.88s: case two and then uh we just get an\n618.0s: increase in the computational cost that\n619.64s: is marginal uh because we are\n621.76s: essentially emulating this processes\n623.64s: with uh with uh with generative AI\n625.92s: techniques that are much faster uh than\n628.279s: running physics based emble so so uh our\n631.64s: goal is to basically lower this line uh\n634.24s: into this one so that we can increase\n636.16s: the Ensemble arbitrarily without\n637.6s: compromising on the on the\n640.92s: resolution um so the approach that we've\n645.36s: taken uh in order to uh to accomplish\n648.6s: this is is a method that we've called\n650.32s: seeds um and uh it essentially uh it's\n655.24s: it's um basically described the\n657.12s: schematic on the slide uh which trying\n659.48s: to do generative emble emulation where\n662.399s: uh we're going to take as input uh first\n664.72s: the climatological information for some\n667.2s: field so you can think about this this\n668.92s: Cloud as giving us the potential all the\n670.959s: potential States uh of that particular\n673.68s: field without initial condition\n675.68s: information and we're also going to uh\n678.6s: consider two samples uh in this case\n681.72s: from a forecasting system uh so we would\n685.0s: need basically a two member Ensemble\n687.279s: from a forecasting system and the\n689.279s: climatology and the idea is to uh with\n692.72s: is to use a diffusion model a\n695.56s: conditional diffusion model um to sample\n698.959s: more plausible weather States so we want\n701.12s: to infill the probability forecast\n703.56s: distribution uh from just a handful from\n706.44s: just a handful of States so we're going\n707.68s: to use these states to steer uh the\n710.32s: probability distribution into one that\n712.72s: would be given by a much larger emble um\n716.2s: and for instance you know we could we\n717.88s: could expand to embl that have on the\n720.0s: order of 500 emble members which is on\n722.8s: the order of 10 10 times of more or more\n725.839s: of the operational forecasting systems\n727.639s: today um and so one important difference\n731.04s: between this method and other AI based\n733.6s: methods that you might have read about\n736.279s: uh for for weather forecasting is that\n738.399s: we're actually not doing any forecasting\n740.24s: in time in these tasks so I'm always\n742.88s: taking uh data that comes from a c like\n745.8s: a fixed sleep time so let's say I'm\n747.079s: taking input I'm taking the four of some\n749.92s: forecasting system at a lead time PL\n752.6s: this could be seven days and I'm\n754.36s: essentially giving you other uh samples\n757.44s: other potential samples if you were to\n759.079s: run a bigger Ensemble of that system at\n761.56s: that same forecast time so there's uh\n763.839s: Concepts such as Rola in stability um\n767.279s: and and and changes of the Spectra and\n768.959s: so on with time are not applicable in\n770.519s: this case because time is not a variable\n772.92s: so that's that's a big difference with\n774.56s: respect to models such as uh neural GCM\n777.48s: or or graph cast that people might have\n779.76s: might be familiar with um so how do we\n783.44s: how do we train a model to do this so\n785.16s: the approach that we've taken is again\n787.12s: uh we're going to train a conditional\n789.56s: diffusion model uh that is conditioned\n791.639s: on K Ensemble members and\n794.04s: climatology uh and we're going to fit\n796.36s: that conditioning with some gaussian\n798.6s: noise uh to some diffusion model and\n801.16s: we're going to try to learn uh the score\n803.959s: function within the reverse diffusion\n806.519s: stochastic differential equation so that\n808.279s: it gives us actually\n809.959s: a plausible weather State and so the\n812.48s: labels that we're going to use uh for\n814.88s: this learning method uh are going to be\n817.24s: other Ensemble members of the same\n818.639s: forecast system so um essentially if you\n822.72s: if you give me an ensemble system with\n824.519s: say five members I'm going to use CH two\n827.199s: condition let's say k or CH two\n828.68s: condition and then I'm going to try to\n830.6s: uh predict labels that are close to any\n832.6s: of the other three so this is the\n834.32s: approach that uh that is taken for for\n836.48s: learning uh in this method um and then\n840.36s: the the score function this is the the\n842.0s: part that is learnable in in our method\n844.88s: and in our case we're going to use a\n847.44s: vision Transformer uh to parameterize\n849.36s: the score function here and learn the\n852.0s: learn basically this this transformation\n854.12s: from noise to to two samples from the\n856.32s: distribution that we're interested\n858.72s: in um so for uh for now we've used uh\n864.56s: this approach uh on on the GFS version\n868.199s: 12 system uh yes mention I didn't get\n872.88s: where did\n874.92s: you oh yes so the climatology so this uh\n879.8s: this cor this is H kind of an update\n882.199s: State for the system where you go so you\n884.32s: can think of this probability as the\n886.279s: noise and this is going to be the final\n889.079s: sample and so this uh reverse diffusion\n892.639s: stochastic differential equation is um\n895.44s: it's going to be conditioned on this Y\n897.639s: and this y That's where the climatology\n900.199s: can see so every step we're always\n902.399s: conditioning on on the climatology and\n904.0s: also these Ensemble members and what we\n905.639s: are transforming is noce yeah and this\n909.16s: is different from for for instance\n911.04s: unconditional diffusion where you just\n913.0s: uh learn to transform a distribution to\n915.24s: another without any more inputs\n918.92s: yeah uh so the as I was saying we've\n922.759s: we've apply this approach to the Noah's\n925.68s: GFS version 12 model which is the\n927.24s: operational model uh currently used by\n929.16s: NOA um the our training approach has\n932.639s: been to train one model per lead time as\n935.6s: I said we're not forecasting in time so\n937.0s: we can either do this or pull in time in\n938.639s: this case we decided to train one model\n940.56s: per per lead time um we're going to use\n943.6s: for conditioning uh two seting forecast\n945.959s: for most of the results that I'm going\n947.399s: to show today I also have a slide where\n949.36s: uh we're showing uh what's the what's\n952.199s: the sensitivity to this parameter um and\n955.959s: uh for the the the training data we're\n958.079s: going to use the 20 years of daily\n960.8s: forecast that the GFS version 12 model\n963.04s: has for the historical period so this is\n964.959s: the reforecast data set that most\n967.44s: operational systems have available\n969.079s: because they need this to uh calibrate\n971.24s: uh their operational system so this is\n972.72s: something that we would we would uh\n974.959s: always having an operational system to\n976.48s: train on um in this case the uh\n980.04s: reforecast emble from GFS has five\n982.48s: members and so since we're conditioning\n985.399s: on two members uh for every forecast\n988.199s: date we can essentially choose any\n991.319s: combination of two members to forecast\n993.759s: another one so in the end we have 10\n995.319s: combinations per forecast date that we\n996.8s: can use for training so this is kind of\n998.199s: a data augmentation uh uh step that we\n1001.16s: can take to train our model and in the\n1004.0s: end uh it's important to note this is a\n1005.92s: generative problem and if if if you if\n1008.68s: you uh think about it we actually have\n1010.519s: three labels per conditioning because\n1013.199s: every time that we condition on two\n1014.8s: sitting forecast we might have three of\n1016.68s: the possible of the other possible\n1018.48s: States so that's going to allow the\n1020.199s: diffusion model to learn about the\n1021.6s: variability uh in in the\n1024.28s: forecast um for evaluation we are\n1027.36s: considering the the entire year of\n1029.799s: 2022 um the ground truth that we're\n1032.72s: comparing our results to is er five and\n1035.72s: the Baseline is the full GFS uh version\n1038.24s: 12 operational model which has 31\n1040.24s: members um and the sitting forecast are\n1042.52s: going to take are going to be taken from\n1044.12s: the operational GFS version 12 so so you\n1046.679s: could essentially download uh the\n1049.0s: operational GFS forecast for today and\n1050.919s: and do inference on that that would be\n1052.32s: the essentially what we did\n1055.0s: um so uh we trained our model using this\n1058.96s: approach and and some uh some things\n1061.52s: that we can look at first is whether the\n1063.0s: samples actually look realistic and so\n1066.039s: um here I'm comparing samples from both\n1068.96s: uh our emulator on top and the the full\n1072.16s: GFS system in the bottom and so I'm\n1074.32s: showing here uh Global a global picture\n1078.24s: of the total colum vertically integrated\n1079.88s: water vapor uh for the two systems this\n1082.36s: is one sample and I'm also zooming in to\n1084.32s: Europe uh for a particular date in July\n1086.799s: of 2022 where there was a heatwave\n1089.4s: conditions over the Iberian Peninsula\n1091.32s: and so you can see uh this geop\n1093.919s: potential important geop potential\n1095.36s: anomaly here off the west coast of uh of\n1099.12s: Portugal and we can see that uh the\n1101.36s: diffusion model uh is also able to\n1103.919s: capture uh the the spatial correlations\n1107.0s: the spatial structure of the samples and\n1109.36s: also the intervariable correlation so in\n1111.84s: this case I'm plotting in color you can\n1113.88s: see the geop potential height at 500\n1116.159s: hectopascals and uh the the shadings are\n1118.76s: for the for the C Level pressure anomaly\n1122.559s: and so they have similar similar\n1124.2s: correlations there uh we can also look\n1126.84s: at how well the uh model is preserving\n1129.6s: the Spectra and so this is what I'm\n1130.919s: showing on on the right hand side of the\n1132.48s: slide for the temperature 2 meters above\n1134.64s: the surface uh and we essentially see\n1137.4s: that the differences between\n1139.24s: our emulator and the full GFS system are\n1142.64s: are are actually smaller than the\n1144.12s: difference with respect to the er5\n1146.039s: reanalysis that comes from uh that\n1148.36s: essentially comes from another uh\n1149.919s: operational system ifs from\n1152.72s: acwf um so we can also look at different\n1157.159s: metrics at how well our model is doing\n1159.919s: and so um here I'm looking at the root\n1162.919s: mean square error uh of the ensemble\n1165.72s: mean of all three Ensemble of all three\n1168.72s: examples where I'm showing in blue I'm\n1171.64s: just showing the conditioning forecast\n1173.96s: so this is just the average of or yeah\n1176.84s: the the the root me square of the\n1178.84s: average of the forecast that I use to\n1180.36s: condition my model so this is all the\n1181.72s: information that I'm giving during\n1183.28s: inference time to my model um in Orange\n1186.559s: we have the metric for the full 31\n1189.72s: member GFS Ensemble and in green we have\n1192.08s: the the metric for our ensembles in this\n1194.28s: case since it's very cheap to generate\n1196.4s: uh members in our case we generated uh\n1198.88s: 512 uh member Ensemble for this um and\n1202.44s: so what we can see is that the emulator\n1204.799s: condition and two emble members uh has\n1207.48s: comparable skill to the full physics\n1210.039s: based emble um of course it's a little\n1212.72s: bit worse because we we wouldn't expect\n1214.679s: it to do better in this case because\n1216.24s: we're just doing pure emulation uh so it\n1218.679s: it's where we're the the best thing we\n1220.799s: could do is actually to match it in a\n1222.48s: way because we are just in the pure\n1223.88s: emulation process we haven't tried to uh\n1226.24s: we haven't tried to correct for any any\n1228.919s: any um any issues that the model might\n1231.039s: have but essentially we see that the\n1232.919s: they're very close together and and the\n1235.36s: the gain with respect uh to the\n1238.12s: conditioning is is very substantial um\n1241.32s: but the the really the really useful\n1243.4s: thing about this uh very very cheap uh\n1247.36s: to to sample generators is that you can\n1250.2s: actually uh you can actually generate\n1252.32s: gigantic ensembles uh very very fast and\n1254.559s: very cheaply and so uh why this uh why\n1258.08s: this matters\n1259.12s: uh is is is shown in this in this\n1261.96s: example on the slide where I'm\n1263.64s: considering the same conditions that I\n1265.08s: was showing before so I'm showing uh\n1267.28s: conditions during the July 2022 uh heat\n1269.679s: wve over Portugal and in particular this\n1271.76s: is for the 7-day forecast um and in the\n1275.039s: scatter plot just to show I want I\n1277.08s: wanted to show also the the the\n1278.919s: intervariable correlations I'm showing\n1281.12s: the temperature at 2 metters uh in in\n1283.48s: degrees celsius in the x-axis and also\n1286.12s: the total column vertically integrated\n1287.72s: water vapor uh in the y-axis um the\n1291.36s: analysis the the reanalysis of what\n1293.76s: actually happened uh given by Era five\n1295.88s: is this star here the brown star uh the\n1299.08s: conditioning forecast that I'm giving uh\n1301.679s: the emulator are shown as the blue\n1303.6s: squares and the entire GFS Ensemble is\n1306.559s: shown uh as the um as the two blue\n1309.88s: squares plus the plus the orange\n1311.48s: triangles and so one thing that we can\n1313.88s: first uh see from this is that uh none\n1316.88s: of the Ensemble members from the GFS\n1319.039s: forecast had analoges that were uh that\n1322.4s: were uh that had the same temperature\n1324.84s: attain the same temperature or higher\n1326.72s: than the temperature that was actually\n1328.039s: observed uh so in this case we might get\n1331.12s: an estimate of the likelihood of such\n1332.84s: events uh you can still get it uh with\n1334.96s: techniques such as kernel density\n1336.24s: estimation but uh the key here is that\n1338.84s: the the error bounds that you're going\n1340.4s: to get on that likelihood are very\n1341.96s: significant and or the order of\n1343.32s: magnitude of the likelihood so it's not\n1345.039s: going to be extremely useful and you\n1346.32s: also don't have analoges for what's\n1348.0s: happening there\n1349.48s: um in contrast uh we can generate many\n1353.72s: more samples with our emulator and in\n1355.88s: this case we generated 16,000 uh samples\n1358.6s: for this and I'm showing the the uh\n1361.24s: probability probability uh Contours uh\n1364.4s: here as Dash lines and uh one useful\n1367.159s: thing is that we can see that we\n1368.32s: actually uh get analoges that are more\n1370.76s: extreme than what was observed and we\n1373.52s: have a lot of points that are close uh\n1375.799s: to the start which means that this\n1377.679s: likelihood we're going to be able to\n1379.4s: evaluate the likelihood uh according to\n1382.159s: our model at least uh with with high\n1384.32s: Precision so that's going to allow us to\n1386.24s: make more informed decisions with with\n1388.159s: Quantified and certainty um we can also\n1391.36s: look at this on on a more global spal\n1394.0s: global scale over the whole data set by\n1395.559s: looking at metrics such as the Brier\n1396.96s: score uh which just measures what's your\n1399.36s: classification skill for for certain\n1401.039s: events in this case we binarize the\n1403.52s: events uh by being three sigma plus\n1406.44s: three sigma events in temperature so\n1407.88s: these are events that are very very warm\n1410.88s: compared to climatological conditions um\n1413.84s: and what we see is that thanks to our\n1415.559s: better sampling uh with our model we are\n1418.4s: able to get a lower Brier score uh than\n1421.679s: the the full GFS on sampol and I should\n1423.919s: say that Brier score uh it's better to\n1426.76s: get a lower uh PRI score so the pr score\n1429.4s: is kind of an error on probability space\n1431.279s: so you want it to be um as low as\n1434.44s: possible um as I said before uh we we we\n1438.919s: have chosen uh to use two seing forecast\n1441.72s: for our system for our emulator uh we\n1444.0s: did uh compare the results for different\n1447.0s: seting forecast and what we observed is\n1448.64s: that there's there's sort of diminishing\n1451.44s: returns in in skill improvements uh\n1453.6s: above uh above k equal to so if we start\n1456.159s: using more uh forecast to condition we\n1458.84s: get some improvements but they're really\n1460.559s: marginal um I should say that for our\n1463.2s: evaluation protocol we strictly only\n1466.039s: computed the uh metrics on the\n1469.159s: on the on the emulator samples so we\n1471.6s: always we we never consider the cas\n1474.399s: samples that we would actually have so\n1476.44s: you would imagine this metrics to\n1477.799s: actually be a little bit better but that\n1478.919s: would give you a false sense of\n1480.48s: improvement with K because it's just\n1482.48s: taking into account the effect of those\n1484.08s: and so uh this is one of the reasons why\n1486.24s: we uh we settle for K well to because as\n1489.039s: you increase in the x-axis here you are\n1491.76s: increasing the compute by that much uh\n1494.039s: so going from two to three is 50% more\n1496.2s: expensive and so on\n1498.48s: um and yeah so for for for k equal to\n1501.0s: Che we basically get good good results\n1503.24s: so still lower CRPS than uh I mean\n1506.96s: higher CRPS so worse than the model\n1509.6s: we're trying to emulate but we all we\n1511.039s: already get better uh sampling of of\n1513.88s: extremes and so the question uh that we\n1516.799s: had is well can we use this approach to\n1519.0s: actually improve upon the forecast\n1521.24s: system that we're trying to emulate and\n1523.72s: so uh uh in order to do this we actually\n1526.84s: went back to the problem formulation and\n1528.52s: we tged it a little bit so again I'm\n1530.96s: going to uh here use the same diffusion\n1534.44s: model uh so same conditioning uh I'm\n1537.6s: going to use the same modeling approach\n1539.2s: same architecture what's going to change\n1541.52s: here is that the labels that I'm going\n1543.279s: to give the model uh when it's training\n1546.679s: um are going to be a mixture between\n1549.799s: other samples from The Ensemble system\n1551.64s: that I'm trying to emulate and also\n1553.919s: reanalysis data so so what I'm really\n1556.96s: doing here is if you consider there\n1558.88s: three probability distributions of\n1560.44s: temperature this is this in this case\n1562.48s: this was uh the probability distribution\n1564.039s: of temperature over Mountain View uh for\n1566.52s: some date in\n1568.679s: 2022 um what we were trying to learn\n1571.6s: before is this green curve here uh which\n1574.32s: is given by the the full GFS Ensemble uh\n1577.48s: but we do have some information about\n1579.039s: what actually happened uh year five and\n1581.88s: we might know that maybe our the emble\n1584.48s: that we're trying to ulate has some\n1585.72s: biases in some variable so it might be\n1587.52s: actually good to correct for those and\n1589.36s: so what we're proposing here is not to\n1591.76s: try to learn with a diffusion model this\n1594.399s: green curve but actually try to learn\n1595.84s: this blue curve uh that corrects uh uh\n1598.919s: that corrects the the biases within the\n1601.88s: within the Ensemble so we've carried out\n1606.0s: uh this approach and what we see is that\n1608.2s: this generative postprocessing approach\n1609.96s: which is how we call it uh improves the\n1612.12s: predictive skill across the board uh for\n1615.32s: uh for all the metrics and all the\n1616.48s: fields so in this case uh we should\n1619.52s: compare here this uh Pink line which is\n1622.36s: the generative postprocessing results to\n1624.679s: the to the green line uh which is the\n1626.64s: one that I was showing before the\n1628.159s: emulator um and so the improvements in\n1631.2s: some variables are bigger than others so\n1633.159s: for instance uh we know that there are\n1636.279s: uh there are small biases in in two\n1638.96s: meter temperature in the GFS in the GFS\n1641.679s: system and so what the generative post\n1643.88s: processing model uh is able to pick up\n1646.08s: is these biases are correct for them so\n1647.6s: we actually see not only that are uh the\n1650.44s: root me square around the CRPS are\n1652.2s: significantly improved with respect to\n1653.64s: the emulator we're actually now\n1655.559s: outperforming the the original ensemble\n1658.32s: in this variable in other variables it's\n1660.159s: not as clear so if if if you if the\n1663.159s: emulated Ensemble was already really\n1665.519s: good at predicting one variable we might\n1667.48s: not see these improvements but for the\n1669.0s: others it actually corrects uh so this\n1670.84s: is something that that uh we found\n1674.08s: useful um we've uh done we we can also\n1678.96s: analyze how this generative\n1680.44s: postprocessing uh model works for\n1682.84s: extremes and so what we see here is that\n1685.279s: it actually also improves the per the\n1687.88s: performance of our model uh so here\n1689.72s: again I'm I'm showing the brighter score\n1692.44s: for events that are three sigma above\n1695.88s: the climatology so very rare events in\n1698.919s: very extreme events in terms of their\n1700.36s: positive anomalies and also events that\n1703.2s: uh deviated minus 3 Sigma from the\n1705.039s: events so on the other side uh and uh\n1707.72s: what we see is that for a 2 met\n1709.88s: temperature we significantly outperform\n1712.159s: all other models with the generative\n1714.12s: post processing approach and uh the same\n1716.799s: is true for for other uh for other\n1719.519s: variables even though those games are\n1721.72s: maybe a little bit less\n1724.6s: significant\n1726.32s: um finally uh one thing that uh we\n1730.64s: should do is we are in a way\n1733.2s: postprocessing in these Tas so we are\n1735.0s: using ER five labels uh for training our\n1738.159s: so one thing that we wanted to see is\n1739.44s: whether uh our approach would be not\n1742.32s: only the system that it's emulating but\n1744.159s: also a post-processed version of the\n1746.679s: model that we're emulating and so what\n1748.159s: we did here is uh we took the the output\n1751.88s: from the GFS Ensemble and we performed\n1754.96s: uh postprocessing through quantal\n1756.6s: mapping uh to era five so that uh\n1759.24s: essentially the calibrated GFS Ensemble\n1761.399s: is perfectly reliable and then we uh\n1764.6s: recomputed the Brier score for that\n1766.24s: system and compared it to our system and\n1768.279s: so what we observed is that even though\n1770.64s: we were not targeting explicitly to have\n1773.159s: the distributions uh completely right\n1775.399s: with respect to the reanalysis we're\n1777.76s: still able uh to beat the uh postprocess\n1780.32s: GFS so in this case this blue line is\n1782.919s: just the the score that you would get\n1784.32s: from the conditioning sample so this is\n1786.039s: all the information that we're passing\n1787.799s: during inference to our model uh in\n1791.0s: Orange we see the Brier score for the\n1793.679s: GFS system uh just uh just the raw\n1797.159s: forecast without recalibration um in\n1800.159s: Gray you can see the quantal mapped\n1802.08s: version of the GFS forecast where we've\n1804.72s: recalibrated so that it's perfectly\n1806.159s: reliable and then in pink you can see\n1807.84s: the results for uh for our model so so\n1810.519s: for many variables they they are\n1812.32s: basically almost the same as the\n1814.559s: postprocess GFS emble uh and for some\n1817.24s: others we actually get a marginal\n1819.039s: Advantage but the the important thing to\n1821.039s: consider here is that um in order to get\n1824.399s: these results you need to run a 31\n1826.08s: member Ensemble and then postprocessing\n1828.64s: for this we just need two members and\n1830.96s: then we're doing everything with uh with\n1833.48s: this very cheap emulator so we even even\n1836.279s: if we didn't we didn't beat uh this\n1838.88s: method we still get a much uh a very\n1842.76s: significant reduction in the\n1844.519s: computational power and something uh to\n1847.6s: note as well when comparing these two is\n1849.96s: that if we perform quantal mapping or\n1852.279s: any other form of of postprocessing this\n1854.84s: is typically done by Downstream users uh\n1857.2s: on a use case\n1858.44s: basis because uh they can have some uh\n1862.559s: uh not particularly useful implications\n1864.76s: for for some other metric so for\n1866.2s: instance if we perform quantile mapping\n1868.399s: uh which is what we did here we're going\n1870.279s: to get very good matching in statistics\n1872.679s: uh if we just look at pixel by pixel\n1874.32s: pointwise but if you actually do this\n1876.36s: and look at spatial correlations they're\n1878.159s: just going to be much worse than the\n1879.76s: original system because you are\n1881.039s: correcting every pixel independently and\n1883.12s: so that is something that uh that we\n1885.36s: don't get in the generative post\n1886.6s: processing we still conserve the\n1888.399s: intervariable and the and the spatial\n1890.12s: correlations well so that's something\n1892.039s: that you get this is sort of a a general\n1894.36s: a general version of post processing uh\n1897.519s: and then you could of course do more\n1899.0s: post processing on that if you want uh\n1900.88s: on that\n1901.72s: output um so then one last question that\n1905.96s: lefts an answered for uh for this\n1908.08s: particular task for generative post\n1909.88s: processing is how do we actually blend\n1913.039s: uh the information from the forecasts\n1914.919s: and the reanalysis right so I said\n1917.0s: before that we're going to\n1918.36s: try to Target a mixture of the two\n1920.519s: distributions but I haven't said what\n1922.32s: kind of mixture and how we choose and uh\n1925.88s: for now the answer has been mostly\n1927.399s: empirical which is we just tried a bunch\n1929.399s: of combinations uh and so uh what we did\n1932.96s: is uh here uh we essentially train\n1935.519s: models uh going from the pure emulation\n1938.559s: so this would be the first uh the first\n1940.88s: methodology that I was explaining on the\n1942.84s: on the right hand side and then we\n1945.559s: increase the the probability with which\n1947.919s: one of the samples of The Ensemble\n1949.44s: system would be replaced by uh by a\n1952.24s: sample from the era five reanalysis all\n1954.559s: the way to 100 so on this in this axis\n1956.6s: on zero uh you would basically just\n1958.559s: train your model uh with labels from ear\n1961.44s: five and what we see interestingly is\n1963.72s: that the optimum is not to train uh the\n1966.679s: model always with your five it's\n1968.32s: actually to to train with a blend of\n1970.44s: them and and it seems like there's\n1972.039s: there's a small there's a small Valley\n1974.0s: where where you can choose uh many many\n1976.519s: uh many fractions there but but\n1978.919s: essentially if you if you train your\n1980.84s: model with a mixture distribution that\n1983.2s: has more weight in the re to the toward\n1986.44s: the reanalysis than towards the forecast\n1988.24s: system for this combination so for GFS\n1990.12s: and era 5 we're not saying that this\n1991.84s: generalizes to other models then you\n1993.6s: typically get the best results so you\n1995.159s: know from 50% to say 75% probability you\n1998.519s: would sample your five that's when we\n2000.44s: observed that the root me square of our\n2003.159s: system uh is minimum and also the things\n2006.6s: like sampling uh extreme events which\n2008.88s: would be the prior score uh\n2013.44s: yes C\n2018.76s: localis uh that's that I mean that's a\n2021.0s: good question so you could do the same\n2023.24s: you could do the same thing but just\n2024.6s: looking at at different locations and\n2026.76s: and and\n2029.519s: perhaps the buas yes I think so yes uh\n2032.88s: that that's a very good point so this\n2034.84s: certainly I think certainly the change\n2036.919s: with respect to this parameter Alpha\n2039.72s: tells you a lot about the bias so you\n2041.36s: can see that for instance for the mean\n2042.84s: SE level pressure there's a change but\n2045.2s: it's moderate if you compare it to the\n2047.039s: difference with respect to the the GFS\n2049.919s: uh system but for temperature which is\n2052.399s: the the variable that we actually knew\n2053.8s: that is kind of biased in in GFS with\n2056.04s: respect to R5 you see actually this huge\n2058.2s: jump when you start using that\n2059.52s: information so this definitely so this\n2062.639s: is definitely going to be variable\n2064.0s: dependent uh so maybe maybe this uh this\n2067.359s: would depend on the variable that you\n2068.56s: want to optimize with one good thing\n2071.159s: that we've seen is that even though this\n2073.44s: change uh the change in the magnitude is\n2075.879s: so dramatic between them between them\n2077.8s: the optimum kind of seems to be on the\n2079.56s: same uh on the same range of Alphas so\n2082.119s: it just seems there there's a there's a\n2083.48s: region where the model can essentially\n2085.8s: use the fields to complement the\n2087.159s: information and match it uh better but\n2090.04s: again this is we we've only done this\n2091.76s: analysis for on the on the global scale\n2094.2s: so maybe if you do it uh if you were to\n2096.2s: do this regionally if you were\n2097.68s: interested in like optimizing the model\n2100.04s: uh for Regions you know let's say\n2101.48s: California or or or something like that\n2103.92s: I'm not sure that this would give you\n2105.079s: the same result it might be it might be\n2106.839s: something to a parameter to optimize um\n2112.079s: definitely um yeah and and with that uh\n2117.16s: I will just end with some of uh some\n2121.32s: parting thoughts about our results so uh\n2124.24s: we've seen that we can use uh generative\n2126.4s: AI uh to efficiently augment The\n2129.44s: Ensemble size of numerical weather\n2131.119s: prediction systems so in our case we\n2133.8s: were using two conditioning members uh\n2136.92s: and we were matching the the statistics\n2139.64s: in some cases improving the sampling uh\n2142.2s: of of the original system that have 31\n2144.32s: members uh so there you get a\n2146.2s: computational gain of about you know\n2148.4s: higher than 90% uh with respect to the\n2150.68s: original system which is very\n2151.88s: significant and so um one idea there is\n2155.4s: that this safe computational expense\n2157.16s: could be uh could be devoted to to\n2159.119s: increasing the spatial resolution of\n2160.68s: systems and so if if suddenly more more\n2163.28s: compute is available to systems then uh\n2166.119s: then this Ensemble Ensemble size to\n2168.16s: resolution tradeoff wouldn't be uh such\n2170.64s: such a problem uh if if we were to use\n2172.56s: these approaches for to augment\n2174.319s: operational systems uh or we could also\n2176.92s: use this uh to instead of increasing the\n2180.2s: number of Ensemble sizes increasing the\n2182.119s: the size of the emble we could also\n2183.48s: increase the forecast frequency so this\n2185.24s: is a particularly it's not so in the\n2187.96s: medium range where forecast are actually\n2189.8s: performed uh very frequently but for\n2191.92s: instance in the subseasonal range if you\n2193.4s: look at different operational agencies\n2195.96s: um there's there there's agencies that\n2198.92s: uh are going to issue forecast uh maybe\n2201.44s: two days a week uh for instance and so\n2203.92s: and actually CWF uh uh just updated\n2206.48s: their subseasonal to seasonal forecast\n2208.64s: system and they showed that if you\n2209.76s: increase the frequency you can for\n2211.0s: instance get much better prediction for\n2213.28s: the the mad and Julian illation that we\n2215.079s: were learning about uh in the previous\n2216.92s: talk\n2218.56s: and uh apart from that we've also seen\n2220.599s: that reanalysis data uh can be blended\n2223.24s: into the training labels to the buas the\n2225.079s: generative emulator uh and so so far\n2227.44s: we've done this with grided data uh uh\n2231.04s: supposedly for some variables uh if we\n2232.92s: had better data sets that weren't graded\n2234.8s: that could also be done but that\n2236.0s: requires uh dealing with data that is\n2238.52s: not gred such as precipitation products\n2240.72s: and so on and then uh just another\n2243.839s: parting thought is that there's uh\n2246.8s: there's no reason why if this has worked\n2248.92s: for uh for example weather prediction\n2251.079s: why something similar shouldn't work for\n2253.64s: certain problems in in in climate\n2255.48s: science in climate projection where we\n2256.839s: also need a lot of uh a lot of uh large\n2260.4s: ensembles in order to to know what's\n2262.839s: internal variability what's uh what's\n2265.319s: the anthropogenic forcing and what's the\n2267.079s: probability of of certain extreme events\n2269.28s: as the climate changes and I've uh also\n2272.44s: added here um a QR link uh to an to our\n2276.319s: article and with that I'll take uh any\n2283.72s: questions we do have a question online\n2287.04s: chatan do you want to unmute yourself or\n2288.839s: do you just want me to read your\n2290.76s: question\n2293.319s: onl I canot mute\n2296.64s: myself uh can you hear me uh yes I think\n2300.319s: so okay cool uh thanks for a great talk\n2303.4s: um I was just wondering if you've\n2304.68s: compared uh the structure of internal\n2306.599s: viability and in the physical ensembles\n2309.72s: versus uh what your diffusion model\n2312.64s: emulates um and if is is there any\n2315.64s: spatial variability to the structure of\n2317.72s: internal variability so essentially the\n2320.2s: on\n2322.119s: sprad oh we compare the spread yes uh I\n2324.839s: didn't I didn't add the if the question\n2327.8s: was whether we compare the spread of The\n2330.56s: Ensemble to of our Ensemble to the full\n2333.52s: GFS Ensemble uh we did I haven't added\n2336.4s: that uh figure uh in the slides but uh\n2339.4s: we do have it it's the last figure in\n2341.16s: the in the paper um so uh what what we\n2345.28s: did essentially is we computed the\n2346.8s: correlation between The Ensemble spread\n2349.48s: of um of our system and the full GFS\n2352.319s: system and what we see is that that\n2354.119s: correlation is a higher than the\n2356.52s: correlation with respect to the\n2357.839s: conditioning members so we are actually\n2359.52s: learning some dynamical features there\n2362.4s: uh we're learning to infill the the the\n2365.0s: attractor if you will close to the the\n2367.72s: members and what we also verified is\n2369.88s: that if we actually um when we were\n2372.599s: dealing with lead times that are beyond\n2374.92s: the medium range so let's say like 16\n2376.68s: days uh that our model had higher\n2380.16s: correlation as well than climatology\n2382.0s: because at some point all these all\n2383.64s: these distributions all the uncertainty\n2385.079s: is going to converge to climatology and\n2386.599s: so what we see is that our model is able\n2387.92s: to learn that transition but still has a\n2390.119s: bigger correlation with the full\n2393.68s: Ensemble thank you\n2400.8s: yeah great talk um I have a question it\n2403.92s: looks like you use like temperature data\n2405.92s: and like a wind data lot for this for\n2408.2s: the forecasting and like temperatures\n2409.88s: kind of normally distributed how would\n2411.839s: you could this be applied to like\n2414.44s: whether that patterns that are like not\n2416.44s: so normally distributed like you know\n2417.72s: presentation is not going to be a Bel\n2419.28s: curve it's kind of hard to like right\n2422.16s: like the extremes are hard to find I\n2423.4s: guess yeah yeah so that's a that's a\n2425.04s: very good question so so one uh one one\n2427.48s: thing that since this was like the our\n2429.48s: our first approach to the to the problem\n2432.16s: uh we wanted to focus on on fields where\n2434.8s: uh both we have uh good reanalysis data\n2439.16s: and also that the data is not too\n2442.0s: complicated to model uh so that's one\n2444.64s: reason why we explicitly left\n2446.68s: precipitation out of this uh of course\n2448.92s: we understand that precipitation is very\n2450.839s: important so this is something that uh\n2453.2s: we're looking at at the moment but we\n2455.16s: just know that basically I I think\n2457.52s: anyone that has worked with like data\n2458.76s: driven methods and then try something on\n2460.56s: temperature and then on precipitation\n2462.04s: there's a jump there so so we didn't\n2464.76s: want to do that jump uh for now but\n2466.839s: that's something that we have in in mind\n2468.44s: thank you\n2471.359s: yeah we have another question online\n2474.28s: parsa would you like to unmute yourself\n2489.4s: Mara would you like to unmute yourself\n2491.88s: or hi hi uh thank you thank you for the\n2494.8s: time and thanks for interesting talk I\n2496.599s: was talking and I was muted so yeah uh\n2500.16s: this was quite interesting my question\n2502.24s: is I'm curious about uh if I remember\n2505.079s: correctly you mentioned something of the\n2507.4s: order of 1,000 ensembles or thousands of\n2509.88s: ensembles that you generated in order to\n2512.44s: sample that extreme event that you\n2514.119s: showed so my question is do we have any\n2516.56s: sort of objective measure of how many\n2520.24s: ensembles we're going to require to be\n2522.52s: able to sample this space so basically\n2525.2s: what I mean is that do we have any\n2526.839s: measure of the um equivalent number\n2531.319s: of for for the number of Ensemble that\n2533.92s: we need for this model to sample an\n2536.079s: equivalent distribution of the uh\n2538.48s: numerical model yeah so so yeah that's a\n2541.52s: good question so uh the answer is that\n2543.48s: yes we can get it so so the the the way\n2546.04s: that uh and I didn't add this here but\n2548.4s: we did that uh which is that you can\n2550.839s: essentially uh for any for so any of\n2553.04s: these forecast systems any of these\n2554.359s: forecast ensembles are going to assign a\n2556.04s: probability to this event if you just\n2558.24s: ask what that probability is and so what\n2560.559s: we did is um we fit uh we fit a a a\n2565.68s: gaussian kernel so we we basically\n2567.319s: performed kernel density estimation uh\n2569.76s: supported on the on the GFS full data uh\n2572.8s: for this particular date and the\n2574.8s: probability of it happening was about\n2576.319s: 0.7% % according to the kernel density\n2579.599s: and so what that tells us is that you\n2582.04s: know if we have a probability of it\n2584.48s: happening of 0.7% and we only have like\n2586.76s: 30 members then the uncertainty on that\n2589.599s: 0.7% like the error bars are going to be\n2591.68s: very very large they're actually going\n2593.079s: to be larger than that 0.7% so that\n2595.64s: tells you that you would need so from\n2597.559s: that it depends on the P value that you\n2598.96s: want to assign um so depending on the P\n2602.119s: value you're going to get a number of\n2603.4s: emble members that would be required to\n2605.0s: get that so that's kind of similar to\n2606.72s: how the authors uh got this map here\n2610.319s: which is you tell me the you tell me the\n2612.04s: acceptable error I'm going to tell you\n2613.319s: how many emble members you get uh and so\n2615.92s: for a P value of for a P value of 0.05\n2619.2s: for this particular measurement if I\n2621.359s: remember correctly I think uh you would\n2623.119s: have needed about 130 Ensemble members\n2626.72s: uh and the order of magnitude for the\n2629.2s: for the Ensemble emulator was similar so\n2631.319s: you can again uh do the same thing uh\n2634.319s: for uh you can also perform konal\n2636.24s: density estimation with the mulated\n2638.319s: emble the probability was also around 1%\n2641.64s: uh but the uncertainty bounds were very\n2643.64s: very small here because we got uh we had\n2645.8s: a 16,000 samples so what this allows you\n2648.48s: to do is just essentially reduce the\n2651.44s: error vals of the likelihood as much as\n2653.319s: you want uh but of course there's also\n2655.24s: this is just with respect to the\n2656.52s: sampling error not with respect to other\n2658.64s: errors but yeah good\n2660.76s: question thank you"
    },
    {
        "class": "YouTubeVideo",
        "title": "A Multiscale Framework for Airflow-Canopy Interaction with Jaeyoung Jung",
        "videoId": "VD8hx2aPDKY",
        "url": "https://www.youtube.com/watch?v=VD8hx2aPDKY",
        "publishedAt": "2024-03-19T17:10:57Z",
        "transcript": "5.279s: okay um okay so next um we are going to\n8.0s: hear from Jang Jang who is a postdoc\n11.4s: postdoctoral scholar um working with\n13.44s: leap um Jang has his um PhD in civil and\n18.88s: environmental engineering from Su\n20.8s: National University in South Korea his\n22.92s: research areas include multiscale\n24.92s: mechanics theoretical and numerical\n26.84s: analysis of flow physics and canopy\n29.119s: flows and learning thank you so\n32.52s: much thank you for interesting me hello\n36.28s: everyone um thank you first of all uh\n40.16s: thank you for your time uh joining my\n43.12s: presentations regarding research update\n46.559s: and today i' would like to introduce my\n48.8s: work which is mer scaling framework uh\n52.359s: for a macroscopic modeling of airflow\n56.6s: kind of\n58.92s: interactions\n61.039s: so my interest our interest is alow kind\n64.559s: of interaction problems and there is\n66.479s: multiple process between airflow uh\n69.56s: atmosphere and\n70.84s: canopies um the first first of all like\n74.4s: there is biophysical and chemical\n76.2s: processes such as gas exchanges and\n79.2s: radiation heat and humidity\n81.88s: fluxes and another essential component\n85.32s: is wind Dynamics uh regarding tolerance\n88.92s: flow in or around the canopis and which\n92.079s: is plays a key role in the various\n94.32s: processes between the atmosphere and\n97.479s: canopis and so in order to achieve like\n100.88s: a better understanding of\n103.0s: microclimate uh the accurate predictions\n106.68s: of well flow in canopy is quite\n108.92s: important issues so this study U mainly\n113.24s: focused on the on providing uh an more\n117.759s: advanced model for uh canopy flows but\n121.92s: first of all uh I want to start briefly\n124.479s: recap the uh the uh the existing work on\n128.959s: the physic biophysical and chemical\n131.08s: process\n132.319s: first and which includes the heat\n134.959s: humidity gas fluxes uh exchanges and\n138.84s: which is related with Pho synthetics and\n141.44s: Greening and sunl shade and finology and\n144.44s: so on in order to analyze uh the complex\n148.319s: and multiple processes\n150.36s: there are a bunch of options the and one\n153.8s: of the most widely used and cheapest and\n156.68s: simplest one is a single layer\n159.04s: models uh this model regard the canopy\n162.08s: layer as a um the a big\n165.879s: lies relying on the homogeneous and\n170.36s: isotropic canopy assumptions and I want\n173.48s: to point out uh this model requires at\n176.8s: least one point window speed to assess\n179.84s: aerodynamic conductance regarding\n181.76s: tobulance fluxes between atmosphere and\n184.72s: canopy\n186.159s: layers and more recently multi-layer\n189.0s: model was proposed this model can\n192.799s: reflect the vertical\n195.4s: heterogenity heterogeneous structure of\n197.64s: the canopies but still rely on the\n201.599s: horizontally homogeneous and I Tropic uh\n205.36s: canopy\n206.76s: distributions and and this model\n210.239s: requires ond uh canopy window profile\n213.239s: for uh estimate the tobulance fluxes\n217.28s: between each layers and as the\n220.2s: computation Powers keep growing up the\n223.159s: the demand for the more accurate more\n225.76s: more accurate production also increased\n229.56s: so what's next in my opinion it would be\n234.159s: like uh much more advanced and accurate\n237.799s: model that can handle hat genous uh\n241.64s: canopies and so so that we can uh deepen\n245.36s: our understanding regarding the micro\n247.879s: climate\n250.68s: situations so this kinds of like a more\n254.159s: complex model might required 3D window\n258.32s: basted\n259.6s: fields and and um but this is quite\n264.24s: challenging stuff to provide um High\n267.199s: Fidelity simulations in this scales in\n269.88s: this microclimate scales uh due to its\n273.24s: complexity and the mergy scale nature of\n277.68s: it so aerodynamics in canopies mainly um\n283.32s: basically it regards uh complex fluid\n287.56s: structure interaction\n289.4s: problems and this occurs on a broad\n292.84s: continum mob scales start from Leaf\n295.24s: scales and trees and bunch of trees\n297.88s: forest and Global scales\n300.96s: so if we want to provide High Fidelity\n304.759s: simulations then the choices the best\n307.32s: choic is the direct numerical\n309.0s: simulations uh on the fine resoling\n311.44s: measures which resor every single scales\n315.28s: uh all the scales in this canopy and flu\n319.28s: structures by imposing a world boundary\n322.28s: condition along the solid and fluid\n325.36s: interfaces but this requires a lot of\n328.639s: computational cost\n330.44s: so this method can cover bunch of leaves\n334.12s: or branches so this is not visible for\n338.88s: our uh scar of interest it's micro\n342.479s: climate simulations so this is not\n344.84s: visible way for our uh goal another uh\n349.6s: existing approach is canopy drag models\n352.12s: and this model neglect the physical\n354.36s: presence of the uh canopies and just add\n358.639s: uh this kinds of auditioner source term\n362.88s: here and which has a meaning of physical\n367.24s: sub scale canopy drag\n371.199s: effect but this this method is really\n374.8s: easy to implement but um uh this method\n379.24s: adopt uh homogeneous canopy assumptions\n383.759s: so this method also can be a poly cou\n386.68s: for quite large scale where the\n388.8s: homogeneous SC canopy assumptions make\n391.199s: sense if we apply this method on like\n394.599s: heterogeneous canopies then it can be\n397.319s: prob problematics because at this in\n401.56s: this cases uh the source ter FD will\n405.639s: contain the uh reservable information of\n410.0s: U uh like some part of inertial effect\n413.68s: due to the heterogeneities\n416.479s: so the parameter estimation for d\n419.919s: coefficient CD uh will be Pro prob Pro\n424.639s: problematic in this\n426.919s: cases another way is uh adopting a 1D\n430.919s: analytic models uh this model adopt like\n435.0s: an additional assumptions which is\n438.12s: neutral or stady state\n440.72s: assumptions uh for the flow over the\n442.96s: canopies uh the 1D model is used as a\n447.199s: word models based on the concept of\n450.639s: insight and for the airflow in inside\n454.56s: the canopies uh weor this uh reduced\n459.08s: version of momentum equations uh this\n462.08s: can be derived by applying a neutral\n465.479s: State assumtion and neglecting the\n467.36s: inertial part then we have this and also\n471.12s: using utilizing a gradient models and\n474.44s: mixing length hypothesis and we also use\n478.12s: uh canopy Dragon model then we can\n480.4s: derive the 1D profile inside of the\n483.319s: canopis and those model also adopt\n486.68s: isotropic and homogeneous canopy\n489.4s: assumtion so it cannot Oly couple a\n492.319s: smaller scale information uh problems\n495.52s: where the the uh the anistropy or\n500.159s: heterogeneous canopies cannot be\n502.28s: negligible cannot\n504.919s: yeah so the existing method has can be\n509.0s: applicable only for a quite large scale\n511.84s: where the homogeneous assumptions uh\n514.8s: make sense so due to this assumption\n517.919s: those two method has some limitation in\n520.399s: terms of downs scalings and for the DNS\n524.56s: a fully reserving strategy has also its\n527.08s: own limitation in terms of upscaling due\n529.72s: to the computational cost so there is a\n532.8s: missing Gap from here to here and the\n535.2s: present study aim to uh briding this Gap\n539.12s: by multiscaling method so in this uh\n543.56s: range of scales we our interest scale of\n547.0s: Interest might be a\n549.44s: kilometers or 100s meter scales for the\n553.16s: entire uh computational domain in this\n556.2s: case uh the the grid size might be uh a\n560.8s: few meter scale at least 50 cm scales is\n564.64s: much larger than leap or smallest\n567.399s: structure of the canopy so we should\n569.44s: consider a course grid model which is\n572.0s: the model where this grid size is larger\n575.2s: than smallest structure of the solid\n577.56s: part so so we we need to formulate first\n582.56s: grid model and it should be um capable\n587.279s: of heterogeneous situation and it should\n591.959s: be uh implemented so that you can uh\n595.04s: over the wide range of length scales to\n597.92s: breaching the missing Gap\n602.76s: so for this purpose we upscale the\n605.0s: problems based on the volume averaging\n607.76s: theorems in this if we are scaling if we\n612.24s: taking the volum averaging then the\n614.399s: solid part and FID part in the given\n616.959s: cells homogenized as follow and uh\n620.12s: they're represented by Pro defined by\n623.64s: volumetric ratio between fluid and cells\n627.32s: then the heterogene\n629.88s: canopy Fields can be represented by\n633.36s: heterogeneous par\n636.639s: Fields likewise upscaling the\n640.12s: incompressible nebio toxification which\n642.2s: is not feasible in our scales then we\n645.6s: have volume average nvos toxication\n648.2s: which might be febles and this\n650.92s: formulation has two different scales one\n654.04s: is reservable scales and the other is\n656.12s: subgrid or un reservable scales for the\n659.48s: reservable scale can be directly soled\n662.04s: the numerical approximations on the\n664.16s: finite Creed system and but the the sub\n668.16s: scale terms uh cannot because it\n671.079s: includes specially fluctuating component\n673.56s: which is microscopic informations much\n676.2s: is smaller than the grid size scales so\n679.16s: it should be replaced with the San\n681.36s: models and the s model should be uh\n685.16s: function of uh reservable variables to\n688.12s: close the problem to make those uh\n690.639s: problem\n693.8s: solvable in order to do that we proposed\n696.959s: the following Martis scaling framework\n699.399s: which consist of a training step for\n701.88s: microscopic problem and simulation step\n704.079s: for macroscopic\n707.48s: simulations for the training steps we\n710.88s: will consider a unicell problem which is\n713.68s: representative and periodized\n716.56s: microscopic structure over the canopies\n719.44s: and we will idealize it to produce tonso\n723.92s: unisell problem with bearing of\n729.399s: parameters then for each uh unisel\n732.68s: problem we can directly compute\n734.56s: reservable variable by taking cell\n736.839s: averaging over the entire unell domain\n739.8s: and we also directly compute subgrid\n743.36s: scale terms now we need to find out\n745.8s: functional relationship from left to\n748.8s: right\n749.88s: and which will be done with supervised\n752.279s: machine learnings and it will\n755.0s: be coupled with volum Mage NE St\n758.079s: equation servers then in the simulation\n761.44s: steps we will going Tove this equations\n764.399s: and here the softw scale part will be\n766.72s: replaced with ML based s model then the\n770.399s: problem is closed we can solve it then\n772.68s: we can perform the microscopic\n774.279s: simulation for the can of flows like\n778.12s: this\n780.399s: so uh in order to accomplish this uh\n783.92s: framework we need to uh complete two\n788.519s: task\n790.04s: firstly uh we need to implement a stable\n793.16s: and accurate numerical scheme for\n795.6s: reservable part of the volum average\n799.44s: indications and another thing another uh\n802.68s: second Tas is we need to train the ml\n805.12s: based surg modeling of for the sub scale\n809.199s: terms in Vol average NE\n813.36s: intoxications for the first task we uh\n816.72s: developed the noble newer schemes and\n820.16s: the story is quite long so to make this\n823.0s: short like uh we implemented High method\n827.36s: based on this three schemes uh firstly\n830.48s: for temporary integration we use a third\n832.639s: order L method and uh the for the first\n836.56s: derivative special derivative of the\n839.279s: flux T we Implement uh all order wio\n845.16s: finite volume window method and the\n847.48s: second order derivative we use uh even\n852.079s: order window\n853.48s: method and we also formulate our scheme\n856.24s: so that it has well balanced properly uh\n859.8s: to achieve Advanced force balance\n862.639s: between flux and Source TS here the um\n867.04s: blue blue color TS represent uh the net\n871.199s: pressure force from ambient fluid and\n874.8s: this red T represent uh the pressure\n877.519s: force from solid to flu fluid so in\n880.44s: order to achieve balance perfect balance\n883.0s: between two tomies should be uh it\n885.839s: should be treated very carefully\n889.72s: and and this this example is shows like\n893.8s: stationary conditions with zero velocity\n897.72s: over the irregular Pro City and our our\n901.199s: servers uh preserve the the stationary\n904.399s: exact solution up to round opat if if\n908.12s: the scheme don't have a well balanced\n910.0s: property then the the The Unwanted flux\n913.68s: comes uh occurs at the level of\n916.24s: truncation errors and it it will\n918.16s: contaminate the entire domain but\n920.519s: fortunately our uh scheme has uh well\n923.959s: balanced property so it's good and we\n929.24s: also consider reman serber which\n932.72s: is which can treat strong heterogenity\n936.519s: situations uh including discontinuous\n939.199s: procity so in order to achieve this\n942.519s: reman server we firstly uh we derive the\n945.759s: eject Solutions of this discontinuous\n948.519s: problem over the discontinuous procity\n951.44s: and then uh we provide and through some\n955.68s: mathematical theorems regarding unic and\n958.56s: exist\n959.56s: serum of the of the solutions uh\n963.6s: discontinous solution over the\n965.639s: discontinous pro and we confirm that our\n969.6s: and know our uh REM serers based on the\n973.48s: theorems designed like to be satisfied\n976.88s: the theum so our remon servers can\n979.68s: capture all the types of discontinuous\n982.36s: solution neighbor over the discontinuous\n985.88s: procity so and this study\n989.639s: uh is\n991.04s: prepared uh as a draft entitled to like\n996.839s: this for the uh task two we need to\n1000.24s: build the ml based surate\n1003.6s: models uh first of all in order to\n1006.72s: verify our framework worse or not uh\n1010.48s: here we consider very very simple\n1014.319s: unicell problems with only one single\n1017.72s: scared cubes and bearing the SI of cubes\n1020.88s: and the rer number and the flow angle we\n1024.6s: produce tons of\n1026.559s: simulations and and then train\n1031.199s: it and coupled it with the volume\n1033.72s: average\n1034.839s: nacations then in the solution\n1037.76s: simulation step it gives this kinds of a\n1040.36s: close resolution simulation and which\n1043.12s: shows good agreement to with the\n1044.679s: reference Solutions DNS\n1047.4s: Solutions so this also another type of\n1051.24s: work my takeaway from here is if we if\n1055.919s: the unisell problem is welld designed\n1058.4s: then the multiscale framework can use\n1061.08s: accurate\n1063.44s: prediction so now at this moment we are\n1066.88s: challenging for the realistic canopy\n1069.4s: flows and the major key questions we are\n1073.4s: facing now is how do we design the uniso\n1076.12s: problems for the plant canopies\n1080.6s: so in order to do it we implemented\n1083.039s: artificial tree generator comprised of a\n1085.28s: pror branching part and Li structure\n1087.64s: approximating part then we have these\n1089.24s: kinds of synthetic synthetic\n1092.52s: tree if we recognize uh the a dominant\n1098.0s: spaces of the tree in the Target area\n1100.96s: then we can generate uh this kinds of\n1104.24s: synthetic Tree by giving those\n1106.24s: information to the artificial tree\n1108.44s: generator\n1112.12s: if we divide the the tree into two part\n1115.52s: uh the part one is Crown part and part\n1118.0s: two is trunk\n1122.799s: part uh let me uh explain about uh part\n1126.919s: one first and we also implemented\n1129.32s: sampling modules using this module we\n1131.84s: can sample like this uh the smallest\n1135.72s: structure inside of the canopies and\n1138.36s: actually\n1139.919s: this is what have we done so far and\n1143.28s: after here is kind of a plan future\n1146.08s: plans so if we sample here then we can\n1149.559s: extract some geometrical parameter such\n1152.12s: as Pro and canopy area index comprised\n1155.64s: of uh leap area index plus Branch area\n1159.76s: index and we also extract a mean pre\n1163.88s: space between leaves or\n1167.72s: branches and a lot of number of sampling\n1170.96s: gives uh PDF function for each\n1175.12s: parameters and then using based on this\n1179.2s: PDF function we will generate it like\n1181.799s: statistically IDE and representative uh\n1186.08s: unell\n1187.6s: geometry this was for the uh part one\n1191.52s: and part two is much simpler because\n1193.88s: it's only contain like trunk part\n1197.64s: so\n1199.679s: but the un uh basically we will reserve\n1203.2s: it using a boundary condition if if it's\n1205.84s: possible but if not when the grid side\n1209.84s: is much larger than diameter of the\n1211.919s: trunk then we should consider unisell\n1214.12s: problem the size of Unis problem can be\n1216.76s: different depending on the flow\n1218.919s: condition or\n1221.88s: like\n1226.52s: so okay I got it\n1229.28s: so yeah this yeah so it's like for the\n1232.679s: lamina flow the become he this side and\n1236.12s: for the to flow the UN should be much\n1240.159s: larger and this is how this is our idea\n1244.52s: for the how we design the Unis\n1246.96s: problems and using this geometry so\n1249.559s: we're going to train the surate models\n1252.24s: and eventually um we believe that our\n1256.96s: our method can be extend it to like can\n1260.72s: cover a wide range of scales by\n1262.48s: extending it to multiple steps\n1266.64s: recursively and this is summary and\n1270.24s: thank you so\n1275.159s: much thank you so much Jang um we've\n1278.32s: well we are overtime but um hopefully\n1280.0s: people can sa for a couple of questions\n1281.679s: does\n1282.679s: anybody um want to start with a\n1287.52s: question\n1292.44s: uh thank you for our talk uh you already\n1295.4s: uh implement the single cell model\n1298.12s: online right like single like the simp\n1302.24s: like the unit cell model yeah like you\n1304.799s: train the ne Network and you put it in\n1306.44s: theal software and run the online\n1308.52s: simulations yeah we have a procedure but\n1311.36s: like yeah we uh have a\n1315.88s: like\n1317.52s: pardon me you you have finished uh like\n1321.039s: training your new network and you put it\n1323.919s: like couple it into the numerical solver\n1327.0s: and yeah right and you perform some\n1329.24s: simulations right yeah it's for the\n1331.919s: verification stage like we do it with a\n1334.48s: very idealized geometry and then now we\n1337.279s: are trying to move up to the next pce\n1340.32s: with a more realistic geometry so uh did\n1343.36s: you face some numerical instability when\n1346.08s: you round the online train uh online\n1348.2s: like\n1350.6s: uh actually it's not because like our\n1353.48s: server is is discontinuous server so\n1356.279s: even though there is a big difference\n1357.76s: between each sales it can capture some\n1361.76s: like discontinous solution due to that\n1363.88s: thing so it gives some solutions even\n1368.279s: yeah we need to check it this yeah like\n1371.4s: phys physically reasonable or not but\n1374.279s: yeah so far we don't have like\n1376.12s: instability issue yet so\n1379.2s: thank you thank you so\n1385.64s: much hi um what a real world application\n1390.72s: would this apply to like for example\n1392.72s: modeling Wildfire spread or like\n1396.039s: potential\n1398.279s: spread oh okay so like you\n1402.0s: means oh the application area of what\n1405.32s: would this be used for out in the world\n1409.279s: um for example I could see that wind\n1411.799s: moving through a forest would impact\n1413.76s: wildfires that's just an example like if\n1416.32s: you're trying to predict where the\n1417.559s: Wildfire could go and how fast it could\n1420.84s: spread\n1421.91s: [Music]\n1423.48s: um in my opinion our server is like uh\n1427.2s: can provide very high resolution\n1429.32s: simulation for uh uh\n1433.2s: aerodynamical sense so\n1437.44s: um\n1439.039s: before before this method actually is\n1442.12s: the previous studies cannot capture the\n1446.08s: uh like how to say the effect uh the the\n1450.559s: mechanical interaction between the\n1452.96s: canopy structure and wind so it should\n1455.039s: be assumed and like with very powerful\n1459.679s: like simplifications and we she hindered\n1463.919s: the accurate prediction for shortterm\n1467.039s: time so in my opinion it's like as um\n1472.0s: yeah it's\n1474.64s: like uh our method can offer more\n1479.36s: accurate simulation in terms which like\n1482.799s: um wind\n1485.039s: behaviors interact with\n1487.32s: some\n1489.159s: like solid\n1492.159s: structures to\n1495.039s: say and so and\n1498.96s: uh we already checked that our our\n1501.6s: schemes can cover a wide range of like\n1504.88s: uh scales so if we scaling down it\n1508.799s: converg it to DNS and it scaling up it\n1511.72s: converg it to direct force model so it\n1514.36s: has it can a breaching the the the\n1516.76s: missing cap\n1518.24s: so um it can include like existing\n1522.159s: method application but also uh it can\n1525.36s: include it can offer some area the the\n1528.84s: existing scheme does not reserve it\n1532.919s: like is it correct for your oh I'm just\n1536.32s: wondering what what this is used for\n1538.44s: it's okay oh okay it's like what's the\n1541.64s: time frame what the interval 24 hours or\n1545.279s: a week or yeah if you if you want to uh\n1550.12s: like apply our method to larg scales\n1553.12s: then the temp temporary scale ver become\n1556.48s: larger if you want to\n1558.76s: like applied our method to very\n1560.919s: shortterm scale then we can reserve the\n1563.84s: shortterm scale phenomena too because it\n1566.279s: has very wider range of cover isues in\n1569.08s: terms of scales I\n1576.559s: guess thanks for this nice talk uh very\n1581.159s: um\n1581.96s: informing I wonder if um like when you\n1586.279s: see someone doing climate model modeling\n1588.679s: they usually say oh we improved the\n1590.679s: parameterization and now this model is\n1594.12s: outperforming all the rest or uh they're\n1597.44s: using a new formulation say oh no this\n1599.96s: new formulation is now outperforming all\n1602.32s: the rest so but then there is also a lot\n1605.32s: of un uncertainty in different aspects\n1608.84s: um but I wonder in your approach what\n1612.279s: would be or if you have any benchmarks\n1615.96s: to say or showcase that really this is\n1619.96s: an improvement compared to what has been\n1622.399s: done before actually that one is our\n1625.44s: next step to to provide a realistic\n1628.52s: verific validations it's\n1631.86s: [Music]\n1633.64s: like at at this moment the advantage of\n1638.12s: our um like we we checked our advantage\n1642.12s: of our models in terms of mathematical\n1644.72s: aspect so far it mathematically more\n1647.72s: stable and mathematically can cover wide\n1650.159s: range of scales\n1652.399s: so and yeah it's it your your question\n1656.24s: might be our next like next pace so we\n1660.2s: are looking for a very nice um site\n1664.159s: observation data so that we can show our\n1667.6s: superiority compared to existing ones\n1670.6s: the existing method cannot capture but\n1673.08s: our one is captured like yeah it's like\n1676.2s: yeah we're yeah trying to find the good\n1679.399s: application areas like that so but not\n1682.519s: yet I cannot say yeah Aras this my my\n1687.24s: model is always good in in the physical\n1690.36s: application yeah because I don't have\n1692.36s: any EV evidence so yeah let's\n1697.399s: yeah\n1701.159s: yeah and we have a question from the\n1704.0s: chat uh sorry if I put the inflection in\n1707.679s: any weird we places in these words I am\n1710.039s: not a modeler shouldn't it matter that\n1712.72s: the trunks are currently spaced in a\n1714.919s: diamond grid there are genetic\n1717.279s: algorithms for plotting is this what\n1719.08s: you're talking about now like I don't\n1721.12s: think it would be as\n1727.0s: laminer oh okay it's kind of like simple\n1729.919s: schematics it's kind of like uh it's\n1733.399s: kind of a simple schematics examples to\n1735.919s: show you you\n1738.679s: um uh depending on the uh flow and\n1743.36s: the uh geometrical structures the\n1746.72s: unicell can be Chang it\n1754.2s: so so this Arrangement is kind of just\n1757.519s: examples and for the realistic cases we\n1760.72s: will uh uh we will observed uh with like\n1764.919s: remote sensing we can have like some\n1768.36s: more exact uh uh configuration of it\n1772.559s: though when and and here is like yeah it\n1778.159s: uh for the for uh if I compared the\n1781.44s: between the laminar and toin actually\n1783.799s: there was some studies um is it's\n1786.84s: related with the question whether the\n1789.679s: macroscopic toin can survive inside of\n1792.32s: this Pro media uh it it depends on the\n1796.36s: parity and it depends on the poe scale\n1799.519s: length length scale of Poe size and the\n1802.64s: the flow speed uh when the uh the\n1807.039s: procity is quite High then the the\n1810.519s: microscopic tobulance cannot be survived\n1812.559s: inside of the this domain so in in that\n1816.24s: case we can use the unisell problem with\n1819.12s: this blue line but if there is some\n1821.399s: macroscopic structure larger than po\n1823.48s: scale then we should consider larger\n1826.519s: size of the unicell problem\n1828.559s: so in order to address this issues I\n1831.08s: just it's kind of just\n1833.399s: example\n1837.279s: figures do you have a term for the\n1841.039s: distribution of the leads inside your C\n1844.44s: because with wind they you have a yeah\n1849.48s: you have a a\n1853.08s: term\n1856.519s: your no sorry we're at 1:15 we do need\n1859.88s: to respect everyone's time I'm sorry\n1862.12s: thank you thank you so\n1865.559s: much thank you so much thanks for thanks\n1868.48s: everybody um and again sorry for going a\n1870.36s: bit over time but there is pizza and\n1872.039s: some salads in the back and we hope\n1873.48s: you'll stay for our some lunch thanks\n1875.48s: again Jang thank you so\n1882.559s: much"
    },
    {
        "class": "YouTubeVideo",
        "title": "Conservation Laws in a Neural Network Architecture (v0.2.0) with Obin Sturm (USC)",
        "videoId": "aKrml0jXfU0",
        "url": "https://www.youtube.com/watch?v=aKrml0jXfU0",
        "publishedAt": "2024-03-19T17:43:23Z",
        "transcript": "4.04s: I've got a\n5.2s: longer got a longer subtitle down here a\n8.4s: flux based framework for physically\n11.599s: consistent hard constraints in machine\n13.44s: learning models and I'll be talking\n16.16s: about an atmospheric chemistry example\n18.439s: and a few other\n20.72s: applications um and also just the\n23.199s: general framework um which I think is\n27.279s: generalizable to many other potential\n30.039s: machine learning\n31.559s: applications uh so before I dive into it\n35.04s: uh I just want to say takes a village to\n37.96s: raise good research and I want to\n39.48s: acknowledge my mentor on this project um\n42.92s: Tony Wexler uh at Davis at UC Davis\n48.079s: and he was a fantastic collaborator I've\n51.8s: since moved to University of Southern\n54.12s: California where I'm in Sam Silva's\n57.239s: group uh who Sam\n60.719s: gave a leap talk last year and uh I want\n65.36s: to acknowledge my group members who uh\n68.439s: let me test all these slides on them\n71.04s: yesterday and uh have been just a\n74.56s: fantastic team to work\n77.159s: with so want to talk about today is\n82.32s: scientists know a lot about the Earth\n86.079s: system and there's a lot of data out\n89.72s: there\n91.0s: you can apply machine learning tools to\n94.799s: analyze to learn more about the Earth\n99.68s: system connect\n102.799s: those so\n105.079s: the work that I'll be talking about\n107.2s: today embeds domain knowledge into\n110.0s: machine learning models of air quality\n113.759s: and I think this is extendable and\n115.92s: generalizable to most geoscientific\n119.119s: process is uh today I'll set up the\n128.119s: framework then show how it can be\n131.44s: applied to a model of air quality and\n134.879s: then talk about how this relates to\n137.56s: graph Theory network analysis and graph\n140.4s: neural\n141.4s: networks and the motivation here\n147.68s: is we can embed\n150.519s: scientific\n154.56s: knowledge mentals into these new\n158.84s: emerging machine learning tools and\n160.92s: that'll ultimately make them more\n164.519s: scientifically trustworthy and\n167.36s: interpretable\n169.0s: so this is how we can do it we can embed\n172.92s: these machine learning tools with domain\n176.08s: knowledge uh I've thought a lot about\n178.959s: hard constraints there are also soft\n181.12s: ways to do it via the loss function but\n184.319s: we can encourage or strictly enforce\n188.12s: physical consistency there's been a lot\n190.64s: of work on this in the climate um I'm\n194.12s: going to present a non-exhaustive list\n196.319s: so if you don't see if you've done some\n198.84s: a project similar to this and don't see\n200.4s: your work there email it to me um so\n203.799s: there's a list of corrective approaches\n206.48s: corrective hard constraints where um\n210.439s: once some\n213.0s: output from a machine learning model a\n216.76s: machine learning model generates some\n219.48s: output that output is\n222.519s: then adjusted to satisfy some analytical\n226.36s: constraints and so Tom buer has done\n230.64s: some inspiring early work on this with a\n234.48s: focus on conservation of energy but also\n236.72s: a general analytic framework where a PO\n239.84s: portion of the of the targets are\n243.04s: unconstrained and a portion of the\n244.959s: targets are constrained to satisfy some\n247.72s: equation uh Paula Harter who gave a leak\n250.56s: talk uh last year has done this for\n253.56s: aerosol Mass conservation and also\n256.0s: downscaling where they want to make sure\n258.479s: that\n260.68s: the of a bunch of\n263.68s: fine grid cells is equal to the\n268.72s: value of course grid cell and Andrew G\n272.56s: Along With Sam\n273.96s: Silva have done some a similar\n277.0s: application to atmospheric chemistry\n279.52s: using the NASA gscf\n282.44s: data um there are also unsupervised\n285.8s: approaches for encouraging or enforcing\n289.8s: uh Mass\n290.759s: conservation in and so I I've worked on\n293.44s: this for um reduced order modeling of\n297.039s: organic aerosol where we use an\n299.72s: unsupervised approach to find latent\n301.4s: patterns that we called super species\n303.36s: but we made sure that we conserved mass\n306.479s: and phase using uh Matrix\n309.72s: factorization with some scaling factors\n313.96s: we tried a bunch of approaches though\n316.32s: and\n317.44s: then also flux based approaches which I\n320.6s: really the take-home message that I'm\n322.84s: trying to send you all home with today\n325.52s: uh there are these block baced\n328.199s: approaches where you focus on\n331.72s: how these flow between neighbors much\n335.88s: like the process models that learning\n338.8s: tools can emulate or the processes that\n342.08s: machine learning tools can emulate so um\n346.36s: all laying\n348.919s: out maass conserving framework and then\n351.6s: talk about how this can be applied to\n353.039s: smog chemistry and some other\n355.44s: applications\n357.479s: um youall has also done analogous stuff\n362.039s: um uh a lot of this work was actually\n364.639s: done in parallel um both the Tom buler\n368.4s: paper and our original math conserving\n370.08s: framework U which are distinct\n372.0s: approaches were developed in parallel\n374.24s: and Yanni yal also um had a subgrid flux\n379.52s: um targets that his machine learning\n382.319s: tools emulated um so with that I'll get\n387.28s: into the the flux based\n390.599s: conservation law\n394.199s: framework um so there's a lot of ways we\n397.8s: can go about this um I can describe it\n400.039s: in math I can relate it to uh finite\n404.28s: volume methods for solving ordinary\n406.08s: differential equations but I'm going to\n408.199s: try out a new uh visualization on you\n411.36s: all today and I'm going to start with\n413.319s: two boxes we got a closed system with\n415.96s: two boxes uh closed meaning that two\n420.08s: boxes can interact but nothing else can\n422.44s: interact with it think about it as uh\n425.36s: maybe uh two Cloud Parcels that are\n428.16s: otherwise adiabatic or one of the boxes\n431.599s: is a gas phase um concentration and a\n436.96s: particle the other is a particle phase\n438.879s: concentration or them as two distinct\n441.599s: molecules in a chemical system or you\n444.199s: can just think of them as two squares\n445.479s: for now um and these squares these boxes\n450.0s: are neighbors they're next to each\n452.919s: other want to attract some quantity of\n458.4s: Interest tendency over time so how that\n461.8s: quantity of Interest changes C can stand\n465.24s: for anything for now can stand for color\n467.52s: can stand for concentration Columbia\n470.68s: whatever it's our quantity of interest\n473.879s: and so in a process-based model that's\n476.56s: often based on these first principle\n479.759s: whether\n481.199s: it's momentum conservation the\n484.199s: continuity equation uh conserved\n487.879s: quantities will flow between these\n489.68s: Neighbors in a balanced manner right\n491.36s: we'll have these\n495.84s: fluxes\n498.84s: so\n500.4s: the space model moves forward in\n504.36s: time material will flow between these\n507.879s: Neighbors in a balanced way\n511.36s: where we started with with Cals 8 on\n515.32s: this side and C equals 2 on this side\n517.12s: three units of C flowed between the two\n520.08s: boxes leaving them both with five we\n522.479s: didn't add any c to this system okay but\n527.399s: then a lot of work that I've seen throws\n530.72s: unconstrained machine learning models at\n533.959s: this where they they're just trying to\n535.48s: predict C of the two different boxes or\n539.44s: Delta\n540.279s: SE box without\n543.92s: relating global system so what that can\n547.24s: look like is you can just manufacture\n550.279s: these machine learning models can\n551.88s: manufacture this quantity out of thin\n554.0s: air um adding C to the system or it can\n560.16s: slowly move C from the system in a\n562.76s: non-physical way\n566.0s: um this\n567.839s: is process model of a closed\n573.0s: system\n574.6s: be\n576.12s: Stu than air or removing it\n580.24s: non-physically so our conservation law\n583.399s: framework for machine learning reposes\n586.0s: the machine learning targets to be\n588.2s: fluxes so that's our Pink Arrow relating\n592.32s: how the quantity flows between our\n595.68s: boxes between our\n597.839s: neighbors we can the fluxes to\n601.32s: Tendencies balanced manner much like the\n604.279s: process models\n606.8s: that learning tools are trying to model\n610.16s: are trying to machine\n612.76s: learn\n614.48s: so that looks like that um\n618.079s: we that we don't introduce anyc to the\n621.68s: system and this flux based conservation\n625.279s: framework is distinct from some of the\n627.079s: other approaches because it's reposing\n628.8s: the learning t targets but like some\n631.959s: other um approaches like Tom bucer's\n635.0s: analytic constraints it also will\n637.399s: conserve our uh conserved quantities to\n641.079s: machine\n643.2s: precision mean that we've solved the\n645.36s: problem right so the fluxes themselves\n647.56s: can be under or overestimated in a given\n650.2s: time step the\n653.72s: Tendencies exactly match process based\n657.399s: model so our process based model\n659.8s: led to two\n663.48s: evenly colored squares uh but if we\n667.44s: underestimate the flux we might not end\n669.8s: with\n674.48s: that the conservation principle that\n677.12s: we're trying to adhere\n680.959s: to so what this looks like\n684.079s: mathematically and I'll just skip pretty\n686.44s: quickly through the math um but\n692.24s: can formulate the relationship between\n697.04s: Tendencies and\n698.6s: fluxes via some sort of Matrix a often\n703.36s: um and so a relates the actually the\n707.88s: temporal change of C to R the\n710.959s: instantaneous fluxes\n715.079s: and um this is all you need if you're\n718.519s: wanting to use use the serving\n721.8s: framework\n723.48s: flux framework to for a neural\n727.0s: OD does somebody have a question yeah\n729.44s: yes well sorry to interrupt you but I\n731.519s: think yeah we we noticed this on the on\n734.199s: our end too but could you try removing\n736.399s: your uh earphones because what happens\n739.079s: is I think you know when when whenever\n740.959s: the pitch drops uh it's unable to pick\n743.6s: up your voice and so it feels like uh\n746.76s: like we we miss a few seconds of audio\n750.0s: but I think it's just something to do\n751.639s: maybe with just how Apple designs its\n754.56s: headphones or something oh thanks um one\n757.16s: second let\n760.279s: me I think it's a Cadence thing\n778.12s: um\n780.04s: alrighty let's get back on track okay\n783.12s: yeah sorry about that thank you no\n784.92s: thanks thanks for letting me know\n787.399s: um how how's this airpods\n791.199s: ejected okay H yeah I think I think this\n793.639s: should be good okay let me know much\n795.959s: better thanks a lot okay great thanks so\n798.92s: much for telling me um I'll take a look\n801.36s: at these airpods later um this is all\n804.24s: okay because um I'm about to take you to\n808.279s: the main takeway that I want everybody\n810.0s: to leave with anyway so the flux based\n812.88s: framework just relates Tendencies to\n815.32s: fluxes whether or not they're\n816.72s: instantaneous or an integral form um if\n820.36s: you're using a neural\n821.92s: OD and want to use the flux based\n824.12s: framework this first bullet point is all\n826.04s: you need and we'll be able to figure out\n829.48s: how to set up the relationship between\n832.279s: the Tendencies and the fluxes in a\n834.0s: balanced way but if you're wanting to\n836.12s: predict the time Evolution over say an\n839.399s: operator splitting time step in a 3D\n841.639s: climate or air quality model um then you\n846.519s: can\n848.639s: integrate this\n851.519s: forward where s is the integral form of\n856.519s: the instantaneous fluxes and in every\n860.72s: application that I've looked at so far a\n863.079s: is not a function of time the uh\n865.8s: relationship between neighbors um\n870.519s: the the connectivity of the neighbors\n873.48s: rather doesn't change over time um even\n876.8s: though flow of between the neighbors\n879.04s: might so this looks\n881.399s: like in integral form Tendencies are\n885.16s: related to fluxes VI an a matrix and for\n887.6s: our simple example that just looks like\n892.959s: um there was a flux of three C between\n897.0s: these two squares and our a matrix is um\n902.959s: with defines flux to Tendencies with\n906.36s: respect to our leftmost\n908.56s: square and then after um 3 C is removed\n914.12s: from our leftmost square and gained in\n916.959s: our rightmost\n918.32s: Square so the takeaway for this\n922.639s: flux-based machine learn learning uh\n926.279s: conservation approach is if you have the\n930.079s: fluxes Repose your learning targets to\n932.839s: be the fluxes rather than the Tendencies\n935.839s: then you can relate fluxes to neighbors\n938.92s: um fluxes between these these neighbors\n942.639s: um to the Tendencies of each um location\n947.92s: or each box in a way that is balanced V\n951.48s: via this framework and so this is the\n954.72s: that's the take-home message that uh I\n958.519s: if you take one thing out of this talk\n961.0s: that's what I want you to leave with um\n964.16s: fluxes can be excellent learning targets\n966.44s: and that was uh that was the point of\n969.199s: our paper in\n972.639s: 2020\n974.36s: and then our application of interest in\n977.959s: 2020 and perhaps a limitation of the\n980.92s: paper one of many um that I'll get into\n984.16s: is that we Dove right into a few\n987.519s: abstractions um and we didn't talk about\n991.12s: boxes we Dove straight into a non- ukian\n995.959s: air quality\n997.279s: example which I'll get into right now so\n1001.04s: how do we Define neighbors right the\n1002.639s: boxes um we have our two squares and\n1006.24s: they interacted because they were next\n1007.92s: to each other but what if they're not\n1010.24s: next to each other so that's where\n1012.959s: graphs come in and network analysis\n1016.12s: graph theory is a way of formalizing um\n1019.6s: and\n1020.56s: abstracting uh neighbors it's\n1023.92s: generalizing it between Beyond uh\n1026.28s: physical idian\n1028.16s: space so what happens when our uh two\n1031.199s: boxes look more like this graph system\n1034.24s: which uh as I'll get into in a second\n1038.16s: resembles smog\n1041.28s: formation our first application of this\n1043.679s: framework was for machine learning\n1045.319s: emulation of air quality and\n1047.52s: specifically we wanted to conserve atoms\n1050.679s: to machine Precision in a atmospheric\n1053.76s: chemistry model of smog\n1056.96s: formation so how do we Define Neighbors\n1059.16s: in this space and we need a new\n1063.0s: definition of localities so that's where\n1065.64s: graph Theory comes in and Sam Silva had\n1069.48s: uh a very interesting way of looking at\n1073.799s: this using the species reaction graph\n1076.559s: that\n1077.84s: relates\n1079.64s: species as individual nodes to reactions\n1082.52s: which are a distinct set of nodes in a\n1085.12s: bipartite species reaction graph\n1089.08s: framework and this connects species to\n1091.96s: species via\n1093.72s: reactions and that's how we Define\n1096.08s: Neighbors in the\n1098.36s: system I want to talk about the smog air\n1102.6s: quality model briefly that it's\n1105.039s: represented as a graph on the left and\n1108.4s: on the right right is a system of\n1110.64s: reactions uh depending on how you want\n1112.64s: to think about it but what it does is it\n1116.64s: um\n1118.4s: models how uh it it has nox chemistry\n1123.159s: that Cycles to produce ozone in the\n1125.6s: formance in the in the presence of\n1129.159s: volatile organic compounds in our case\n1132.32s: it was form Malahide um so as this\n1135.48s: system progresses ozone can be formed it\n1139.6s: can also be destroyed depending on the\n1142.28s: kinetic and meteorological conditions\n1144.88s: but this was our Baseline model that we\n1148.64s: wanted to constrain a machine learning\n1151.72s: emulator to respect the fundamental um\n1156.88s: carbon and nitrogen atom conservation\n1159.64s: that the process-based model had built\n1162.08s: into\n1163.2s: it and um this photo this little\n1166.84s: photochemical mechanism that I wrote in\n1169.44s: Julia I want to acknowledge Mike ceman\n1172.08s: for giving me a Fortran model um a while\n1175.12s: back has be it's surprisingly become\n1177.6s: this hello world for a few data science\n1180.159s: applications in air quality and um\n1183.159s: authors of these papers have made some\n1185.799s: nicer visuals of the graph Network than\n1188.039s: I have so uh paper that I actually found\n1191.28s: this week\n1193.799s: um shows it like this um this is the\n1197.72s: same photo chemical system of smog\n1200.52s: formation uh shown as a directed uni\n1203.159s: partite hyper multigraph um and there\n1206.799s: are other ways there are loads of ways\n1208.799s: to represent the atmospheric chemical\n1211.159s: system as a graph uh specific\n1213.28s: architecture is useful in the mass\n1215.0s: conserving framework and that's as a\n1217.72s: directed bipartite species reaction\n1220.28s: graph like I mentioned where species and\n1223.12s: reactions are distinct\n1226.559s: nodes so the graph as the mass\n1229.76s: conserving framework how does this\n1231.08s: relate back to the mass conserving\n1232.28s: framework well we have our Tendencies\n1234.52s: related to fluxes and in this case the\n1237.76s: relation is\n1239.64s: a it's the adjacency matrix it's the\n1242.76s: weighted incidence Matrix of the species\n1245.08s: reaction graph so the Tendencies have\n1248.88s: become uh species chemical concentration\n1252.24s: changes and S is the flux Vector in this\n1255.919s: case that's the integrated reaction\n1257.6s: rates\n1259.76s: and a looks like this it's a\n1263.12s: sparse it's a sparse Matrix specifying\n1267.12s: the graph locality of the chemical\n1269.76s: mechanism chemists if there are any\n1271.799s: Chemists in the room or online that is\n1274.919s: often called the story gometric Matrix\n1277.76s: um but it's the bi adjacency Matrix um\n1282.6s: that specifies how the reaction nodes\n1287.279s: are related to\n1289.2s: the species\n1291.559s: nodes and a little bit about this Matrix\n1295.08s: a few other fun facts it's ranked\n1298.96s: efficient\n1301.72s: and and it uh it's it's sparse and rank\n1306.159s: deficient there's no easy way to invert\n1308.679s: it which became a problem and a\n1311.279s: limitation of our first paper that we\n1313.08s: were stuck on for a while um because\n1316.279s: fluxes our s values aren't standard\n1318.96s: output for chemical\n1320.679s: mechanisms so for forward Oiler\n1324.12s: integration in the Julio photochemistry\n1326.64s: mechanism that I wrote we added\n1329.52s: functionality to Output these fluxes\n1332.2s: much like Yan uall did for subgrid\n1334.279s: fluxes in um their 2021\n1338.52s: paper but these fluxes are not standard\n1343.6s: output and actually quite difficult to\n1345.64s: get from standard stiff solvers um\n1351.24s: and moreover we can't just invert a to\n1355.64s: get from the Tendencies fluxes to then\n1360.039s: train our machine learning models on\n1362.039s: because a in our case is ranked\n1364.799s: deficient underdetermined so it becomes\n1367.32s: a hard inverse problem and in our first\n1370.12s: paper we tried a few different\n1372.0s: projection methods to estimate fluxes\n1375.0s: from Tendencies um but they led to\n1377.72s: negative forward fluxes um which in the\n1380.72s: specific example for atmospheric\n1382.6s: chemistry was non-physical some of these\n1385.559s: reaction reactions can only happen um in\n1389.72s: the forward Direction so we were kind of\n1392.159s: at a\n1395.4s: quandry um and how do we get around this\n1398.72s: for atmospheric chemistry\n1402.12s: well then after reading Tom Buckler's\n1405.64s: analytic constraints paper I realized\n1408.2s: that\n1409.44s: we can embed our flux based framework\n1412.44s: directly into the last layer of a neural\n1417.44s: network so when we do that the\n1421.08s: Tendencies can be set as the\n1425.72s: targets and the fluxes become predicted\n1429.72s: just prior to the hard constraints\n1432.4s: layer and the weight the weights of the\n1435.64s: hard constraints layer contain the\n1437.2s: graphical structure of the chemical\n1441.44s: mechanism so this paper was a\n1444.039s: breakthrough for us where we realized\n1446.52s: that we could get around some of the\n1449.84s: limitations of the first work and um\n1453.32s: encode this graph locality in a neural\n1456.679s: network to conserve atoms as they flow\n1459.64s: between\n1460.76s: molecules um we compared this to a few\n1463.96s: other architectures from uh feed forward\n1467.679s: neural network that we called naive um\n1470.2s: maybe that's a little harsh um neural\n1472.559s: networks are pretty powerful and then uh\n1475.159s: a physics constrained neural network and\n1477.159s: we where we also supplied it with um\n1480.72s: physically informed input uh resembling\n1483.64s: the mass action law that drives the\n1486.039s: Dynamics of the system um and we also\n1488.84s: had an intermediate neuron Network that\n1491.039s: had the physically informed input\n1492.96s: without the hard\n1494.72s: constraints\n1496.6s: um and we found that adding this\n1498.919s: physical information improved prediction\n1501.159s: somewhat where up here for two different\n1503.96s: species we did look at all the species\n1506.559s: but um I'll show ozone and no no is a uh\n1511.399s: Prim often a primary pollutant from car\n1514.679s: uh exhaust pipes um\n1517.6s: and the adding yeah go for it uh can you\n1522.76s: go back to the previous slide or the one\n1524.76s: before that actually yeah uh I'm a bit\n1527.48s: confused as to\n1529.0s: okay so U I think I think I understand\n1531.679s: why the constraints are are important\n1534.44s: and how that's solved um against the\n1537.559s: problem with the first model but I'm I'm\n1539.88s: unclear as to like what like are you\n1542.76s: training on on like model\n1546.799s: output so are you emulating a model and\n1549.279s: then enforcing the constraints to\n1551.2s: extract the conservation laws or are you\n1553.52s: writing the model from scratch because I\n1555.679s: am slightly thrown up the Julia based\n1557.6s: photochemical model model like where\n1559.279s: does jul enter into the scene\n1562.279s: um and is this like sort of like fit\n1565.0s: into the Julia model and now that has\n1566.96s: become the full\n1568.24s: emulator no the um the Julia based\n1572.159s: photochemical model was just our our\n1574.039s: reference model so that's that's our\n1577.2s: kind of bread and butter ress based\n1580.48s: model um and\n1584.0s: uh yeah the Julia part isn't too uh too\n1587.919s: important\n1588.76s: unless you're into the programming\n1590.32s: language in that case happy to talk\n1592.64s: about it more but um it's it was really\n1595.12s: just the reference model that we were\n1596.36s: trying to emulate that being said and\n1598.76s: and actually we did all the machine\n1599.799s: learning in Python anyway okay no no but\n1603.159s: I mean the ultimate question being of\n1604.88s: course not language but like is this\n1606.6s: online or offline so if this is an\n1608.559s: offline emulator then yeah and because\n1611.64s: if it's online then it becomes\n1613.0s: interesting which I don't think it\n1615.32s: is yeah wow yeah that would be that that\n1618.72s: would be really really interesting so we\n1621.08s: have um I've since tried some like\n1623.2s: neural OD approaches um with the same\n1626.64s: constraints built in um but yeah I\n1630.44s: haven't really thought\n1632.039s: about it it was offline and it just\n1634.76s: tried to predict uh time increments of\n1637.2s: about six minutes which is like a kind\n1640.48s: of operator splitting time step in um in\n1643.96s: case you would put this chemical\n1645.679s: mechanism into like a 3D air quality\n1647.84s: model\n1649.72s: make sense yep very clear thank you hi\n1653.08s: can I can I interrupt yeah go for it\n1656.08s: yeah I have a question so so in this\n1658.399s: figure on the right so the a is a\n1661.399s: deterministic like you like The Matrix\n1663.679s: you show like The Green a on the right\n1667.2s: yeah yeah so it's a hard constraint that\n1670.0s: we actually hardcoded and um for so for\n1674.44s: the case of chemistry it's the uh it's a\n1678.36s: stochiometric\n1680.279s: matrix it's the it's the incidence\n1683.519s: Matrix of the species reaction graph and\n1686.32s: it encodes some conservation laws in our\n1689.76s: case conservation of carbon and\n1692.32s: nitrogen yes thanks and then what about\n1695.399s: the the pink M and the CI and CJ on the\n1699.519s: left lost there the CI and CJ that is\n1703.44s: our physically ined input that those are\n1707.279s: the products of concentrations and those\n1710.0s: um it's physically important because\n1711.799s: we're using domain knowledge here and uh\n1714.72s: that that is proportional to the mass\n1718.36s: action law which is the driving force of\n1721.6s: this photochemical system m stands for\n1724.399s: meteorological input that's like\n1726.96s: temperature and oh okay yeah relative\n1731.36s: humidity yeah sure thing um and so we\n1737.399s: found that adding this physically\n1739.559s: informed input um improves the\n1742.679s: predictions and um so for both the\n1745.919s: intermediate neural network that only\n1747.799s: had the physically informed input and\n1751.24s: for uh the flux based conservation law\n1757.24s: neural network we improve predictions\n1759.44s: over a baseline model um and that is\n1763.08s: especially that was especially true in\n1765.32s: edge cases um where the chemical system\n1768.12s: was really far\n1769.279s: from some sort of pseudo equilibrium\n1771.96s: where things weren't happening as fast\n1774.519s: and um this has some analogies to\n1777.76s: actually the project talked Sam talked\n1779.559s: about at leap last year where um\n1782.64s: physically adding some physical\n1784.88s: process-based information to a neural\n1787.279s: network benefited their um their neural\n1791.559s: network prediction of aerosol activation\n1793.36s: in edge\n1794.919s: cases\n1797.039s: um but moving onward this framework\n1801.48s: didn't work for all species and um the\n1804.24s: main failure point of this for the for\n1807.64s: the air quality machine learning neuron\n1810.84s: network was that we failed to predict\n1814.159s: the concentration of O and uh recent\n1817.64s: work there was a good agu talk by Peter\n1820.08s: ivet um that suggesting that some s\n1823.08s: short Liv species if we're trying to use\n1825.279s: machine learning to predict their\n1826.84s: evolution we might be better off\n1829.039s: predicting their concentrations rather\n1830.799s: than their tendencies in this case I\n1833.48s: also want to say that o hydroxy radical\n1837.279s: is um doesn't have carbon or nitrogen\n1841.76s: and\n1842.84s: so uh it\n1845.679s: didn't didn't have any of those atom\n1848.96s: conservation constraints on it\n1851.559s: anyway um and finally the main result\n1856.48s: and what we wanted to check uh just to\n1858.84s: make sure that we got the framework\n1860.279s: right is that uh this FRA the the\n1866.639s: physics constrained neural network\n1869.0s: didn't add or remove any carbon atoms\n1872.519s: over time this is the residuals or the\n1875.96s: net carbon added um on the left side and\n1879.6s: on the right side that's the net\n1880.88s: nitrogen added and despite the\n1883.24s: intermediate neural network doing quite\n1886.24s: well just by having some phys physically\n1888.96s: informed input it didn't respect the\n1895.08s: inherent atom balance that the process\n1896.84s: based model did so when we embedded the\n1899.2s: flux based framework into the last layer\n1902.639s: of the neural network we were able to\n1905.76s: conserve atoms to machine Precision so\n1909.08s: that was the take away of our air\n1912.88s: quality uh application and I want to\n1916.6s: take a little bit of time to talk about\n1918.919s: um some other things because I know not\n1921.24s: everybody here thinks about atmospheric\n1923.08s: chemistry every day um so I wanted to\n1926.44s: get into a microphysics example um\n1931.2s: which does not which is a little bit\n1934.639s: different than the atmospheric chemistry\n1937.039s: example um in this slide I'll just lay\n1939.6s: it out uh so let's say that you wanted\n1942.799s: to make a machine learned emulator of\n1946.159s: evaporation and condensation of aerosol\n1949.12s: species it could be a system of aerosol\n1951.679s: species or it um could be a single\n1954.799s: aerosol species let's think about a\n1956.88s: single aerosol species in maybe a\n1961.279s: discretized bin or sectional model\n1964.0s: depending on if you're a cloud or an\n1965.919s: aerosol um modeler and\n1969.76s: so\n1971.559s: the Sylvester arabis in his leap talk\n1974.48s: last month talked about or two months\n1976.48s: ago talked about um the Mosaic aerosol\n1981.48s: microphysics scheme microphysics and uh\n1985.08s: thermodynamics and it\n1987.039s: discretizes the radius space which leads\n1990.519s: us to a system of stiff ordinary\n1992.88s: differential equations here's some math\n1996.44s: um where describing how the\n1999.24s: concentration of aerosol species in each\n2002.36s: size bin changes and the concentration\n2005.919s: of gas based species in uh changes as a\n2010.08s: function of both gas phase and aerosol\n2014.32s: phase\n2015.32s: concentrations and uh this is a mass\n2019.519s: transfer problem uh that governs the\n2023.84s: microphysical interactions of\n2026.6s: condensation and\n2028.639s: evaporation\n2030.44s: uh if we wanted to turn this if we\n2033.36s: wanted to vectorize this OD system it\n2035.96s: looks a little something like this\n2038.559s: um where\n2040.799s: A1\n2042.399s: um looks\n2044.6s: like that and so if you made it to\n2048.2s: appendix a of the 2022 paper thanks for\n2051.159s: reading if you made it if you didn't but\n2053.399s: you made it to this part of the talk\n2055.0s: also thanks for listening um because\n2058.48s: this is showing that the framework is a\n2062.679s: little bit more generalizable uh and it\n2065.839s: doesn't just apply to air quality\n2068.24s: uh or or smog formation it also has\n2071.639s: other potential applications one thing\n2073.56s: I'd like to say about this this Matrix\n2076.599s: here it's also sparse just like\n2080.359s: the just like the bi adjacency Matrix\n2083.76s: for the smog chemistry example but it's\n2087.639s: actually\n2089.159s: overdetermined which means that if you\n2092.52s: didn't have fluxes but you had\n2094.2s: Tendencies from a from a reference model\n2097.079s: that you wanted to ulate you could\n2099.68s: invert you could use a pseudo inverse to\n2103.28s: a left pseudo inverse to invert this\n2105.44s: Matrix to get a unique set of\n2109.88s: fluxes from the Tendencies alone so you\n2113.079s: wouldn't have to dig for the fluxes and\n2115.24s: you could use the mass conserving\n2117.16s: framework in its original form not the\n2120.079s: directly embedded into a neural network\n2124.68s: form I also want to briefly talk about\n2127.32s: some applications of the flux based\n2129.64s: framework which um I'm excited to see uh\n2133.56s: has been taken up um so uh mono park\n2138.48s: over at University of Illinois is\n2140.72s: working on uh using it to make sure that\n2144.64s: advective transport in the atmosphere\n2146.64s: when winds blow stuff around uh you\n2149.48s: don't create mass in new grid cells it\n2152.599s: just gets moved around the system um and\n2156.64s: if you're you want want to learn more\n2158.44s: about this model gave an excellent talk\n2160.44s: at uh Journal club that uh I along with\n2165.119s: Makoto help and some other people host\n2168.16s: um called slack statistical learning and\n2170.28s: Atmospheric\n2171.88s: chemistry um the intive transport a\n2175.28s: matrix looks a lot more like our two\n2177.319s: squares here um because it's relating G\n2182.839s: uh uh flow between flow of um property\n2187.72s: interest in this case a\n2189.319s: concentration uh of some particulate\n2193.359s: matter between um grid cells on a\n2196.76s: regular grid so you can really think of\n2199.599s: this the flux based framework for\n2201.64s: Effective transport as a bunch of these\n2203.76s: squares and learning the fluxes at the\n2206.04s: boundaries of our grid\n2209.319s: cells um this framework has also been\n2212.359s: extended to other um chemistry\n2214.88s: applications uh so where they embed the\n2217.16s: sto geometry the graph locality of the\n2220.24s: chemical mechanism into a neural network\n2222.52s: to learn some kinetic parameters what's\n2224.64s: driving the\n2226.64s: process um this has also been applied to\n2229.96s: evolution of organic aerosol over the\n2232.4s: Amazon and last\n2235.079s: year\n2237.16s: and I would be curious um while I've\n2241.76s: I've got a few more slides but if you\n2243.68s: have any ideas about how you could apply\n2246.28s: this framework to your research I'm game\n2248.76s: to talk about it\n2251.48s: um so I have a few more slides and i'\n2254.119s: just like to touch on some other um some\n2257.64s: other topics on conservation laws hard\n2259.76s: constraints and machine learning so\n2262.24s: outside of the flux based framework um\n2264.44s: you can also enforce hard constraints in\n2267.48s: this case mad Mass conservation in\n2269.8s: unsupervised learning so um I in a\n2274.48s: previous project that I put out last\n2276.24s: year we had um a model we had a pretty\n2282.04s: complex organic aerosol model that was\n2286.079s: used in that uh the lotos Euros\n2289.52s: transport model wanted to use because it\n2291.88s: had a\n2293.0s: realistic uh description of how organic\n2296.64s: aerosol ages and evolves in the\n2299.839s: atmosphere and in it's called a\n2303.079s: volatility basis set and is similar to a\n2306.52s: bin or section\n2308.28s: model but instead of discretizing over\n2311.92s: radius bins you discretize over\n2315.079s: volatility um\n2317.119s: saturation Vapor concentration of uh\n2321.16s: species and you lump Mass into these\n2323.16s: different volatility bins uh and so we\n2326.4s: wanted to find a set of super species uh\n2329.04s: reduced form uh reduced set of latent\n2334.68s: Dimensions that we called super species\n2336.92s: that could\n2338.0s: um represent\n2340.119s: the uh the high dimensional complex OA\n2344.4s: chemistry and so what we did is we used\n2347.04s: non- negative Matrix factorization and\n2349.44s: some scaling factors to make sure that\n2351.28s: we conserved mass and phase so that\n2355.24s: particle super\n2357.079s: species were made up of the individual\n2363.64s: high-dimensional uh species that they\n2365.68s: were um that the unsup\n2367.88s: vised approach was uh trained on and so\n2372.64s: all that to say that we used that to\n2376.28s: compress\n2377.88s: the high dimensional space down to\n2381.0s: superp species in a way that conserved\n2383.04s: mass and then we transported the uh we\n2388.319s: transported these reduced form super\n2390.64s: species to speed up the advection\n2393.04s: operator and facilitate uh using a more\n2397.56s: istic organic aerosol uh scheme in a\n2401.4s: chemical transport model in an air\n2403.2s: quality model that is used in air\n2405.359s: quality forecast for Europe so that's an\n2408.96s: example of how unsupervised learning can\n2410.96s: have hard\n2412.8s: constraints um but I also wanted to say\n2415.359s: unsupervised approaches can discover\n2418.24s: additional hard constraints\n2420.68s: so going back to this um Julia mechanism\n2425.599s: this this photochemical smog\n2428.079s: uh\n2428.92s: mechanism\n2430.599s: we in the flux based framework\n2434.079s: we in we enforced carbon and nitrogen\n2437.92s: atom conservation because we knew that\n2439.8s: the process based model did that but we\n2444.359s: using a data driven method we found that\n2446.28s: it actually has an a third invariant\n2448.68s: property that we're going to call cq3 or\n2452.96s: third conserved quantity that over a\n2455.2s: range of atmospheric conditions\n2458.0s: is invariant it stays the it just\n2462.68s: doesn't change it is a linear\n2464.16s: combination of species concentrations\n2466.839s: that does not change no matter where we\n2470.4s: put our air parcel uh with where the\n2474.28s: chemistry is going on so it can be at\n2476.28s: the surface or it can be up\n2479.24s: higher or in Denver however you want to\n2481.96s: think about it um and so we used uh this\n2486.16s: was a fun collaboration with jiming L\n2489.079s: and Max Tark and we when we discovered\n2492.96s: it we didn't really know what to make of\n2495.16s: it we scratched our heads and tried a\n2497.64s: few things out on it um but this is kind\n2500.92s: of a success story for in terms of\n2503.28s: scientific communication we put out the\n2505.64s: paper and then earlier this week I saw\n2508.359s: that there was an answer to it and on\n2511.359s: archive somebody has explained this\n2515.16s: invariant property that we discovered\n2518.04s: using a data driven method um and they\n2521.04s: have a physical explanation for it that\n2523.2s: checks out that makes a lot of sense\n2525.88s: um and that that's Alex block House's\n2530.72s: paper and they have a nice uh diagram of\n2534.24s: the chemical system where they explain\n2536.92s: what this co-production law as they call\n2539.52s: it is and how it\n2542.319s: arises so this is my last slide and I\n2544.92s: want to end on some takeaways um\n2549.92s: so this conservation law framework\n2552.48s: leverages domain knowledge as a hard\n2555.48s: constraint um to ensure physical\n2560.04s: consistency in machine learning models\n2562.4s: and that's within machine\n2564.8s: Precision the this is a flux based\n2567.72s: framework distinct from other strict\n2570.92s: constraint approaches and it relates\n2573.559s: fluxes between neighbors to tendencies\n2578.0s: by\n2578.88s: embedding the graph locality of the\n2581.52s: neighbors into neural\n2584.359s: networks by embedding\n2588.04s: these uh fundamental process the the\n2592.2s: same fundamental balances that the\n2593.96s: process models use into machine learning\n2598.0s: uh we can conserve our quantities of\n2600.0s: interest to machine prision in the same\n2603.24s: way that the fundamental\n2606.119s: balances do rather than\n2609.52s: uh trying to satisfy some Global\n2612.04s: constraint we instead use the exact same\n2614.559s: balances that the process models are\n2621.599s: um and\n2623.4s: so oops I want\n2633.079s: to wait did you um my my PowerPoint is\n2638.24s: actually\n2639.839s: uh Frozen but uh I well while the other\n2645.88s: stuff loads I just want to say um the\n2649.64s: embedding the graph locality into neural\n2651.52s: networks\n2653.52s: um means that we uh don't need to\n2658.319s: machine learn the fluxes we don't need\n2660.28s: those as learning targets we can train\n2661.96s: them on Tendencies which are more\n2664.119s: readily available um\n2667.92s: sorry um let me end on my last two\n2670.839s: points\n2672.04s: here\n2677.96s: um\n2685.92s: oh sorry one\n2696.04s: second\n2698.98s: [Music]\n2705.839s: um all\n2709.48s: righty funny that this happened on my\n2711.559s: takeaway slide but\n2714.24s: um I wanted to just leave with two\n2717.839s: questions um I I'm curious if this\n2720.559s: framework could allow us to machine\n2722.4s: learning to machine learn fluxes and\n2725.76s: hidden interactions\n2727.839s: um without necessarily access to them as\n2731.24s: explicit learning targets um I'd be\n2733.599s: curious to see that um because we're\n2737.0s: embedding this flux based framework into\n2739.96s: the neural network it back propagates\n2743.16s: interpretability so we know that the um\n2746.88s: the output or the output of a hidden\n2749.16s: layer should correspond to fluxes which\n2753.119s: we might not have access to otherwise so\n2755.599s: if we task a neural network with this\n2757.76s: framework embedded to it on Tendencies\n2760.68s: can we get\n2762.24s: fluxes somewhere in the hidden layer of\n2764.8s: a neural network and wanted to end on\n2768.28s: the last question\n2769.72s: on how would you apply this framework to\n2773.04s: your\n2775.44s: research um that's that's it thanks for\n2778.76s: listening everybody and I'm happy to\n2780.44s: talk about um any of\n2783.119s: this thank\n2785.92s: you\n2791.68s: um any questions in the\n2795.52s: room um so how important is here this\n2799.76s: cicj as an extra input and would you get\n2804.04s: similar results if you would leave it\n2807.16s: out um yeah that's that's the kind of\n2809.88s: the the fourth quadrant that we didn't\n2812.92s: that we didn't look at um in in the\n2815.24s: paper at least um\n2818.24s: I think it's pretty it it was clearly\n2821.48s: pretty important if you want me to go\n2823.119s: back it\n2826.16s: um it led to improvements in predictions\n2830.079s: uh we didn't try just the physical\n2832.8s: constraints without the physics informed\n2836.48s: constraints\n2838.04s: um I don't know but it's pretty\n2840.48s: important because those inputs um if I\n2844.079s: go back here these uh products of\n2846.92s: concentrations are proportional to the\n2849.599s: mass action law which drives the system\n2851.8s: forward so I'd say they're pretty\n2853.839s: important just using domain\n2857.0s: knowledge okay\n2863.68s: thanks uh questions online\n2866.64s: or feel free to unmute yourself and jump\n2872.2s: in I had a quick question if you can\n2875.4s: hear me yeah I can hear you okay um I\n2878.64s: was just curious as a as a Julia myself\n2882.76s: why do you use your model in Julia and\n2885.28s: then do all the machine learning and\n2886.48s: python instead of just using Julia yeah\n2890.96s: um I started it yeah good good question\n2893.88s: I'm not sure if flux\n2896.8s: umj packages were um out when I was\n2900.28s: first trying to do this um in\n2903.16s: 2019\n2905.28s: um that's I don't have a good reason it\n2908.88s: uh it was just python had uh a\n2912.48s: great a few good contenders for\n2915.24s: libraries and um Julia didn't\n2921.0s: necessarily got it\n2923.839s: thanks it's come a long way of\n2935.28s: course I have another question yeah go\n2938.319s: for it yeah I so in this case so is your\n2942.28s: model I me I'm assuming it's an oian\n2944.52s: model right or like uh at least yeah\n2948.72s: more oian the lran and I wonder um so\n2952.28s: yeah the flux based framework it it sort\n2954.24s: of Demands like a certain um continuity\n2958.079s: like you know you need to\n2959.52s: know uh like between these these\n2961.96s: neighbors and so on like they like you\n2964.559s: know basically you need a like a\n2966.119s: continuous re reaction I wonder if\n2968.16s: you've looked at\n2969.96s: some environments where this is not the\n2972.799s: case so what happens you know when it's\n2974.88s: a dilute uh sort of situation where I'm\n2979.28s: saying this because I've been working\n2980.52s: with lran models currently so I'm I'm\n2983.72s: thinking here like you know I don't know\n2986.559s: uh\n2987.48s: solar uh like radiation management so\n2990.359s: like statosphere aerosol injection right\n2992.92s: um yeah uh and in which case I mean I'm\n2996.04s: wondering if if these sort of\n2997.72s: conservation laws hold or like if these\n3000.2s: kind of Frameworks hold um I don't know\n3002.799s: this is just vaguely speculating U like\n3007.559s: it's a v vaguely speculative question\n3009.24s: I'm curious if You' thought about this\n3012.52s: yeah I I do some work with uh lran Cloud\n3016.839s: models myself and I've I've been trying\n3018.64s: to think of a way to apply this to the\n3020.799s: flux space work super droplets um super\n3025.599s: droplets have their own weird conserved\n3027.599s: quantity which is the number of Super\n3029.359s: droplets doesn't change even as the\n3031.24s: number of particles are changing um just\n3034.559s: side so uh for for like the two squares\n3039.119s: that's such an oian perspective right\n3041.68s: that's that's two neighboring squares\n3044.52s: interacting um I'm not sure if you see\n3047.839s: it but I I don't necessarily see how the\n3050.04s: chemical mechanism is oian um we have um\n3057.359s: it's it's it's it's it's not ukian at\n3059.76s: all right so we have a different way of\n3063.24s: relating neighbors and um I I I just\n3067.44s: don't have an easy answer to whether or\n3069.16s: not this graph based structure\n3073.72s: is oian legian because it's got distinct\n3079.559s: um distinct things that we're tracking\n3081.92s: continuous concentrations for or a third\n3085.64s: thing entirely\n3087.24s: um yeah so I can't I can't quite answer\n3090.119s: your question because I'm not sure if\n3091.64s: our initial application was\n3095.4s: either yeah I mean yeah maybe maybe the\n3098.44s: the the correct thing to say would be\n3101.68s: well like the flow itself could be o\n3104.559s: Arian so even if the the uh the the\n3108.0s: graph that you're modeling is somewhere\n3110.799s: in between it maybe not adhere to either\n3114.319s: regime it could still be that\n3117.24s: um like the Dynamics that are sort of\n3118.96s: driving this like uh well not the well I\n3122.76s: guess I guess they they are being ined\n3125.119s: under some flow uh so that that could be\n3128.079s: the oil Arian uh system there um yeah it\n3133.76s: it could be applied to let's say we had\n3136.44s: a bunch of like little little lran\n3138.599s: Parcels or whatever floating around\n3140.96s: these squares so we have like you know\n3142.76s: some sort of oil Arian lran interaction\n3145.559s: here um at any point the flow between a\n3149.48s: little Arian parol and its more bulk\n3153.0s: environment could still be constrained\n3155.16s: using this flux based framework does\n3156.68s: that make sense yeah very cool no that's\n3158.799s: exactly what I was trying to get at but\n3161.319s: yeah I think this is a there's a longer\n3163.04s: conversation which I won't like totally\n3165.72s: and I'm happy to continue it um\n3168.599s: definitely especially with the super\n3169.72s: droplets yeah we've been thinking about\n3171.4s: that there um I'm curious what you think\n3173.52s: of uh what's a good\n3175.44s: approach yeah I I don't have a great\n3178.44s: answer for um for using an approach like\n3184.0s: the the the flux based approach for\n3185.799s: super droplets yet um but it's certainly\n3190.16s: interesting to think about it yeah yeah\n3191.599s: I'm happy to talk about this more\n3193.799s: offline yep I mean online but like\n3197.119s: offline this\n3200.24s: conversation oh yeah yeah yeah true true\n3204.559s: true okay there's a question that chat\n3206.96s: from\n3208.24s: Makoto all righty Makoto you still there\n3212.079s: you want to just ask it oh I can I can\n3215.16s: just ask this I guess sorry um so I'm\n3217.72s: curious the first part of question does\n3219.76s: embedding the physical based constraints\n3222.04s: decrease the accuracy of the prediction\n3223.92s: as if there's is there a tradeoff in\n3225.96s: doing this by kind of putting these hard\n3229.359s: constraints in and two you're showing\n3232.839s: this kind of schematic of going from a\n3235.2s: graph net to a neural net and defining\n3238.839s: the connections of the graph you know\n3240.559s: makes sense for this kind of low\n3242.16s: dimensional mechanism but when you scale\n3243.839s: it up to something with hundreds of\n3246.64s: species does is this you know still an\n3250.68s: easy way to do this do you have to is\n3254.04s: there an automatic way to construct the\n3255.559s: graph and then translate that into a\n3257.0s: neural network format or is this all\n3259.24s: kind of you know by hand still\n3262.319s: tuning well makot you're asking me about\n3264.88s: my kpp work um\n3267.0s: the the other we get slack and that's a\n3269.4s: lot of what the kpp work is just you\n3271.72s: know generating these graphs as edgeless\n3274.359s: sparse edgeless uh automatically and um\n3279.4s: so to answer your questions in reverse\n3281.319s: order in terms of the tractability as\n3285.119s: the mechanisms get large um the a matrix\n3288.64s: that I'm not going to skip to uh skip\n3291.16s: back to right now um was a sparse Matrix\n3294.92s: and uh\n3297.079s: we don't it's not it's not like a fully\n3298.76s: connected graph where we need to connect\n3301.0s: 300 species um all to 900 reactions um\n3307.88s: the it's a much sparer space than that\n3311.16s: um so we wouldn't I don't think it would\n3313.16s: be that much of an issue um and the to\n3317.319s: answer the first question does the\n3319.04s: embedding the constraints decrease the\n3320.52s: accuracy of the prediction\n3323.44s: um this uh\n3329.68s: I'm not sure because we looked we added\n3333.599s: two things at the same time and we\n3335.44s: didn't do the like the earlier\n3338.48s: question did we just trying try\n3341.4s: embedding the hard constraints without\n3342.839s: the physically informed input um and we\n3346.039s: did not do that in the paper um so that\n3348.92s: would be something to explore that being\n3351.559s: said uh those hard constraints they're\n3354.92s: not arbit they're not kind of global\n3357.44s: hard constraints where you um just\n3361.119s: unconstraint some of the input and then\n3363.599s: hard constrain others to satisfy a\n3365.96s: global constraint it specifies how each\n3370.359s: Target each each element in the Target\n3372.92s: Vector interacts with each other so if\n3376.2s: you're trying to use graph neural\n3377.92s: networks to motivate um the buils in uh\n3383.4s: structure of the system that you're\n3384.88s: looking at um\n3387.039s: this framework allows you to build those\n3389.92s: hard constraints in in a way that\n3392.16s: encodes domain\n3395.96s: knowledge great thanks Oben yeah thanks\n3399.0s: for\n3401.28s: COD I seee if there are no further\n3403.68s: questions we thank openin\n3409.64s: again thanks\n3412.0s: everybody awesome\n3415.24s: uming"
    },
    {
        "class": "YouTubeVideo",
        "title": "2023 Train-the-Trainer Bootcamp Day 1: Climate and Geospatial Data Analysis",
        "videoId": "jm5Lb9lQdQQ",
        "url": "https://www.youtube.com/watch?v=jm5Lb9lQdQQ",
        "publishedAt": "2023-01-17T22:40:06Z",
        "transcript": "No transcript available"
    },
    {
        "class": "YouTubeVideo",
        "title": "A Bayesian-Gamma Deep Learning Approach to Capture Heavy-Tailed Behavior in the ClimSim Dataset",
        "videoId": "P4AFQRBsdo4",
        "url": "https://www.youtube.com/watch?v=P4AFQRBsdo4",
        "publishedAt": "2023-08-02T18:18:17Z",
        "transcript": "5.94s: um yeah okay my name is um Sebastian\n7.68s: Romania and I'm a rising sophomore at\n9.54s: Columbia studying um computer science\n11.58s: and operations research and my project\n14.519s: is focused on capturing heavy tail\n16.5s: behavior in the Clinton data set\n19.02s: so first for some background Mark did a\n21.72s: great job at explaining how in the\n23.82s: precipitation variable we see a lot of\n25.619s: extreme values and that's kind of\n27.96s: similar well that is what a heavy tail\n29.88s: Behavior a heavy tail variable is\n32.88s: because we see especially like around\n35.04s: like the edges of the distribution\n37.62s: um compared to a normal distribution\n38.94s: there's a higher concentration of\n41.04s: extreme values and specifically with\n43.2s: precipitation or climate variables this\n45.18s: is really important to predict because\n46.86s: we want to be more aware of extreme\n49.079s: phenomenon\n50.76s: um and also it's really important in the\n53.219s: scope of machine learning because a lot\n55.32s: of machine learning techniques nowadays\n57.84s: um use a loss function called mean\n59.399s: squared error and MSC loss doesn't\n62.34s: um assume a heavy till distribution it\n65.28s: assumes a normal distribution so that\n67.74s: heavy tail Behavior might not be fully\n69.78s: captured by using an MSE loss or a\n73.439s: normal\n74.4s: distribution prior trained um machine\n77.28s: learning or neural network uh so that's\n80.64s: kind of the background as to why I\n82.68s: decided to focus on this\n85.56s: and for my methodology the first step\n87.72s: was to pre-process the data so I focused\n89.7s: on the precipitation variable in the\n91.439s: Clemson data set because just uh\n93.78s: universally precipitation data does have\n96.96s: um it does show pretty strong heavy tail\n99.479s: Behavior Uh and so there's a lot of\n102.24s: pre-processing and log normal\n103.86s: transformations to do taking the raw\n106.2s: data\n107.28s: um which is like shaped in this like\n108.84s: gamma distribution and then filtering\n110.52s: out the values which are very very close\n113.159s: to zero the scale is about uh 10 to the\n116.82s: negative 8 10 to the negative nine and\n119.7s: at that point uh the data can kind of\n122.46s: conflict with the Transformations later\n125.28s: on\n126.479s: um so yeah filtering out those really\n128.039s: low values by experimenting with\n129.66s: different thresholds and finding the one\n131.099s: that's best capturing heavy tail\n133.2s: Behavior while still filtering out\n134.7s: unnecessary data and then we apply like\n137.76s: a log normal transformation to see a\n140.76s: different shape of the data as well\n142.26s: which is going to play\n143.7s: um into the picture later on with the\n145.5s: Bayesian neural network and then we can\n147.9s: also visualize the heavy tail Behavior\n149.58s: by using these QQ plots so these are\n151.92s: quantile quantile plots and they\n153.48s: basically show us how um these uh these\n157.379s: uh distributions are shaping according\n159.66s: to a normal distribution so from this\n161.76s: slide you can see on the right how a\n163.98s: normal QQ plot is kind of straight and a\n165.84s: heavy tail Kiki plot has this very\n167.819s: interesting skew\n169.62s: um for both the left and the right sides\n171.54s: of the distribution in this case it's\n174.06s: because there's a lot of uniform values\n175.86s: on the left side that skews more\n177.36s: prominent on the right side so you can\n178.8s: see that in both of these and you can\n180.3s: also see how once we apply the log\n182.04s: normal transformation that skew is less\n184.019s: evident but it is certainly still there\n188.34s: and um then this was a big part of uh\n192.78s: the research so understanding a Bayesian\n194.7s: neural network architecture I was really\n196.8s: interested in using evasion neural\n198.48s: network\n199.2s: um also called like a BNN I'm creating\n201.239s: that term\n202.56s: um because Bayesian inference is taking\n204.78s: into account prior information or prior\n207.84s: like hypotheses and then\n210.659s: kind of using that to\n213.3s: Aid the training along the way but in\n216.0s: this case we want to really be focusing\n217.5s: on the shape of the distribution so in a\n219.72s: Bayesian neural network model we can\n221.58s: input weights into our neural network\n223.2s: but also look at specific prior and\n225.54s: posterior distributions and see how\n227.519s: those are changing along the layers and\n229.56s: really try to focus on getting our why\n233.28s: um in this case the precipitation\n234.959s: variable to to follow that heavy tail\n237.54s: distribution at the end of our training\n239.7s: and the loss function that we're using\n241.319s: for this is the nll or negative log\n243.18s: likelihood loss so if we think of it as\n245.64s: like a maximum likelihood estimation\n247.92s: problem we want to maximize the\n250.92s: likelihood by minimizing to minimize the\n253.56s: loss value so this is just an example\n255.72s: with a normal PDF and that would be\n258.54s: translated to\n260.22s: um different uh a different nll loss\n263.46s: depending on what prior distribution\n265.8s: we're setting\n268.86s: so yeah and then um looking into some\n271.08s: possible Beijing priors based on the\n273.06s: shapes of our data uh so we can see from\n275.699s: this very interesting curve of our\n277.919s: filtered precipitation data it looks\n279.9s: very similar to a gamma PDF so I had\n282.18s: this kind of like preconception going in\n284.22s: oh maybe the gamma uh prior would be a\n287.639s: good estimator\n289.02s: um for this data and then we can also\n291.06s: see once we apply the log normal\n292.62s: transformation it looks kind of similar\n294.72s: to Akashi prior uh that like heavy tail\n297.3s: distribution\n298.5s: um but also we can experiment with log\n300.12s: normal or gaussian priors just to see\n302.1s: how different metrics are scoping in the\n305.04s: Bayesian neural network setup and then\n307.62s: that's like uh my model set up with the\n309.84s: layers and then um looking specifically\n312.0s: at the distribution Lambda for our\n313.8s: output\n316.38s: okay um and so this is a baseline this\n319.8s: uh so the scaling is a bit off so it\n321.9s: looks really weird in the plot um but\n323.88s: this is actually just really\n324.96s: concentrated so that's why it looks like\n326.88s: a line but it's actually a distribution\n328.44s: just very concentrated\n330.6s: um and we can see from our loss we do\n332.82s: have a decent loss value\n335.34s: um but a lot of the data this doesn't\n337.56s: like we can see that it just isn't\n339.66s: correct there is something very wrong\n341.639s: with this and I I kind of hypothesized\n344.46s: at this point maybe it's because we're\n345.96s: not taking into account the distribution\n347.4s: as much as we should but then when we\n349.5s: look at once we start using the Bayesian\n351.479s: neural network model\n353.52s: um the model prediction versus actual\n355.56s: data um kind of visualize as a histogram\n358.139s: does look a lot more you know it looks\n361.86s: better and so we can see the prediction\n364.68s: versus the actual here and then we can\n367.02s: also see in our loss values the R square\n369.539s: values are negative which is not a good\n371.52s: sign\n372.24s: um but I have a few hypotheses about why\n374.4s: that is I think it might be just because\n375.96s: of the the quantity of data so while the\n378.3s: distribution seems similar it's not\n380.34s: perfect and anything that's outlying is\n383.699s: going to be really\n385.02s: um like the magnitude is really going to\n386.52s: be increased because just the sheer\n387.96s: number of data points which might work\n389.52s: against us in the rsphere uh test so\n392.88s: yeah I think uh for future research\n395.1s: definitely doing some some more\n396.66s: correlation based tactics and kind of\n398.699s: trying to do Scatter Plots and visualize\n400.44s: the data that way might be helpful in\n403.259s: improving this and then this is with the\n405.84s: gaussian prior filtered on the log\n408.3s: normal data with the nll loss we can see\n411.18s: this is a step closer to what we want to\n413.699s: get to\n414.72s: um but there is definitely still\n416.4s: something missing in terms of like\n417.84s: capturing like the tail Behavior Uh for\n420.78s: the prediction predicted versus actual\n422.699s: histogram\n424.38s: um and then I also tried um for our\n426.96s: gamma prior approach so the gamma prior\n429.539s: can be applied both to the log normal\n431.28s: data and to the regular filter data\n433.5s: which is really\n435.0s: um really interesting\n436.8s: um and yeah I saw that uh we can see\n438.9s: from like the loss functions it's\n440.099s: training well but also the prediction\n442.199s: does seem to be much more accurate in\n444.24s: both cases which is really interesting\n446.099s: as well\n449.22s: um so yeah I found like uh just through\n451.68s: my initial testing and I've only been\n453.24s: working on this for a few weeks because\n454.74s: I kind of switched from creating my own\n456.84s: loss function which was based on like\n458.28s: quantile regression to this problem uh\n460.8s: just a couple weeks ago after a really\n462.9s: good suggestion from Professor Grant so\n464.819s: I do really appreciate that because I'm\n466.86s: really happy with the work that I've\n468.18s: done and I hope to be able to continue\n469.5s: and uh kind of work on this a bit more\n472.199s: um but we can see that the best uh the\n474.72s: in my opinion the best predictor was the\n477.06s: the gamma prior uh the Bayesian neural\n479.699s: network scheme with the gamma prior\n480.96s: distributions not only did it both work\n482.94s: for the log normal and the filtered data\n485.039s: but\n486.3s: um the loss values and um the the\n489.599s: piercing correlation coefficient values\n491.639s: are quite good as well\n493.5s: um and the best uh the best correlation\n496.319s: was um I mean the\n499.02s: yeah and that that that uh continued\n502.08s: with all the standard metrics which is\n504.3s: really interesting as well\n506.099s: okay and then some takeaways and future\n508.139s: research opportunities with this uh we\n510.84s: can definitely see the benefits of using\n512.279s: a BNN because the uh in the histograms\n515.459s: we can see that the shape of the\n516.539s: distribution is much more effectively\n518.7s: conveyed after uh training with the BNN\n521.339s: architecture\n523.14s: um and we can also see that the uh the\n528.06s: most effective prior network uh the most\n531.18s: effective prior distribution\n533.64s: um is very dependent on the shape of the\n535.56s: Y data so this might not be\n537.6s: generalizable to other shapes of\n539.16s: distributions that might require other\n541.26s: uh training with different prior\n542.82s: distributions\n544.38s: um but definitely for heavy till\n545.82s: distributions and this can hopefully be\n547.92s: generalized to other variables in the\n549.839s: Clinton data set as well maybe like the\n552.06s: solar uh solar insulation box I believe\n555.899s: um and uh the input and output for that\n558.54s: we can see maybe this can be generalized\n561.0s: to those approaches as well and for\n563.64s: future research actually with climate\n565.5s: change unfortunately there is a an\n569.339s: increase in extreme behavior for a lot\n572.16s: of climate variables not just\n574.2s: precipitation but\n576.24s: um many other variables as well so there\n578.64s: is a growing importance in predicting\n580.32s: heavy-tailed Behavior Uh and there are\n583.2s: like a lot of opportunities for taking\n585.779s: this further by visualizing successful\n587.82s: predictions with QQ plots and looking\n590.459s: more into other accuracy metrics as well\n592.44s: so yeah I think that was my presentation\n596.339s: they'll take any questions and I do also\n598.8s: just want to say thank you so much to\n601.08s: all of our mentors for all the health\n602.58s: throughout this process but I'll do q a\n604.44s: first\n617.6s: presentation\n619.38s: um I wanted to ask more about the setup\n622.74s: so\n624.42s: um what exactly is your input data how\n627.06s: many dimensions does it have how many\n629.04s: trading samples do you have\n631.08s: oh yeah yeah\n633.42s: um so we input data in this case so I\n636.06s: just used for my ex uh the specific\n638.58s: humidity and the pressure I believe for\n641.22s: the input data and then the output is\n643.74s: going to be the precipitation variable\n645.36s: which is uh as Mark described created by\n648.06s: combining the rain rate and the snow\n649.98s: rate\n651.18s: um and then the dimensionality it's\n653.279s: quite large they're about I think\n655.8s: trying to think of the exact number it\n658.5s: changes depending on the amount of\n659.94s: filtering you do so the threshold that\n661.5s: you choose actually really impacts the\n663.6s: shape of the data pre and post\n665.22s: normalization\n667.079s: um but I think I had somewhere in the\n669.72s: hundreds of thousands of data samples uh\n672.6s: I want to say\n674.04s: I want to say consistently above 200\n676.68s: 000.\n677.64s: um so yeah and I'm I think definitely\n680.04s: this this result would also be dependent\n682.079s: on the size of the data because that is\n683.94s: very important in the shape of the\n685.74s: distribution as well so yeah\n690.72s: um yeah I just have a comment for you\n693.06s: and Sammy actually because you both had\n696.72s: uh negative ask where it could indicate\n699.66s: that your bias from the neural network\n702.0s: is even larger than the variance of the\n705.12s: neural network of the of the prediction\n707.7s: value of the target itself\n710.399s: so\n711.959s: yeah I think maybe you can try further\n714.54s: tuning the parameters of the neural\n716.64s: networks I think you both use the\n718.14s: relatives more neural network set up or\n721.079s: maybe later you can try some different\n723.18s: tuning\n725.04s: for the network yeah\n726.839s: yeah I think that would be really\n728.22s: interesting and I don't feel like sami's\n729.959s: gonna say this but we were actually\n730.92s: thinking about like an ensemble approach\n733.019s: too between uh between like the\n736.079s: variational autoencoders and kind of\n739.019s: this concept because those do assume\n741.06s: like a normal distribution for the data\n742.86s: and it could be interesting to see how\n744.839s: changing the shape of distribution would\n746.64s: affect the accuracy of the predictions\n749.279s: so yeah\n753.26s: can you go back to your results table\n756.839s: yes\n758.42s: so when you're calculating like the\n760.62s: regularized and non-regularized laws\n762.66s: those values are MSE right\n765.48s: so kind of\n767.579s: um the reason why I had to do that not\n769.44s: only well first it was because once he\n771.72s: applied the log the scale of the data\n773.639s: completely changes so the the the\n776.399s: whatever loss value you're getting\n779.339s: um could be similar but it might not\n781.2s: necessarily reflect the same thing when\n783.12s: it's compared to the overall data\n785.519s: um and then also the nll loss and the\n788.519s: mean squared error loss Just Between the\n790.139s: Baseline and then the training for the\n791.579s: Bayesian neural networks\n793.26s: um is completely different in the sense\n795.18s: that with NLS you can actually have like\n797.22s: pretty high like negative values like uh\n799.74s: you can see\n801.0s: in this plot like we actually have like\n802.92s: a loss of negative 16 which in any other\n805.44s: setting would be like what is going on\n806.82s: but with nll\n808.56s: um I think because it's e to the\n810.06s: negative 16\n811.38s: um that would be like the in scale that\n813.66s: becomes something around like 10 uh I\n816.6s: would say like the scale of 10 to the\n818.579s: negative 9 I believe\n820.5s: um and then when you look at it uh in\n824.459s: into into perspective with the actual\n826.68s: data values you end up with the\n828.72s: regularized loss function so just so\n830.76s: that it can be translatable between MSC\n832.56s: and lll I had to kind of that\n835.98s: okay\n838.5s: you might like would that be a reason\n840.6s: why the loss for like the uh sorry King\n843.54s: goodbye because it looks like a direct\n846.0s: like just a spike\n849.06s: like could that be why the spike has\n851.16s: such a low loss because like the loss\n853.079s: there is Embassy that doesn't oh that's\n855.6s: a good metric this this loss the one\n857.76s: that's like a gas in Prior but it's just\n859.8s: like a spike\n861.48s: wait let me see\n864.92s: on the left\n868.139s: oh this one yeah like is that why the\n870.66s: loss might be so low because the Lost\n872.76s: metric being used was actually like not\n875.1s: good\n877.44s: um oh you're saying like the mean\n878.88s: squared error loss is not applicable\n880.56s: there I think that could be interesting\n882.12s: looking into and that's what I was doing\n883.62s: actually before I kind of switched into\n885.12s: the Bayesian\n886.44s: um framework looking at how different\n888.18s: loss functions are affecting\n890.699s: um the outputted uh data after training\n893.519s: with the neural network so yeah I did\n895.32s: find that\n896.519s: um they're like there are a lot of other\n898.199s: approaches and I think quantile\n899.82s: regression loss would probably be like a\n901.92s: really good approach to take here\n903.06s: because we want to once again look more\n905.339s: at the shape of distributions and try to\n907.32s: like minimize the distance in the\n909.06s: quantile quantile plots so yeah that\n910.86s: could be interesting\n914.22s: thanks thank you"
    },
    {
        "class": "YouTubeVideo",
        "title": "Emulating Cloud Droplets in a Climate Model with Sam Silva",
        "videoId": "V7UZS4Ct_zU",
        "url": "https://www.youtube.com/watch?v=V7UZS4Ct_zU",
        "publishedAt": "2023-04-21T02:39:37Z",
        "transcript": "4.22s: okay so um thanks everyone for coming uh\n7.859s: today we have Sam Silva sorry I need to\n10.98s: look at my notes um he's currently an\n13.08s: assistant professor in the department of\n14.639s: Earth sciences and the Department of\n16.379s: Civil and environmental engineering at\n17.64s: the University of Southern California\n19.859s: um so today he's going to be talking to\n21.359s: us about\n22.439s: um physically regularized machine\n23.88s: learning emulation of aerosol Activation\n25.74s: so if you want to take it away\n28.56s: you can hear great yeah thank you and uh\n31.98s: just one note\n33.66s: um the building I'm in right now has\n35.219s: been doing this very very fun thing\n37.079s: where sometimes the internet just stops\n38.88s: and there's no warning and it's a\n40.739s: stochastic process that no one can\n42.48s: predict so if there are issues with\n44.52s: connectivity or I need to repeat\n45.6s: anything please let me know that's just\n47.579s: the the way the way it goes with zoom um\n50.1s: so I'd appreciate that so great yeah I'm\n52.86s: Sam Silva I'm an assistant professor at\n54.42s: the University of Southern California\n55.32s: and um and uh I'd like to get right into\n58.739s: it so first I just want to acknowledge\n60.12s: some collaborators at this work this is\n62.52s: work that started when I was a data\n64.799s: scientist at the Pacific Northwest\n65.76s: National Lab and has since continued\n68.34s: into my time here at USC I've had a\n70.38s: bunch of great collaborators they're\n71.52s: listed here um it's been helpful in a\n73.619s: variety of different contexts from both\n76.26s: the National Labs universities and\n79.26s: um private private companies\n81.84s: so to get started uh the the research\n84.479s: that we do in my group is really all\n86.04s: about atmospheric chemistry and\n87.42s: composition uh and mostly because we're\n90.18s: very interested in why the chemical\n92.64s: composition of the atmosphere and how\n93.84s: the chemical composition of the\n94.92s: atmosphere is relevant to two modern\n96.6s: environmental crises air quality and\n98.34s: climate change and today I'm going to be\n100.259s: discussing uh some work we've been doing\n101.88s: focusing on the the climate aspect of\n105.24s: this uh this this major research Focus\n108.72s: so I don't need to really\n111.6s: um spend too much time on this I think\n113.22s: for this audience we all have are\n114.96s: broadly motivated by studying climate\n116.82s: but just to broadly state right the\n118.2s: impacts of climate change are large and\n120.0s: far-reaching I'm showing here uh the uh\n124.02s: CO2 concentration with respect to time\n126.119s: from about 1960 to roughly present day\n129.239s: at Mauna Loa you see this Stark increase\n132.12s: in CO2 concentrations and associated\n133.92s: with that has been a large change in in\n136.68s: the earth system from changes to\n139.379s: um\n140.22s: acute extreme events like severe weather\n142.98s: as well as longer term changes\n145.56s: um to to the environmental State\n147.739s: alluding to\n149.64s: um\n150.26s: impacts like like drought and so on\n153.72s: and the important thing to note about\n155.34s: this and the thing that is is really\n156.78s: relevant to my work is that uh all all\n159.66s: of or atmospheric composition is is a\n162.36s: real primary driver of climate change so\n164.519s: what you're looking at here is a figure\n165.66s: from the ipcc in 2021 every time the\n168.72s: ipcc comes out uh they have a version of\n171.239s: this figure and everyone in the\n172.56s: atmospheric composition Community gets\n173.94s: really excited and wants to be the first\n175.44s: one to post it to Twitter so you get the\n177.0s: most likes and retweets and all that\n178.8s: good stuff but what you're looking at is\n180.06s: the here is the simulated temperature\n182.58s: contribution from a variety of radiative\n184.98s: forcing agents this is a temperature\n186.599s: contribution the change in temperature\n187.86s: from 2019 relative to 1750. and on the\n191.819s: y-axis you see various climate forcing\n193.92s: agents carbon dioxide is on the top\n195.9s: flomix greenhouse gases is below ozone\n198.36s: water vapor Albedo aerosol and so on\n202.14s: and they're split by natural and an\n203.94s: antibodynamic sources and the real key\n205.56s: take-home Point here is that nearly all\n207.42s: of these processes on or or all of these\n210.18s: factors these forcing agents on the\n212.519s: y-axis are tied in some way to the\n215.76s: chemical composition of the atmosphere\n218.94s: and so a major research question that\n220.68s: we're trying to uh get after in in my\n222.599s: group and I know many many on this call\n224.22s: are also interested in this is how we\n226.14s: can use data science and machine\n227.099s: learning\n227.959s: methods to address problems in in\n231.62s: Earth system science research how we can\n234.659s: design better computation computational\n236.34s: systems and gain more insight from data\n238.2s: and in particular with respect to the\n240.78s: image I showed on the previous slide\n242.22s: really interested in how we can use\n243.9s: machine learning to address some of the\n245.459s: uncertainty some of the error bars\n247.08s: associated with the overall magnitudes\n249.659s: predicted here and it's worth noting\n251.64s: that for aerosol and a particular\n253.379s: aerosol Cloud interactions the error bar\n255.659s: is the largest right so this is the\n258.12s: largest error bar in terms of the impact\n260.28s: of the forcing agent on our\n262.74s: on the the total change in surface\n266.46s: temperature and so in many respects\n269.1s: aerosol and aerosol Cloud interactions\n271.32s: are the largest or one of the largest\n274.08s: uncertainties on our understanding of\n275.58s: the physical climate system and so we're\n277.86s: really interested in in trying to reduce\n279.72s: that uncertainty\n281.22s: um through a variety of means and one\n283.86s: particular process that we're interested\n285.72s: in that has garnered a lot of attention\n287.699s: for being a potential cause of some of\n289.56s: this uncertainty is what is is a process\n291.72s: known as aerosol activation\n293.94s: right so um the direct formation of\n297.96s: cloud droplets through condensation of\n300.6s: liquid water alone\n302.88s: it's thermodynamically very unfavorable\n304.56s: in the atmosphere and it turns out that\n305.88s: nearly all Cloud droplets form through\n308.4s: heterogeneous interactions with aerosol\n311.04s: in the atmosphere and\n313.56s: the process by which this happens is\n315.36s: aerosol ultimately\n317.28s: um Can can become suitable for cloud\n319.38s: droplets to form on them through a\n320.639s: process known as activation and and um\n323.4s: and that is uh that is really what we're\n325.5s: interested in here it's a critical\n326.759s: component of aerosol Cloud interactions\n328.56s: and uh really initiates the vast\n331.38s: majority of the aerosol Collide\n332.4s: interactions that that happen in the\n334.979s: overall Earth system\n337.08s: so it turns out that numerically\n339.539s: simulating all of the processes relevant\n342.0s: to aerosol activation which occurs on\n344.039s: the scale of an individual aerosol in\n345.72s: matter and and things like micro scale\n348.36s: um\n349.02s: surface tension and chemistry and so on\n350.82s: are are very relevant we're trying to\n353.1s: simulate that in a climate model with\n354.539s: grid spacings of hundreds of kilometers\n356.52s: is far too computationally expensive to\n359.4s: be to be routinely used in in global\n361.32s: climate model simulations and so instead\n363.24s: we've developed a variety of\n364.62s: parameterizations these\n365.699s: parameterizations are skillful and fast\n368.28s: but there are known limitations\n372.06s: and these these are some of the\n373.5s: limitations that um I I have been very\n376.02s: interested in over the past couple of\n377.52s: years focused on on this work\n380.52s: when you\n383.1s: run these parametrizations in models and\n386.46s: then compare them to a detailed but slow\n389.28s: parametrization you find that Mo that\n391.68s: many models have uh parameterizations\n394.02s: that are fairly low and this is an\n395.34s: example from the does Earth System model\n397.319s: e3sm the parametrization they're using\n399.539s: for aerosol activation for those of you\n401.52s: who are super into this stuff is the\n402.72s: Abdul rezak and Gan ARG scheme this is a\n404.94s: very widely used parameterization and it\n407.039s: predicts the fraction of aerosol in a\n409.259s: given location\n410.46s: that are activated and are then able to\n413.46s: to form Cloud droplets and participate\n415.319s: in aerosol Cloud interactions in some\n418.44s: interesting ways so this is a value that\n420.36s: ranges from zero to one and you see the\n422.639s: the parameterization is shown here on\n424.08s: the left and the difference between the\n425.699s: parameterization and\n427.56s: um a truth truth is in quotes this is a\n429.6s: truth as uh as a detailed parcel model\n433.02s: that is that is has the latest and\n434.699s: greatest physics but in chemistry but is\n436.8s: slow right you can see the difference\n438.66s: between those two is that in general the\n440.94s: parameterization tends to be biased low\n442.62s: and it tends to be biased low in\n444.12s: particular over certain regions like\n446.46s: East Asia where there are very high\n448.199s: aerosol concentrations and this is uh no\n450.539s: this is a well-known limitation of this\n452.819s: scheme and so what we're interested in\n454.74s: is if we could develop high quality\n456.24s: machine learning parameterizations to\n457.8s: help\n459.539s: address this issue right um I think\n462.539s: trying to\n464.28s: um address uh limitations in Earth\n467.16s: system models is something that a lot of\n468.539s: folks affiliated with leap have have\n470.22s: been interested in from and a machine\n473.46s: learning perspective and we definitely\n474.9s: took inspiration from the work of some\n477.539s: of the folks who are here on this call\n479.58s: so\n480.78s: to start with we wanted to work with a\n482.88s: case study some some offline uh data\n485.699s: that was relatively simple to handle and\n487.86s: relatively simple to work with to even\n489.599s: demonstrate that this technique could\n490.919s: even work in this case because of course\n492.8s: machine learning for for prediction\n494.94s: doesn't always work in all cases and so\n496.919s: we wanted to start with with something\n498.06s: simple and offline and here what we're\n500.4s: interested in using is\n502.44s: the differences in prediction between a\n506.879s: detailed Cloud parcel model this is a a\n509.36s: detailed but slow model that could not\n511.68s: be used in a nervous system model but\n512.94s: has the latest and greatest physics and\n514.5s: compare that with the parameterization\n516.3s: numerical approximation from the Abdul\n518.76s: razak and Gans game this is what I\n520.2s: showed on the previous slide and we want\n522.0s: to predict the fraction of aerosol\n523.68s: activated and the performance of that\n525.0s: original scheme\n526.44s: is shown here on\n528.899s: uh in in this figure where on the on the\n531.48s: x-axis you have what we're considering\n532.98s: the truth here this is the detailed but\n535.26s: slow model and on the y-axis we have the\n538.44s: existing parameterization right this\n540.3s: quantity varies from zero to one because\n541.8s: we're predicting a fraction of aerosol\n543.48s: in a given location that are activated\n546.12s: and you can see uh broadly that the the\n549.68s: parameterization tends to do a fairly\n551.459s: decent job the one-to-one line is shown\n552.899s: as red the two to one lines are shown in\n554.58s: in blue in general we cluster pretty\n556.8s: closely on that one-to-one line with\n558.12s: with some some reasonably substantial uh\n561.3s: spread\n562.32s: and so we're interested if machine\n564.18s: learning um methods could you could do a\n566.64s: better job and to do this we were using\n569.04s: a data driven modeling approach where we\n571.019s: take some input data use that to drive a\n573.12s: data driven model estimates an output\n574.62s: quantity compare our estimated output to\n576.6s: what the true value is and use that\n577.86s: difference to refine the parameters in a\n579.24s: data driven model this is essentially\n580.68s: just training in a machine learning\n582.36s: model context\n583.56s: here we're using model input variables\n586.56s: so these are our input variables that\n588.24s: would be simulated in an earth System\n589.62s: model\n590.7s: using that for most of the stock I'm\n592.62s: going to talk about deep learning\n593.459s: regression models but we did try some\n594.899s: other machine learning techniques as\n596.1s: well use that to predict the fraction of\n598.08s: aerosol activated this act Frac value\n600.3s: compare that with the truth and then use\n602.519s: that difference to refine all of the\n603.839s: parameters within our deep learning\n605.519s: regression model\n607.62s: now what that actually looks like from a\n609.66s: structural perspective is our input\n611.16s: variables are things like aerosol size\n613.019s: number hydroscopicity and vertical\n615.42s: velocity and our prediction or the\n617.22s: output is the fraction of aerosol\n619.019s: activated and the neural network we used\n621.6s: was a fairly small\n625.26s: um neural network with with three hidden\n627.0s: layers and\n629.1s: um and then and then each node of course\n631.38s: computes a non-linear activation\n633.779s: function on top of some some linear\n635.459s: operations so again we take as input\n637.44s: variables\n638.82s: um parameters related to the\n640.14s: meteorological state that we know Drive\n642.54s: uh aerosol Activation so these are the\n644.76s: inputs to the actual parameterization\n647.519s: um as as they would exist in an earth\n649.44s: System model\n650.64s: we predict the fraction of aerosol\n652.5s: activated\n653.76s: and uh the reason being is because we\n656.04s: actually want to use this online in an\n657.54s: earth System model right we're not just\n658.98s: interested in training this method to\n661.98s: just show that in this toy example we\n664.019s: can develop good predictions we actually\n665.88s: want to get this online into the e3sm or\n668.94s: in other other system models as well\n672.06s: and then we use a relu activation\n674.7s: function it looks like there's something\n676.26s: in our chat um\n680.959s: so yeah\n682.86s: um Jerry Lynn asked how do we Design\n684.24s: This architecture I can talk about hyper\n685.8s: parameter tuning uh later on but\n687.899s: essentially\n689.339s: um this particular architecture we use\n691.38s: the Keras tuner uh hyper parameter\n693.36s: optimization\n694.64s: package and I think we used a hyperband\n697.98s: search parameters in fact I know we use\n699.66s: hyperband and I searched across a wide\n701.339s: variety of ranges here\n703.2s: um\n704.04s: but the architecture that we chose was\n706.079s: indeed a trade-off between keeping the\n708.3s: model reasonably small because at\n710.7s: inference time a very large model still\n713.339s: takes some amount of time to predict and\n715.2s: we need this to be fast if we're going\n717.18s: to use it in an earth System model which\n718.8s: when I you know ask all the folks\n721.62s: um in in the model development team if I\n723.18s: can have you know half the compute\n724.8s: devoted to my one deep learning\n726.959s: regression model they said no so then\n728.7s: you know you need to keep things\n729.6s: reasonably quick and so\n732.66s: um to please let me know if I missed\n734.579s: anything else that pops into the chat\n735.72s: I'm not super super excellent at\n737.64s: monitoring that in real time so of\n740.519s: course with with a um\n742.8s: a regression model such as this what you\n745.079s: really need is sufficient data to\n746.399s: optimize all the different weights and\n747.6s: biases and to do that we were able to\n749.94s: artificially generate as much data as we\n751.86s: wanted in this initial test case and in\n754.38s: the paper I sent along we generated 20\n757.74s: 000 realizations of the\n759.839s: um slow but but detailed parcel model\n762.3s: using Latin hyper group sampling across\n764.399s: the input space so across realistic\n766.74s: aerosol size and aerosol number\n768.899s: distributions realistic higher splicity\n770.94s: and so on and so forth\n772.74s: um again the goal is to predict the\n775.5s: activation fraction and with inputs of\n777.899s: aerosol and meteorological parameters\n780.54s: and the real take home message is of\n782.459s: course um that that this works right\n784.26s: I'll show that first on this slide with\n786.48s: um\n787.019s: again this is a figure that you've seen\n788.519s: before this is the existing\n789.66s: parameterization that's widely used in\n791.279s: many many Earth system models with the\n793.68s: parametrization on the y-axis and the\n796.079s: truth as we're saying it here on the\n798.06s: x-axis and we compare that to something\n800.16s: like a deep neural network you see that\n801.959s: you get a significantly better\n803.279s: performance right I want to note that\n805.44s: we've tried other emulator methods as\n807.3s: well and I'll touch a bit on those in in\n809.16s: the coming slides but what we're really\n811.32s: interested in here is that this was this\n812.76s: was fairly straightforward right this\n814.2s: deep neural network that we trained was\n815.639s: not particularly challenging to\n819.06s: construct and we had some more time on\n820.68s: the project and we're really interested\n821.88s: in how we could improve this accuracy\n823.68s: even further\n825.36s: and in particular how we can improve the\n828.36s: accuracy further but still end up with a\n831.48s: neural network or machine learning\n832.86s: approach that could be easily integrated\n835.32s: into a modern Fortran based Earth System\n838.139s: model so what does that mean that means\n840.0s: that really Advanced Techniques\n843.3s: um you know a complex model\n844.56s: architectures with various skip\n846.12s: connections and recurrence and\n848.519s: um you know spatial awareness and so on\n850.26s: those can give you very very good\n852.24s: predictions but actually getting that\n853.98s: online into a Fortran based Earth System\n855.72s: model is a really big Challenge and the\n857.519s: tools for that are still being developed\n858.779s: and I think should be developed that\n859.98s: should be supported\n861.42s: um because I think that's that's one of\n863.7s: the big big challenges we'll be facing\n865.5s: and I'll touch more on that a little bit\n866.519s: as well\n867.66s: um so so what we were interested in is\n869.1s: just this this process of implicit\n871.2s: regularization through known physics\n873.0s: right um in um the the sort of broad\n876.839s: sense regularization is the process of\n878.76s: adding information in order to help\n880.26s: solve an ill post problem or prevent\n881.82s: overfitting\n883.38s: um there are a bunch of ways to do this\n885.36s: and here\n886.56s: um we we are interested in this from\n888.24s: from changing the the the way in which\n890.88s: we predict from this what were we termed\n893.16s: sort of physically naive approach this\n894.54s: is the typical way that I have used\n896.76s: machine learning in my own research and\n898.68s: many of us do in the earth Sciences\n900.72s: where we take some set of inputs use\n902.519s: that\n903.48s: um use that to to drive a machine\n905.16s: learning prediction model and predict\n906.42s: some quantity in this physically\n908.88s: regularized approaches we've called it\n910.199s: here you first calculate\n912.959s: a um you first calculate a quantity that\n916.019s: you're interested in and then on top of\n919.019s: that run a machine learning approach to\n920.94s: help get you more closer closer to the\n923.1s: truth other ways of thinking about this\n924.72s: could be residual learning bias\n926.279s: correction learning hybrid learning and\n927.839s: so on the important thing here is that\n929.579s: this is a very straightforward technique\n932.459s: to implement in a modern Nervous System\n934.32s: model right we already have in in Earth\n936.779s: system models ways to calculate the\n938.639s: activation fraction using existing\n940.92s: knowledge using the ARG scheme here that\n943.079s: I described previously and so all we're\n945.18s: doing is we're taking that calculation\n946.68s: and then adding to it some prediction\n949.019s: from the machine learning model approach\n951.54s: to get us a better overall prediction of\n954.36s: the quantity that we care about here\n955.8s: which is the activated activation\n958.26s: fraction\n960.66s: um I want to note that there are of\n962.1s: course far more advanced ways to add\n964.079s: physical information into into neural\n967.139s: networks I have some students working on\n968.339s: that in my group Tom beukler and and\n970.139s: others have done a really fantastic job\n972.18s: of this\n973.32s: um but but this was our sort of first\n975.24s: approach to to get something\n976.98s: um that we could actually work with in a\n978.72s: model development space and the key\n981.0s: take-home message here is that adding\n982.86s: this physical information improves the\n984.6s: parameterization predictive skill right\n986.519s: so on now on the left you're seeing the\n988.44s: basic neural network and what I just\n989.76s: popped in is the Deep neural network as\n992.88s: regularized in this in this language by\n996.0s: the ARG scheme and you can see a much\n997.92s: tighter fit much closer to that one to\n999.48s: one line\n1000.38s: and things tend to look much better now\n1003.56s: it's worth noting and I'm I'm happy to\n1005.54s: be able to talk to to a group of people\n1006.98s: who are very interested in machine\n1008.54s: learning and learning in general so I\n1009.8s: can get into these these gory details\n1012.32s: that sometimes I avoid is that the\n1013.579s: quality of the physical information that\n1014.839s: you add matters and model classification\n1017.779s: model type still matters so what you're\n1020.18s: looking at here now is a similar set of\n1022.579s: figures but just multiple painters\n1024.02s: panels with the emulator prediction on\n1027.199s: the y-axis and the parcel model truth\n1029.839s: right this detailed but slow model on\n1032.6s: the x-axis\n1034.16s: for three different model types for this\n1036.319s: ARG regularization the first is just a\n1038.179s: linear regression with\n1040.339s: multiple linear regression with a ridge\n1041.839s: penalty that is to keep the uh to try to\n1045.079s: deal with\n1046.16s: um\n1047.0s: issues associated with with\n1048.62s: autocorrelation and any individual\n1050.0s: coefficient getting too large then XG\n1051.919s: boosts boosted regression trees and the\n1055.16s: Deep neural network that you saw before\n1056.36s: and you can see that the high capacity\n1059.059s: non-linear approaches like XC boost and\n1060.98s: a neural network tend to perform better\n1062.72s: than the ridge regression however we can\n1065.48s: still get pretty good prediction with\n1066.919s: just a linear linear ridge ridge\n1068.96s: correction there\n1070.88s: um\n1072.14s: it looks like\n1073.64s: um\n1074.72s: Marcus asked if the outliers are from\n1077.059s: the physical or the neural network model\n1078.62s: the outliers that were predicting\n1080.66s: in in this this regularized approach are\n1083.299s: first from We're predicting the outliers\n1085.16s: or the residuals from the\n1088.64s: um\n1090.2s: from the ARG scheme I'm not sure if I\n1091.76s: entirely understand your question\n1093.44s: um you can of course chime in and just\n1095.24s: chat as well if you'd like\n1098.96s: um again so this what I've shown here is\n1101.48s: this this regularization from the ARG\n1103.28s: scheme but we have other ways of\n1105.5s: predicting aerosol activation and one\n1107.66s: that I was really excited about was\n1109.16s: using techniques from a paper that was\n1111.2s: published in the 1950s uh from Sean\n1113.72s: Toomey it's famous for the Tumi effect\n1115.76s: this is a very very simple\n1118.64s: um\n1119.24s: power law relationship to try to\n1121.46s: calculate the aerosol that are activated\n1123.62s: it is unbounded meaning uh in in the\n1126.38s: positive direction meaning that it can\n1127.58s: predict anywhere from zero aerosol or\n1129.44s: activated to infinite aerosol activated\n1131.84s: this of course presents some issues in\n1134.0s: the fact that there are not infinite\n1135.26s: aerosol in a given location and you can\n1137.66s: see that that this this relatively quite\n1140.6s: simple and great crude approximation\n1141.919s: from the 1950s does not provide the\n1145.88s: additional benefit for prediction that\n1148.46s: the um the existing parameterizations do\n1150.799s: in particular you can see for example\n1152.36s: the linear correction predicting I'm far\n1154.46s: outside of the bounds of zero to one\n1157.22s: in terms which of course in terms of a\n1159.26s: fraction violates conservation of of\n1161.299s: mass\n1163.4s: uh the last thing I'll say about the\n1165.02s: details of of\n1167.48s: a lot of the ml underneath the hood is\n1169.7s: that the impact of this regularization\n1171.08s: decreases with model complexity right\n1173.24s: I'm showing that here for now the mean\n1174.799s: squared error on the y-axis and model\n1177.919s: complexity on the x-axis here this is\n1179.9s: just constraining the number of trees\n1181.4s: that we or that we allow in this um\n1184.1s: boosted regression approach and as you\n1187.82s: increase model complexity the difference\n1189.86s: between the ARG regularized model shown\n1192.32s: in black and the model with no\n1193.76s: regularization shown in red these things\n1195.86s: tend to converge right this makes sense\n1197.84s: because as the model grows uh the the\n1201.559s: overall capacity of the model to predict\n1204.08s: um\n1204.62s: some some complex non-linear functions\n1207.44s: uh grows as well right so it it\n1210.919s: um this was nice to see that as we let\n1213.2s: our models get huge we don't really need\n1215.24s: this extra simple physical information\n1216.74s: in the beginning but it's worth noting\n1218.96s: that we don't necessarily want our\n1220.58s: models to get huge because we want to\n1222.32s: use this online in an earth System model\n1225.26s: and the bigger the model the slower it\n1227.24s: is in inference time for the same you\n1229.82s: know the sort of a big broad hand wavy\n1231.86s: statement but larger models tend to be\n1233.24s: slower at inference time which is\n1235.1s: something that we care deeply about\n1236.36s: avoiding and so we can get away with a\n1238.76s: slightly smaller model for\n1241.76s: uh better predictions at smaller models\n1243.799s: which is which is good for for getting\n1245.36s: things online\n1247.22s: so taking a step back right I showed\n1249.14s: this slide before that adding physical\n1250.58s: information can improve parameterization\n1252.26s: predictive skill and I want to dig into\n1253.7s: that statement a little bit right what\n1254.96s: do we mean about improving\n1255.98s: parameterization predictive skill one\n1257.96s: thing in particular is that you notice\n1259.58s: in the basic neural network approach we\n1261.32s: tend to have this weird Kink down near\n1263.78s: very low activation fractions right if\n1266.84s: you zoom in on that you can see here\n1268.7s: that in the basic neural network we\n1270.08s: actually overestimate quite a lot in\n1272.84s: these very very\n1274.46s: um low now between 0 and 0.1 so just\n1278.539s: zooming in on those axes\n1280.34s: um we we overestimate quite a bit but by\n1282.62s: adding um you know by this biased\n1284.6s: correction approach we pretty much\n1285.799s: correct for that almost entirely\n1288.14s: another interesting feature is that if\n1290.179s: you take the training data set that we\n1292.7s: use and then just continue to sample it\n1294.2s: out with uh your your temperature range\n1296.84s: going for Kelvin warmer this is sort of\n1299.179s: a a pseudo-generalizability test right\n1301.7s: this is not perfectly satisfying this is\n1303.559s: not saying an exact assessment of how\n1306.32s: we're performing a warmer climate but\n1307.52s: this is getting us us toward that\n1309.26s: question you can you can show how the\n1311.24s: basic neural network performs in a four\n1313.4s: Kelvin warmer case\n1315.08s: um again fairly good but adding this\n1316.58s: physical information gets you much\n1318.559s: closer and much more bang on to that one\n1320.299s: to one line and so this helps lend\n1322.7s: confidence to the fact that in the case\n1324.86s: that\n1326.539s: um if we were to use this online in our\n1328.159s: system model and use it for\n1329.96s: extrapolation as opposed to\n1331.52s: interpolation we would likely have more\n1334.159s: confidence in the model that\n1337.539s: includes some of this physical\n1339.08s: information underneath the hood and\n1341.12s: while we don't want our what you know\n1343.4s: ideally all of our methods would be\n1345.2s: interpolating in in the online machine\n1347.179s: learning space it is unlikely that we\n1349.88s: can generate sufficiently large training\n1351.38s: data for all possible use cases of Earth\n1353.419s: system models that they will never\n1355.659s: extrapolate right so it is still good to\n1357.799s: good to to check this sort of thing\n1360.62s: so a big question we've had is what does\n1363.26s: this actually look like in a real\n1364.34s: climate model right I spent all this\n1365.659s: time caveating a bunch of these\n1367.22s: statements about you know we we actually\n1368.96s: want to develop something that we can\n1370.039s: get online in an earth System model and\n1372.799s: um that has been the bulk of our work\n1374.9s: over the past year and a half since um\n1377.84s: this this initial initial paper was was\n1380.299s: published\n1381.5s: and to get at this first we just want to\n1383.96s: implement the base deep neural network\n1385.28s: uh on into the department of energies or\n1388.039s: System model e3sm\n1389.96s: and we did that using the for trying to\n1392.299s: Keras bridge that\n1394.1s: um was led by a student partially\n1396.98s: supervised by Mike Pritchard Jordan\n1398.539s: Jordan Ott and when you do that this is\n1401.059s: I think probably the most exciting\n1402.62s: result of my entire time working at the\n1404.36s: Pacific Northwest National Lab is a\n1406.28s: figure with two figures that look the\n1407.78s: same right\n1408.98s: um what we find is that in putting the\n1411.98s: base deep neural network activation\n1413.9s: scheme online into the energy X color\n1415.94s: System model e3sm does not crash in a\n1418.7s: real climate simulation so what you're\n1420.919s: looking at is a precipitation rate for\n1422.78s: the annual average for a one-year\n1424.28s: simulation with the base DBL Network on\n1425.9s: top and e3sm the Doe's climate model on\n1429.38s: the bottom and these Maps look very very\n1431.24s: similar with only minor differences\n1433.9s: for those of you who have actually tried\n1436.1s: to get\n1437.299s: machine learning approaches online in an\n1439.7s: earth System model you know that that\n1441.86s: this result is not\n1443.78s: um not a trivia with trivial results to\n1446.0s: get right it's very easy to blow up the\n1448.34s: model with with your machine learning\n1450.02s: technique I think there are a couple of\n1451.22s: reasons why our approach was uh was was\n1454.1s: successful that that\n1456.2s: um\n1456.919s: lens lends itself toward towards this\n1459.559s: this type of approach and and makes this\n1461.36s: a little bit easier than what some of my\n1462.86s: colleagues doing things like subgrid\n1464.24s: Cloud physics has Travel Group with and\n1466.159s: one is that this problem is explicitly\n1468.799s: bounded right all predictions have to\n1470.48s: fall between zero and one and so we can\n1472.64s: just clip any core predictions to set\n1475.4s: them immediately to between zero and one\n1477.2s: and that really helps fix things from\n1478.46s: blowing up hugely I also want to note\n1480.62s: that runtime differences are are\n1482.659s: reasonably negligible between these two\n1485.36s: simulations so\n1487.039s: um you know if you get slightly\n1488.24s: different nodes you're going to get much\n1490.7s: much different simulation times than\n1492.14s: using using these different approaches\n1495.32s: so while the basic prototype works it is\n1497.84s: imperfect\n1499.1s: and this is particularly as it relates\n1501.02s: to what we know about the number of\n1502.88s: cloud droplets in the at in the\n1504.559s: atmosphere so\n1506.72s: when then aerosol is is activated to\n1509.24s: form Cloud a cloud droplet you know more\n1511.76s: activation will generally lead to\n1514.4s: increased Cloud droplet numbers and what\n1517.22s: you're looking at here is the column\n1518.539s: integrated Cloud droplet number\n1519.74s: concentration for the basic neural\n1522.02s: network approach in that same model\n1523.82s: simulation you can see large numbers of\n1526.58s: cloud droplets for example over over\n1528.679s: East Asia and if you compare that to the\n1530.96s: original version of e3sm you see\n1532.88s: significantly fewer Cloud droplets\n1534.98s: almost everywhere and the difference\n1536.84s: between the two which is shown on the\n1538.22s: bottom panel here shows the um\n1541.279s: that by using this online approach we\n1545.24s: get a massive increase in Cloud droplets\n1547.4s: everywhere now we don't know if this is\n1550.4s: correct and we know that there are some\n1552.74s: limitations in our uh case study that I\n1556.52s: described earlier right this sort of\n1557.96s: offline convenience approach and so we\n1560.9s: wanted to make this more realistic and\n1562.52s: more representative of the conditions in\n1564.02s: which it would be used and so to do that\n1566.0s: we\n1567.32s: updated our training data strategy in\n1569.419s: particular first we just updated e3sm to\n1572.96s: the latest and greatest version of that\n1574.4s: model and improve the generator of data\n1576.86s: to consider multiple aerosol modes\n1579.32s: whereas before we were just considering\n1580.64s: one type of aerosol ammonium sulfate and\n1582.799s: to account for additional processes in\n1584.9s: our\n1585.86s: um\n1586.64s: in our emulation Target so so for the\n1589.159s: detailed and slow model now we're adding\n1590.659s: additional processes into that to help\n1592.22s: account for for all of the all the\n1594.2s: physics that we want to have have have\n1596.72s: contained there and then importantly\n1598.58s: here we changed our sampling strategy\n1600.32s: from Latin hypercube sampling in the\n1602.539s: input distribution space to a real\n1604.64s: climate model distribution sampling so\n1606.32s: we actually ran e3sm and output all of\n1609.919s: the parameters from the all of the input\n1611.9s: parameters from e3sm as opposed to just\n1614.779s: random sampling across this entire space\n1616.46s: and I've just shown what Latin hypercube\n1618.5s: sampling might look like for for a two\n1620.179s: parameter distribution hypercube\n1622.1s: sampling is in is in Gray it samples the\n1624.26s: whole entire space whereas our real\n1626.539s: distribution might actually be fairly\n1628.1s: correlated and and what's shown in red\n1630.38s: what this does is it certainly biases\n1632.84s: our prediction to be better in this red\n1635.36s: regime right\n1637.039s: however we that's what we want right we\n1639.74s: want our neural network to work online\n1641.539s: in a climate model we don't necessarily\n1643.4s: care if it makes good predictions in\n1645.919s: spaces of input parameters that have no\n1648.38s: bearing on reality\n1650.12s: um on earth right so extremely cold\n1652.76s: temperatures extremely high pressures\n1654.86s: and extremely high vertical velocities\n1656.779s: sort of parts of that input distribution\n1658.58s: that joint distribution that are not\n1660.2s: physical\n1661.82s: and so we don't we don't want to weight\n1663.14s: those predictions very high\n1665.299s: uh it turns out that having this more\n1667.279s: realistic aerosol treatment and a more\n1669.14s: realistic problem is much harder to\n1670.76s: emulate because it's a more complex\n1672.14s: model so here you're looking at the ARG\n1674.48s: prediction scheme again this is just the\n1676.46s: existing parameterization for this real\n1679.039s: scenario and you can see that things are\n1681.26s: a lot Messier right this is much less\n1683.24s: tidy around that one-to-one line and\n1685.46s: have much less confidence in existing\n1686.96s: parameterizations knowing\n1688.94s: um in in this specific use case right so\n1691.4s: using this real online model you see a\n1693.919s: lot more complexity and when you use the\n1696.2s: Deep neural network approach\n1697.82s: um with with all that we can give it you\n1699.679s: get significantly better predictions but\n1701.6s: still not as good as the nice convenient\n1704.179s: uh case study that that\n1706.64s: um\n1707.36s: that we published earlier and I think\n1708.86s: that this is a really important result\n1710.12s: right that of course uh developing these\n1712.64s: these contrived case study examples that\n1714.559s: can help tell you if a technique is even\n1716.299s: worth approach uh getting after is a\n1719.36s: really important thing to do but then\n1721.46s: reapplying your Technique where the\n1723.2s: rubber meets the road in a real Earth\n1724.34s: System model things can get far more\n1725.659s: complex and a little bit more you know\n1727.159s: far more difficult to\n1729.98s: um to really work with\n1732.2s: however when we when we get this online\n1735.2s: into e3sm we do get a more realistic\n1737.659s: climate\n1739.22s: um here I'm showing column integrated\n1740.419s: number constant uh number concentration\n1742.52s: of cloud droplets again I showed this\n1744.26s: figure before but when you compare that\n1746.539s: to the newer version of e3sm we still\n1749.24s: see an increase in Cloud droplets which\n1750.74s: is consistent with the\n1752.48s: um\n1753.38s: increase in activation but it's less of\n1756.44s: an enormous increase and this is uh good\n1758.539s: to know because when we start comparing\n1760.159s: this to satellite observations we get\n1762.14s: better agreement overall in in that\n1765.679s: space and so\n1767.539s: the big Lessons Learned I think from\n1769.22s: this approach so far that these physical\n1770.84s: regulations regularization approaches\n1772.76s: are simple and effective strategy for\n1774.74s: improving machine learning\n1776.059s: prioritization performance and so if you\n1778.1s: have an existing Tech existing\n1780.14s: parameterization or existing method in\n1781.76s: your Earth System model that you want to\n1783.44s: improve upon maybe removing the entire\n1785.899s: thing and replacing it with a neural\n1787.159s: network is not the best approach and\n1788.899s: instead using a small neural network or\n1791.0s: a small machine learning method to\n1792.2s: actually just bias correct can be a\n1794.36s: better approach and this is something\n1795.38s: that of course other people have found\n1796.94s: in\n1798.559s: and various nudging studies from the the\n1801.2s: Allen Institute folks for example have\n1802.82s: found some of my results\n1804.919s: um as with all ml applications I think\n1806.96s: training data really is key and reformat\n1809.659s: reforming our problem for the training\n1811.88s: data in and on in the real Earth System\n1814.279s: model has really shown I think\n1816.74s: um some some striking results and also\n1818.96s: just getting these things to run online\n1820.22s: is a significant challenge right\n1821.659s: building this case study where pretty\n1823.46s: much everything could be hacked together\n1824.6s: on my laptop or on an individual GPU was\n1827.72s: was quite nice and convenient for\n1829.64s: working through this but but getting\n1831.14s: things online in a real Fortran based\n1833.12s: Earth System model has been a really big\n1835.7s: significant challenge that we've dealt\n1836.96s: with and sort of gloss past this as we\n1839.0s: put this online but really that's six\n1841.039s: months of work or as much time as it\n1842.6s: took to do the entire first the first\n1844.46s: half of the project and so the next\n1846.2s: steps and what we're actually doing\n1847.1s: right now we're running online in the\n1848.899s: background is to fully assess the new\n1851.299s: emulator against observations so going\n1854.24s: back to this slide here right does this\n1856.1s: new climate as predicted by the um\n1858.559s: energy radio wise DNA does this match\n1860.48s: our satellite observations of clouds\n1862.58s: Cloud droplets things like effective\n1864.559s: radius and so on did that have better\n1866.48s: agreement than the prior version right\n1869.179s: does this help us right because we know\n1870.799s: that we're getting a better prediction\n1872.72s: of the activation process so we've\n1875.659s: reduced that structural uncertainty in\n1877.34s: our model but that doesn't mean that\n1879.559s: we're necessarily going to get better\n1880.76s: agreement of cloud properties because\n1882.38s: this is very complex and of course\n1884.659s: um compensating errors can exist all\n1886.22s: over the place\n1887.299s: and so it's not necessarily true in my\n1889.7s: mind that improving a the prediction of\n1893.779s: an individual process makes your model\n1895.539s: better with respect to observations you\n1898.22s: have to actually do that assessment and\n1899.6s: make sure that that's true and hopefully\n1901.76s: we'll learn something interesting about\n1903.2s: the model along along the way\n1906.62s: so um I want to just briefly kind of\n1908.899s: plug the the other types of work that\n1910.279s: I'd be happy to chat about\n1911.72s: um as well if folks are interested that\n1913.76s: that we do in in my group including\n1915.98s: using some explainable and interpretable\n1917.899s: methods for\n1919.46s: um understanding model processes whether\n1920.899s: that's a physics of light and plant\n1922.159s: canopies or lightning occurrence\n1924.62s: um world worldwide and errors in that\n1928.1s: prediction as well as using field\n1929.84s: observations directly for model\n1931.64s: parameterization development we did this\n1933.62s: as it relates to the loss of\n1936.279s: tropospheric oxidants to vegetation and\n1940.1s: then lastly a major a major major effort\n1941.72s: that we've been focusing on right now in\n1943.159s: my research group I have a couple of\n1944.299s: students working on this now I was just\n1945.5s: using some of these data science methods\n1947.12s: for model development understanding in\n1948.919s: particular as it relates to Applications\n1950.539s: of graph Theory and network analysis to\n1953.12s: try to understand atmospheric chemical\n1955.039s: reactions and I have a bunch of\n1958.82s: um you know overall this this big\n1960.14s: conclusion that some of these data\n1961.34s: science and machine learning methods can\n1963.02s: improve predictability is something that\n1964.88s: I think is really exciting and\n1967.1s: um I'm very interested in pursuing\n1968.539s: further but there's a lot more work to\n1969.679s: do\n1970.58s: um including some some work that if you\n1972.919s: um will be at for example conferences\n1974.96s: like agu and\n1976.52s: um in Nepal you will see students like\n1978.32s: my student a student my group Kaylee\n1980.659s: Butler looking at aerosol Cloud\n1982.58s: interactions from an observational\n1983.659s: perspective and seeing if we can use\n1985.1s: some dimensionality reduction techniques\n1986.659s: to understand why modern Earth system\n1989.12s: models are wrong a soon to be graduated\n1991.58s: student looking at the impacts of\n1993.76s: vegetation on the atmosphere in in Los\n1997.46s: Angeles so as the city decides to add\n1999.26s: trees everywhere what will actually\n2000.34s: happen I know Joe Koh who's in the\n2002.26s: audience knows quite a bit about this\n2004.299s: um\n2004.919s: a superstar undergraduate who worked\n2007.84s: with me for 11 weeks and has already\n2009.34s: submitted a manuscript looking at\n2011.919s: um novel neural network architectures so\n2014.2s: instead of feed forward neural networks\n2016.36s: what if we add Skip connections\n2018.22s: everywhere and sort of randomly wire\n2019.36s: these things this is taken in part from\n2021.159s: some really great work that Andrew guys\n2022.539s: said piano has done we're using this for\n2024.7s: for climate model emulation and\n2027.279s: um and will is Will is truly truly\n2029.62s: remarkable I feel like I'm supposed to\n2030.82s: plug him as a superstar that everyone\n2032.14s: should try to recruit but I also have\n2033.519s: this slight motivation to not do that so\n2035.62s: he comes to stay in my group but\n2037.419s: actually in in reality\n2039.22s: um it's uh it's fantastic to get to work\n2041.38s: with such such great students and then\n2043.24s: obinster is another student in my group\n2044.86s: looking at just the numerical methods\n2048.339s: for for simulating atmospheric chemistry\n2050.5s: and how turns out there's some\n2051.879s: surprising results of the chemistry\n2053.139s: being the slowest at sunrise and sunset\n2054.94s: maybe it's not surprising if there's any\n2056.32s: heterogeneous Chemists in the audience\n2057.879s: but it was fun to see for me\n2060.639s: so overall just want to say thank you I\n2062.619s: hope to keep this a little bit short\n2063.58s: because I have to dip out and I want to\n2064.96s: have time for for questions before\n2066.76s: before leaving I do want to note that if\n2069.159s: you know anyone who wants to come live\n2070.48s: in Los Angeles which is the best city in\n2073.599s: America\n2074.619s: um especially in the winter I am I'm\n2076.659s: recruiting and I'd love to love the chat\n2080.379s: so thank you\n2093.58s: all right so a question in the chat is\n2095.56s: from Jerry Lynn asking to explain the\n2097.78s: ARG method again and I actually think I\n2100.78s: can I have a slide here that might make\n2103.06s: it a lit make a little bit more sense\n2104.5s: let's see if I can move with the chat\n2107.26s: um\n2107.92s: so what we're doing with this this\n2109.839s: regularization approach is in I think\n2111.94s: it's helpful to contrast this with the\n2113.44s: sort of traditional approach we use for\n2115.54s: um in in in machine learning which is\n2118.359s: where we want to predict some quantity\n2119.5s: here the fraction of aerosol activated\n2121.06s: between zero and one and we use just\n2123.16s: some machine learning function of some\n2124.72s: inputs X\n2127.06s: instead what we're doing is we're\n2128.92s: predicting the activation fraction by\n2130.839s: first calculating the activation\n2132.579s: fraction predicted by the ARG scheme\n2135.52s: and then calculating the an additional\n2137.68s: term from a machine learning approach as\n2140.14s: a function of those inputs to ultimately\n2141.82s: help us get a slightly better prediction\n2143.14s: right so you can imagine this as\n2145.44s: an implicit regularization right this is\n2147.88s: not directly changing the the\n2149.32s: optimization or anything like that or\n2151.9s: you could imagine this is bias\n2153.04s: correction we're actually just training\n2154.06s: a machine learning bias corrector\n2157.0s: I hope that I hope that helps\n2161.56s: I have a question uh can you hear me Sam\n2164.38s: yes this is Marcus uh my question was\n2167.2s: about like um on I mean there's only\n2168.94s: like a few points on those uh one-to-one\n2170.859s: lines that are kind of set off it yeah\n2173.8s: um but is the error in those mostly a\n2175.839s: function of the base physical model or\n2177.64s: is it in the error is it in the bias\n2179.44s: correction of the physical model\n2181.48s: okay yeah yeah that's a really\n2183.22s: interesting question right so is this\n2184.96s: are we just doing a bad job of bias\n2187.06s: correction or are we\n2189.579s: um\n2190.48s: or is the bias correction actually\n2191.92s: driving us further from the truth I\n2193.96s: don't actually have have an answer to\n2195.52s: that I can tell you what these errors\n2198.52s: look like from a uh from the input\n2201.339s: parameter distribution and in particular\n2203.2s: we tend to find the worst performance\n2205.599s: over very low hydroscopicity values\n2209.079s: um this is corrected for the most in in\n2212.8s: using the ARG scheme but they're still\n2214.839s: there are still challenges there so I\n2217.24s: don't I don't actually have a specific\n2218.56s: you know I didn't I didn't pull out\n2220.119s: individual outliers and say are they the\n2221.98s: you know where does this error mostly\n2223.359s: come from so but my hunch is that it\n2225.94s: comes from\n2227.14s: um uh incorrect uh the the sort of bad\n2230.38s: predictions from from the neural network\n2231.7s: approach\n2233.44s: in areas that are that are relatively\n2235.78s: poorly sampled or surprising for uh for\n2238.18s: the network to Sage\n2243.46s: and then I have another question if\n2244.78s: nobody else has one right now\n2247.18s: um with the uh with using the\n2249.04s: climatological distribution of\n2251.099s: environmental variables are you worried\n2253.48s: that that changes under like changing\n2255.579s: climate that you'll be going sort of out\n2257.079s: of sample is there a need to sort of\n2258.76s: combine uh that with like a limited\n2260.74s: Latin hypercube or something yeah yeah\n2263.26s: so this is that's actually a really\n2264.76s: interesting question I think\n2266.92s: in our case we ran\n2269.2s: um we ran the model for exactly when we\n2271.359s: wanted to use it and then are looking\n2273.82s: only at regions very similar to that\n2276.52s: right but if we wanted to run this for\n2278.02s: 150 years we're likely to get out of\n2280.42s: sample and that can cause some uh\n2282.52s: actually I'm not gonna go through it\n2283.48s: that can cause some pretty pretty\n2284.92s: substantial issues right\n2286.72s: um I think an ideal approach would be\n2289.72s: ideal meaning if you had the resources\n2292.66s: to actually maintain this type of\n2294.579s: parameterization is to make sure that\n2296.56s: your training data is generated\n2297.82s: effectively per\n2300.28s: um on a on a per use case basis right\n2302.56s: now of course that's very unrealistic to\n2305.38s: retrain everything in your model\n2308.14s: um for any scenario that you're\n2310.0s: interested in and so I do think that\n2312.04s: maybe something like a limited hyper\n2313.48s: Latin hyper group sampling is a good\n2315.04s: idea we propose doing something like\n2316.48s: that of basically saying\n2318.22s: um augmenting our training data set with\n2320.32s: with\n2321.4s: um sampling from slightly outside of\n2323.079s: that distribution\n2324.76s: um or another strategy is just to\n2326.68s: broadly think about you know what is the\n2328.24s: actual role of machine learning\n2330.16s: emulators in an earth System model right\n2332.32s: if they are so sensitive to training\n2334.839s: data maybe they're better used in\n2338.02s: studies like the one we've done where\n2339.16s: we're really trying to assess model\n2340.24s: structural uncertainty then\n2343.359s: um a world where a huge amount of our\n2345.579s: model is a huge you know amount of model\n2347.74s: code and model processes just comes from\n2350.04s: neural networks that have no real real\n2353.26s: um\n2354.24s: guarantee that they'll perform well out\n2356.2s: of sample\n2358.42s: Hi Sam this is Kara\n2361.9s: for your satellite for the work that\n2364.0s: you're doing now with satellites are you\n2365.14s: planning to like tune the model in some\n2367.0s: way or is it like what exactly is or can\n2369.4s: you talk more about what your plan is\n2370.72s: with the uh\n2372.24s: comparisons yeah so um we have a variety\n2376.0s: of satellite observations of cloud\n2377.5s: properties including things like Cloud\n2379.119s: fraction\n2380.56s: um\n2381.22s: effective radius and um and and and and\n2384.52s: other parameters from from for example\n2386.44s: Modis and what we really want to do is\n2388.359s: just see if\n2390.339s: um in in you know the The Limited way in\n2392.68s: which you can use these satellite\n2394.0s: observations to really assess climate\n2395.68s: models right understanding all of those\n2397.18s: caveats\n2398.56s: are we getting closer to observations\n2401.8s: by using the improved aerosol activation\n2406.24s: scheme or not and I think what this will\n2408.94s: really tell us is how uh\n2412.72s: if we're confident that our activation\n2414.579s: scheme is correct or more correct but we\n2417.4s: don't actually do a better job of\n2418.599s: reproducing observations that can tell\n2420.22s: us a lot about where to put our efforts\n2421.66s: for improving model development and can\n2425.2s: tell us something about potentially\n2426.339s: compensating errors that exist in the\n2427.839s: model\n2428.68s: um as we have it right because I think\n2430.48s: oh go ahead all right\n2434.2s: okay like things like Cloud fraction or\n2437.5s: um\n2439.119s: I mean I guess maybe that's part of the\n2440.56s: study is like figuring out what are the\n2442.24s: appropriate metrics yeah yeah and\n2444.04s: there's you know I think literature on\n2446.079s: on\n2447.099s: um the ways in which these things have\n2448.42s: historically been done I think what what\n2450.16s: you might be getting at is that it's\n2452.26s: it's not a trivial one-to-one comparison\n2454.359s: right we're not using an um\n2457.119s: everything doesn't work perfectly and\n2458.8s: once you start nudging you start to\n2460.24s: break some of the physics and so it's\n2461.8s: hard to really really assess things and\n2463.72s: that's something that we're struggling\n2464.56s: with right now\n2466.0s: um fortunately some of the collaborators\n2467.92s: at at pnnl who I'm working with have\n2470.14s: done this quite a bit this is this Cloud\n2472.14s: process assessment it's something that's\n2474.04s: a little bit new for me from a satellite\n2475.54s: perspective so it is it is something\n2477.28s: that I'm still learning but yeah I think\n2478.96s: the first order\n2480.579s: um\n2481.42s: there there are a variety of approaches\n2483.46s: that you can use used to assess these\n2485.38s: um\n2499.9s: if there's a question in the chat\n2504.76s: ah jerlin asks to bound the neural\n2506.8s: network predictions between zero and one\n2508.06s: do we use a special activation layer at\n2509.859s: the end so\n2511.66s: what this is getting at is your your\n2513.52s: final layer of your neural network for\n2515.98s: regression approaches commonly has a\n2517.839s: linear activation function right where\n2519.579s: it can just predict any value between\n2521.02s: negative infinity and infinity\n2522.94s: but since we know our predictions should\n2525.22s: range between zero and one you could\n2527.82s: implicitly use something like a sigmoid\n2530.32s: activation function that always predicts\n2532.839s: between zero and one\n2534.64s: as it turns out using a sigmoid\n2536.859s: activation function gets you slightly\n2538.54s: worse predictions out to like the\n2540.099s: seventh decimal place\n2541.66s: and so we just went with the linear\n2543.7s: activation function and then just\n2545.2s: clipped the value in Fortran right so\n2547.359s: the maximum that this could be is\n2548.619s: whatever it's predicted or one the\n2550.42s: minimum it can be is whatever is\n2551.68s: predicted or zero\n2578.2s: anybody else have any other questions\n2584.02s: um it's a I have a quick question\n2585.28s: actually yeah so um if I'm remembering\n2587.859s: correctly I think the XG boost uh\n2590.26s: performed like you know simple\n2592.78s: um analysis performed like on par with\n2595.66s: the neural network yeah I was wondering\n2597.7s: if you kind of well what if you why if\n2599.859s: you did why you had a preference to\n2601.359s: implement the neural network online yeah\n2604.18s: so this there there are two main reasons\n2606.64s: for this\n2607.839s: um and I will I'll say two but really\n2609.7s: the biggest reason is just that there\n2611.2s: are tools available for getting feed\n2613.359s: forward neural networks online into\n2614.859s: Fortran models reasonably reasonably\n2617.14s: easily right this was really just a are\n2619.96s: there existing software techniques to\n2622.66s: get this working well\n2624.28s: um and then at the time that we started\n2625.839s: this getting something like xgboost into\n2628.599s: Fortran was\n2630.88s: um was not\n2632.14s: identified as as something that was\n2634.18s: particularly feasible additionally\n2636.099s: timing tests showed that the neural\n2638.44s: network was the neural network approach\n2640.78s: given the number of parameters we've had\n2642.46s: and the way that you can just do matrix\n2644.26s: multiplication very quickly the neural\n2645.819s: network approach was faster and so for\n2648.099s: roughly similar accuracy or even\n2650.38s: slightly worse accuracy the neural\n2652.42s: network was preferred from from the sort\n2654.099s: of challenges of getting things online\n2656.26s: yeah thank you right but I think this\n2658.54s: broadly speaks to the idea of the fact\n2660.22s: that it's really necessary to develop\n2661.72s: these sort of tools to get these these\n2663.819s: methods into into our system models or\n2665.92s: convince people to do more more work\n2668.68s: moving from Fortran to C plus or or\n2671.5s: whatever\n2673.0s: uh Sam one one kind of final question\n2675.04s: about\n2676.18s: um the implementation uh since there is\n2679.0s: such a push at um At Doe labs to you\n2682.24s: know utilize gpus is there any potential\n2684.64s: benefit or theoretical benefit to\n2687.76s: um sort of offloading the neural network\n2689.02s: calculations to the gpus is that\n2691.66s: something that's like somebody's looking\n2693.22s: into or or not\n2695.68s: so um there should be a benefit of\n2698.26s: running these things on gpus right\n2699.579s: that's expected\n2701.2s: um I'm no longer a doe employee so I can\n2703.359s: kind of more safely say that I don't\n2705.099s: think anyone's working on this right now\n2706.66s: I think it's important I think as we\n2709.66s: move to gpus this will be seen if this\n2711.819s: benefit comes to pass\n2713.619s: um something that I've been broadly\n2714.76s: frustrated by and a lot of this sort of\n2716.38s: case study land of climate and machine\n2719.2s: learning is how the benefits that you\n2721.66s: see in the case studies with Advanced\n2723.819s: Techniques don't always\n2725.5s: you know we don't always realize them\n2727.3s: online\n2728.92s: um I remember reading papers about you\n2730.359s: know increasing integration steps by\n2732.819s: integration speeds by a factor of a\n2734.92s: hundred thousand and then you get it\n2736.359s: online and your model finishes an hour\n2738.099s: sooner which is still great but it's not\n2741.28s: um you know a micro second like I was\n2742.96s: expecting and I think that that we'll\n2745.0s: find some of those challenges for sure\n2751.24s: okay well if nobody has any other\n2754.18s: questions\n2755.26s: um thank you very much for speaking\n2756.64s: today Sam thank you\n2758.56s: and it just seems it's like really in\n2760.48s: life I think a lot of the work that\n2761.68s: people are doing here I think\n2763.78s: so\n2764.98s: um I guess I'm still organizing a\n2766.96s: speaker for next week or sorry in two\n2768.88s: weeks but um I think we'll have somebody\n2771.16s: potentially talking about uh causal\n2773.02s: invariance\n2774.88s: um and then there's going to be a\n2777.22s: researcher from Stefan men's group who's\n2778.96s: talking in April as well as Peter Yan\n2782.02s: so\n2783.22s: um yeah thanks everyone for coming and\n2785.2s: see you next time\n2786.88s: all right thank you all thanks Sam\n2796.3s: feeling better all right glad to hear it\n2802.319s: all right\n2811.599s: foreign"
    },
    {
        "class": "YouTubeVideo",
        "title": "LEAP Research Experiences for Undergraduates: Summer 2023",
        "videoId": "b2vi42FK_mg",
        "url": "https://www.youtube.com/watch?v=b2vi42FK_mg",
        "publishedAt": "2023-03-03T21:09:06Z",
        "transcript": "3.78s: hi everyone\n5.22s: um happy Friday my name is ji hey Moon\n7.319s: and I'm the assistant director of\n9.24s: education programs for elite art\n11.34s: learning the Earth with AI and physics\n13.139s: at Columbia University School of\n15.24s: Engineering and applied sciences\n17.64s: um we're just housed under Columbia\n18.9s: we're not a Columbia program\n21.6s: um but it we have to have a home leave\n24.9s: is a National Science Foundation funded\n26.88s: Science and Technology Center which our\n29.4s: program director Pierre will introduce\n31.5s: shortly after that we will get into the\n34.38s: details of leap's research experience\n36.48s: for undergraduate students or reu with\n39.12s: one of our mentors research mentors Mike\n41.46s: Pritchard then I'll review the\n43.739s: application eligibility and next steps\n46.379s: before we go into q a so that said\n48.78s: please hold your questions until the end\n50.64s: of the session or you can chat me\n52.379s: directly if questions come along and we\n55.26s: can go over those at the end of the\n56.46s: presentation\n58.26s: and I will have\n61.62s: Pierre get started\n64.14s: they're great thanks so much to you and\n66.479s: welcome everyone that's uh exciting to\n68.64s: to to see you interested in this topic\n70.86s: so uh maybe just to give you a little\n73.5s: bit of background so we are actually\n75.54s: what we call an STC so Science and\n77.7s: Technology Center so it's one of the\n79.2s: largest uh sources of funding from the\n81.42s: National Science Foundation which is\n83.159s: better\n84.78s: um funding Agency for science as a whole\n87.6s: in the US we are partnering between\n90.299s: Colombia and where you use cerebians\n93.0s: actually uh my Pritchard and Stephen are\n95.1s: actually professors there\n97.2s: um Teachers College uh uh right around\n99.96s: the block here at Columbia and\n101.88s: University of Minnesota as well and what\n105.0s: we are trying to do is really trying to\n106.619s: get to the next generation of uh climate\n109.68s: modeling and we're trying to think about\n111.479s: what we call climate data science so\n113.399s: trying to really merge two disciplines\n115.68s: you know the interface between data\n117.42s: science and climate science and with the\n119.88s: Hope really to kind of lead to the next\n122.22s: generation of climate injection so\n125.159s: typically what we do is we use a model\n127.56s: so this is a typical climate model here\n129.539s: very very pixelated you know it looks\n131.22s: like an older video game if you will and\n133.68s: what we are trying to do is to do\n135.239s: something much more precise you know a\n136.8s: little bit like what you have on the\n137.819s: right hand side we want to see clouds\n139.2s: really well we want to represent the\n140.819s: future really well and that's kind of\n142.92s: the ultimate goal so it's not just about\n144.42s: resolution but really about a better\n146.879s: physics and better representation of a\n149.28s: lot of different processes because those\n151.08s: models are trying to do a lot of\n153.72s: different things from representing the\n155.879s: carbon cycle to representing clouds to\n158.64s: representing precipitation and and\n160.739s: whatnot you know so we are just trying\n162.12s: to do a better job overall so and the\n165.06s: reason for that is we want to give\n166.8s: everyone and basically a wide range of\n170.22s: stakeholders from the public to the\n172.14s: private side who want to give them much\n174.84s: much more accurate uh what we call it\n178.92s: projection which is a prediction ahead\n181.2s: of time you know especially by the end\n182.64s: of the century and we want to do that\n184.62s: and be as precise as possible so that\n186.36s: people can plan you know so if you think\n188.519s: for instance about infrastructure\n190.019s: planning you need to know what's going\n191.7s: to happen like what what is going to be\n194.159s: the typical level of a flooding event uh\n197.34s: 20 to 30 years from now what's going to\n199.68s: be sea level rise if we want to be on\n201.599s: the wall what's going to be sea level\n203.459s: rise by 2060 say in New York city so we\n206.519s: need to have really accurate and precise\n208.8s: information and cannot be unfortunate\n212.34s: truth is that a lot of the current\n214.98s: generation models are really not up to\n217.319s: the task so we want to change the game\n219.06s: and we want to have models that are more\n221.7s: useful if that makes sense I feel free\n224.64s: to interrupt you know if you have any\n225.9s: questions I'd be happy to if anything is\n228.12s: unclear\n230.659s: so the way we formulate that is we uh so\n234.84s: that's our mission statement uh that's\n236.819s: uh when you have a strategy plan you\n238.319s: have a vision and a mission statement\n239.7s: like for any type of like typical\n241.56s: companies also have that\n243.84s: um and our mission is really to provide\n245.7s: some sort of Leap Forward in uh\n247.799s: reliability utility and reach of climate\n250.62s: projection uh through that synergistic\n253.14s: Innovation between data science and\n254.879s: climate science so the way we see that\n256.799s: and what we mean by reliability is that\n259.199s: we want to really start thinking about\n261.239s: data-driven climate projection so really\n264.0s: putting data as a core component of\n267.12s: climate projection and that's not\n269.28s: something that's happening right now\n270.479s: typically now it's kind of a natural to\n272.759s: build your model you know based on some\n274.32s: you know thoughts you have about physics\n277.44s: or physical processes and then you have\n279.3s: some basic checks you know does the\n281.46s: temperature of the globe looks\n282.84s: reasonable or not you know some basic\n284.58s: things right and now what we want to do\n286.5s: is we want to plug a lot more data we\n288.36s: want to say\n289.38s: we have plenty of satellite observations\n291.66s: we have plenty of measurements can we\n293.94s: plug that into the development of those\n296.639s: models and can we use AI in particular\n298.86s: to improve those models if that makes\n301.259s: sense\n302.1s: we want to also improve the utility and\n305.699s: what we mean by that is that there's a\n308.88s: little bit of a disconnect so uh and\n310.919s: we've we test a lot of that for kovid as\n313.259s: well is that you know even the best\n315.24s: scientists in the world if you're trying\n316.68s: to do the best science in the world you\n318.84s: need to connect right you need to\n320.22s: connect to real world impact and to do\n323.1s: that really what you need is you need to\n324.66s: have a way to provide the data and in\n327.3s: that case planet information and and\n330.06s: basically those projections in the\n331.919s: future you need to provide that and put\n333.96s: that in the hand of the people and you\n336.12s: need to do it in a way that's easy to\n338.039s: use that's easily accessible and that's\n340.56s: public you know and share with everyone\n342.18s: so that's also something we want to do\n344.039s: is having a platform where people can\n345.66s: basically get the data it could be even\n348.3s: on a laptop that's what we are actually\n349.919s: working on right now where they can see\n352.08s: okay what's going to be the conditions\n353.639s: in New York by say 2016 or 2070 can I\n357.479s: get that directly on my laptop can I use\n359.22s: that for say my company or for my you\n362.82s: know public sector uh or public agency\n366.479s: so that's what we also want to do so\n368.759s: really making climate data much more\n371.039s: useful you know and providing that to\n373.32s: the to wide range of users\n375.74s: uh and we also want to extend the reach\n378.539s: so that's actually very connected to\n380.16s: that having uh basically This Cloud\n383.759s: infrastructure and everything all of the\n386.46s: data on the cloud so that people can use\n388.02s: that for their research for the\n390.24s: education so that's part of this uh\n392.819s: research experience for undergrads where\n395.039s: a lot of the data will be on the cloud\n396.419s: but also using the same data for all of\n399.66s: the public and private stakeholders you\n401.4s: know they will use the same data we can\n403.199s: replicate everything and we can like\n405.419s: really strikes and also this this\n407.039s: pipeline in terms of having a much uh\n409.979s: broader use of climate data and also a\n412.38s: much broader community of data\n415.08s: scientists than what we call climate\n416.46s: data scientists so again people that are\n418.44s: really well versed in terms of climate\n420.0s: and data and we want to really reach out\n422.16s: to crowd that's diverse because climate\n424.8s: is affecting everyone so we want to also\n426.6s: be representative of society so we can\n428.819s: really act on climate you know and\n430.979s: especially with the climate crisis so\n432.6s: that we actually represent society as\n434.94s: well\n435.96s: uh and find the kind of how we see that\n439.56s: we believe that there's quite a bit of\n441.419s: novelty in terms of the fact that we\n444.24s: hope to be some of the first ones who\n446.28s: really leverage and really Advance the\n448.259s: use of data science across the entire\n450.66s: climate model pipeline in the sense that\n452.699s: we want to use a lot of the existing\n455.46s: data platforms again such as satellite\n457.68s: data etc etc to improve climate models\n460.62s: but also using data science for the\n463.56s: first processing or for the use of those\n465.78s: data like how can we provide a ton of\n468.78s: data to the users on a laptop right you\n472.139s: want to go in with your laptop you want\n473.699s: to zoom into a region of the world they\n475.979s: are huge technical challenges because we\n478.02s: are dealing with petabytes of data so\n479.58s: how can you do that efficiently so so\n482.099s: really we believe that uh improved and\n486.479s: much more advanced use of data science\n488.639s: and AI across a different pipeline of\n491.22s: the climate model is going to be really\n493.259s: leveraging first of all improving\n495.84s: climate models but also making climate\n498.3s: model data much more accessible to\n500.639s: emerge broader community and we believe\n503.039s: that this is how we can actually help\n504.539s: with the climate crisis and especially\n506.58s: for climate adaptation if that makes\n508.5s: sense\n512.839s: so kind of the roadmap so that's a\n515.76s: little bit how we see the center so we\n517.32s: have this connection between climate and\n519.36s: data sales so we call that climate data\n521.279s: science we see that in terms of\n522.899s: educational research uh so we are\n525.54s: training a new generation of scientists\n527.839s: within the center and the satellite\n530.7s: institutions but also through uh some\n533.279s: research exposures such as this IU\n535.68s: program you know where we really want to\n538.019s: connect different groups of individuals\n540.779s: people that have different skill sets\n542.76s: and and by working together working\n545.519s: tandem working in groups and in in pods\n549.18s: we can actually create that Synergy\n550.98s: between discipline people can basically\n552.72s: learn from each other and we believe\n554.76s: that this is how we can actually\n556.8s: generate uh or create this kind of new\n559.62s: generation of models where people can\n562.38s: actually really use data at scale you\n564.54s: know they can actually use and and\n566.1s: develop better climate models that are\n568.32s: also more useful for society because\n570.12s: they are more precise again and then\n572.1s: more informative you know of what's\n573.779s: going to happen next time and then we\n575.94s: have on the right hand side we have what\n577.44s: we call again this bi-directional noise\n579.0s: transfer in the sense that we want to\n582.24s: provide the data that we are creating in\n585.12s: particular moving forward we want to use\n587.339s: and provide this data to the to a wide\n589.5s: range of uh public and private\n591.48s: stakeholders so that they can really use\n593.04s: data and they can add act against uh\n596.1s: climate especially for climate\n598.32s: resilience and climate adaptation\n599.82s: because they will have the right type of\n602.22s: data and they could therefore plan in\n604.56s: advance\n605.3s: and be more resident and adapt it to\n607.98s: that and we see that as really\n610.32s: throughout the entire Center is running\n613.14s: participation as well so again because\n615.3s: we believe that climate is affecting\n617.04s: everyone there's actually a very tight\n619.019s: connection with social justice as well\n620.94s: so uh social justice and climate Justice\n623.519s: are tightly connected actually I just\n625.8s: ran Yesterday by there was a very nice\n628.019s: posture of the subway yesterday about\n630.779s: that so those are very technically\n632.58s: connected topics and that's why we\n634.08s: believe it's really important to provide\n635.88s: participation at all levels of the\n637.98s: center\n638.88s: and finally to really do that we need a\n642.36s: modern data infrastructure so this is\n644.519s: the so-called tangio and we call that\n646.68s: lip and juice so the fusion between leap\n649.8s: and Pangea it's a modern cloud data\n652.98s: infrastructure especially for climate\n654.839s: data where you can basically do a lot of\n657.72s: the compute on the cloud and therefore\n660.54s: you can you don't need to download\n661.92s: everything on your laptop right so you\n663.6s: can actually do a lot of the compute on\n665.04s: the cloud and that's what we also want\n666.72s: to leverage in that I use so that you\n668.7s: don't need to download like The\n670.079s: petabytes of data which is impossible on\n672.18s: your laptop but actually doing that\n673.92s: directly on the chat and also that in\n676.32s: that sense it's also much easier to\n677.88s: replicate and to share codes right\n679.56s: people can redo the exact same thing\n681.54s: it's not dependent on your particular\n683.76s: platform your particular environment but\n686.1s: that's something we can easily replicate\n687.66s: so that's actually very important for us\n690.18s: next next year\n692.76s: so uh we kind of see that as um on the\n697.019s: science front in terms of two what we\n699.36s: call challenges uh the first challenge\n701.76s: is to again develop the next generation\n704.459s: of climate models so models that are way\n706.32s: more precise you know and we do that by\n709.68s: basically trying to have this\n712.68s: combination of new algorithms so not\n714.779s: just of the Shelf type of algorithms but\n716.88s: potentially it's also trying to develop\n718.62s: algorithms that are more physically\n720.42s: based as well so AI that can include\n722.76s: physics or causal mechanisms as well and\n726.54s: that can efficiently leverage uh\n729.18s: observations such as from satellites or\n731.76s: a lot of Point data that we have across\n733.86s: the globe and also some simulations that\n736.38s: we call High Fidelity simulations that\n738.6s: are really precise you know like on the\n740.399s: uh bottom left you can see a simulation\n742.8s: of clouds which basically at a TENS of\n745.079s: meter scale we can see like very time\n747.24s: details of clouds and we can use that\n748.8s: but we cannot run that forever because\n750.42s: it's very computationally expensive but\n752.519s: we can still leverage a lot of the\n753.899s: information that is coming from that so\n755.519s: we really want to harvest a lot of those\n757.56s: different data streams that are pretty\n760.079s: diverse because we want to combine that\n761.76s: together as a way to basically improve\n764.399s: how we represent physical processes uh\n767.459s: in climate models and again with the\n769.62s: hope that at the end so really on the\n771.48s: right hand side here that it will lead\n773.399s: to more accurate climate projection so\n775.98s: that people can act better against\n777.779s: climate change\n780.06s: thanks\n781.38s: and uh on the algorithmic thought so\n784.5s: especially for the computer savvy people\n787.8s: uh in the room or the the the\n790.339s: statisticians in the room so we are\n792.42s: trying to also develop new types of\n795.36s: algorithms and especially in terms of\n797.16s: algorithms that could actually include\n798.959s: physical and causal knowledge as I\n801.42s: mentioned before and the reason for that\n803.519s: is that we don't want to just fit the\n805.98s: data so uh and now we feel being exposed\n808.8s: to chat gpp so every year it's actually\n810.54s: even more exciting what's going on with\n812.1s: AI but what we want to do is we we have\n815.339s: this big challenge that we've never seen\n817.26s: climate change right or we've we are\n819.72s: just witnessing a kind of a small\n822.06s: version of that or a small amplitude of\n823.98s: that and we don't know how the future is\n825.899s: going to look like right so it's a\n827.639s: little bit different from like\n829.38s: um computer vision or natural language\n831.66s: processing where we have this huge\n834.12s: amount of data and we just want to\n836.22s: replicate a lot of the data right in our\n838.5s: case we don't want to just replicate we\n840.18s: want to extrapolate right we want to\n842.16s: predict the future right so it's a huge\n844.26s: challenge you know even from a machine\n845.639s: learning or algorithmic perspective but\n848.279s: it's also super interesting like how can\n850.38s: you learn from the past to actually\n852.48s: infer the future right when there's a\n855.12s: shift in distribution when things are\n856.68s: not stationary right so it's super\n858.24s: interesting a lot of interesting\n860.16s: challenges as well and that's uh one\n862.68s: thing we are trying to do so trying to\n864.18s: see maybe by bringing some Physics or by\n867.18s: bringing some causal uh inference or\n870.48s: causal knowledge maybe potentially that\n873.0s: could help and we could actually develop\n874.86s: better algorithms algorithms that can\n877.019s: better better extrapolate into the\n879.36s: future\n885.0s: um and just uh quickly on the on the\n887.94s: education side so uh very similar to\n891.06s: what we discussed before so we are\n892.5s: trying to create this kind of new\n893.579s: discipline again at the interface\n895.44s: between climate and data science and and\n897.959s: we have to deal with a lot of challenges\n899.639s: right so people have different jargons\n901.44s: you know people have different\n902.699s: vocabularies so for instance a typical\n905.04s: example would be uh you know a machine\n908.339s: learning person will tell you I have\n909.899s: this model and then the time a climate\n912.0s: science person will tell you I have this\n913.32s: model and they mean very different\n914.459s: things right is it a climate model or is\n916.56s: it a machine learning model right so so\n918.3s: those are huge challenges that we need\n920.459s: to face uh and we need to to to\n922.62s: basically solve uh and we are really\n925.079s: trying to bridge the gap by uh\n927.3s: especially research uh immersion right\n930.18s: where people can actually work in tandem\n932.22s: but also creating\n934.199s: um new classes that are really at the\n935.88s: interface between those two things so\n938.399s: um for instance uh I have a class on\n940.38s: machine learning but apply to\n941.639s: environmental science and engineering\n943.44s: there's one class which is this\n945.42s: so-called climate prediction challenge\n947.1s: where we we it's like an immersion class\n949.74s: where Hands-On where we try to work on a\n951.899s: project we lead to using climate data\n954.36s: and doing some machine learning and\n955.86s: statistics on on climate so we are truly\n958.26s: trying to bridge that gap between the\n959.82s: two different uh disciplines\n961.98s: and as part of that so we do that at a\n964.74s: different levels so there's this IU\n966.42s: program that we have here we have uh we\n968.88s: are supporting graduate students as well\n970.74s: and we will have also a summer program\n972.6s: for K-12 uh teachers as well so they can\n975.18s: also communicate that through the to the\n977.459s: high schoolers uh and again across that\n980.579s: we also want to increase uh\n982.199s: representation of uh underrepresented\n984.86s: underrepresented minorities uh and again\n987.839s: because climate is affecting everyone\n989.459s: and we need to have basically a lot of\n991.74s: voices that actually represents Society\n993.74s: uh uh across so I think that's all I had\n997.38s: and happy to take any questions or we\n999.24s: can leave that to the end however you\n1001.399s: see\n1002.779s: thank you\n1008.72s: uh is it all right if I ask a question\n1010.519s: about I noticed with the models which\n1012.8s: model would you say is the most common\n1014.12s: would you say it's neural network with\n1015.8s: machine learning or are there other ones\n1018.199s: that are kind of taking over\n1020.779s: on the machine learning side you mean on\n1023.06s: the machine learning side\n1024.5s: uh that's the great question yeah there\n1026.48s: are many different things so uh we are\n1028.76s: using of course some neural networks I\n1031.22s: mean there are some more sophisticated\n1032.66s: things so for instance uh Stephen has\n1034.64s: been uh is a computer scientist here\n1037.1s: he's been doing a lot of things also on\n1039.079s: uh dimensional reduction\n1042.02s: um using uh a lot of more\n1045.26s: can I say more recent models as well so\n1049.04s: it's not just stand up your networks but\n1051.44s: there's kind of a variety of tools as\n1053.9s: well maybe Stephanie want to talk more\n1056.0s: about those things yeah but you've been\n1057.98s: excited about recently\n1060.26s: yeah absolutely uh yeah welcome everyone\n1062.66s: and uh thanks Pierre for the great\n1064.4s: introduction so yeah there are lots of\n1066.02s: exciting neural network models being\n1068.059s: used\n1068.9s: um first of all you can of course treat\n1070.58s: climate prediction as a supervised\n1072.26s: problem where you can almost think of uh\n1074.6s: you know the sequence of atmospheric\n1077.299s: clouds as a video that you would like to\n1078.98s: forecast into the future and it turns\n1081.38s: out in machine learning there are many\n1082.58s: recent video prediction models that have\n1084.799s: been proposed for example\n1087.44s: um and the interesting part is now with\n1089.059s: all the excitement about generative Ai\n1090.799s: and the fusion models there's actually a\n1092.84s: lot of use cases for these kind of\n1094.4s: generative tools also in climate science\n1095.96s: for example you might want to\n1097.76s: hallucinate lower level details of\n1099.5s: clouds that you cannot really uh\n1101.48s: represent numerically because it's too\n1103.52s: expensive so then you want to kind of\n1105.08s: take a course simulation and fine-grain\n1106.94s: it and you know generate all the low\n1108.98s: level details to that simulation but\n1111.38s: there are also use cases of unsupervised\n1113.12s: learning for example uh you might want\n1114.98s: to look at all the data at present\n1117.5s: temperatures all the possible you know\n1119.299s: climates that have been simulated and\n1121.34s: now we assimilate everything at global\n1123.2s: warming and you want to quantify you\n1124.94s: know\n1125.6s: how strong is that distribution shift\n1127.4s: and then what can we learn from that and\n1129.02s: for example the three of us here on the\n1130.7s: call have already joined work on this if\n1132.86s: you're interested you can look it up on\n1134.24s: on the web\n1136.34s: yeah those are just a couple of examples\n1145.28s: yeah there are questions\n1150.86s: I had a logistics question\n1153.74s: um like could you tell us more about\n1155.96s: like what the three weeks before the\n1158.48s: program actually kicks off like the the\n1160.4s: virtual boot camp like what that looks\n1162.559s: like or what it's what it is\n1164.96s: yeah so we'll actually be talking a bit\n1167.12s: more about it over the next few slides\n1169.46s: um and so once we go over those and you\n1171.679s: have more questions definitely let me\n1173.179s: know later okay yeah my bad okay thank\n1175.22s: you\n1176.6s: Mike do you wanna get started\n1179.66s: sure yeah let's Dive In\n1192.679s: okay so so yeah I guess this will review\n1194.78s: some of the components\n1196.64s: um you've you've alluded some Mark to\n1198.5s: the three requirement and boot camp\n1199.64s: we'll learn more about that\n1201.26s: um and maybe I'll let jihet speak to\n1204.2s: these elements afterwards but I'd like\n1205.64s: to drill down into the specific project\n1207.14s: that we have in mind for the reu\n1210.26s: um can we go to the next slide\n1212.72s: and the next one\n1216.62s: okay right so uh for the research\n1219.679s: um Pierce stuff and I will all be acting\n1221.78s: as mentors the big picture here is about\n1224.36s: uh clouds in my opinion\n1226.64s: um so these are stratocumulus clouds I\n1228.2s: live next to them in Southern California\n1229.46s: I'm a professor here at UC Irvine on the\n1231.38s: west coast\n1232.4s: um and how these clouds will respond to\n1234.679s: climate change is a huge question\n1235.82s: multiple trillions of dollars if they\n1237.5s: shrink like ice sheets making climate\n1239.0s: change worse that's going to add more\n1240.38s: Hazard geopolitical and wildfire and all\n1242.48s: the rest because a warmer planet with\n1244.46s: darker ocean surfaces that are more\n1246.02s: absorptive if they if they thicken up\n1247.82s: which they might unlike ice sheets it's\n1249.44s: a less hazardous Planet so there's\n1251.36s: really big expensive questions attached\n1253.22s: to these questions about what clouds\n1254.9s: will do as a planet warms and uh Pierre\n1257.48s: mentioned the limitations of climate\n1258.679s: models and fixing those with AI is one\n1260.36s: of our goals in leap and we know that\n1262.82s: climate models cannot afford\n1264.38s: computationally to represent the details\n1266.299s: of cloud forming processes so that's\n1268.64s: part of the context for the summer\n1269.78s: project we go to the next slide\n1272.539s: now specifically what we want to do is\n1275.12s: to Target a particular simulation\n1276.919s: approach that allows us to make progress\n1278.96s: with testing the potential of ml to for\n1281.12s: this problem it's called multi-scale\n1282.679s: climate modeling usually in climate\n1284.66s: modeling what we do is we carve the\n1286.039s: world up into little grid cells and the\n1287.66s: grids those are too big to resolve Cloud\n1289.28s: physics and uh because we haven't really\n1291.38s: come to the whole world with resolution\n1292.7s: and simulated the whole world for 100\n1294.38s: years so there's a limit computationally\n1296.179s: on how how high-res you can be\n1298.659s: multi-scale Cloud models sort of\n1301.64s: sidestep this problem by putting high\n1303.74s: resolution physics in but just in little\n1305.9s: patches of atmosphere that are separated\n1307.94s: from each other and periodic so it's a\n1309.74s: way to sort of get high resolution\n1311.0s: physics in ahead of schedule if you make\n1313.34s: a few idealizations by combining them\n1315.14s: two Dimensions Etc but the key point is\n1317.659s: is that in these multi-scope climate\n1319.46s: simulation there are arteries between\n1321.08s: high resolution physics and planetary\n1323.059s: climate Dynamics and these arteries\n1324.799s: become excellent machine learning\n1326.539s: targets and they contain a lot of the\n1328.94s: complexity of learning even more\n1330.799s: complicated forms of high resolution\n1332.12s: physics it's like stochasticity and\n1334.159s: Chaos the micro models are chaotic\n1336.38s: models that produce little clouds and\n1338.6s: complexity they involve the mixture of\n1340.52s: turbulence and microphysics and\n1342.2s: radiation that that adds up to the\n1345.08s: important effects of clouds on climate\n1346.64s: and then also importantly\n1348.679s: um these multi-scale climate models\n1350.059s: allow convenient ways to learn Machine\n1351.74s: model surrogates for the high resolution\n1353.539s: physics that once trained you can couple\n1355.76s: back in and look at multi-skill machine\n1358.64s: learning hybrid physics simulations a\n1360.679s: new way of doing climate simulation so\n1362.299s: there's an easy way to implant\n1363.98s: surgically that trained machine learning\n1365.9s: models so some of the contexts so our Ru\n1368.48s: program is going to be focused around\n1369.86s: the opportunities in these multi-scale\n1371.539s: climate models Next Step\n1375.559s: um and and we're excited because we leap\n1377.9s: has championed the development of the\n1379.46s: best ever version of one of these data\n1381.08s: libraries\n1382.1s: um It's it's hot off the press with some\n1384.32s: of our our collaborators who build\n1385.88s: climate models in National Laboratories\n1387.62s: and so that's important because they've\n1389.48s: made sure to go through the code with\n1391.1s: the fine tooth comb and make sure all\n1392.9s: the causatively complete ingredients are\n1394.76s: there for everything that comes into the\n1396.26s: micro models and everything that comes\n1397.7s: out and we've also Advanced from the\n1400.58s: this sort of work has been happening for\n1401.9s: five years or so but mostly in\n1403.46s: fictitious ocean covered worlds and this\n1405.5s: data set now includes the challenges of\n1407.179s: real geography that you want to lean\n1408.86s: into for operational climate prediction\n1411.62s: um and so yeah the point here is that\n1413.24s: we're trying to expose our you students\n1414.74s: to real world research on the frontiers\n1416.659s: of um of of this kind of this kind of\n1419.96s: work and that means you'll be able to\n1422.299s: pipeline relevant data variables\n1423.98s: relevant formats that are relevant to\n1425.539s: Modern climate simulation and we've\n1427.58s: we're designing the data set to have two\n1429.14s: tiers of ambition one of which is course\n1430.7s: resolution so the data volumes are not\n1432.799s: super difficult and then one of which is\n1435.32s: operational resolution and there is you\n1437.72s: know bigger challenges of trying to\n1439.1s: scale Performance Machine learning when\n1440.539s: you want to work in that limit so a few\n1442.88s: opportunities next slide please\n1445.34s: yeah and I want to I want to present\n1447.38s: this as sort of like mdmnist of climate\n1449.78s: simulation for AI climate simulation so\n1452.059s: mnist for those who don't know was a uh\n1454.88s: an important step along the road to the\n1456.799s: disruptive image recognition deep\n1458.78s: learning Revolution we enjoyed to get\n1460.28s: today which began with a simple toy\n1462.5s: problem of categorizing digits\n1464.659s: um but coordinated competition and\n1466.46s: curated data sets around that problem\n1468.559s: really paved the way for uh advances\n1471.44s: that we now enjoy\n1473.539s: um and yeah so the spirit of this\n1475.94s: exercise is that leap is trying to make\n1477.679s: a climate eminist and you could be one\n1479.419s: of the first to work on it that contains\n1481.22s: the essence of high resolution physics\n1483.74s: um in these multi-scale climate models\n1485.36s: and sidesteps some of the complexities\n1486.799s: of non-locality but includes a lot of\n1489.08s: the complexities of stochasticity and\n1491.84s: um and high resolution Cloud physics\n1494.84s: Next Step\n1497.419s: and so um so some of the learning\n1499.76s: outcomes here are that you'll be trained\n1501.98s: in machine learning operations\n1504.26s: um you'll have to work on quality\n1506.24s: controlling input data you'll have to\n1507.74s: work on data engineering the sorts of\n1509.12s: things that people in in tech companies\n1511.039s: have to do all the time\n1512.78s: um you'll have to build training\n1514.88s: pipelines to do machine learning maybe\n1516.38s: those training pipelines will have to be\n1518.179s: really performant if you want to work on\n1519.799s: the ambitious data at high resolution\n1521.299s: the the large data libraries you'll have\n1524.0s: to do the things like assessing the\n1526.22s: goodness of fit you may Tinker with\n1527.659s: different loss functions different ways\n1529.159s: of measuring uh skill\n1531.799s: um Pierre mentioned and Stefan mentioned\n1533.659s: the the opportunity of exploring new\n1535.34s: algorithms so there's Advanced\n1536.48s: possibilities here of using modern\n1538.46s: methods that can learn multimodal\n1540.32s: physics that are generative that are\n1542.72s: stochastic including variational encoder\n1545.419s: decoders or or\n1547.6s: generative diffusion-based models\n1550.76s: um yeah so so a tier of opportunities\n1554.059s: but the goal is to get you to do\n1555.62s: Frontline stuff\n1557.059s: um Next Step\n1560.84s: yeah and you know it's possible things\n1562.4s: could work out great right if anybody\n1563.84s: happens to get a really great fit\n1566.539s: um for these data you know so brand new\n1568.1s: data no one's trying to fit it before\n1570.26s: um then you know at the end of the\n1572.6s: summer there could be opportunities to\n1574.159s: continue it on we are motivated to test\n1577.1s: provocative good fits that are\n1579.44s: exhibiting nice offline error skill\n1581.48s: scores and and taking those machine\n1582.86s: learning models and implanting them in\n1584.96s: the climate model which is a much richer\n1586.52s: testing environment where the\n1587.72s: imperfections of machine learning can\n1589.159s: feedback with fluid dynamics and that's\n1590.659s: another big research Frontier but one\n1592.7s: that takes a long longer than a summer\n1594.559s: to really explore but you can see the\n1596.779s: extensions of how this work on fitting\n1599.12s: this data Library might evolve into\n1601.36s: implanting promising machine learning\n1603.44s: models in hybrid simulation codes and\n1605.12s: examining the pathologies and hopefully\n1607.039s: the successes for the merged there and\n1608.84s: push us along the path of the peer\n1610.76s: mentioned of enriching today's climate\n1612.5s: simulations with AI sub modules so so\n1615.02s: these are the granular steps that move\n1616.58s: us along that path and the focus of the\n1619.279s: summer\n1620.24s: and I think that's it you want to move\n1623.0s: to Logistics\n1625.22s: um before we go a little bit deeper into\n1627.32s: the logistics of things does anyone have\n1629.419s: any questions for Mike while we are\n1631.82s: still on the research\n1637.279s: well you have some time and you can\n1638.659s: think of more questions if you'd like\n1641.179s: um so to go over some of the logistics\n1644.48s: um so the first three weeks will be\n1646.52s: entirely virtual this is a change from\n1648.62s: last year\n1650.12s: um last year was the first time the reu\n1652.1s: on for leap was\n1654.559s: um that was our inaugural summer and\n1657.44s: after that we've made a couple of\n1658.64s: changes to make things a little bit\n1660.02s: better for our undergraduate students\n1661.88s: and kind of offer a more robust and\n1664.22s: enriching experience so the first three\n1666.38s: weeks will be cut a boot camp online\n1669.559s: um and this will be\n1671.48s: one to two hours of live class per day\n1673.7s: likely in the morning Depend and we will\n1677.0s: get you that schedule later on and this\n1680.24s: will also be four hours of self-guided\n1682.159s: learning about four days a week in the\n1684.14s: first three weeks\n1685.82s: um after those first three weeks\n1688.22s: um campus move-in will be on June 25th\n1690.62s: which is a Sunday and then the Monday\n1693.44s: after that your research will begin on\n1696.26s: campus depending on how what you will be\n1699.5s: working on\n1700.7s: um over the summer we'll have weekly\n1702.38s: enrichment and social events\n1704.419s: um there will be mentorship\n1705.32s: opportunities with graduate student\n1707.36s: mentors and finally\n1711.5s: um\n1712.039s: this sorry the program ends at on July\n1715.1s: 29th\n1716.299s: um but to go over in a little bit more\n1718.7s: detail what the virtual summer uh the\n1721.039s: momentum boot camp will look like\n1723.86s: um to go back\n1726.14s: the first three weeks will be week one\n1728.72s: will be with Dr Julia suseki he is our\n1731.12s: data and manager of data and Computing\n1733.34s: at leap he will be covering data\n1735.38s: Computing and collaboration\n1737.419s: Candace agonafir will be going over\n1739.88s: foundations and ML and climate modeling\n1741.98s: and then finally Dr Jin will be going\n1745.039s: over paper reading and presentation so\n1746.9s: these are all skills that we are hoping\n1748.76s: that you have going into your research\n1751.279s: so that everyone is kind of going into\n1753.14s: their summer research on the same page\n1754.88s: with you know similar skills and making\n1757.7s: sure that everyone is set up for Success\n1759.5s: throughout the rest of the summer\n1764.48s: um for our eligibility and application\n1766.159s: so I'm hoping that everyone here has\n1768.44s: already taken a look at the application\n1771.2s: um eligible students include Rising\n1773.299s: sophomores Juniors or seniors in the\n1775.399s: fall of 2023 so if you are graduating\n1777.919s: this may unfortunately you will not be\n1780.08s: eligible\n1781.52s: um we will also we are also working with\n1783.26s: current Source Protege and applicants\n1786.02s: must be a U.S citizen or a permanent\n1788.179s: resident\n1789.08s: if you have any specific questions about\n1790.94s: that feel free to reach out to me\n1792.44s: directly over email and we'll get I'll\n1794.84s: show I'll get you the email address soon\n1797.419s: um the application is due next Friday\n1800.48s: um at 11 59 PM we would need your resume\n1803.539s: a transcript it could be unofficial a\n1807.38s: statement of interest and a reference\n1810.02s: who will provide a recommendation letter\n1811.7s: and that can be sent to LEAP\n1814.24s: columbia.edu all of the application\n1817.1s: information is on this link at the\n1819.559s: bottom which you will also receive after\n1821.96s: this session\n1823.76s: um and some important dates again\n1826.279s: applications are open deadline is next\n1829.1s: week and you should know by the end of\n1831.14s: the month whether you will be joining us\n1833.6s: on campus\n1835.399s: a few frequently asked questions are are\n1838.58s: here can students reach out to Elite\n1840.44s: researchers directly\n1841.82s: we prefer that you don't if you have any\n1843.919s: questions please reach out to leap\n1845.679s: columbia.edu and we'll get those um\n1848.059s: questions answered for you\n1850.1s: um the program will be hybrid this year\n1851.659s: so again the first three book weeks will\n1853.94s: be virtual you can tune in from wherever\n1856.159s: you wish\n1857.48s: um that that I think that flexibility is\n1859.46s: nice for the first three weeks and then\n1861.38s: the last five will be in person in New\n1863.659s: York City\n1865.34s: um summer housing will be provided for\n1867.38s: those that are not already local\n1869.179s: students and you will be on campus in\n1871.88s: the Columbia University East Campus\n1874.46s: storm\n1876.14s: um I mentioned this earlier but\n1877.52s: International students are not eligible\n1880.22s: to apply\n1881.779s: um if you have specific questions again\n1883.64s: please reach out and finally the stipend\n1886.76s: for the eight weeks\n1888.32s: um in addition to the housing the\n1890.0s: stipend for the summer will be five\n1892.52s: thousand four hundred dollars so this\n1894.38s: gives you a bit of flexibility to\n1897.08s: um you know spend time in New York in\n1898.76s: person and\n1900.679s: um you know\n1901.88s: have a good time in New York while\n1903.32s: you're also engaging in some really cool\n1904.88s: research\n1906.14s: again the link to all of the information\n1908.96s: is at the bottom we'll get you this\n1911.12s: recording as well so that you know you\n1913.399s: don't miss anything\n1914.779s: and we'll take any questions if you have\n1917.0s: any\n1922.34s: um yeah I have a question about the\n1925.34s: application\n1927.32s: um so I was wondering\n1929.299s: um is there any specific courses that\n1932.0s: you should take before you apply like do\n1934.46s: you need to know like the basics of like\n1937.039s: machine learning or on physics or any\n1939.799s: other courses\n1941.779s: um before you apply for this program\n1946.76s: I will let um here Mike and step and go\n1949.94s: answer that question\n1952.88s: I mean we will have some tutorials but\n1955.7s: we also have some uh online tutorial\n1958.94s: that we can provide especially for the\n1961.039s: use of um the panzero platform\n1963.38s: especially basically uh cloud data\n1966.2s: infrastructure and also\n1968.12s: for the use of machine learning\n1969.98s: especially the basics you know neural\n1972.32s: network and some neural networks so this\n1974.48s: we can totally provide\n1976.1s: okay okay thank you\n1982.399s: uh I had a question about the sores\n1984.26s: affiliation so do we also have to apply\n1986.659s: then because would that be a whole other\n1988.58s: process of applying and doing that same\n1990.14s: thing again with you for the leap um I\n1993.08s: guess email with the uh information you\n1996.44s: provided or how would that work\n1998.36s: um if you could submit an application\n1999.86s: regardless um we will be coordinating\n2001.96s: with cadetia\n2003.46s: um to see what that format is going to\n2005.32s: look like\n2006.519s: um after we review applications so\n2008.62s: definitely submit an application\n2010.6s: um I think I have some information\n2011.679s: already but\n2013.84s: um definitely submit so we have it all\n2015.76s: in one place\n2019.0s: foreign\n2022.96s: so during the main sort of research\n2025.539s: portion of the summer uh will students\n2027.58s: be working in teams or individually and\n2030.64s: how often will we be meeting with our\n2032.919s: mentors\n2039.82s: um Mike\n2040.46s: [Music]\n2043.179s: over the research piece of this but in\n2045.7s: terms of the social\n2047.32s: in-person piece we will definitely have\n2050.379s: at least once a week in person on\n2052.96s: Thursdays for you all to come in person\n2055.06s: to The Innovation Hub located in the\n2058.419s: manhattanville campus of Columbia\n2060.879s: um so you will be expected to join us in\n2063.639s: person at least once a week for group\n2066.46s: work that will also that can also be\n2069.82s: happening virtually and I'll let Mike\n2071.679s: appearance back over there\n2078.419s: is again to team up to some extent so\n2081.52s: the the expectation would be to have\n2083.8s: like specific sub-topics that one that\n2086.74s: that could draw like a few students\n2088.359s: together you know so that you can\n2089.44s: collaborate on some pieces of code\n2091.06s: ideally across disciplines as well\n2094.599s: um and then uh there's gonna be some\n2097.359s: mentoring directly from PhD students on\n2100.24s: a more regular basis and then uh once a\n2103.54s: week uh basically uh meeting with the\n2107.02s: the ti so the three of us you know so\n2109.06s: all\n2110.14s: so that uh you have basically two\n2111.82s: interaction points you know because also\n2114.64s: like typically\n2116.26s: my experience or our experience is that\n2118.599s: uh especially in laboratory it's\n2120.22s: students sometimes don't feel super\n2121.96s: comfortable talking to faculty members\n2123.94s: you know it's just like maybe eight now\n2126.16s: that we are aging uh but uh so it's nice\n2129.88s: to have like a PhD student they feel a\n2131.619s: bit more comfortable asking like uh more\n2133.9s: routine type of questions especially\n2135.52s: about coding and things like that makes\n2137.619s: it a bit less can I say intimidating\n2140.92s: let's put it this way it's good to have\n2143.38s: those two pieces of instructions\n2147.16s: and I think one I think your question\n2148.66s: about whether you're working in groups\n2150.099s: is a really good one because you know\n2151.72s: part of the goal of the center is to\n2153.339s: Champion the new field of climate data\n2154.96s: science and and certainly we were aware\n2157.06s: of the software engineering and team\n2158.8s: programming benefits that you can also\n2161.14s: see in Industry as something that we\n2162.76s: want to Mentor on and so that's where I\n2164.8s: think the existence of the Central\n2166.42s: Computing Hub uh this Lee pangeo\n2169.06s: Computing resource which I I imagine\n2171.76s: you'll be trained on in the first three\n2173.32s: weeks of this program will hopefully\n2175.48s: provide a a place to congregate and uh\n2178.42s: conditions for for team\n2181.24s: um sort of you know self-assembly\n2184.3s: um but it's always difficult to predict\n2186.22s: whether a team will gel and whether one\n2188.14s: will ignite but we very much want to\n2189.76s: Foster that that sort of uh\n2192.64s: experience because the technical skills\n2194.92s: are shared more efficiently that way and\n2196.599s: I fully agree with Pierre that this\n2198.76s: tiered mentorship strategy of having PhD\n2201.16s: students doing this work on the front\n2202.66s: lines are really better equipped to\n2205.119s: transmit those tools to you as well is a\n2207.4s: big part of the plan\n2213.579s: thank you\n2219.88s: any more questions\n2227.56s: great okay I'm going to take that as a\n2230.44s: no there are more no more questions but\n2232.3s: again you know how to reach us leap\n2234.3s: columbia.edu should any questions come\n2236.5s: up and I will be responding to those\n2239.56s: um so\n2241.119s: um yeah let us know if you have any\n2243.04s: questions about the application uh the\n2246.52s: link uh to the website I will actually\n2249.4s: drop into the chat right now\n2253.24s: in case that's easier to access\n2256.24s: okay great\n2258.22s: that is everything that we have for you\n2259.96s: today but again reach out with any\n2263.26s: questions\n2264.28s: um that might be more specific to you\n2267.28s: and thank you Mike here Stephen for\n2269.68s: joining us\n2271.96s: thanks a lot yeah and the data is really\n2273.82s: exciting so maybe we could share later\n2275.859s: some some cool videos or some cool\n2278.2s: animations it's pretty impressive to see\n2279.88s: like those small details about the\n2281.56s: clouds Etc it's really cool cool stuff\n2286.359s: thanks everyone have a great weekend"
    },
    {
        "class": "YouTubeVideo",
        "title": "LEAP ML Journal Club: Kevin Xia",
        "videoId": "LJZMUwqBZ4Y",
        "url": "https://www.youtube.com/watch?v=LJZMUwqBZ4Y",
        "publishedAt": "2023-02-09T23:04:03Z",
        "transcript": "4.259s: okay\n5.759s: um so hi everyone\n6.96s: um my name is Kevin Shaw I'm a I'm a PhD\n9.54s: student\n10.559s: um in the Cs Department here at Columbia\n12.0s: University my advisor is Elias baronboy\n14.46s: and um we're part of the causal AI lab\n17.279s: and today I'm going to be talking about\n18.9s: the causal neural connection\n21.84s: so\n22.92s: first let me introduce the the\n24.66s: references that this talk will be based\n26.22s: on\n26.939s: um there's three papers the first is the\n29.58s: causal neural connection expressiveness\n31.32s: learnability and inference uh this was\n33.48s: joint work with kaizan Lee and Joshua\n35.399s: bengio and Elise baronboy and this one\n38.04s: introduces the idea of this connection\n40.26s: between uh causal models and neural\n42.48s: models\n43.5s: then more recently we have neural causal\n46.079s: models for counter factual\n47.04s: identification and estimation this is\n48.78s: Joint work with yushu pan and Elise\n50.52s: verbum and this one is an extension of\n54.48s: the previous work that greatly\n55.62s: generalizes um all of the content and uh\n58.86s: um reaches over into\n60.66s: um not just causal domains but also\n62.579s: counter factual uh quantities\n65.46s: and then finally the third work isn't\n67.14s: really related to neural models it's on\n69.78s: Pearl's hierarchy and the foundations of\n71.4s: causal inference this one is more of\n73.32s: like the It sets the foundations in\n75.299s: causal inference about what I'm going to\n77.58s: be talking about here today\n79.619s: so\n80.939s: before\n82.02s: um before we uh\n83.64s: dive into the details uh let's talk\n85.92s: about a little bit about the motivation\n87.36s: of of this this work so first\n91.439s: um neural networks are Universal\n93.299s: function approximators so this there's a\n94.74s: well-known uh theorem in in deep\n97.2s: learning theory which is the uh the\n99.119s: universal approximation theorem it\n100.74s: basically says that neural networks can\n102.659s: can\n104.579s: um Can approximate any function to\n106.74s: arbitrary Precision essentially\n109.68s: um\n110.579s: and since most tasks in AI can be\n112.799s: modeled using functions then it's\n114.24s: hypothesized that neural networks can\n116.04s: solve can be used to solve these tasks\n118.259s: and some even say maybe neural networks\n120.659s: can solve everything\n122.7s: and this is further um supported by the\n125.64s: fact that neural networks have a lot of\n127.439s: empirical success in several areas like\n129.599s: computer vision speech recognition and\n131.22s: game playing to name a few\n134.22s: so the research questions that we want\n135.78s: to investigate are one how are causal\n138.36s: and neural models related and two can\n140.879s: neural models be used to perform causal\n142.8s: reasoning\n146.879s: um so I'm not sure what the uh the level\n149.4s: of um background is here for a causal\n151.98s: inference um so I thought I'd go over a\n154.5s: little bit of causal inference review\n155.459s: first\n156.66s: so um in causal inference one of the\n159.239s: central elements on a central data\n161.879s: structure that we use to study causal\n163.5s: inference is called the structural\n164.58s: causal model or SCM for short so this\n166.86s: goes back to when um when you to Pearl\n169.739s: um was for studying causality uh it's\n171.66s: like kind of like the data structure\n172.86s: that that he uses uh that he studies\n176.879s: so the SCM\n179.099s: um contains it represents an underlying\n181.68s: causal system with two major components\n183.48s: there's the collection of causal\n185.099s: mechanisms or structural functions and\n187.2s: this is represented with the the symbol\n189.12s: F\n189.9s: and there's also the external or\n191.819s: exogenous sources of variation outside\n193.379s: of the system uh essentially like\n195.48s: variables that we don't observe you and\n197.34s: then their corresponding probability\n198.659s: distribution P of U right\n201.18s: and\n202.56s: importantly every SCM induces a\n205.739s: structure called The Parallel causal\n207.48s: hierarchy which includes qualitatively\n210.18s: different distributions in\n212.58s: um this containment hierarchy of three\n214.379s: different layers right so each one\n216.06s: contains excessively richer information\n218.22s: in some sense so layer one is\n220.98s: observational data observational\n222.659s: distributions this is related to the\n223.98s: human Act of like seeing right so\n226.379s: um when you're passively observing the\n228.42s: data when you're passively observing the\n229.92s: environment and you're collecting data\n231.18s: uh this is this is the kind of data you\n233.7s: you you get and this is what most data\n236.4s: in machine learning ends up being\n238.5s: um so this is like typically related to\n240.299s: the machine learning tasks for example\n242.099s: supervised or unsupervised learning for\n244.2s: example when you're doing classification\n245.519s: you're looking at maybe the the\n247.5s: association between the features X and\n250.2s: the label y right then um and this is uh\n252.84s: you're kind of working with\n253.56s: observational data because\n255.239s: um you're not really thinking about\n256.199s: whether there's a causal effect you're\n258.18s: just you're just looking at um any kind\n260.519s: of like link between your features and\n262.44s: the MLA\n264.24s: however if we go one layer higher we\n266.34s: have the Interventional layer so this\n269.22s: corresponds to the human\n271.08s: um the human concept of like doing so\n272.88s: like actually physically going into the\n274.68s: system and changing something yourself\n275.759s: intervening right so\n277.979s: um you make these patients take a drug\n280.74s: or you implement this policy right then\n283.86s: um then that's like you're kind of\n285.12s: intervening on the system and you're\n286.86s: you're you're changing what would have\n289.08s: would have naturally been there\n291.24s: um and these these interventions result\n293.46s: in like a more richer set of information\n295.199s: where like maybe like experiments fall\n297.54s: for example and this is often related to\n300.18s: the uh machine learning concept of\n301.74s: reinforcement learning where you might\n303.66s: have an agent that's like kind of\n305.1s: roaming around the environment and\n307.38s: actually like\n308.4s: um while not just observing things also\n310.5s: kind of like changing things and seeing\n312.36s: what happens right and then finally the\n315.12s: third level\n316.259s: um which is uh an even higher layer uh\n319.68s: encompassing everything else this is the\n321.479s: counter factual layer and it has to do\n323.34s: with the um the concept of imagining so\n326.22s: this would be like\n327.96s: um thinking so this would be like you\n330.0s: you you make a patient take a drug the\n332.34s: patient died for example would the\n334.86s: patient still have died had they not\n336.72s: taken the drug would would we still be\n339.3s: in a recession had we not implemented\n341.28s: this policy right we're we're thinking\n343.139s: about hypothetical worlds that didn't\n345.419s: actually happen\n346.979s: um and uh based on what what did\n349.919s: actually happen right\n351.84s: um so this is one layer above\n353.699s: interventions because we can't just\n355.32s: revert back time and do something else\n357.78s: because we've already kind of committed\n359.28s: to one course of action although it's\n360.96s: very important because we're often\n362.88s: trying to figure out what are the\n364.02s: consequences of the action why did this\n365.58s: happen right what what would have\n367.259s: happened in other uh other situations\n369.479s: yeah I mean also just to say that I\n371.82s: think Polo has collaborated with some\n373.74s: people where you also do the\n375.539s: counterfactual in the future right like\n377.52s: in terms of climate change or so if if\n380.1s: we go through this emissions pathway\n381.96s: like so in principle it's also relevant\n384.9s: to the Future as well right hypothetical\n386.699s: situations absolutely yeah yeah\n389.759s: um if there's many like motivations to\n391.319s: why you would want to know this\n392.639s: information and sometimes\n394.8s: um sometimes we can't because we can't\n397.08s: know Both Worlds at once but um\n399.419s: sometimes you know given certain\n400.74s: assumptions uh this is something that we\n402.6s: want to and can infer\n406.919s: um so this is kind of the more formal\n408.6s: definition of the structural causal\n410.28s: model which I'll briefly discuss so it's\n412.979s: a structural custom model which we\n414.66s: usually label with Adam is a four Tuple\n417.3s: u v f and P U right so U is the set of\n420.78s: background variables or exogenous\n422.4s: variables so these are kind of like like\n423.78s: the the noisy outside factors that we're\n425.759s: we don't really care about and then V is\n428.46s: the set of variables that are endocious\n429.9s: variables these are the variables that\n430.919s: we do care about the ones that we\n432.06s: observe the ones that we are studying\n433.68s: right and then the functions Define the\n436.68s: behavior of these endogenous variables\n438.479s: in V so each V has its own function f of\n441.06s: VI right and then\n443.16s: um what influences that variable are its\n445.979s: parents from the endogenous set and also\n448.139s: certain outside factors from the\n449.4s: exogenous set\n451.38s: um and then finally\n453.18s: um P of U is a distribution over the um\n456.78s: over the random exogenous sources of\n459.36s: variation so\n460.86s: um when you combine all of these\n462.72s: um you can see how maybe um you might be\n465.539s: able to collect samples right like you\n467.46s: you sample from uh from peer view to get\n469.979s: the exogenous sources of noise and then\n473.819s: um and then you successively pass\n475.38s: through all of these functions in in\n477.3s: topological ordering and that provides\n479.22s: samples for for v as well right then\n481.919s: interventions uh have to do with\n483.479s: replacing these functions\n486.72s: all right\n488.34s: so\n490.199s: um to talk a bit about\n492.06s: how the uh how the PCH emerges from the\n495.84s: SCM\n497.4s: um so typically when we're when we're\n498.78s: studying something in causal inference\n501.84s: um we we understand that there are some\n503.52s: that nature has some rules and that\n505.979s: there's some true model that's governing\n507.72s: what whatever we're seeing but we don't\n510.18s: typically know what it is so we may have\n513.3s: this SCM M star that is describing the\n516.18s: underlying on reality but we don't see\n518.7s: this\n519.479s: and\n521.159s: um Instead This sem induces\n524.399s: it's it's three layers of the PCH it\n527.459s: induces observations it induces\n529.74s: interventions and it induces counter\n531.54s: factuals right\n533.7s: um and typically\n536.339s: um typically we don't we don't know uh\n539.82s: we don't know the as the true scmm star\n541.44s: we we only know data from the true sem\n544.019s: that comes in the form of these PCH\n546.12s: distributions and further we don't\n548.1s: always know all of the PCH either we\n549.899s: don't want we don't typically have\n550.92s: counter factual data for example\n553.26s: um so\n554.519s: um the first question is is it possible\n556.08s: to perform inferences when both the SCM\n558.18s: and the PCH are not fully observable so\n560.82s: perhaps you have\n562.38s: um you have only observational data and\n564.6s: you don't have any Interventional or\n565.98s: kind of factual data like these are\n567.3s: unobserved for example\n569.519s: um and so what we want to do is we want\n571.74s: to take our observations and we want to\n574.38s: essentially cross layers we want to\n576.54s: infer something from the other layers\n578.16s: using only the information from layer\n580.14s: one\n581.16s: um so that's called cross layer\n582.36s: inferences and that's the other major\n584.1s: question that we want to answer here\n586.68s: so what's a naive idea to try to like\n589.5s: get started well what if we just like\n591.779s: slap on a neural model because we we\n593.7s: know that neural networks are really\n594.899s: powerful and we try to learn it that way\n596.22s: right so what we'll do is we'll take a\n598.08s: neural model um we'll call it m-hat and\n601.08s: we'll say okay this neural model induces\n604.2s: its own three layers of the PCH it has\n606.0s: its own L1 L2 L3\n608.94s: and what we'll do is what we have\n611.339s: observational data from the real sem\n613.32s: we'll just train this neural model m-hat\n616.32s: so that it also matches in the the true\n620.519s: model in layer one and then we'll query\n623.279s: this model we'll check if uh if there's\n625.98s: anything we can learn from Layer Two\n629.64s: um\n630.36s: so how would this uh neural model be\n633.18s: designed well let's just take an sem and\n635.459s: for the functions we'll replace them\n636.779s: with feed for a neural networks for\n638.519s: example\n639.779s: um and then for for the distribution the\n642.12s: noise distribution let's just use\n643.2s: uniform01 because it tends to be very\n645.36s: flexible right so\n647.279s: um then uh in intuition tells us that if\n649.5s: we design the the neural causal model\n651.42s: this way\n652.56s: um that it uh it is very flexible and\n654.779s: we'll be able to learn many different\n656.279s: like types of functions right\n659.519s: um and indeed\n662.279s: um so we we introduced the uh the neural\n665.16s: causal model or the NCM\n667.26s: um and uh the reason this is important\n669.12s: the reason why we need to use neural\n670.68s: networks is because we can train this\n672.779s: model right it's actually um we can\n674.579s: actually it has parameters and we can\n676.74s: tune those parameters to get the the\n678.24s: function that we want right\n680.04s: right\n680.64s: um and uh\n682.56s: and and indeed intuitively it's\n685.5s: expressive so\n687.12s: um we we show that constraining the\n688.98s: attention to ncns doesn't actually incur\n691.019s: any loss of information compared to\n693.12s: um uh actually just studying in the\n695.16s: space of SCM so just because we fitted\n697.68s: the sem with neural uh with with neural\n700.5s: network functions doesn't make it any\n702.06s: less expressive so actually\n704.579s: um and so the class of ncms is\n706.86s: essentially just as expressive as a\n708.18s: class of SCS thanks to the neural\n709.98s: networks right\n711.24s: but\n712.62s: um unfortunately there's also this\n714.12s: negative result here which is which we\n715.86s: call the neural causal hierarchy Theory\n717.48s: and this states that despite the\n719.279s: expressiveness of the NCM\n721.38s: if we only have data from a lower layer\n724.26s: of a PCH like observational data\n727.079s: we would almost never be able to make\n729.36s: inferences about the higher layers of\n731.459s: the pch-like interventions or\n732.779s: counterfactuals um using ncms without\n734.94s: any further assumptions\n738.06s: so the reason this is the case is\n741.48s: because it turns out that the\n743.76s: observational data highly under\n745.38s: specifies\n746.94s: um the model there are many possible\n748.92s: models which could which could all agree\n751.26s: on on layer one but they have completely\n753.839s: different results for Layer Two and you\n755.94s: can't just uh pick one and and hope that\n758.82s: it works right\n760.2s: right\n760.86s: um\n761.64s: so unfortunately our first idea doesn't\n764.1s: work\n765.72s: but\n769.2s: I mentioned that\n771.06s: um it's not possible without further\n772.98s: assumptions so what can we do with some\n775.019s: assumptions right maybe\n777.3s: there's some sort of like constraint\n779.519s: that we can enforce directly into the\n782.279s: neural model\n783.42s: um something that we assume is true\n784.92s: about the true model and then force that\n786.54s: into the the neural model as well\n789.36s: um we call that the causal inductive\n790.98s: bias right um we force the neural model\n793.139s: to take a specific constraints into\n795.66s: consideration\n796.98s: um before attempting to fit the data\n800.04s: and\n802.5s: um the pipeline is like this so you have\n804.42s: the true model M Star then um presumably\n808.56s: um it induces some sort of uh some some\n810.66s: sort of constraints which\n812.639s: um now where now we're making some\n814.5s: assumptions here we're we're assuming\n816.54s: that there's certain constraints about\n818.04s: the true model that we're now going to\n819.66s: apply to our to our um uh our uh our\n823.26s: learn model\n824.639s: and um the one the specific one that we\n827.16s: use is called the causal diagram and\n828.899s: it's a it's a it's a graph\n831.72s: um where all of the variables are nodes\n833.279s: and the arrows represent qualitative\n835.32s: relationships between uh the variables\n837.959s: so in this case\n839.459s: um here it's saying that X causes z\n843.3s: um or or more specifically that Z\n846.24s: doesn't cause X right um here y doesn't\n849.0s: cause the uh X doesn't cause y uh except\n851.82s: through Z right\n853.5s: um and then uh this bi-directed arrow is\n855.54s: saying that there's some unobserved\n856.68s: confounding between X and Y\n858.779s: uh and maybe more importantly the lack\n862.139s: of one shows that there isn't any\n863.579s: unobsurd compounding between say x and z\n865.5s: right so um this is qualitative because\n868.2s: um unlike knowing the SCM where we know\n870.3s: the exact functions and probability\n871.98s: distributions all we need to know\n874.139s: um about this is we need to just draw an\n875.88s: arrow and say okay there's some causal\n877.32s: effect I don't know what it is but\n879.3s: um we that's uh uh that's something that\n882.6s: we think is is true right so\n884.82s: um we we know that we can't make causal\n887.399s: inferences out of nothing so now let's\n889.44s: try to do it with a little bit of help\n890.94s: with with some um assumptions\n892.86s: essentially\n894.42s: um we take this graph and what we can do\n896.519s: is we can actually force it into the\n898.38s: neural causal model we can force it into\n900.12s: the construction\n902.1s: um and in this for this particular graph\n903.959s: it may look something like this right\n906.42s: um where um we have a neural network for\n908.04s: x z and y\n909.899s: um and then um the uh the network for Z\n913.139s: takes x's and put the network for y\n914.82s: takes Z as it could and then um the uh\n918.12s: the functions for X and Y both share the\n921.48s: same exogenous noise here uh uxy\n926.82s: um\n928.199s: so there's two important properties that\n931.44s: we prove about this constrained class\n932.76s: right\n933.779s: but first\n935.04s: is that so we call these G constrained\n937.44s: ncms where G is the graph right so the\n939.72s: first is that\n940.92s: um any G constrained NCM\n943.32s: is gl3 consistent and what that means is\n946.26s: there's a set of constraints that the\n948.48s: graph is encoding\n950.279s: uh for example in in this graph\n953.579s: um there's no this one one constraint is\n955.86s: that there's no causal effect from Z to\n957.6s: X or for example right\n959.88s: um there's there's many of these that\n961.44s: that are kind of like\n962.88s: um there could be potentially like\n965.04s: exponentially many different constraints\n967.44s: um they're all nicely encoded in this\n968.82s: graph and all of them\n970.62s: all of them hold on all three layers\n972.959s: layer one layer two layer three\n975.0s: um if your NCM is G constrained right so\n978.12s: what that means is\n980.16s: um you have this dark gray area which is\n982.26s: the subset or which is the space of all\n984.3s: seems and then you have this light gray\n986.399s: area which is just the ones that are\n987.899s: satisfying the constraints the\n989.16s: assumptions that you make essentially\n990.779s: and Theorem one here is saying that\n993.0s: there are no G constraint ncms uh better\n996.06s: outside of this gracer this like racer\n1000.32s: uh then the next important result is\n1003.139s: that essentially that these constraints\n1005.779s: don't hurt the expressivity of the NCM\n1008.12s: so for any SCM uh that induces uh this\n1011.959s: graph there exists a g constrained NCM\n1015.86s: that is L3 consistent with respect to\n1018.74s: that SCM so LV consistent meaning it\n1021.44s: matches that SCM on all three layers\n1025.579s: um so what that means is um within this\n1027.799s: gray Circle\n1030.439s: any sem in there can be represented by a\n1033.74s: giencia\n1039.5s: so this brings us to\n1042.079s: um our our tasks now that we have the\n1044.0s: these constraints now now we want to see\n1045.74s: maybe there's some tasks that we can\n1047.059s: solve right so\n1048.5s: um the first task is causal\n1050.059s: identification\n1051.559s: and this task asks can we compute\n1055.76s: higher level effects like interventions\n1057.74s: or counter factuals from lower level\n1059.419s: data it's like a yes or no question\n1061.1s: right like\n1062.48s: um like\n1064.039s: basically we have this query we want\n1066.08s: maybe it's a causal query maybe it's\n1067.7s: counterfactual query but all we have is\n1069.2s: observational data and we want to know\n1071.66s: um can we actually get this can we\n1072.98s: actually answer this\n1075.5s: um and\n1076.46s: the the facts or the the\n1079.039s: um the the goal of answering that\n1080.84s: question is a task in itself\n1082.82s: right so\n1083.9s: um there's uh there's extensive\n1085.4s: literature in this problem\n1087.32s: um\n1088.1s: under various assumptions in terms of\n1089.96s: input and output and one one well-known\n1091.76s: one is Pearls do calculus right so\n1094.76s: um\n1095.9s: uh this has essentially been solved in\n1098.66s: many different um problem settings uh\n1101.179s: symbolically as in\n1102.919s: um people have figured out how to use\n1104.78s: math and like um like tweak around the\n1107.179s: constraints uh looking just at the graph\n1109.1s: to solve this question\n1110.66s: but there's currently no neural or\n1112.64s: optimization method capable of solving\n1114.5s: this method uh or like not until not\n1116.419s: until this is working always\n1118.4s: um\n1119.66s: and then the second one is causal\n1122.179s: estimation where okay we've determined\n1124.7s: that the query is identifiable as in it\n1127.28s: can be computed how do we actually do it\n1129.38s: with finite samples and computational\n1131.96s: resources right\n1134.84s: and actually\n1137.72s: um for for certain for like causal\n1139.88s: queries in L2 which are identifiable\n1142.1s: through adjustment which is um this\n1144.08s: common assumption that you might see in\n1145.34s: the literature it's also known as um uh\n1148.039s: the back door condition or um uh Ruben's\n1150.799s: ignorability conditions\n1152.66s: um there's actually extensive literature\n1154.4s: on how to estimate those cases using\n1156.44s: both neural and non-neural methods so\n1158.179s: these are this is like one specific set\n1160.7s: of assumptions which is made frequently\n1162.679s: throughout the causal inference\n1163.94s: literature\n1165.2s: um this has been very well studied\n1167.72s: on the other hand um\n1169.52s: that set doesn't represent the case of\n1172.4s: or the set of all queries that are\n1174.02s: identifiable so for effects that are for\n1177.2s: other effects that are identifiable the\n1179.36s: the options are a lot more limited and\n1181.46s: there are methods currently that are\n1182.84s: based on machine learning or robust\n1184.28s: statistics but\n1186.08s: um there's no neural method for\n1187.4s: performing estimation in general which\n1189.02s: is one of our our biggest motivations\n1190.52s: because since we believe that since\n1192.98s: we've seen the strong successes of\n1194.539s: neural networks we would like to use\n1196.94s: this uh use the strength to improve our\n1199.64s: performance at estimation yeah what\n1202.28s: methods do you mean\n1204.14s: um yeah there are methods based on\n1205.7s: machine learning yeah so names yeah so\n1208.64s: um so uh there's um there's one approach\n1211.28s: called um weighted empirical risk\n1213.26s: minimization okay yeah yeah uh yeah okay\n1215.78s: yeah\n1216.86s: um yeah that's one of them and then uh\n1218.66s: there's also um these ideas like like\n1220.88s: there's one called double machine\n1221.9s: learning yes yeah\n1224.059s: so uh yeah so these are these are some\n1225.919s: approaches that you can use um and\n1227.419s: they've actually uh these have been um\n1230.24s: Extended more generally past the back\n1232.52s: door and can be used in a wide variety\n1234.26s: of settings sorry a basic question from\n1237.14s: very non-expert\n1238.7s: um what do you mean by identifiable\n1242.6s: um\n1243.26s: so um so basically it's identifiable if\n1247.039s: um if we know that we can if it's like a\n1249.44s: higher level quantity a higher layer\n1251.299s: quantity and we know we can compute it\n1252.62s: from uh the lower layer data right and\n1254.84s: and then um I'll go into more detail\n1257.24s: about like about how this this problem\n1259.52s: is solved uh like later in the\n1261.38s: presentation uh so hopefully it'll be\n1263.24s: more intuitive\n1266.179s: um\n1267.74s: okay yeah so I guess I guess right now\n1271.24s: so the um this is the so before we talk\n1274.7s: about like uh like um identification in\n1277.34s: the context of ncms let me first discuss\n1279.5s: what the classical identification\n1281.419s: problem so the very first like instance\n1283.58s: of the identification problem\n1285.2s: um what is there what does it really say\n1286.58s: right so this is just causal effect\n1288.38s: identification all the way back from\n1290.12s: from Pearl's textbook right\n1292.64s: um and uh\n1294.679s: um the definition is you're given a\n1298.22s: causal diagram\n1300.08s: and the observational distribution PV\n1303.44s: and\n1304.88s: um then we say that the causal effect P\n1307.58s: of Y given to X so this is uh the causal\n1309.98s: effect of X on y\n1311.659s: is identifiable from the observational\n1313.82s: distribution PV and the graph G if and\n1316.28s: only if for every pair of scms that uh\n1319.76s: are that induces ref G\n1322.64s: um if they have if they match in the\n1325.7s: observational data PV\n1327.44s: then they also must match in the causal\n1329.72s: effect of x sub y right so uh the\n1332.419s: diagram here kind of shows what's going\n1333.62s: on it we're saying it's identifiable if\n1335.96s: you can take any pair of scms such that\n1338.78s: they match they match in the\n1340.82s: observational data and in the graph\n1343.1s: um and they must also match in the query\n1345.919s: uh the causal effect of X on y right so\n1348.2s: so what this is saying is okay if we if\n1350.84s: we can\n1351.74s: if we can take any of these seos we can\n1354.14s: just make sure that they map that they\n1355.58s: they match the constraints in this graph\n1357.62s: and then we make sure that they they\n1359.179s: induce this uh this observational data\n1361.76s: then we're guaranteed that they they can\n1363.74s: give us the correct query\n1366.919s: um and and even if it's not the true sem\n1369.08s: right as long as it satisfies this uh\n1371.24s: it's this is this is called identify\n1373.82s: okay\n1376.1s: um so\n1378.2s: um here's like kind of like a visual\n1379.88s: like explanation of how this works so um\n1382.34s: let's say here that um this gray circle\n1385.58s: with this dark gray circle is the space\n1387.62s: of all seos Omega stuff right\n1390.44s: and eat thought each dot is an sem\n1393.44s: we have this unobserved truth this true\n1395.78s: SCM M Star which is this Green Dot\n1398.78s: and then this light gray space is the\n1401.299s: Subspace of all scms such that it\n1403.64s: matches M star in the observational data\n1406.159s: PV and in the graph G right so it\n1408.14s: matches P star B and G Star\n1411.679s: um\n1412.34s: then what we're saying in the definition\n1414.62s: of identification if it's identifiable\n1417.62s: you can take any of these two scms in\n1420.14s: this light gray space and they will\n1422.539s: match in the causal effect of X on y\n1425.299s: right\n1426.559s: on the other hand in the\n1427.88s: non-identifiable case you will you'll\n1429.799s: have like the same thing um you have the\n1431.419s: observational uh or sorry you have the\n1433.159s: true sem M star and then you have the\n1435.14s: space of scms that match uh P star V and\n1437.419s: G Star but you can find two sems where\n1441.14s: um they won't match in the causal effect\n1442.7s: despite matching in both observational\n1444.98s: data and graph\n1449.299s: so how does this like kind of translate\n1450.679s: to\n1451.58s: um when we're working with ncms right so\n1454.039s: uh the definition changes like this so\n1456.74s: um\n1457.46s: um now consider the the true sem star\n1461.12s: and its causal diagram G and\n1462.919s: observational data PV right\n1465.14s: um then the causal effects X of X on Y\n1467.419s: is said to be neural identifiable from\n1470.12s: the set of G constrained ncms which we\n1472.34s: label as Omega G\n1473.96s: and observational distribution PB if and\n1476.78s: only if for every pair of ncms uh that\n1479.179s: are G constrained\n1480.98s: um we have uh we have that both of them\n1484.159s: match the true model in observational\n1486.14s: data\n1487.58s: um\n1488.299s: then they must also match in in the\n1490.76s: causal effect of X on y right so um so\n1493.4s: here um\n1494.72s: um\n1496.52s: the uh\n1501.14s: um yeah so so the the diagram here on\n1503.72s: the right\n1504.62s: um here we're showing that we have the\n1507.38s: space of ncms in blue and that's\n1509.299s: actually a sub a subset of the space of\n1511.34s: SCA right and the true sem star doesn't\n1514.76s: have to be an NCM it can be anywhere\n1517.52s: um but we're saying that it's neural\n1519.5s: identifiable as long as you can take any\n1521.12s: two uh ncns\n1523.52s: um that match in the observational data\n1525.679s: uh and uh and the graph\n1528.559s: um and then uh show that they must also\n1530.6s: match in the causal effect of X upon y\n1534.98s: um so in the uh in the in the graph it\n1538.34s: would be something like this where now\n1540.08s: we're looking at a smaller space we're\n1541.52s: looking at just this blue space\n1543.62s: uh this blue space represents the set of\n1545.72s: seems that are all that are ncms\n1548.659s: um and um and now\n1551.659s: um we're trying to see if any pair of\n1555.02s: ncms as in in this uh intersection\n1558.26s: between the blue circle and the light\n1559.76s: gray Circle we want to see if any pair\n1561.32s: of those\n1562.46s: um match in py uh given ux and in the\n1566.419s: non-identifiable case we we can show\n1568.46s: that there's two enzymes that don't\n1569.779s: match\n1572.419s: um so this this was uh\n1576.2s: um this was kind of like the most basic\n1577.82s: type of identification just to kind of\n1579.86s: give um like a an overview of like how\n1582.62s: it works but um more generally\n1585.799s: um we\n1587.539s: uh in in the in the newer work um we\n1590.059s: have this a much more general definition\n1592.1s: of identification where um now uh\n1595.22s: instead of um instead of just P of V we\n1597.679s: could have any arbitrary set of data\n1599.179s: sets from L1 or L2 right so maybe you\n1602.48s: have observational data uh but you might\n1604.82s: have also done some experiments right\n1606.14s: you um you you you have you have\n1609.559s: Interventional data on this variable but\n1611.299s: maybe not this one\n1612.799s: um and then you can have like some\n1614.0s: arbitrary set of experiments that's\n1615.86s: described in this data set Z\n1618.26s: and then\n1620.6s: um you have a counter factual query q\n1623.779s: um and since counter factuals is the\n1625.34s: third layer uh it kind of it encompasses\n1627.44s: layers two and one as well so it's\n1629.419s: written in this form but um but don't\n1631.1s: worry about that too much basically just\n1632.539s: think of Q as any query from any of the\n1634.7s: three layers right so you're interested\n1636.02s: in some query right\n1637.64s: and then we say that it's neural\n1639.919s: identifiable from Omega G the set of G\n1642.26s: constrained ncms and this data set Z\n1645.86s: um or this collection of data sets Z\n1648.74s: um if for every pair of scms that match\n1651.32s: in the data and in G\n1654.02s: if for every pair of enzymes they also\n1656.72s: match in the query\n1659.6s: so the diagram is similar but rather\n1661.76s: than uh rather than just one data set\n1663.86s: like in the observational data we have\n1665.419s: all of the data sets in C and uh for the\n1668.179s: query um it can be any arbitrary query\n1670.1s: not just necessarily the causal effect\n1671.779s: of X and Y it could be any any query\n1674.24s: from L2 L3\n1676.58s: any query that you're interested in\n1677.9s: answering\n1679.82s: so uh what one thing that's a little bit\n1681.74s: weird about the neural identification\n1684.26s: um definition is well if we're working\n1686.659s: just in the space of ncms and the true\n1689.419s: sem is not an NCM right why do we care\n1692.299s: if all of the ncms match in the query\n1694.9s: how does that what is what does that\n1697.039s: mean about like the uh the true model\n1699.44s: right how does that even relate to uh\n1701.779s: like the regular definition of\n1703.52s: identification\n1705.32s: um and it turns out actually that\n1707.779s: they're equivalent so\n1710.24s: um despite the fact that we're searching\n1711.679s: in the space of ncms it turns out that\n1714.44s: um if we can conclude that it's\n1716.24s: identifiable in the space of ncms we can\n1718.1s: also conclude that it's identifiable in\n1719.419s: the space so\n1721.4s: um\n1722.0s: this is uh the theorem this is what we\n1724.52s: call the Dual ID theorem\n1726.32s: um it's saying that um if Q uh or sorry\n1730.159s: if yeah if Q is neural identifiable from\n1733.039s: the space of uh the space of ncms or\n1735.799s: maybe G and z\n1737.84s: um then it's identifiable in from just G\n1740.6s: and Z like classically identified and\n1743.059s: also vice versa so this is a an if and\n1744.98s: only have state\n1749.48s: so that allows us to actually solve the\n1751.94s: identification problem using an\n1754.039s: algorithm like this so what we'll do\n1756.559s: is first we'll create two\n1759.559s: parametrizations of the of the neural\n1761.84s: causal model\n1763.46s: um first of all this this uh just to\n1765.919s: reiterate this this NCM is constrained\n1768.26s: with G right and then what we'll do is\n1770.48s: we'll we'll create two sets of\n1771.559s: parameters for it or you can also think\n1773.48s: of it as creating two ncms\n1776.419s: um such that one of them is trying to\n1778.52s: Mac uh one of them trying to maximize\n1780.38s: the query the other one's Trying to\n1781.64s: minimize the query and they're both\n1783.32s: trying to fit the data set okay can you\n1786.08s: can you remind us\n1787.94s: what what you really mean when you say\n1790.1s: the ncmsg constraint yeah so um so um\n1793.34s: you we we had the graph right\n1796.46s: um which uh that's an assumption\n1798.62s: um that we we have that we make out of\n1800.539s: necessity because we can't make\n1801.5s: inferences otherwise and um what we're\n1804.32s: doing is we're we're straight up like\n1805.82s: enforcing that graph into the\n1807.86s: construction of our NCM right right um\n1809.899s: when the functions are literally like\n1811.46s: created this way to fit the graph um\n1813.08s: it's it's very much constrained right so\n1814.76s: it satisfies all of the constraints as\n1816.26s: we prove as well yeah\n1818.899s: uh\n1823.64s: thank you\n1825.1s: yeah so um so what we're doing here is\n1828.74s: we're creating two parameterizations one\n1830.419s: that's maximizing one that's minimizing\n1831.98s: the query sorry could you just maybe\n1833.96s: give a intuition for what does back\n1836.299s: spies or minimize yeah so um so let's\n1839.48s: say um\n1840.62s: let's say that uh we want to see the\n1843.14s: causal effects of of taking this drug on\n1845.899s: the recovery rate of a disease right\n1847.82s: maybe um maybe if they didn't take the\n1850.279s: drug their recovery rate would be 0.6 or\n1852.74s: like 60 and if they took the drug the\n1854.779s: recovery rate is 80 right now um we want\n1857.539s: to know the causal effect of giving the\n1859.22s: drug\n1860.12s: um and we want to know this 80 number\n1861.559s: right\n1862.94s: um so what we'll do is we want to know\n1865.76s: if it's identifiable right like if we\n1867.32s: just like train some model and it spat\n1870.38s: out 80 we don't know if we can trust\n1872.059s: that number right what if it's just what\n1873.86s: if it could be anything and it just\n1874.94s: happened to give like 80 right so what\n1877.279s: we'll do is one of the models will um\n1879.14s: we'll try to uh make the number as high\n1881.48s: as possible while still being\n1883.7s: constrained by the graph and also still\n1885.5s: fitting the data set right and the other\n1887.72s: one will try to make it as small as\n1888.919s: possible while doing those same things\n1890.48s: so what will happen is if they both give\n1893.299s: 80 what that means is they tried as hard\n1895.52s: as they could to make it not 80 and it\n1897.26s: still ended up 80\n1899.059s: um which means you can trust the number\n1900.02s: otherwise one of them will be like maybe\n1901.94s: 90 and the other one will be like 50 and\n1903.74s: then you'll know that okay\n1905.24s: um it's it maybe it's probably not 80\n1907.399s: because it could be like pretty much\n1908.84s: anything in between those those two\n1910.1s: ranges right so\n1912.14s: um that's what we that's what we're\n1913.34s: trying to do here so yeah\n1916.64s: um yeah so um so this uh there's two\n1919.94s: approaches\n1921.44s: um one the first one we tried was with\n1923.84s: the maximum uh maximum likelihood\n1925.94s: estimation approach\n1927.62s: um you're\n1928.7s: um so I I\n1930.34s: do have a slide on this I actually\n1932.179s: removed it from the presentation because\n1933.44s: it's uh it's um I thought it would take\n1935.84s: too long to explain but we could get to\n1937.1s: that like at the end if um if there's\n1938.899s: time\n1939.799s: um but to like kind of explain it\n1941.12s: briefly there's like one one approach\n1942.44s: that's maximum likelihood estimation\n1943.94s: you're essentially um maximizing the\n1946.399s: likelihood of the data sets while\n1948.679s: simultaneously um trying to maximize or\n1951.98s: minimize the likelihood of the query\n1954.08s: right and the other the other one like\n1956.299s: that's that's done using um uh some sort\n1959.059s: of uh\n1960.26s: like uh gradient descent optimization\n1962.24s: approach with a lost term that has like\n1964.46s: kind of both right\n1965.779s: um so like as the two losses together\n1968.299s: the second approach which is more recent\n1970.1s: uh yeah it's like it's like less\n1972.2s: accurate on smaller scales but like a\n1975.14s: lot more attractable at larger scales\n1977.72s: it's using like a generative adversarial\n1980.299s: approach so um this is more of an\n1982.82s: implicit approach you're not really\n1983.899s: modeling the likelihood of the query or\n1986.059s: the or the data set you're you're\n1987.62s: actually just implicitly modeling it\n1989.539s: through samples right and then um you\n1991.88s: can use you can essentially if you're\n1993.38s: familiar with Gans\n1994.94s: um that's how you can train to fit the\n1997.279s: data sets and then um and then there's\n1999.5s: another term that penalizes or\n2002.14s: um rewards uh the value of the query\n2004.659s: essentially\n2006.039s: um so those are kind of like the two\n2007.299s: approaches that we use in practice but\n2009.1s: um we can we can go over to the slide\n2010.84s: with more details at the end if there's\n2012.34s: time\n2013.6s: um so so yeah it's a good question\n2015.88s: though because this formulation of the\n2018.399s: of the algorithm is just to kind of like\n2020.44s: explain intuitive like what we're trying\n2021.76s: to do not actually show how it's done\n2023.26s: right\n2024.039s: right um\n2025.179s: so here we're trying to maximize and\n2026.919s: minimize it uh well well satisfying\n2029.019s: these constraints\n2030.279s: uh then we're gonna check if they give\n2032.38s: the same result and uh they if they give\n2035.679s: the same result then they match or sorry\n2037.6s: if they get the same result then it's\n2038.919s: identifiable if they don't then it's not\n2040.6s: identified right in practice they're not\n2042.159s: going to exactly match ever so we we um\n2044.44s: we do some hypothesis testing and check\n2046.179s: to see if it's under some threshold\n2049.3s: um and then finally if it is\n2050.98s: identifiable we can actually just\n2053.02s: directly compute that value from either\n2055.0s: of the models right\n2057.399s: um and uh and and then the effect like\n2060.52s: if you um the nice thing about this is\n2063.22s: that um when you query a a causal effect\n2066.399s: or a counterfactual from an sem it's\n2068.08s: already well defined so then you can\n2069.7s: just directly compute it from the this\n2071.619s: NCM you don't have to do any kind of\n2073.0s: fancy like uh like uh curve fitting or\n2075.52s: anything it's already there\n2079.3s: just a minor question\n2081.399s: do we know in priori the such that\n2085.119s: condition where m m hat is what you're\n2087.76s: optimizing for an M Star is the true\n2089.5s: distribution so so it's kind of like in\n2091.599s: in practice\n2092.619s: um uh wait sorry sorry\n2094.54s: um are you saying um uh like I mean\n2098.26s: these are the optimization conditions\n2100.3s: right yeah yeah but do we do we know\n2102.4s: anything about M Star uh\n2105.099s: yeah so so um so Z is is the data sets\n2108.7s: that you're giving right right so so the\n2110.98s: um\n2111.82s: um in theory I guess um when you're\n2114.28s: given uh Z they come from the real SEO\n2117.52s: right and then these are certain\n2118.96s: distributions that you actually have\n2120.16s: from the real SEO\n2121.96s: um these might be uh certain\n2123.64s: observational or Interventional\n2125.14s: distributions\n2126.7s: um but you probably don't have\n2127.839s: everything right but this this is what\n2129.339s: you at least do have right\n2131.38s: right so of course if you're given\n2132.579s: something you want to at least make sure\n2134.14s: you match what you're given\n2135.94s: um and then um everything else uh you\n2138.82s: you have to use the identification\n2140.38s: algorithm to see if if you can infer\n2142.78s: that yeah maybe because in my mind it\n2145.0s: was always like two layers of separately\n2146.98s: at least one degree of separation\n2148.24s: between M star and what you're given uh\n2150.46s: but you're just saying what you're given\n2152.14s: is you can treat that as Epstein exactly\n2154.0s: yeah well so like you don't have the\n2155.859s: whole M star and you don't have even\n2157.96s: every distribution of M Star either you\n2160.18s: just have certain data sets that's\n2161.619s: represented in C\n2163.72s: yeah so when the notation I'm using here\n2166.119s: it when I say Z of M Star I'm saying uh\n2168.579s: the distributions of Z came from M star\n2171.46s: versus the distributions of Z that come\n2173.32s: from our NCM M hat\n2177.76s: um yeah so\n2179.619s: um this algorithm that we just discussed\n2181.78s: in theory uh is both sound and complete\n2184.72s: so what that means is if we run the\n2188.14s: algorithm and we get this our result Q\n2190.54s: hat\n2192.28s: um then it turns out that Q is\n2194.74s: identifiable from G and Z if and only if\n2197.8s: Q hat is not failed\n2199.96s: moreover if it's not failed then that\n2202.66s: value is equal to the True Value Q star\n2209.859s: okay yeah let's ask maybe a naive\n2212.02s: question if Q if your query is not\n2214.98s: identifiable does this process do the\n2218.38s: bounds you get out of your uh neural\n2222.52s: models that give you real bounds on your\n2225.04s: query or is it just meaningless that's a\n2227.619s: good question um so uh theoretically Yes\n2230.38s: actually so um so if you if uh if it's\n2233.859s: not identifiable then the results can be\n2235.54s: interpreted as bounds on the causal\n2236.859s: effect\n2237.82s: but in practice we've had a hard time\n2239.74s: getting accurate bounds so um so we\n2242.38s: didn't include that as a result in the\n2243.52s: paper but theoretically yes you can you\n2245.079s: can treat it as balance\n2247.72s: balance um yeah it's a\n2249.88s: it's very very ripe open uh research\n2251.74s: Direction\n2254.8s: um\n2255.94s: so um\n2259.9s: yeah so I guess uh at this point um all\n2262.48s: that's left to talk about is experiments\n2263.8s: I'm not sure if anyone still has any\n2265.0s: questions about\n2266.14s: um like the theoretical content I had a\n2269.56s: question\n2271.78s: um like do you have to worry about how\n2273.64s: long this would take to I don't know\n2275.8s: converge is the right word but like to\n2277.9s: not fail basically depending on\n2281.26s: like how complex the\n2285.7s: uh you mean um are you talking about\n2287.74s: like to get the identification result or\n2289.839s: to get accurate estimation yeah yeah to\n2291.7s: get the identification result so\n2294.579s: um uh maybe this will be more evident in\n2297.64s: the experiments but um\n2299.88s: uh generally speaking\n2303.52s: um the longer you run\n2306.339s: um the uh the the more confident you can\n2309.099s: be in the results right\n2311.14s: uh but uh but certain results you can be\n2313.78s: confident without running that long as\n2315.4s: well right\n2316.96s: um so uh I guess it's kind of like it's\n2319.359s: kind of up to you\n2321.64s: um if you want to have more faith in\n2324.4s: your results you can just try to run it\n2326.079s: for longer\n2328.359s: um but um but we'll we'll show that um\n2331.92s: so we we do uh these experiments in a\n2336.28s: very small amount of epochs like maybe a\n2337.72s: thousand ish\n2339.099s: um which doesn't take that long in\n2340.42s: practice\n2341.56s: um so uh even like maybe like a small\n2343.599s: amount that you could run on your laptop\n2344.92s: it's it's\n2346.54s: um you can reasonably expect good\n2348.82s: results I guess\n2354.28s: and and and also this depends on uh this\n2356.98s: depends on your um your implementation\n2359.14s: and practice of course because um\n2360.64s: there's different ideas on how you might\n2362.079s: want to implement this and uh\n2364.06s: um and I guess that's it's some some in\n2366.16s: some ways it's more of an art rather\n2367.3s: than a science but um\n2370.839s: um here's like uh like essentially like\n2373.42s: what we're doing with identification\n2374.68s: right so\n2376.78s: uh so on the left here we have um we\n2379.359s: have uh four identifiable cases this is\n2381.64s: specifically just the causal effect of X\n2383.14s: and Y from observational data\n2385.119s: um on the left here there's uh four\n2386.44s: identifiable cases where the causal\n2388.3s: effect of X and Y is identifiable and on\n2390.52s: the right there's four non-identifiable\n2392.32s: cases where the causal effect of X and Y\n2393.94s: is not identifiable from just\n2395.26s: observational data and so we we analyze\n2398.079s: um what happens when we run the\n2399.28s: algorithm uh on these eight cases\n2402.28s: um\n2402.94s: so what happens is um I guess maybe the\n2405.22s: bottom graph is more interesting\n2406.3s: initially so\n2407.859s: um the bottom graph\n2409.42s: um we ran everything several times\n2412.359s: um and the bottom graph shows it's kind\n2414.7s: of like the distribution the percentiles\n2416.5s: of of these gaps right these uh these um\n2420.7s: the difference between the maximize and\n2422.32s: the minimized result\n2424.78s: um and uh\n2426.579s: and what happens is um we kind of like\n2430.54s: um we we enforce the penalty\n2433.9s: um on on not on not fitting the data as\n2438.04s: we progress through training and what\n2439.78s: happens is in the identifiable cases you\n2441.64s: can see in the bottom row\n2443.44s: um that the gaps move to nothing in the\n2446.079s: identifiable cases but then in the uh\n2448.42s: non-identifiable cases they tend to stay\n2450.04s: pretty large\n2451.06s: right so um so um what's what's going on\n2454.24s: here is like if you see even like the\n2456.82s: largest gaps between the the\n2459.82s: um\n2460.9s: the maximize causal effect and the\n2462.46s: minimized causal effect is very very\n2464.32s: small so they're they they kind of match\n2466.66s: um but in the non-identifiable cases um\n2468.82s: someone like this first graph for\n2470.5s: example like all of them agree that the\n2472.119s: Gap should be really really big\n2475.42s: and and uh there's some variation in in\n2478.24s: this result um but some of that is also\n2480.579s: because of um of uh when we're working\n2483.22s: with different true models sometimes the\n2485.859s: the gaps can can the true Gap can vary\n2488.02s: like the true bounds\n2490.839s: um and then of course this top uh this\n2492.88s: top row then is uh converting this\n2495.099s: bottom row the results on the bottom row\n2497.02s: to um an actual ID result like a yes or\n2499.42s: no\n2500.38s: um based on our hypothesis testing\n2501.94s: procedure so we we have three thresholds\n2503.859s: here\n2504.52s: um blue is uh 0.01 green is 0.03 and red\n2508.3s: is 0.05\n2510.099s: um and then uh you can you can adjust\n2511.96s: how based on um uh\n2515.02s: you're based on your experimental like\n2517.359s: needs I guess uh where if you choose a\n2519.88s: lower value\n2521.079s: um then you'll end up with more um false\n2523.599s: uh false negatives and then if you\n2525.82s: choose a higher value you'll end up with\n2526.9s: more false positives\n2528.46s: oops\n2532.18s: um and then um for estimation we took\n2535.119s: the four identifiable cases yeah before\n2537.099s: you move on can you just like for\n2538.9s: somebody who doesn't do this very much\n2540.28s: explain how the graphs or like how do\n2543.4s: you know what's an identifiable case and\n2545.2s: or non-identifiable in this like you\n2548.2s: build those experiments right how did\n2550.24s: you make something identifiable oh um\n2552.94s: well like how did I know they were\n2554.14s: identifiable in the first place uh so\n2555.82s: these are uh these are well-known uh\n2557.68s: graphs in the literature\n2559.42s: um and uh and uh for for this particular\n2562.48s: setting you can actually use do calculus\n2564.579s: to derive the fact that these are\n2566.26s: identifiable uh and then there's also\n2568.0s: proofs that show that these these\n2570.099s: non-identifiable cases are not\n2571.3s: identifiable\n2572.98s: um so um but this is like a very limited\n2575.8s: setting in which uh it's the um\n2578.8s: um it's the specific case where you have\n2581.26s: observational data and you're trying to\n2582.94s: get the causal effect of X on y\n2585.4s: um and it's these specific graphs I\n2587.68s: guess yeah\n2590.56s: yeah\n2591.099s: um the um uh there's certain\n2594.04s: tasks are there certain identification\n2596.44s: settings uh like for example the one\n2598.72s: where you're given the graph and\n2599.92s: observational data and you're trying to\n2601.359s: get the causal effect of X and Y there's\n2603.16s: certain cases where it is it is actually\n2604.66s: solved like in generality symbolically\n2607.18s: like using math basically so you could\n2609.4s: design an algorithm that doesn't have to\n2610.78s: go through all of this\n2612.4s: um and uh and get the result that way\n2614.98s: um but um but this is providing like a\n2617.44s: very flexible approach that solves any\n2619.18s: kind of General\n2620.5s: um uh problem setting uh that might be\n2623.02s: kind of related to the identification\n2624.76s: problem\n2625.72s: um or like different versions of the\n2627.7s: identification problems that aren't just\n2629.74s: like the classical identification\n2632.14s: um and uh um also it's\n2636.16s: philosophically it's kind of neat that\n2638.2s: it's the neural network itself that's\n2639.7s: actually doing the um the causal\n2641.92s: inference in some sense like here um you\n2644.68s: didn't have to know that it was\n2646.06s: identifiable or not identifiable but you\n2647.74s: can tell just by looking at the graphs\n2649.06s: because um like these cases uh oh it's\n2651.52s: like\n2652.66s: um like the gaps are so small but over\n2654.46s: there the gaps are so large right\n2656.98s: so uh so that's that's kind of like the\n2658.9s: neat part that the experiments run\n2660.4s: through\n2661.839s: um there's a question online yeah what's\n2664.06s: up\n2665.859s: um I I don't know if this is a dumb\n2667.06s: question but like as far as for the\n2668.68s: experiments um like are there any\n2670.3s: assumptions that go into the\n2671.5s: observations like do they have to all be\n2673.119s: independent or\n2679.119s: um I guess I I guess we do assume IID uh\n2682.359s: okay so in in the theory we actually\n2685.0s: assume that um we have enough data such\n2688.119s: that we know the actual distribution\n2690.18s: like we kind of so maybe we have\n2693.4s: observational data\n2694.9s: um from the distribution PB we assume\n2696.88s: that we have enough data that we we can\n2699.28s: just assume that we have PB basically\n2701.079s: right like the actual distribution over\n2702.88s: v\n2704.079s: um in practice that that's probably not\n2705.7s: going to be the case\n2707.859s: um and um because we have limited data\n2711.579s: the the empirical distribution is\n2713.5s: probably not going to actually be\n2715.359s: um equal to PV\n2717.46s: um and and so the results here are\n2719.619s: limited to the uh how how well the um\n2723.04s: the the\n2724.78s: uh empirical data matches the true data\n2727.18s: or the true distribution\n2729.52s: um and uh uh that is a limitation\n2732.819s: um I think it would be it would be\n2734.68s: interesting to see some um kind of like\n2736.72s: error analysis uh but um uh for now uh\n2741.28s: the interpretation is that your result\n2742.78s: is only going to be as good as your data\n2744.22s: is\n2747.099s: uh so does that answer the question\n2749.619s: yeah I think so I guess I was just\n2751.24s: curious like how do you actually\n2753.04s: generate the data here like are you\n2755.14s: creating functions\n2756.88s: yeah I guess I I don't know if you have\n2758.92s: time to go into more details about that\n2760.48s: but uh that's like these are simulations\n2762.76s: right and then yeah yeah yeah yeah so uh\n2765.579s: yeah we we have uh we randomly generate\n2767.8s: some some sems and then we we we sample\n2771.339s: the data IID and then that's how we\n2773.26s: that's how we kept the experiments okay\n2775.599s: cool\n2778.78s: um\n2779.8s: yeah um\n2781.66s: uh so uh once you conclude that um the\n2786.04s: results is identifiable you can then I\n2787.9s: try to estimate it right so this is the\n2789.76s: these are the estimation results uh we\n2791.859s: show like the error plotted with against\n2793.72s: like having more samples\n2796.0s: um the uh the top row shows how well\n2798.28s: we're able to match the the given data\n2800.8s: sets so we plot kale Divergence here\n2802.839s: with uh with PB and the bottom row shows\n2805.599s: how well we're able to estimate the\n2807.46s: query this is the error over our query\n2809.74s: which is the causal effect of X on y\n2812.859s: um\n2813.4s: and um here we're comparing three models\n2817.18s: um so\n2818.26s: uh orange is our method with the NCM\n2820.78s: blue is a naive model where you're\n2823.9s: you're kind of training a neural network\n2825.88s: to fit the data without the graph and\n2828.22s: seeing if it'll give the right causal\n2829.96s: effect\n2830.68s: and then um and then green is is\n2833.079s: weighted empirical risk minimization\n2834.579s: which is another technique that's not\n2836.2s: really related to\n2837.7s: um fitting in sem uh that's also used\n2839.92s: for estimation all right so when it\n2842.02s: comes to fitting the data which worm\n2844.359s: doesn't need to do\n2845.859s: um the uh\n2847.78s: um the both the naive model and the NCM\n2850.06s: are capable of fitting the data right\n2851.5s: right so as we get more samples we\n2853.359s: reduce the KL Divergence data and um\n2855.96s: both models are good at doing that but\n2858.4s: when it comes to estimating the query um\n2860.38s: you can see that um with more samples\n2863.14s: the NCM is able to improve its\n2865.24s: estimation whereas the the naive model\n2867.099s: is basically not learning anything\n2869.2s: except in this third case where\n2871.14s: conveniently the um the causal effect\n2873.579s: happens to also be the association\n2875.44s: between the\n2877.0s: the two models right so in in this third\n2879.28s: case the causal effect of X and Y is\n2880.96s: actually just equal to\n2882.339s: P of Y given X\n2884.2s: um then then in that case uh it is\n2887.319s: giving the right result but um but of\n2889.24s: course the NCM can give the right result\n2890.56s: as well and then um and then worm which\n2893.92s: uh is an entirely different estimation\n2895.66s: method and uh part of like the one of\n2898.96s: the state-of-the-art methods in some\n2900.16s: sense it's uh it gives uh comparable or\n2903.04s: even worse results sometimes\n2907.78s: uh so POV is the joint distribution of\n2910.48s: of your variables this is like the\n2912.76s: observational data uh across all of your\n2915.04s: variables yeah\n2919.599s: um and I mentioned earlier there's kind\n2921.819s: of two approaches to um that we we've\n2923.92s: tried the first one was the the maximum\n2925.839s: likelihood approach and the second one\n2927.28s: which is like the more implicit methods\n2929.079s: with the the gaps right and um the\n2931.96s: reason we introduced again NCM is\n2933.46s: because even though the maximum\n2934.78s: likelihood approach uh is like\n2936.819s: theoretically the best\n2938.98s: um at lower Dimensions it just scales\n2941.319s: really badly and here we we show that\n2943.78s: when you increase the dimensionality of\n2945.28s: the data the the MLA NTM grows like the\n2948.16s: runtime grows exponentially but then\n2949.599s: with yans you can you can pretty much\n2951.28s: still get the same same runtime same\n2953.44s: performance\n2954.52s: um so that's why um that's why we\n2955.839s: pivoted um later on\n2958.72s: um\n2959.7s: and so um so basically the Gand NCM um\n2962.98s: allows greater tractability at the\n2964.48s: expense of slightly higher estimation\n2966.339s: error at lower dimensions\n2969.94s: so um now here's an experiment showing\n2973.24s: um comparing the two types of ncms but\n2975.28s: for counter factual uh identification so\n2977.859s: these are the the uh the accuracies for\n2981.64s: performing identification\n2983.8s: um in these there's a lot of uh there's\n2987.04s: a lot of settings here each of these\n2988.18s: graphs represents a different setting\n2990.22s: but the the graph on the left shows what\n2992.859s: graph is being used\n2994.599s: the the query at the top is the query\n2997.42s: that we're interested in so there's four\n2999.099s: four different queries here at is just\n3001.38s: the causal effect\n3002.76s: ett is a counter factual effect of the\n3005.88s: treatment on the treated yeah that's\n3007.68s: what it's called\n3009.18s: um and nde\n3010.74s: um natural direct effect that's also a\n3012.54s: counter factual quantity and then ctfd\n3014.819s: or counterfactual direct effect that's\n3016.5s: also a counter factual quantity um so\n3018.66s: each of these has like kind of\n3019.68s: implications In fairness analysis\n3021.96s: um they're kind of well-known queries\n3023.099s: that's why we wanted to test on those uh\n3025.68s: and then um for each of these queries\n3027.9s: there's two columns one is with just the\n3029.579s: observational data and the other one is\n3031.319s: with the observational data and also\n3032.579s: with experimental data on on x\n3035.819s: um\n3036.48s: and uh\n3038.28s: um\n3039.0s: the blue backgrounds show the ID cases\n3040.92s: and then the orange backgrounds or the\n3042.599s: yellow backgrounds show the the non-it\n3043.98s: cases\n3045.78s: um so um so here we're comparing um\n3048.18s: we're comparing uh the the can NCM with\n3051.18s: the mle NCM the two approaches from\n3053.819s: before\n3054.599s: um the MLA NCM um uh it actually tends\n3058.8s: to have like sharper performance for um\n3061.079s: for identifiable cases but for\n3063.3s: non-identifiable cases it's sometimes\n3064.92s: mistakenly classifies it as ID which is\n3068.04s: kind of dangerous actually\n3069.78s: um because if it's not identifiable you\n3071.22s: really don't want it to be ID\n3073.26s: um and if it's if it's ID but you\n3074.94s: accidentally say it's not ID then that's\n3076.619s: okay like that\n3078.24s: that's you're kind of just leaning on\n3079.8s: the safer side\n3081.24s: um so again NCM does a better job of\n3082.68s: balancing both cases\n3084.48s: uh and then moreover um here we also\n3086.88s: show the Canon CM with the 16\n3088.02s: dimensional case\n3089.28s: um which the MLA NCM just straight up\n3090.96s: can't do\n3092.52s: um so that's that's uh one additional\n3094.74s: result that we have here\n3097.619s: and then um there's there were 16\n3099.42s: identifiable cases here uh and then here\n3102.3s: we're showing um the estimation error as\n3104.339s: well\n3105.66s: comparing between the two models so in\n3107.52s: some cases the the MLA NTM is better\n3110.28s: um but the Canon CM\n3112.2s: um does pretty well and it can also work\n3113.819s: in 16 Dimensions so that's kind of like\n3115.8s: the\n3116.94s: um the benefit over the MLA ncu\n3121.2s: um\n3123.24s: so I I believe yeah so that's everything\n3125.099s: for experiments does anyone have any\n3127.44s: questions on experiments\n3129.66s: foreign\n3139.559s: so um the first takeaway is that\n3142.559s: um cross-layer inferences are provably\n3144.24s: impossible without assumptions\n3147.18s: um even if you're using something as\n3148.559s: expressive as an NC as a neural network\n3153.54s: but a graphical inductive bias can allow\n3155.76s: neural models to solve the causal\n3157.26s: identification and estimation tasks so\n3158.88s: when you when you have this graph for\n3160.38s: example and you like impose it into the\n3162.18s: NCM you can then perhaps get some of\n3165.24s: these results that you can you can maybe\n3167.04s: do some inferences across layers\n3169.619s: um\n3170.52s: and um the causal diagram is not the\n3172.8s: only type of assumption that that um\n3174.54s: that can be made um and different\n3176.819s: looking at different assumptions that's\n3178.38s: an Avenue of future work as well um so\n3181.5s: uh but um uh with some of us or or um\n3185.28s: without assumptions we can't get\n3186.9s: anything so it's interesting to see what\n3189.059s: kinds of assumptions can lead to\n3190.44s: something and what what kinds of results\n3192.059s: they can lead to\n3194.339s: uh and so\n3196.26s: um what's what's cool about this work I\n3197.94s: guess is that um for the first time\n3199.68s: neural networks have performed like\n3201.359s: causal reasoning in some sense like um\n3203.88s: neural networks are pretty good at um at\n3206.76s: fitting functions and like uh like\n3209.04s: fitting uh and\n3211.38s: um like once you already have the the\n3213.24s: function that you want to fit or the\n3214.68s: query that you're trying to answer you\n3215.819s: can use a you can use a neural network\n3217.2s: to fit that but in this case we're\n3218.76s: actually using neural networks to\n3220.559s: um actually see hey is this query causal\n3222.9s: right\n3223.859s: um and so so in that sense\n3226.079s: um the neural networks have actually\n3227.22s: done the causal reasoning themselves\n3228.54s: that's uh\n3230.099s: um that's uh one one aspect of this work\n3232.619s: that um\n3233.88s: knows it's cool\n3236.52s: um and we hope that this uh this work\n3241.02s: um\n3242.22s: um shows the foundational connection\n3244.02s: between causal neural models and it'll\n3246.54s: pave the way for a rich symbiosis\n3248.46s: between these modes of reasoning which\n3249.78s: will lead to more robust and scalable uh\n3252.059s: causal inferences through neural\n3253.26s: Technologies\n3255.74s: thank you\n3260.04s: um I guess um before\n3262.319s: uh do we have time to like pull up the\n3265.559s: other slide I guess I don't know yeah I\n3268.74s: think I think since since you're in the\n3271.44s: room maybe we can open the the floor for\n3273.839s: online questions and yeah I mean we can\n3277.079s: uh yeah sure let's let's do questions\n3278.4s: first right right is that okay yeah\n3282.54s: okay Cara\n3284.46s: I'm sorry okay um I was curious like do\n3287.22s: you think there's a way to connect this\n3288.359s: eventually to things like\n3290.04s: um equation Discovery using neural\n3291.78s: networks or\n3293.4s: um is that I don't know if that's at all\n3296.099s: in your line of thinking okay can you uh\n3299.339s: um can you can you um Define to me what\n3301.619s: that is\n3303.72s: I'm not familiar oh I mean like directly\n3307.14s: like trying to determine what the neural\n3309.24s: network is you know learning in terms of\n3312.18s: like a functional model for a\n3313.98s: geophysical system like you mean like um\n3316.8s: actually finding the true functions yeah\n3319.079s: exactly yeah yeah so um so yeah that's a\n3322.559s: that's an interesting point so in this\n3324.0s: work\n3324.839s: um we're we're learning to fit the data\n3327.24s: but we don't actually care what the\n3328.859s: actual functions are we're just like\n3331.26s: we're just like saying okay learn\n3332.88s: whatever parameterization is necessary\n3334.5s: to fit the data right\n3336.54s: um then if we could get the actual\n3338.28s: functions that that might be more\n3339.839s: interesting because\n3341.7s: um because then we would have we would\n3344.64s: learn something that's kind of\n3346.2s: fundamental about nature in some sense\n3347.819s: right\n3348.66s: right\n3349.2s: um and I think like maybe maybe it's\n3351.599s: possible\n3352.74s: um but\n3354.0s: um there's always going to be like a few\n3355.5s: barriers so one is that like if we don't\n3357.72s: know the um if we don't know the\n3359.94s: exogenous sources of noise like if we\n3362.64s: don't really have a full understanding\n3364.619s: of the whole system then it's always\n3366.66s: going to be hard because there's going\n3367.74s: to be some sort of outside Factor that's\n3369.119s: affecting those functions that we don't\n3370.859s: know about right\n3373.14s: um and then the uh the second issue is\n3376.14s: that uh uh\n3378.3s: learning the function is just so much of\n3380.22s: a stricter requirement than identifying\n3382.92s: a just like a causal query\n3385.68s: um so you may end up with a lot of\n3387.66s: negative results which which would suck\n3389.339s: I guess\n3391.559s: but um but uh but it but it certainly\n3394.92s: would be interesting and I think there\n3396.18s: might be there might be problem settings\n3398.099s: in which it could be possible\n3402.359s: thank you\n3403.68s: thank you\n3409.46s: any other questions\n3420.54s: yeah I don't see any other questions\n3423.119s: online okay okay sounds good oh good\n3426.66s: I was just gonna ask that you know\n3428.4s: beyond the experiments that you showed\n3430.92s: uh has this been tried in some real\n3433.44s: world applications\n3434.94s: available data so far or is that future\n3437.22s: work I think um like nothing published\n3440.64s: um\n3441.48s: but um\n3443.16s: it would be it would be interesting to\n3444.66s: see\n3445.44s: um I guess uh the difficulty is that um\n3448.02s: there's not a lot of like well-known\n3450.26s: causal data sets that isn't like\n3453.48s: um like for example just uh with the\n3456.66s: backdoor conditions for example\n3459.3s: um so um so it's kind of difficult to\n3462.18s: have like um to have real world\n3463.859s: experiments\n3465.42s: um\n3466.38s: like uh in like in like a paper for\n3469.26s: example but\n3470.4s: um certainly like it'd be interesting to\n3471.66s: see like what what kinds of applications\n3473.099s: are possible like in industry for\n3475.26s: example\n3476.46s: um backdoor conditions sorry yeah like\n3479.16s: uh like\n3480.24s: um so there's actually maybe I can\n3482.22s: highlight that here uh so so you see\n3484.5s: this graph here uh so this graph is\n3486.599s: known as the back door graph and it\n3488.46s: comes with a set of assumptions which\n3490.26s: are actually very commonly made\n3492.059s: um so a lot of papers they actually just\n3493.44s: make they don't assume they have a graph\n3495.059s: they just directly make the assumptions\n3496.68s: that this graph has so um so uh uh that\n3502.319s: proportion of literature is like a very\n3504.839s: big chunk of like the causal inference\n3506.4s: literature\n3507.42s: um and um because it's so widespread\n3509.88s: like there's a lot of techniques out\n3511.26s: there that um that uh solve solve the\n3514.26s: problem under those assumptions and then\n3516.119s: uh and then they of course there's\n3517.98s: there's a few data sets as well but\n3520.859s: uh because like our approach works with\n3522.48s: a lot of different settings we didn't\n3523.5s: want to just test on like\n3525.18s: of outdoor setting for example\n3536.28s: any other questions\n3539.22s: oh um I was just wondering like you this\n3541.98s: is all conditioned on knowing\n3543.48s: information about your\n3545.099s: endogenous variables if you do you also\n3548.46s: need to know information about like\n3551.16s: those exogenous variables or so actually\n3555.0s: that's that that's uh that's kind of\n3556.74s: like a neat part of uh this work it's\n3558.599s: like um\n3559.799s: I guess in general you don't care about\n3561.42s: those variables right so um uh but like\n3565.619s: um when you're when you're defining the\n3567.24s: um when you're thinking about it\n3568.799s: semantically in terms of like the true\n3570.119s: sem they are going to be well defined\n3571.799s: and they are going to have like certain\n3572.819s: forms certain properties right\n3574.859s: um the nice thing here is that um we\n3577.319s: just use uniform01 like we don't care\n3579.78s: what the the um the exogenous variables\n3582.359s: are we just use uniform01 random\n3584.16s: variables uh pass that in as input and\n3586.319s: then would it can kind of like mold that\n3588.72s: distribution to whatever it needs to be\n3590.04s: to fit the fit the data essentially do\n3592.859s: you need to maintain the same\n3594.599s: distribution of those exogenous\n3597.66s: variables in order to\n3599.46s: like make\n3602.52s: um yeah so um so uh\n3606.599s: so we we don't um we don't know the the\n3609.599s: true distribution of the exhaustion\n3611.099s: variables but if we uh\n3614.28s: if we manage to fit the data\n3615.9s: successfully\n3617.64s: um I mean it'll it'll do its own\n3619.799s: interpretation of the it'll kind of like\n3621.72s: change that exhaustionist noise into\n3623.16s: some some one of its own distributions\n3624.96s: like through the function that it learns\n3626.819s: and then um as long as that distribution\n3629.7s: that final result fits the data and you\n3632.7s: find that it's identifiable\n3634.26s: um the neat part is it didn't really\n3635.4s: matter what the um what the true\n3637.2s: exogenous noise was or what the true\n3638.52s: functions were\n3639.599s: um you can you can still get the correct\n3640.859s: result\n3642.18s: and then that's what makes it difficult\n3644.339s: to then extract it exactly yeah yeah so\n3648.18s: um if you if you had to know the real\n3649.92s: noise or like the real functions yeah um\n3652.44s: that would make it a lot more difficult\n3655.319s: um but this is also something that is\n3656.819s: commonly an assumption like um we don't\n3658.92s: make this assumption but like a lot of\n3660.48s: papers they'll assume that maybe it's\n3662.22s: additive noise right um like noise is\n3664.799s: all gaussian and then you you add that\n3666.42s: like the function is defined such that\n3667.98s: it's you take the exogenous parents or\n3669.96s: start endogenous parents and then you\n3671.339s: just add some like gaussians and then\n3673.14s: not in the real world yeah but yeah we\n3675.78s: don't make that assumption because it\n3677.04s: could be anything really right so\n3689.099s: all right I think uh\n3691.92s: I guess I guess time's up right\n3694.14s: um I mean but uh for for the folks\n3696.18s: online we can thank them\n3698.119s: like uh I don't know I mean it's up to\n3701.52s: you like I I I uh I I felt like um like\n3704.7s: uh I was worried I was maybe going over\n3706.319s: or something but uh yeah I should also\n3710.52s: say that we're going out for lunch after\n3712.2s: this with Kevin Kevin yeah so feel free\n3715.859s: to join\n3716.88s: as well"
    },
    {
        "class": "YouTubeVideo",
        "title": "Data Driven Constraint of Cloud Microphysics Uncertainty at Global and Process Level Scales",
        "videoId": "q0CCKTC1wFY",
        "url": "https://www.youtube.com/watch?v=q0CCKTC1wFY",
        "publishedAt": "2024-09-12T19:18:12Z",
        "transcript": "5.759s: everybody um Molly Lopez managing\n8.0s: director for leap and very happy to\n10.519s: introduce Marcus uh Marcus's talk today\n15.0s: um Marcus is an associate research\n17.56s: scientist and has worked at ccsr since\n21.4s: 2013 his expertise is in using basian\n24.32s: inference methods to estimate parameters\n26.48s: and quantify uncertainty and physical\n28.72s: models of cloud and precipitate ation\n31.039s: this involves making comparison between\n32.84s: observations such as\n34.6s: advanced uh polarimetric and profiling\n37.52s: Radars and model simulations of weather\n40.36s: these efforts leverage the rich\n42.0s: microphysical information content of\n44.079s: observational systems to improve our\n46.239s: understanding and model representation\n48.16s: of cloud and precipitation processes\n50.76s: furthermore the basian methodologies\n52.879s: used allow for robust estimation of\n55.199s: uncertainty that can inform forecast\n57.64s: representations of physical process UNC\n60.6s: egva probabilistic forecast on SS thank\n65.24s: much sorry I should\n67.2s: probably I should probably shorten that\n69.52s: for next time um okay so yeah uh I want\n72.159s: to talk a little bit about this issue of\n74.84s: constraining sort of basically how\n77.6s: clouds are represented inside of uh\n79.64s: climate models and kind of from two\n81.36s: different directions uh what we call\n83.479s: sort of topown approach where we're\n85.2s: looking at Satellite observations and\n87.799s: what they can tell us about the climate\n89.64s: and then also sort of bottom up from\n92.92s: more of a detailed process uh point of\n95.32s: view so and then the the other thing is\n97.32s: that a lot of this work is well pretty\n99.32s: much all of this work is collaborative\n101.119s: and relying heavily on uh the work that\n104.64s: Kate lus has done hopefully you guys\n106.92s: have seen one of her talks I don't know\n109.159s: I think she gave a talk ear um and also\n113.2s: collaborators Greg Alister Hugh\n115.68s: Morrison um and so on okay all right so\n119.92s: first of all I I did manage to sneak in\n121.84s: some uh I was just at the International\n123.799s: Conference on clouds and precipitation\n125.96s: in uh Juju Island Korea so I figured i'\n129.679s: I'd put in some weather here so this is\n131.879s: a time lapse of a Squall line hitting\n136.319s: that was a lot of fun um you can see\n138.08s: some rotation In This Cloud by the way\n140.64s: uh right about there which is kind of\n142.76s: fun also so uh of course sometimes Squad\n146.0s: lines spawn up tornadoes and whatnot so\n149.0s: and this is when it hit\n150.56s: and uh yeah it was uh it was pretty\n153.16s: impressive pretty strong wind so pretty\n155.28s: high precipitation I also mention that\n157.28s: Kate Loft this uh sampled the storm in\n160.599s: situ on her way to the\n163.08s: conference unforunate you know the\n166.2s: things we do for science uh in any case\n168.68s: uh yeah let me move on from\n170.56s: there okay so uh what's the big problem\n173.36s: that we're dealing with well the big\n174.599s: problem is that uh we want to try to\n177.28s: represent a lot of things that happen in\n178.879s: the atmosphere such as this Cloud right\n180.92s: over here uh but what's the problem well\n183.239s: the problem is that our climate model\n184.879s: grid scales are really big right we in\n188.04s: climate model we kind of break up the\n189.64s: earth into all these little grid points\n191.4s: and then we predict Cloud properties on\n193.76s: those grid points right each grid Point\n195.64s: has um you know maybe one or two numbers\n199.28s: to describe the cloud population and one\n202.12s: or two numbers to describe rain and so\n204.4s: on so it's really boiling down a lot\n207.36s: there's a lot that's happening here that\n208.879s: gets boiled down into just a few numbers\n211.56s: uh even if we go down to like weather\n213.2s: models or higher resolution models what\n215.319s: they call U storm resolving models or\n218.68s: convective convection permitting models\n221.319s: uh the the model grid is typically still\n224.4s: missing a lot of these like sort of\n226.28s: smaller little Eddy features and uh and\n230.08s: smaller details of the updraft and\n232.439s: certainly it's not going to resolve\n233.599s: something like a turbulence in the air\n236.72s: okay now once we actually let's say we\n239.319s: could represent those things um even\n243.04s: then you have a issue because you have\n244.92s: basically like a population of droplets\n246.799s: in the cloud right so there's a there's\n249.599s: a population of of of droplets of\n251.879s: different size and well how do you\n253.959s: characterize it you can't follow every\n255.319s: single drop um this is something that uh\n258.84s: that Kate brought up in a in in one of\n261.44s: her talks that if you kind of grabbed a\n263.12s: handful of cloud you'd have around a\n265.759s: billion Cloud particles in your hand so\n270.0s: okay you can't fall around a billion\n271.4s: particles Lally uh so what do we do well\n275.56s: uh we just kind of stick a probability\n277.68s: distribution on the drop sizes right and\n280.6s: there's different ways that you can\n281.6s: represent that probability distribution\n283.8s: so you just kind of like stick a\n285.12s: function on it right imagine that you\n287.36s: stick like a gaussian function on it\n289.039s: that represents the distribution of drop\n291.16s: sizes you're more likely to find this\n292.56s: size particle than this size particle\n294.639s: and so on or you can kind of chop it up\n297.4s: into little chunks right like a little\n300.479s: and that's uh that's better in a way\n302.479s: because you know maybe you have two\n303.8s: peaks instead of\n305.639s: one uh there's newer fancier methods\n308.56s: where you actually do kind of fall\n310.199s: around particles that are floating\n311.52s: around in the cloud they're called the\n312.84s: bronan methods um and then each little\n316.28s: super particle that you're following\n317.8s: around actually represents uh many\n320.12s: particles so it's sort of like the uh\n322.8s: the particle congressman who is going to\n324.72s: represent that population of particles\n326.8s: in the particle Senate\n330.44s: I I just came up with that so please\n332.68s: don't be\n335.479s: to not a bad one okay anyway going on um\n340.12s: all right let's say you could get every\n341.4s: single particle you still have problems\n344.639s: so uh if you look at just like two\n346.759s: raindrops colliding what happens for\n349.36s: them uh we kind of don't know uh we kind\n354.039s: of know we kind of don't know so this\n358.0s: process of two droplets colliding is is\n359.759s: really nonlinear and when they sort of\n362.16s: break apart this uh you see that there's\n364.199s: a little filament over here I should use\n366.479s: the mouse for online people there's a\n368.36s: little filament here and that's going to\n370.16s: just like Snap and when that snaps it\n372.319s: could break up into just two nice little\n374.44s: particles or it could break up into\n376.759s: dozens of tiny little particles uh so\n380.039s: it's a very complicated problem that's\n382.16s: just one process right that's raindrop\n384.52s: uh collisional\n386.36s: breakup okay we go to ice it gets even\n389.0s: nastier\n390.08s: so uh you know you you've probably seen\n392.319s: snowflakes no two snowflakes are alike\n394.479s: it's not really true but in any case um\n397.84s: they are messy and like some of them are\n399.84s: are really weird shapes and like they're\n402.319s: if you look at the textbooks they just\n403.759s: show uh columns just like hexagonal\n407.16s: columns for these ice crystals but\n409.4s: they're not really they're not really\n411.12s: exactly that they have like weird\n412.72s: features where they scroll inward\n414.4s: they're Hollow sometimes they're not\n416.28s: Hollow uh it's extremely messy this is\n418.84s: actually work\n420.039s: uh that Joe Joseph Co and car lamb are\n423.319s: working\n425.16s: on they can tell you more about that all\n428.039s: right and then there's this is there's\n429.36s: like all sorts of processes like this so\n431.44s: like there's like up up and down a cloud\n434.0s: there's every single process has maybe\n436.56s: not every single process but almost\n438.44s: every single process has uncertainties\n440.199s: at that sort of process scale so it's\n442.56s: sort of a problem that's been called the\n444.56s: double parameterization problem we can't\n448.28s: uh we can't resolve clouds themselves in\n452.0s: models right and then uh we can't\n455.36s: resolve the actual processes that are\n457.199s: happening side clouds so there's sort of\n459.919s: two scales of the problem here so what\n461.8s: does it mean it means we have lots of\n463.84s: uncertainty\n465.599s: okay uh oh and this is this is kind of\n467.759s: an important thing especially for this\n469.4s: leap crowd um is that this means that\n472.0s: there's no reference model for for what\n474.319s: happens inside of clouds for cloud\n476.8s: microphysics um and that's important\n479.68s: like a lot of uh machine learning\n481.44s: methods really rely on having that\n484.52s: reference model right you have a\n485.759s: reference model you generate just like\n488.68s: absolute buckets of data and then you\n491.639s: train some other model on that reference\n494.039s: model and then you come up with some\n495.84s: machine learning model that emulates\n497.24s: your reference model great we don't have\n499.759s: a reference model here so um we can't\n503.759s: necessarily rely on those techniques\n506.159s: although they do have maybe limited\n508.319s: relevance\n511.279s: yeah okay so looking at a climate model\n514.64s: this is uh I'm going to be talking about\n516.24s: the NASA Model E climate model it's one\n519.32s: of many climate models out there um we\n524.039s: sort of uh ped the people who work on\n527.56s: this model and ask for which parameters\n529.839s: are most uncertain we got this big old\n532.519s: list of 405 parameters it's quite a few\n535.399s: uh some having to do with uh conductive\n537.64s: clouds like that thunderstorm picture\n539.519s: showed you before some having to do with\n541.64s: what's called large scale clouds that\n543.68s: might be something like um like these\n546.36s: big uh Marine fog Decks that sit over uh\n550.959s: off the coast of California I've ever\n552.6s: been to California in the summer and\n554.079s: expected a sunny Beach day and been\n556.36s: severely disappointed you can think of\n558.44s: these large scale stratfor TOS uh and\n561.72s: then there's the turbulence parameter\n562.959s: here anyways it's a lot of parameters 45\n565.92s: parameters and um okay well if we talk\n569.0s: to a statistician they'll say use base\n570.88s: theorem you estimate the probability of\n575.04s: some parameters given some observations\n578.519s: so parameters are X observations are\n581.519s: y um and you know it's just some way of\n584.6s: combining some observational information\n586.36s: and some\n587.36s: prior basically we just need to solve\n589.959s: this and we get the probability of our\n591.32s: parameters it's too easy\n593.72s: really um one thing to mention here is\n596.839s: that we have this Condition it's\n598.6s: conditional on uh basically any other\n601.839s: assumptions in our model so we make lots\n604.279s: of assumptions in our model right way\n606.76s: back here when we simplified our model\n609.399s: uh into these things that's an\n611.24s: assumption something that's baked in\n614.0s: whatever we do um we can estimate the\n616.279s: uncertainty in our parameters but it's\n617.64s: always going to be sort of conditional\n618.92s: on all those things that we' baked into\n620.88s: our\n622.32s: model okay uh what can we use to observe\n625.399s: uh we have a bunch of satellite metrics\n627.8s: there's uh things related to radiation\n630.72s: water vapor specific humidity\n633.8s: temperature um and so on from various\n636.8s: satellite sources so some of these might\n638.44s: be a single satellite some of them might\n640.04s: be multiple satellites sometimes there's\n642.68s: a a m a single multi-satellite product\n645.48s: sometimes there's multiple products from\n647.24s: different satellites um\n650.12s: interestingly uh I think it's\n651.88s: interesting at least uh sometimes these\n654.399s: disagree and sometimes they disagree by\n657.24s: an amount that's actually greater than\n659.0s: the published uncertainties of each\n661.24s: observation so that's a little bit scary\n663.92s: too um but in any case there's\n666.04s: observations they have some uncertainty\n668.2s: um luckily that basian sort of framework\n670.079s: that I showed allows us to incorporate\n673.519s: certainties okay how do we do this well\n677.279s: if our model was linear this would be\n680.639s: easy uh so let's say our model is linear\n683.92s: we vary our parameter in our model right\n686.68s: any one of those 45 parameters and we\n688.92s: look at some measurement and it has a\n690.8s: nice linear relationship beautiful we\n693.56s: have some observation that observation\n695.56s: has some uncertainty and it's basically\n697.44s: just projecting this uncertainty onto\n699.36s: the model down to the parameters and\n701.959s: then we get our uncertainty and our\n703.279s: parameters and wow look this is gaussian\n706.56s: over here nice gaussian function and we\n708.639s: get a gaussian back it's very easy it's\n711.48s: very nice unfortunately our models are\n715.0s: nonlinear they don't have these simple\n717.32s: behaviors and uh nonlinear models are\n720.88s: harder so if our model is nonlinear it\n723.48s: has some nonlinear variation of the\n725.32s: outputs of these uh these measurable\n727.92s: quantities with variations of the\n729.72s: parameter uh you don't get a simple G\n732.16s: you get something that's really kind of\n734.56s: lumpy uh and well there's a bunch of\n738.8s: simple methods that you can use here for\n740.519s: parameter estimation that are really\n742.079s: easy really powerful they work really\n744.04s: well uh that completely fail over here\n747.72s: so what the bottom line is you have to\n749.519s: use uh markof chain mon Carlo um or\n753.56s: similar techniques if you want to get at\n755.519s: this uh quantifying these uncertainties\n758.04s: and estimating parameters now what is\n760.36s: that all right so basically what this is\n762.6s: is it's an iterative method where you um\n766.56s: you sample a point in your parameter\n768.44s: space so you say I'm just going to guess\n770.04s: that I have these parameters and then I\n772.48s: take a step away in that parameter space\n775.079s: I just like move and then I look and see\n778.199s: if my model performs better uh with\n781.16s: those new parameters or worse and then\n783.48s: depending on whether it's better or\n784.68s: worse you accept or reject and uh you\n788.44s: kind of just keep on stepping around in\n790.399s: this way building up a whole chain of\n792.639s: points and if you look at the end of\n795.399s: what points you've selected they kind of\n798.16s: uh they're basically samples of the\n800.279s: underlying probability that you're\n801.88s: trying to estimate so that's kind of\n804.56s: nice you just have to run it um times in\n808.639s: this case\n809.959s: uh\n812.399s: yeah okay um that's great wonderful uh\n816.8s: so I'm I'm just simplifying that\n818.24s: methodology into this cartoon sample our\n820.24s: parameters we run our model We compare\n822.8s: to observations and then we iterate\n824.959s: again um but the problem is that climate\n827.32s: models are expensive right so oh by the\n829.92s: way if anyone uh if you want me to stop\n832.12s: at any point or ask a question or\n833.839s: anything like that I'm happy to pause I\n836.639s: if I miss something or or don't describe\n838.88s: anything anything well please just\n840.72s: interact um okay this is too expensive\n843.56s: CL models are expensive uh we can't do\n845.759s: this a million times we can't even do it\n848.199s: uh you know 100,00 or 10,000 times or\n851.68s: you know a thousand we're getting maybe\n853.32s: a little bit closer to round of\n855.32s: posibility um but then like these\n857.24s: methods Don't Really Work Well if you\n858.519s: just have a thousand samples so what do\n860.759s: we do well um okay I'm at leap so of\n864.399s: course we use machine learning so we\n866.399s: what we do instead is we sample our\n867.959s: parameters in\n869.6s: relatively limited way so we maybe do\n872.72s: 500 samples of our parameters sort of\n875.04s: across the range of Uncertain values we\n877.8s: run our model and then we train a\n880.399s: model sometimes we call this an emulator\n883.279s: although people use the word emulator or\n885.199s: surrogate for different things anyways\n887.72s: um we train a model surrogate and all\n890.639s: this model surrogate does is basically\n892.44s: relate to relate variations in the\n894.44s: parameters to uh variation sorry\n897.519s: variations in the parameters two\n899.399s: variations in the output it doesn't do\n901.079s: anything else ask it for outputs it\n903.839s: doesn't simulate all of the processes\n905.68s: inside of the climate model all that\n907.12s: says is if I play around with this\n909.24s: parameter what happens to all of the\n911.399s: outputs okay and that's all we need for\n913.68s: this because we stick it into this\n915.519s: framework uh where we basically replace\n918.48s: it for the purposes of parameter\n920.32s: estimation and yeah again let me\n922.759s: emphasize that we only replace it for\n924.6s: the for the purposes of parameter\n926.16s: estimation we don't take this emulator\n928.079s: and then try to simulate climate it's\n930.399s: very it's very uh simple it only knows\n933.8s: this very limited sort of\n936.319s: sensitivity but then which we can run in\n939.199s: the\n941.88s: full okay so what do we get uh we get\n945.92s: this beautiful diagram this beautiful um\n950.319s: 45 dimensional probability distribution\n953.36s: that's uh completely uninterpretable and\n956.399s: not very helpful but in any case uh the\n958.639s: f things that we want to uh pull out of\n960.8s: this is that basically we started out\n962.12s: with flat distributions for each of\n963.8s: these parameters um and then we've\n966.04s: gained information right so this one if\n967.959s: I could zoom in uh way up here in the\n971.12s: top left uh we it now has like a little\n973.6s: Peak so we it's it's constrain the\n975.519s: parameter down to a plausible range\n977.88s: right by comparing the model to\n979.8s: observations and similarly basically uh\n982.56s: almost all of these parameters have been\n984.519s: constrained to some extent by our\n986.16s: observations that's great and we have\n988.12s: uncertainty too it's not just a single\n990.0s: value right it's a probability\n991.959s: distribution telling us what the likely\n993.68s: values\n994.72s: are and if we plug this into our climate\n997.759s: model again we can look at how well we\n999.639s: do so we can look at certain\n1001.8s: outputs um this is longwave uh Cloud\n1004.8s: rative effect and precipitation and\n1007.36s: these lines are sort of our Target uh\n1009.6s: our Target um and this sort of maybe our\n1013.36s: tolerance for our con certainty in the\n1015.199s: actual observation specification and uh\n1018.279s: these black Point are what we started\n1019.68s: out with um and these green points are\n1022.48s: sort of the final of what we've got and\n1024.76s: so that sort of zeroed in on on these\n1027.28s: points so okay let good and just to sort\n1030.439s: of drive this point home in our original\n1032.52s: sampling so we we ran 450 parameter\n1035.959s: values through the model basically zero\n1038.36s: of those produce a realistic\n1040.319s: climate and um our final\n1044.839s: sample uh out of 100 samples drawn from\n1048.24s: that uh 30 of them were good so we've\n1050.48s: gone from basically a 0% success rate to\n1052.919s: a 30% success rate which is a huge\n1055.12s: Improvement for us um and the the sort\n1058.559s: of important thing here is that like\n1060.2s: those 30 samples are very different\n1063.0s: parameter values and they produce like\n1064.64s: different model behaviors but they all\n1067.08s: basically agree with observations so\n1069.32s: this is sort of uh something that that\n1071.4s: um is kind of uh interesting from the\n1073.84s: point of view of uh climate\n1076.72s: modeling uh in climate modeling you have\n1078.88s: have these uh model intercomparison\n1081.36s: projects where you take different models\n1082.919s: from different centers and you compare\n1085.32s: them together and uh people look at that\n1088.0s: and they say okay well do the models\n1090.12s: agree they usually don't and uh when\n1093.72s: they don't agree that uncertainty is\n1095.36s: sort of viewed as some sort of\n1097.28s: informative uncertainty of how well we\n1099.72s: understand the climate but really these\n1101.52s: models have just been created with\n1102.919s: different methodologies um so they're\n1105.08s: not necessarily that uncertainty is not\n1107.12s: uh consistent it's uh been produced by\n1109.48s: sort of just the opportunity of many\n1111.039s: groups putting together different\n1112.88s: climate models different ways uh this uh\n1116.799s: sample of parameters is sort of all\n1119.96s: parameters that have been constrained in\n1121.88s: the same way in some sort of consistent\n1123.799s: way so we think of this as a we call\n1126.919s: this a calibrated physics\n1129.08s: Ensemble um and it's basically a way\n1132.84s: maybe one of the first sort of uh fully\n1135.52s: realized attempts at characterizing the\n1137.44s: uncertainty of the climate model\n1139.28s: and it would be nice to compare these\n1141.44s: results to similar results from\n1143.76s: different climate\n1147.44s: mods um yeah I'll skip that bottom line\n1150.36s: for now uh and as I said so if we\n1153.88s: compare just like sticking in the\n1155.24s: regular values into our climate model uh\n1157.44s: we get a big spread in uh this shortwave\n1160.96s: absorve shortwave and like these values\n1163.039s: out here are Bonkers they don't make any\n1164.679s: sense so if you just perturb the\n1166.72s: parameters and you look at your model's\n1168.159s: producing it produces lots of uh crazy\n1170.6s: values so it doesn't necessarily make\n1172.52s: sense to analyze your model on those\n1174.4s: values what we get in set our Cal\n1176.88s: physics Ensemble is they're all in\n1178.72s: reasonable agreement with observations\n1182.44s: more okay I think I'm going to skip this\n1185.52s: slide and go to this one um sometimes\n1189.32s: people like to uh perturb parameters in\n1192.159s: models and then say okay which ones are\n1194.64s: the important ones to perturb and then\n1197.799s: uh kind of throw out ones that are not\n1199.36s: important so uh you might get like you\n1203.2s: know this is just a correlation you\n1205.48s: might get and these are all parameters\n1206.919s: and these are all outputs and basically\n1208.84s: where you have Reds or Blues you have\n1210.84s: stronger correlation between the\n1212.36s: parameters and the outputs so you might\n1214.799s: say okay well maybe these ones I can\n1216.36s: throw out uh but these ones look really\n1218.48s: important this one looks really\n1220.32s: important uh okay you might like pick\n1222.88s: and choose and throw some out people do\n1224.679s: this quite\n1226.0s: often but if you start to look at other\n1228.159s: metrics so here this is a sort of metric\n1231.919s: that shows how much the uncertainty\n1235.039s: varies in an output as you perturb a\n1238.799s: parameter uh you see other parameters\n1241.76s: are important for that okay so that's\n1244.28s: interesting right um moving on from\n1247.6s: there if we compare our initial perur\n1250.4s: parameter Ensemble that's just sampling\n1252.52s: across the parameter ranges versus the\n1254.72s: constrained one the one that's been\n1256.12s: constrained by observations then we also\n1258.679s: see a completely different picture so\n1260.28s: here like there's a zillion parameters\n1262.0s: that are important it's hard to pick out\n1263.32s: a parameter that isn't important sort of\n1266.039s: after constraint by observations so\n1268.72s: there's a big difference between looking\n1270.12s: at the sensitivity of a climate model\n1272.679s: with by turbing parameters um when\n1275.6s: you're just perturbing the parameters\n1278.0s: and when you're perturbing the\n1279.08s: parameters in a realistic way way where\n1281.44s: you actually are producing a simulation\n1284.24s: that has any match up to reality\n1286.64s: whatsoever so that's sort of an\n1294.919s: somewhat y was a question about that\n1298.32s: like what's different between when it\n1300.52s: becomes more sensitive or not is it like\n1302.6s: just the ranges of what you call a\n1304.24s: perturbation or is it like yeah I think\n1306.919s: that's mostly it is that we've basically\n1308.88s: constrained down the range perturbations\n1310.76s: down to more realistic range range that\n1313.0s: produces realistic results it's a little\n1315.12s: bit more complicated than that because\n1316.48s: there are sort of co-variances in the\n1318.679s: parameters but basically we've just\n1320.279s: reduced it down to what produces\n1322.96s: acceptably realistic\n1327.559s: situations okay uh we can also do other\n1330.0s: fun stuff with this uh sort of\n1332.0s: calibrated physics Ensemble approach um\n1334.679s: one thing we've done is we've like asked\n1337.72s: ourselves like well what if I have\n1339.48s: better observations in the future so I\n1342.4s: can look at all of my parameter values\n1344.6s: all of my parameter uh PDFs and I can\n1348.039s: compare\n1349.559s: what I get as constraint on the\n1351.24s: parameters with sort of default\n1353.039s: uncertainty in some observable\n1354.679s: quantities versus if I had a better\n1357.08s: observation of that quantity one with\n1358.96s: less uncertainty so in other words how\n1361.159s: much is um each observation giving me if\n1364.96s: I sent out a new satellite to outer\n1367.159s: space uh how much would how much\n1369.08s: information would I gain on my\n1372.08s: parameters from that new observation so\n1375.64s: uh basically I just have the PDFs\n1377.4s: comparing like so default uncertainty\n1379.88s: with a new lower uncertainty and you can\n1382.279s: kind of look at which processes which\n1384.88s: parameters related to which processes\n1386.72s: getting sort of constrained so if you're\n1389.36s: developing a satellite you can you know\n1391.12s: we can now give information about how\n1393.4s: valuable will that actually be for\n1397.32s: physics um okay so uh moving stepping\n1401.24s: back a little bit again uh for some of\n1403.2s: these things we get a uh good match up\n1407.12s: show this this is basically outputs from\n1409.44s: the model these green crosshairs are\n1411.76s: sort of those obervational targets from\n1413.32s: the satellites black dots are our\n1416.159s: original Ensemble and the green dots are\n1418.48s: sort of our\n1420.12s: fining great we get a good match up\n1422.96s: pretty\n1423.799s: good uh for some of these we don't\n1426.279s: though so this is h a total cloud cover\n1431.919s: um and this is a shortwave uh Cloud\n1435.12s: radiative effect and a liquid water path\n1438.559s: so basically uh we're able to match the\n1441.08s: total liquid water path total amount of\n1443.4s: liquid that's in in clouds um and the\n1447.44s: cloud radiative effect but only if we\n1450.159s: have too few\n1452.36s: clouds so in other words uh our model uh\n1457.44s: is basically getting the right radiation\n1460.159s: by making too few clouds that are too\n1463.159s: shiny it's basically the answer and this\n1465.36s: is actually like something that's pretty\n1466.799s: common in clim BLS that they tend to\n1468.96s: make twoo few clocks that are too shiny\n1472.08s: um and we kind of show here by looking\n1475.48s: at this uh these perations in our\n1477.44s: parameters that this isn't because we\n1479.24s: don't have the right uh parameter values\n1481.64s: right no parameter values can get us at\n1483.6s: this at the Target right this is\n1485.919s: something that's likely\n1487.36s: structural probably associated with a\n1489.6s: lot of those assumptions that we baked\n1491.24s: in if you remember when I had the base\n1492.88s: theorem there and I said it was\n1494.24s: conditional on those\n1496.12s: assumptions this is basically an\n1497.88s: effective right we're we're not able to\n1500.64s: get at our Target because of some some\n1502.799s: structural things that model so what\n1505.679s: structural changes need to be made okay\n1508.44s: uh let me just uh say that we would like\n1510.52s: to guide a lot of this with a detailed\n1513.039s: observations so this is maybe taking\n1515.08s: another step back but we don't just want\n1517.159s: to look at climate models we can also\n1518.919s: look at detailed uh Cloud models right\n1521.88s: so this is a image from a large Eddie\n1524.32s: simulation where U you just resolve a\n1528.0s: lot more of the clouds it's very high\n1531.08s: resolution it's all part of the sort of\n1534.36s: turbulent\n1537.0s: Cascade uh so we would like to sort of\n1539.32s: inform all of our decision makings with\n1541.2s: structure with parameters uh both in a\n1544.48s: sort of detailed way from bottom up but\n1547.52s: also uh with top down from the uh from\n1550.559s: the satellite observations we'd like to\n1552.08s: be able to meet in the middle in some\n1553.279s: sort of intelligent way some sort of way\n1555.52s: where they can talk to each other\n1558.64s: and um well what's one way we can do\n1561.52s: that uh we have observations for example\n1564.52s: this is satellite obser I'm sorry this\n1566.039s: is not s observations these are\n1567.88s: groundbased radar observations of\n1570.36s: clouds um this is basically columns I I\n1574.279s: should have cited this paper this is\n1575.6s: from Silver at\n1577.799s: all sorry about that I think it's\n1581.72s: 2022 uh these are sort of uh samples\n1585.0s: drawn from something like this large Ed\n1587.44s: simulation\n1589.24s: so uh we can sort of make this\n1591.08s: comparison there and then uh we have\n1593.36s: what's called a single column model\n1594.96s: which is a representation of our Global\n1598.2s: Climate model but just a single column\n1600.279s: just like take out a single column and\n1602.2s: we simulate just one column of that um\n1605.32s: and the nice thing is you can basically\n1607.679s: set up the situation to simulate this\n1610.399s: large EDD simulation the single column\n1611.96s: model in the exact same way so this\n1614.64s: might be some way to sort of make that\n1616.0s: translation across St\n1619.159s: uh we could do a consistent comparison\n1620.919s: between these two and then perhaps a\n1622.52s: statistical comparison with the\n1624.24s: observations that's sort of the hope uh\n1627.279s: and we've played around with this a\n1628.36s: little bit we've run uh we basically ran\n1631.559s: uh those same parameters that I showed\n1633.039s: you that we run with a global model uh\n1635.36s: through a single column model for some\n1639.08s: uh specific cases so we have a single\n1640.76s: column model case that predicts uh trade\n1643.2s: wi cumulus the sort of cumulus that um\n1646.44s: might look pretty on vacation in\n1648.64s: Barbados I guess um and we can look at\n1652.96s: the range of values that we produce\n1654.919s: that's in black with our perturbed\n1657.279s: parameter Ensemble and then the values\n1660.08s: um that come out of our uh constrained\n1662.36s: our our calibrated physics Ensemble\n1664.48s: that's like after con observations so\n1667.2s: you see a pretty big difference in\n1668.32s: Behavior there and we can also compare\n1669.919s: it to what large ulations do and so I\n1673.519s: basically I plug that into the\n1675.84s: framework for a few cases and got out a\n1679.12s: posterior distribution and uh obviously\n1682.279s: we don't have a lot of constraint here\n1684.399s: but this actually is encouraging in that\n1687.6s: what we've done is basically reduce the\n1689.519s: parameter volume by about 40 times so\n1692.44s: we've made um\n1694.32s: estimating the parameters about 40 times\n1697.399s: simpler than it was before if you have\n1699.88s: less space to search in then it makes it\n1702.08s: more efficient so that's just one step\n1704.559s: in that direction not there yet okay\n1706.76s: going back to this uh um I don't know\n1708.84s: why I put this here again um oh yeah we\n1711.44s: want to uh address the processes so we\n1715.0s: have uh basically do you have a question\n1716.919s: yeah can you briefly re explain how you\n1719.279s: constrained the parameter space like how\n1721.72s: you made it 40 times smaller yeah so I\n1723.919s: basically did the exact same framework\n1725.36s: that I did for the global model but um\n1727.799s: for each parameter selection I ran three\n1730.799s: single column model cases and the single\n1733.519s: column one is a drizzling Strat\n1735.12s: accumulus one was a trade accumulus one\n1736.88s: was a precipitating TR cumulus and I\n1739.32s: compared it to sort of uh an ensemble of\n1743.6s: large Ed\n1744.679s: simulations sort of detailed high\n1746.72s: resolution models what they produce and\n1749.32s: I said okay the single column models\n1751.279s: should match this within some tolerance\n1754.08s: and then I did the basian parameter\n1755.88s: constraint to uh constrain down these\n1758.6s: parameters so basically I view this as\n1761.159s: like a methodology as like a first cut\n1763.24s: before you apply the satellite\n1764.919s: observations running the climate model\n1766.84s: super call models are cheap so I can do\n1770.44s: this very cheaply cut down on the\n1773.08s: samples that I run through my full\n1775.32s: climate model and make the whole process\n1777.399s: hopefully a lot more efficient and a lot\n1780.559s: more basically won't waste as much time\n1782.88s: looking at bad that Mak\n1786.44s: sense and yeah this this whole idea\n1789.2s: isn't that new there's this paper from\n1791.399s: 2003 um where there's a sort of chain in\n1794.24s: between uh these things where our Global\n1796.919s: models are being informed by by single\n1798.48s: column\n1799.76s: models think my battery's\n1803.96s: dying um and also by observations and\n1806.96s: these high resolution mods okay uh so\n1811.0s: getting down to the process level well\n1813.799s: we've made all these assumptions in our\n1815.08s: climate models how do we get around that\n1817.279s: how do we deal with that structural\n1818.6s: element we've come up with basically a\n1820.559s: structurally flexible microphysics\n1822.519s: scheme um where we do certain things\n1825.6s: that haven't been done in the past so if\n1827.64s: you remember remember when we had those\n1828.76s: little\n1829.919s: distributions um for the for the size\n1833.76s: distribution of cloud droplets we don't\n1835.72s: assume any functional form for\n1838.24s: that uh we predict moments of the size\n1841.32s: distribution so these are quantities\n1843.2s: like number or mass or other\n1846.679s: quantities um and uh we include whatever\n1850.88s: limited physical constraints do exist\n1852.799s: but we don't add ones uh that do not\n1855.919s: need to be added in that we don't know\n1857.679s: for sure and then we can choose whatever\n1861.6s: uh quantities we want basically to\n1863.72s: describe the cloud and we can use uh\n1866.96s: beian estimation to figure out all the\n1869.6s: parameters of that\n1871.76s: basically so this is something that uh\n1874.44s: Kate is working on right now basically\n1876.84s: trying to um get our our ban\n1880.799s: microphysics scheme which we call boss\n1883.159s: to match up with a more detailed model\n1886.0s: which you know I did say there's no\n1887.519s: reference but there are models which are\n1889.44s: more complicated so one question is can\n1892.279s: we reproduce those complicated models\n1894.399s: with our less complicated model and I\n1897.32s: won't go too much into what she's done\n1898.88s: she's basically run this a billion times\n1901.24s: U with different parameters and then\n1902.919s: used this sort of reference model as a\n1906.159s: constraint so this is sort of without\n1908.32s: constraint and this is with constraint\n1910.36s: so um yes I won't go too much into that\n1913.6s: because that's her work uh but we have a\n1916.36s: question so uh\n1919.519s: sorry I should get past this how well\n1922.279s: does it actually work we actually stick\n1924.88s: this into a climate model does this work\n1928.159s: uh so we actually tried this this with a\n1930.12s: collaborator Ma at pnnl in\n1934.84s: Washington and uh if we look at sort of\n1937.76s: observations This Global observations of\n1939.799s: shortwave and pration and the default\n1942.799s: version of uh the Doe's climate model\n1945.88s: over here you can see sort of values\n1947.639s: here average 45 average -60 and boss\n1952.12s: gets a lot closer to that okay that's\n1954.72s: good uh prip is basically\n1958.72s: unchanged um so that's that's sort of a\n1961.679s: encouraging result but I will say that I\n1964.12s: think this is mostly by accident like I\n1966.96s: we we didn't actually tune boss in the\n1969.2s: climate model we tuned it in those\n1970.799s: detailed high resolution models and then\n1973.039s: just stuck it in here and I hoped it\n1974.6s: worked and it did work um but I I don't\n1978.2s: think uh that's necessarily the most\n1980.6s: robust result requires a lot more\n1982.96s: testing the main thing here is that it\n1985.0s: didn't cause the model to blow up and\n1986.519s: it's a promising Avenue for further\n1989.639s: work okay uh I want to just go back\n1992.039s: actually to this uh so there are other\n1994.559s: structural issues in clouds and\n1997.12s: precipitation um that can be readdressed\n2001.559s: so traditionally what we've done in the\n2002.96s: past is break up droplets into Cloud\n2005.399s: droplets and\n2006.639s: Rain um but is it really artificial like\n2009.2s: when does a cloud become rain when does\n2011.6s: rain become Cloud if evaporating and it\n2014.639s: requires also all these processes so I\n2017.08s: might have I might ask the question of\n2018.6s: when two Cloud droplets bump together do\n2020.6s: they make a larger cloud droplet or do\n2022.2s: they make rain so um that's basically\n2026.159s: the difference between self-collection\n2027.96s: and autoc conversion oops uh and then we\n2031.399s: also have to have a process of accretion\n2032.919s: where basically rain bumps into Cloud\n2034.48s: droplets it makes bigger rain so we have\n2037.0s: basically four processes that we have to\n2039.36s: simulate here when in reality there's\n2041.639s: only one process in nature right it's\n2043.559s: just droplets bumping into other\n2045.559s: droplets so uh by moving to sort of a\n2048.72s: single category\n2050.32s: approach you can actually get rid of a\n2052.44s: lot of this complexity so uh Carol Lan\n2055.079s: uh who's here at Le also has a recent\n2057.679s: paper on this on some work using machine\n2060.2s: learning to to investigate this and\n2063.32s: there's also recent work by D igel um\n2066.359s: that looks into this I won't get into\n2067.72s: into the details of this plot basically\n2069.44s: if you assume a single category you get\n2071.72s: lower error than if you assume two\n2076.04s: categories okay and then this has uh\n2078.119s: been taken up by Adele's former PhD\n2080.72s: student Arthur who who's now doing a\n2082.44s: post here at Columbia um and this is\n2085.76s: yeah similar work May perform better\n2088.44s: with the unified Cloud R category that's\n2090.639s: sort of the bottom line there and the\n2092.24s: reasons are a little bit complicated um\n2094.44s: but he has lots of nice explanations\n2096.48s: here why I won't get into the details\n2099.119s: have questions about that\n2101.76s: talk okay we went through that all right\n2104.28s: and then putting it all together we want\n2106.52s: to be able to sort of unify this sort of\n2108.96s: the these two things we're doing this\n2110.96s: work on the full climate model um both\n2113.839s: the global version and the single column\n2116.64s: versions and uh this sort of bottom up\n2119.4s: work where we're figuring out how to\n2121.119s: best represent clouds testing out things\n2124.04s: like boss as an approach for doing cloud\n2126.4s: microphysics uh and we want to join them\n2128.839s: together so this is sort of the very\n2130.359s: first step at doing that uh basically\n2132.64s: what Kate did is she ran boss uh with\n2136.0s: different parameters many times for the\n2137.72s: single column model um and so this is a\n2140.28s: Time series of liquid water path that's\n2142.599s: just total amount of liquid you have\n2144.16s: there and Rain rate and then compared it\n2148.2s: to what the high resolution models say\n2150.72s: we should get those are the sort of\n2152.0s: black\n2153.04s: lines um and then also uh played around\n2158.079s: with evaporation bit just did some\n2161.0s: tweaks to that that she thought made\n2162.64s: sense uh in the structure of how\n2164.839s: evaporation is\n2166.52s: calculated um so this is just sort of\n2168.76s: first attempt but the but basically our\n2170.44s: goal would be to use constraints like\n2172.599s: this so which lines which of these many\n2175.839s: lines that are from parameter variations\n2177.8s: in boss in Model E U match up with these\n2181.48s: observations so that's sort of the next\n2185.119s: steps all right so on a second not so\n2188.64s: fast why you say not so fast okay there\n2192.4s: are issues so one of the issues is that\n2195.56s: um basically if you have a grid and you\n2198.44s: have processes that uh that um are\n2202.319s: happening inside of that grid but you\n2204.16s: assume that there's some variability\n2205.96s: inside of that grid okay so what do I\n2208.359s: mean well if I take a cloud and I look\n2210.8s: at a cloud uh it's not going to be\n2212.599s: across a climate scale grid box doing\n2215.4s: the same thing across that whole say one\n2218.04s: problems right clouds are if you look at\n2219.64s: Clouds they vary along pretty small\n2221.92s: scales so actually most of our models\n2224.079s: have this built in uh we assume that\n2226.8s: there's some variability in the cloud\n2230.4s: properties across that\n2232.8s: grid and uh the reason we need to do\n2235.4s: that is that when you have a process\n2238.56s: that depends on those quantities those\n2240.839s: Cloud quantities and that process is\n2243.8s: nonlinear you can't just average it out\n2246.359s: in other words taking the Me properties\n2248.599s: of those clouds and calculating your\n2251.2s: process rates won't actually give you\n2253.599s: the right answer so it's just the you\n2257.52s: can't average out something that varies\n2260.079s: nonlinearly um so when we sort of turn\n2263.76s: that on sometimes with boss and climate\n2265.8s: models uh we get\n2268.0s: crashes so that's one thing and it might\n2270.839s: be just because of the parameter values\n2272.4s: we've chosen another thing and uh maybe\n2275.359s: a more scary thing is that\n2277.96s: um well in climate models you solve on\n2282.4s: time steps so you say what's happened in\n2284.88s: the last five\n2287.48s: seconds dist Jing what happens in the\n2290.52s: last 10 minutes or 30 minutes okay\n2293.119s: usually it are pretty long time steps so\n2295.4s: a lot can happen in that amount of time\n2297.599s: right uh and a lot can vary in a\n2299.88s: nonlinear way in that amount of\n2302.64s: time and this is kind of a problem\n2305.0s: because uh if you look at the the\n2308.079s: behavior of a climate model trying to\n2310.839s: solve the physics at different time\n2313.079s: steps I going to solve it at 15 minutes\n2316.48s: 10 minutes five minutes the values don't\n2319.079s: converge so you don't get convergence in\n2321.4s: this you're not you're not reaching some\n2323.28s: point where you're like this time step\n2324.839s: is good enough right we get different\n2327.2s: values in the behavior of our model as\n2329.28s: we're increasing the time step so this\n2330.88s: is a tricky thing to deal with and\n2333.599s: basically what it means is that you\n2335.76s: could learn the physics as best as you\n2338.8s: can in your high resolution models and\n2341.28s: you're still going to have difficulty\n2342.44s: running it in climate models that aren't\n2344.359s: solving it at the time steps that it\n2346.4s: needs to be solv that so these are sort\n2348.24s: of existing challenges and uh yeah\n2350.88s: they're being worked\n2352.24s: on they uh their issues with uh\n2355.28s: basically trying to solve these things\n2358.2s: okay uh so just sort of summing\n2361.76s: up what have we done well we've done a\n2364.8s: few different things uh sort of a\n2366.68s: spectrum of ways constrain microphysics\n2369.28s: and uh other processes inside of uh\n2372.119s: climate models we've done sort of\n2374.48s: directly fitting process rates um to\n2377.16s: some reference scheme I didn't really\n2379.04s: talk about this work\n2381.599s: um we've also started fitting things in\n2385.92s: uh in high resolution models that's Kate\n2388.319s: less'\n2390.119s: work uh and we've done this in uh\n2393.0s: climate models also with satellite\n2394.88s: constraints so sort of these things have\n2396.839s: been sort of checked off and we have yet\n2399.16s: to do sort of um constraint\n2402.04s: of our physics with\n2405.52s: uh scale dat actually observing a cloud\n2409.4s: right now as it's evolving over 10 30\n2411.76s: minutes using that to form our physics\n2414.76s: uh this is really important because uh\n2416.319s: if you look at you know if if any of you\n2418.28s: are are like mother nerds you can look\n2420.68s: at like the the American network of uh\n2424.04s: of precipitation Radars and it's it's\n2427.319s: spectacular you have like hundreds of\n2429.24s: Radars Across America measuring\n2431.079s: precipitation measuring storms every\n2433.96s: single day in 3D with multiple variables\n2437.28s: it's incredible it's really fantastic uh\n2439.56s: how much of that data goes into learning\n2442.56s: what the physics of precipitation uh is\n2445.48s: actually doing 0% I'm rounding off here\n2448.44s: but basically 0% we're throwing out all\n2450.72s: this data so uh we basically haven't\n2453.04s: figured out a way to use that\n2454.839s: data certainly not in a systematic way\n2457.64s: so anyway I'll get out my box now okay\n2462.2s: takeaways to do we've done this\n2463.92s: parameter estimation inference um we've\n2466.76s: sort of done it in top down and bottom\n2469.319s: up I would say the top down uh is pretty\n2472.68s: good at the bottom up seems very\n2474.44s: promising but uh yeah the meeting at the\n2477.48s: middle is going to be tricky okay\n2479.119s: calibrated physics ensembles this is\n2480.68s: like one of our our big pushes that\n2482.16s: we're trying to push for is basically\n2484.0s: don't just vary your parameters and\n2486.0s: expect it to mean something we really\n2488.04s: want to look at which parameter\n2489.48s: variations are actually matching up to\n2492.839s: uh about what the clim is\n2495.72s: actually uh so right we can constrain\n2498.119s: our microphysics in high resolution\n2500.079s: simulations large Ed\n2502.359s: simulations bottom up and then there's\n2504.4s: these challenges that exist sub\n2506.68s: variability numerical errors these are\n2509.079s: sort of things that we still need to\n2511.24s: tackle um and then there's yeah there's\n2513.2s: a separate issue of structural errors in\n2515.319s: the bottom of uh method right even even\n2517.319s: if you have a high resolution model well\n2520.0s: am I representing cloud and rain as two\n2521.8s: different categories that introduces ER\n2524.359s: so there's still this issue that's being\n2526.16s: addressed recent work by Carol lamb Adel\n2529.0s: igel Arthur Andrew Gman and ongoing work\n2532.599s: by Kate lus and Sean Santos if you're\n2535.56s: interested in digging up their names and\n2538.0s: uh that's it I'm happy to take any\n2540.04s: questions and yeah we have also\n2551.359s: you\n2556.76s: think sorry um do you think the weather\n2559.72s: scale applications would be like easier\n2562.0s: than a global ECM um because of the like\n2565.24s: subgrid variability and subtime step\n2567.88s: variability or are there like specific\n2571.24s: uh challenges that you see with that\n2573.68s: it's good point that you wouldn't have\n2574.8s: to worry as much about that but uh no I\n2576.96s: think it's going to be a lot harder and\n2578.72s: the reason why is basically because you\n2580.44s: know if you if you look at what like\n2581.8s: weather forecasting Centers do they do\n2583.72s: data simulation where they are basically\n2586.96s: run an ensemble of models that don't\n2589.079s: have different physics they have\n2590.359s: different initial conditions and that's\n2592.48s: because uh if you vary the initial\n2594.96s: conditions in your simulation uh you get\n2596.88s: pretty different uh behaviors of what\n2599.28s: you're you're forecasting and we can\n2602.4s: also not really measure the state of the\n2604.119s: atmosphere that well right if you think\n2606.04s: about what are we measuring in terms of\n2607.76s: the atmosphere we send out balloons like\n2609.44s: twice a day I get profiles of the\n2612.0s: temperature humidity and winds and\n2614.72s: that's super important for botles right\n2617.119s: I would say it's more important than\n2618.359s: Like Satellites and stuff like that\n2619.839s: nobody will talk about it but but some\n2622.24s: other people will talk about it but\n2624.2s: basically that's a huge uncertainty it's\n2625.92s: that state uncertainty so if you have a\n2628.0s: misfit in your mod your observations is\n2629.96s: it because your state is uncertain right\n2632.8s: your initial conditions that you put\n2634.2s: into the mall are uncertain or is it\n2636.119s: because your physics is bad\n2638.119s: really close right but how do you\n2640.92s: disentangle the two so that that problem\n2644.119s: simultaneous State ground estimation is\n2647.2s: one of the really big ones and it's it's\n2650.04s: also why Pier was starting to look into\n2654.28s: Data because that is a really problem\n2657.599s: with huge potential\n2659.319s: benefits inform\n2676.48s: question that's really\n2684.64s: hard what uh could you just reiterate\n2687.68s: what you think the structural errors\n2690.64s: are why like you know converging on uh\n2694.76s: like good parameters didn't help\n2698.48s: yeah um there's some issues in uh so\n2702.92s: this is something that Kate this is like\n2704.52s: Kate's big bug bear is all of the the\n2706.8s: sort of crimes of how clouds are\n2708.48s: represented in clim climate models so\n2710.8s: one of the things is that they don't um\n2713.52s: they don't take into account in in the\n2715.559s: right way basically how the cloud size\n2718.24s: distribution uh changes in width and\n2721.079s: other words uh they assume that the\n2722.72s: cloud distribution tends to be a lot\n2724.96s: wider than it is in nature there's a\n2727.44s: recent paper actually by somebody who\n2729.599s: like flew some instruments through\n2730.839s: clouds and found really narrow\n2732.96s: distributions and um those are going to\n2735.64s: behave in a very different way than like\n2737.359s: very broad distributions that\n2739.359s: variability isn't really captured in\n2743.079s: model so that's one there's\n2748.8s: others Marcus could you could you a\n2751.119s: little explain about that single column\n2753.68s: model how how we can find the\n2756.319s: relationship between a single column\n2758.359s: model and and the model that try to do\n2761.2s: in a distributed way yeah so the the\n2764.64s: single column model is you kind of pluck\n2766.8s: a column out and then you give it\n2768.52s: forcings that are sort of\n2771.44s: matching um some forcings uh that are\n2775.76s: representative of some weather\n2778.68s: phenomenon that you might have studied\n2780.04s: in more depth so very often they come\n2781.599s: out of field campaigns right there's\n2783.559s: aens a field campaign that looks at what\n2785.88s: the large scale flow is in an area what\n2789.16s: the temperature and humidity profiles\n2791.0s: are with just like way more observations\n2792.88s: than you normally do so you can really\n2794.44s: constrain what's going on and um and\n2797.96s: then you can hopefully dve that single\n2800.44s: column in a way that's consistent with\n2803.319s: what you've observed and produce uh an\n2806.24s: atmosphere that behaves consistently\n2808.72s: with what you've observed if you got the\n2810.48s: physics right and you can also put those\n2812.88s: same forcings into a high resolution\n2815.359s: model that has period iotic boundary\n2817.8s: conditions for\n2818.92s: example um and then compare that\n2821.92s: behavior to the single\n2824.52s: model but basically the single colum\n2827.119s: model has all the same physics as the\n2828.96s: global P it's just instead of having uh\n2832.599s: you know advection things coming over\n2835.359s: from the next grids it just has some\n2837.559s: assumed uh\n2840.04s: forcing changing and do you think if\n2843.72s: we emulate a single column model with\n2847.24s: the ml model can we use that ml model to\n2851.359s: substitute for a distributed model\n2853.559s: because this this is one of our problem\n2857.0s: in the\n2858.92s: aerosol yeah that's a good question uh I\n2862.68s: think it'd be\n2863.76s: complicated and I think also you know\n2866.119s: you'd have to tie that to the numerics\n2870.319s: of that vaction in the global model so\n2872.88s: you still have to if you had just an ml\n2874.68s: model saying how that single column\n2876.48s: model response to forcing I think you'd\n2879.68s: still have to figure out how it's\n2882.4s: connecting to its\n2883.88s: neighbors yeah I I I don't have fully\n2887.24s: fun thoughts on that that's\n2896.96s: interesting thank you hey can I up I got\n2900.96s: a\n2901.92s: question\n2903.48s: question\n2905.44s: yes thanks Marcus that was um\n2908.64s: entertaining as always you started at\n2911.8s: the beginning and you said there's no\n2913.52s: reference\n2915.599s: model and then you you used a bunch of\n2918.8s: reference models um instead of using\n2921.839s: observations directly right I mean that\n2923.96s: is to say Robert can you hear us we\n2926.559s: Robert you're um cutting in and out um\n2928.559s: if you put your question into the chat\n2931.119s: uh we can just read it for you uh okay\n2934.0s: hang on let me see that\n2938.319s: yeah uh\n2941.44s: so Robert Robert highlighted a a\n2945.72s: important element of hypocrisy in my\n2947.599s: talk because I said that there are no\n2949.24s: reference models and then I used exactly\n2951.64s: those reference models as a reference\n2953.92s: for our microphysics development this is\n2956.92s: very\n2957.799s: true so yeah we we basically uh trained\n2961.119s: our our bulk uh model our so going back\n2964.68s: to difference between and Bin\n2969.4s: uh we trained our bulk model right this\n2972.599s: thing on a bin model which is this thing\n2974.68s: over here um and yeah it's because\n2979.64s: that's all we have uh and getting to\n2982.52s: observations is another step that is\n2986.24s: very hard at those sort of scales at the\n2988.48s: scale of actually resolving from\n2989.88s: happening inside class so that's just\n2992.799s: why it's a it's a stepping stone to just\n2995.24s: say this is more complicated my bulk\n2997.2s: scheme can I feel it uh data simulation\n3000.119s: uses observations at least indirectly\n3002.44s: yes that's true it would be nice to do\n3004.04s: data simulation it' be nice to do joint\n3006.319s: State parameter estimation I don't know\n3009.119s: anyone who's done that successfully for\n3011.799s: like large number of parameters are\n3014.28s: observations somehow more indirectly\n3015.96s: informative about\n3017.72s: microphysics maybe yeah maybe there's a\n3020.72s: way to look at that in a in a way that\n3023.24s: uh we don't worry about the state there\n3026.839s: okay hopefully that answers your\n3032.119s: questions okay thank\n3038.079s: you thank you Marcus um and everybody\n3040.92s: please help yourselves to lunch in the\n3042.4s: kitchen behind you and um stay in chat\n3045.52s: for a while"
    },
    {
        "class": "YouTubeVideo",
        "title": "Evaluating XGBoost as a Baseline Model for Spatially-Informed Precipitation Predictions",
        "videoId": "0QmF3zTQd_s",
        "url": "https://www.youtube.com/watch?v=0QmF3zTQd_s",
        "publishedAt": "2023-08-02T18:18:11Z",
        "transcript": "12.84s: okay good morning my name is Mark Kirby\n15.66s: Gill and today I'm presenting evaluating\n17.82s: XG boost as a baseline model for\n20.82s: spatially informed uh precipitation\n22.8s: predictions\n26.939s: so I want to start off with some\n28.38s: background here the images on the left\n30.359s: indicate what some of the reasons why we\n32.399s: need uh to predict precipitation the\n34.26s: importance of it uh the pictures on the\n36.54s: left the top and bottom show some areas\n38.64s: that will experience flooding and on the\n40.739s: right we have other areas that will\n42.42s: experience extreme droughts areas like\n45.12s: China and other developed cities\n47.16s: including New York are experienced to\n49.2s: extreme experience extreme flooding\n51.12s: which will impact a lot of different\n53.28s: infrastructure and societal practices\n56.82s: and in economics where other areas like\n59.52s: North Africa will experience extreme\n62.039s: drought some of these development\n63.78s: Nations depend on hydroelectricity for\n66.18s: their development of electricity or for\n68.52s: development of power and so with extreme\n71.58s: flooding which could disrupt the the\n74.82s: production of crops in India or with\n76.799s: extreme drought which could have been\n78.06s: electrical production in developing\n79.619s: countries we want to do a better job at\n81.54s: projecting precipitation and also\n83.52s: extreme precipitation events like\n85.14s: droughts and floods the image on the\n87.6s: right here it just describes how simple\n89.939s: statistical learning in the past does uh\n92.52s: do a good job at predictions but over\n94.38s: time we have found that uh machine\n96.36s: learning especially neural networks do\n98.4s: improve models performance and accuracy\n100.56s: and what and so uh the graph here shows\n103.619s: that actually the Deep neural networks\n105.42s: do a really good job and after getting\n107.34s: some of the best performing models in\n110.64s: the in the in the past\n113.399s: it's\n120.06s: okay sorry guys probably didn't hear\n122.64s: much of that all right no we could yeah\n125.159s: yeah okay perfect\n128.22s: okay\n129.42s: I'm on the wrong\n132.78s: all right so for my methodology I use\n135.9s: the similar variables as the Clemson\n137.94s: data set uh used to evaluate some of\n140.34s: their Baseline architectures so for my\n142.319s: input variables I was using temperature\n144.0s: uh specific humidity surface pressure\n146.76s: insulation\n148.86s: um surface latent heat flux and surface\n151.26s: sensible heat flux for my target\n153.54s: variables I was since I was focusing on\n155.459s: precipitation I ended up using the\n157.2s: precipitation uh values that were\n159.36s: reported from the Clemson data set so we\n161.459s: have the rain rate which was reported in\n163.2s: meters per second the snow rate which\n165.239s: was reported in meters per second and\n166.739s: happens to be the liquid equivalent of\n168.84s: the snow and then we have total\n170.28s: precipitation which I created Myself by\n172.62s: adding the snow rate and the rain rate\n174.239s: together\n175.26s: uh some pre-processing that I had to do\n177.66s: to the data was adding the time\n179.04s: coordinates as well as the latitude and\n181.019s: longitude grids and also took the daily\n183.0s: mean of both the Target and um and input\n186.12s: variables so that I could reduce the\n187.319s: size of some of the data and uh also\n189.959s: added that new additional variable of\n191.58s: total precipitation I then created a\n194.099s: raise of the global data both the input\n196.08s: and Target and then I also um created\n199.019s: some additional uh data sets to to learn\n202.379s: about some of the spatial variability\n205.62s: and so that spatial variability that I\n207.84s: included was based on a map that was\n210.42s: produced by NOAA this shows a change of\n212.94s: precipitation predicted by the end of\n214.5s: the 21st century so about 2100 and is\n216.959s: reported in the inches of liquid water\n219.0s: per year and what I wanted to do was\n221.159s: choose some areas that were projected to\n223.08s: see a strong decrease in precipitation\n225.659s: but also choose some areas that were\n227.659s: expected to see a large increase so if\n230.459s: there might be any changes in whether or\n233.159s: not the model performed better in in\n235.14s: drought events or whether it was better\n236.76s: in in large precipitation or flutter\n238.799s: flooding potential flooding events and I\n241.379s: also chose to make those uh\n243.599s: places neighboring so that way that um\n246.72s: it had a little even though the the\n248.22s: geography might be a little bit\n250.14s: different we have slightly uh more\n252.599s: similar locations than to where if I was\n254.459s: going to compare the northeast of the\n256.68s: United States to uh China or the you\n259.979s: know somewhere else across the world it\n261.72s: might not be as related so\n265.259s: and this brings me into my um model that\n268.68s: I use extreme gradient boosting which\n270.6s: combines a bunch of different features\n272.46s: we have supervised machine learning\n274.62s: which takes the uh labeled input data\n277.5s: and then trains itself based over that\n279.96s: so that it can then be tested with uh\n282.419s: new data that does not have any labels\n284.28s: uh then we use some decision trees the\n287.46s: decision trees are basically like a game\n289.259s: of 21 questions it's going to be asking\n291.3s: certain questions about the different\n292.56s: relationships between variables and at\n294.9s: each level it slips into another uh\n297.479s: another branch which lets you know\n299.82s: whether or not the the model is\n302.46s: improving and so it's hoping that over\n304.199s: time with these uh additional layers\n306.9s: that it's building it's trying to learn\n308.16s: from those and decrease its error over\n310.259s: time and this is kind of where the\n311.82s: Ensemble learning comes in is combining\n313.86s: all of these together to over time\n315.419s: produce a more powerful robust robust\n318.36s: and accurate model\n322.08s: and so this brings me into some of my\n324.18s: initial results I'm going to start with\n326.039s: the global reserve the results here we\n328.199s: have the rain rate on the left in the\n330.12s: middle we have the snow rate and then on\n332.039s: the right we have total precipitation\n333.479s: rate which is the rain rate and the snow\n335.1s: rate on each graph we have on the x-axis\n337.919s: the actual rain rates reported in watts\n339.96s: per meter squared and then we have the\n342.0s: predicted rain rates in Watson meter\n343.56s: squared what I did not mention in my\n345.3s: methods was that I also converted the uh\n348.479s: the meters per second rate into watts\n350.28s: per meter squared so it was similar to\n352.44s: the the\n353.46s: um\n354.84s: the units that were used in the Clemson\n357.12s: data set data paper and as we can see I\n360.18s: have the r squared and mean absolute\n362.039s: errors reported here below each graph\n364.08s: for the rain rate it actually did a\n366.479s: decent job the r squared is uh 0.52 and\n369.539s: r squared is going to let us know how\n371.52s: how good that this model represents the\n373.68s: variability in the in the actual\n375.84s: variable and as far as the Mae it lets\n378.479s: us know about how much are or how large\n380.82s: the errors are between the true and\n382.68s: predicted overall and what we can see is\n385.199s: if we compare uh sorry to go through all\n387.66s: the graphs like this but if we could if\n389.46s: you look at all the the mean absolute\n390.96s: errors between the three different uh\n393.0s: graphs we see that the largest errors\n395.34s: are going to be with the total\n396.6s: precipitation and then we have lower\n398.46s: errors with the rain rate and snow wave\n400.74s: I believe this is uh uh oh let me not\n403.44s: get inside then on the r squared\n406.139s: um we have the the highest value being\n408.12s: the rain rate and then for snow rate it\n410.22s: decreases but then when you add them\n411.539s: together it it drops significantly to uh\n415.34s: 0.07 for the r squared I wanted to see\n418.74s: how this compared to if we actually\n420.78s: shrink the region down further so I'm\n423.6s: just going to be going over the US for\n425.16s: this example the Northwest and the or\n427.259s: sorry Northeast and southwest\n429.36s: uh so we have this one here on the left\n432.24s: we have rain rate for the Southwest then\n434.4s: we do the rain rate for the Northeast\n435.72s: and then I also want to compare that to\n437.34s: the global rain rate itself because uh\n439.44s: uh I only chose rain rate for this uh\n441.18s: portion because the snow and the total\n443.58s: precipitation in that previous slide\n445.139s: they were a lot they did perform a lot\n446.88s: worse so I wanted to introduce just see\n448.919s: on the one that actually was performing\n450.599s: well how that uh performed just to not\n452.699s: overwhelm me with a ton of results and\n454.74s: what we can see is that for the\n456.599s: Southwest it actually the r squared um\n459.539s: decreases a ton but for the Northeast\n462.419s: it's not it's not terrible it decreases\n464.46s: a lot but compared to that Global rain\n466.38s: rate it is still lower and so what I was\n469.02s: uh and so\n470.88s: um\n471.599s: basically\n472.979s: um in summary\n474.419s: what I found was that the parallel\n476.58s: Computing function of the actually\n478.08s: boosting decision trees does make it\n479.699s: easier to implement you don't know I\n481.319s: have to know a lot about the dimensions\n482.88s: of the data or a lot of the um into\n485.58s: relationships\n487.259s: um but there could be a lot more\n489.0s: Improvement for representing the\n491.34s: variability\n492.78s: um but it does lend well to inclusion\n494.88s: and with other Ensemble models so a lot\n497.28s: of other papers use this in addition to\n499.199s: other uh either statistical methods or\n501.479s: models to further improve the\n503.94s: performance of prediction\n505.86s: and its ability to learn from weak\n507.96s: Learners\n509.039s: um again has an ability to uh help with\n512.399s: with unknown variables so like when you\n514.02s: saw in the previous slide here where we\n516.419s: have\n517.14s: um\n517.86s: the the snow snow rate um I believe that\n521.039s: the reason why the snow rate was a lot\n523.38s: lower was because they were more\n524.7s: complicated\n525.839s: um processes that happen some great\n527.519s: processes that happen in relation to\n528.899s: snow especially with that small\n530.76s: threshold between freezing and liquid\n532.62s: water that would uh impact snow whereas\n535.38s: rain is maybe a little bit easier to\n537.48s: predict just because uh there's less\n540.24s: um less of the background\n542.519s: um processes that are going to make it\n544.44s: so variable\n547.44s: all right\n549.24s: and then\n550.98s: so for some of my next steps I thought\n553.74s: that it would be interesting to use that\n555.54s: actually moves with an ensemble method\n558.0s: and I also thought it would be good to\n560.399s: work with smaller regions but then use\n562.98s: the information around and so setting up\n565.62s: a grid where the the test uh data is the\n568.38s: center but then adding a grid where you\n570.18s: have the lag variables from all the\n571.62s: outside variables because that is\n573.3s: basically the first little geography\n575.399s: um the the weather will be in one area\n578.64s: will be impacted by the previous weather\n580.74s: in the surrounding areas and so if we\n583.019s: can do that over a certain grid you\n585.0s: might be able to get a better\n585.839s: information over time and I also wanted\n589.019s: to uh ensure that the results could be\n591.24s: repeated for the remaining output\n592.62s: variables and if uh we could use Pearson\n595.56s: correlation in the first place which\n597.66s: would have been a great idea I might\n598.86s: have been able to figure out if there\n600.24s: were additional variables that I could\n602.1s: have included or some of the variables\n603.48s: that I included weren't even really\n605.279s: necessary\n609.12s: thank you\n616.62s: hi Mark thank you for the great\n618.6s: presentation uh I just have one\n622.74s: uh one thing to mention so previously\n626.459s: when we do the meeting you train is the\n630.36s: extra boost using normalized data uh\n633.839s: standard normalized data and it was\n637.38s: the results was very good were very good\n639.48s: and the R square was like 0.7 around 0.7\n643.04s: and somehow when you convert the unit of\n646.98s: the presentation I can see especially\n649.56s: for the total presentation that square\n651.36s: is very low and I expect X2 boosted to\n655.079s: do better than than than this yeah I\n658.74s: think it's also because of the the the\n660.62s: difference between the rain rate and the\n663.24s: snow rate because it is the liquid\n664.8s: equivalent the liquid equivalent of snow\n666.779s: ends up being like multiple magnitudes\n669.6s: lower than the rain rate and so it's\n672.42s: trying to predict extremely low values\n674.399s: at the same time that it's it's trying\n676.68s: to predict High values and so I believe\n678.18s: that added to some of the issues there\n680.64s: and so I think if we would actually if\n682.86s: in total precipitation if we could maybe\n684.6s: add some of the snow and rain as an\n687.18s: input variable that might help it with\n689.16s: the prediction of total\n695.04s: are there any questions online\n704.88s: I don't think so\n706.74s: um yeah okay thank you again Mark and we\n710.04s: have\n711.18s: um"
    },
    {
        "class": "YouTubeVideo",
        "title": "Landscape Assessment of AI for Climate + Nature with Geneva List",
        "videoId": "xaULNEL8yJo",
        "url": "https://www.youtube.com/watch?v=xaULNEL8yJo",
        "publishedAt": "2024-09-12T19:29:35Z",
        "transcript": "4.799s: okay welcome everybody thank you for\n6.799s: joining us today I'm happy to introduce\n10.2s: Geneva lift um who is a senior staff\n14.48s: associate at the Columbia University\n17.359s: climate School jointly appointed between\n20.68s: leap and the national Center for\n23.16s: disaster\n24.76s: preparedness for over a decade Geneva\n27.08s: has worked at the intersection of\n28.599s: climate and International development at\n30.679s: the international Research Institute for\n33.12s: climate and Society the interamerican\n35.399s: Development Bank Global Affairs Canada\n37.76s: and the International Development\n39.16s: Research Center Geneva holds a master's\n41.6s: degree from Mill University in geography\n43.68s: and development studies and has\n45.239s: published her research in climate risk\n46.92s: management climate and development and\n49.079s: natural hazards and we are excited to\n51.8s: hear her talk today thanks\n58.76s: Gena hey great thank you so much so um\n63.199s: because with my bio I am a social\n65.68s: scientist and I've been working on\n67.2s: sustainable development for my career so\n69.439s: this is going to be a little different\n71.32s: than some of the other talks um it is\n73.72s: geared towards a general audience uh but\n76.36s: please feel free to ask some questions\n78.92s: and uh provide any\n81.32s: commentary so my objective today is to\n84.6s: give you a highlevel overview of a\n86.84s: landscape assessment uh report of AI for\n89.68s: cl climate and nature I wrote this uh\n92.72s: under Pierre jeanine's leadership so\n94.6s: he's the director here at leap and it\n96.36s: was a collaboration between the Columbia\n98.24s: climate School uh and the engineering\n100.759s: school and we wrote it in collaboration\n103.92s: with the University at uh Albany State\n106.92s: University of New York and\n108.799s: SRI uh this landscape assessment report\n111.84s: was commissioned by and produced in\n113.68s: collaboration with the Bezos Earth fund\n116.399s: and the fund recently launched a $100\n119.039s: million AI for climate nature Grand\n122.079s: Challenge so the purpose of this report\n124.28s: was to help inform and guide some of\n126.88s: those philanthropic decisions the the\n129.56s: objective of the report was to identify\n132.239s: the current use cases of AI in climate\n135.04s: and nature and to tease out some of the\n137.599s: emerging opportunities at the Nexus of\n139.599s: those two\n140.519s: Fields so uh we also did a scan I want\n145.04s: to let you know that if you want to have\n147.16s: access to this report it's a really\n148.8s: useful resource um you can scan the QR\n151.84s: code I think I have it again at the end\n154.16s: um but happy to share the link with you\n156.64s: we also created a key stakeholder and\n159.159s: initiative database and I think there's\n161.239s: about 300 uh different stakeholders in\n163.92s: here also on that URL you can find so\n167.04s: you can scan through sectoral area or\n170.2s: location to see who is doing what in\n172.68s: this\n174.0s: field so my presentation H has a couple\n177.64s: goals uh it's going to be a highle\n180.56s: overview of all the different ways that\n182.36s: AI is being applied and I also want to\n184.64s: be a little provocative um I'm a social\n186.799s: scientist I am not an AI specialist I'm\n189.12s: not even a c computer scientist or a\n191.239s: data scientist um I'm a development\n194.0s: practitioner so I want to make you think\n195.959s: outside of the box and up until about a\n198.239s: year ago AI was not so much on my radar\n201.0s: of course climate data for\n202.879s: decision-making was what I had spent my\n204.68s: career thinking about but I I'm trying\n206.72s: to push the boundaries here a little bit\n208.36s: and get you all to think a little\n209.799s: outside of the box so I'll start by\n212.439s: presenting uh the the findings from the\n214.68s: landscape assessment or report some of\n216.4s: the key Concepts I'll go over several\n218.959s: use cases um across several sectoral\n222.439s: applications demonstrating how it can be\n224.56s: applied and is currently being applied\n227.12s: and then I want to think about the key\n228.799s: considerations to ensure that AI does\n231.239s: more good than harm in this world I want\n234.079s: to look at the opportunities and\n235.519s: enablers for transformative change and\n238.12s: end uh with some closing remarks\n240.76s: I also want to take a moment to identify\n243.48s: my positionality and where we are we are\n246.12s: on unseated ancestral territory um and\n250.12s: homelands of the canari Moi lunp and\n253.079s: waper people I myself am a Canadian\n256.959s: settler uh born on treaty for territory\n259.639s: in\n261.96s: Saskatchewan so why are we\n265.639s: here um this is not a surprise to anyone\n268.32s: in this room we we are facing dual\n271.039s: crises of climate change and\n272.639s: biodiversity loss we know the climate is\n275.52s: changing last week we broke two records\n278.4s: we are witnessing massive floods\n280.759s: wildfires and hot tub ocean temperatures\n284.199s: scientists believe that we are in the\n286.0s: middle of a mass extinction event and of\n289.12s: the nine planetary boundaries that keep\n291.24s: this Earth livable we've already\n292.68s: breached six of them clearly\n295.919s: transformative systems oriented changes\n298.84s: are needed\n300.759s: can you guys all hear me okay my my mic\n303.12s: just changed so okay good so AI does\n307.56s: offer a way to better understand these\n309.52s: vital and complex problems and if\n312.199s: applied strategically it can help us to\n314.24s: dramatically accelerate the pace of\n316.08s: solutions to our world's most\n317.639s: intractable\n320.199s: problems it's helpful when we um want to\n324.039s: kind of communicate what AI can do in\n326.12s: this space to think about it in terms of\n328.84s: a few key capabilities what can it help\n331.52s: to unlock so sort of at its core AI has\n335.479s: an ability an unprecedented ability to\n338.6s: process and digest vast quantities of\n340.479s: data from various sources so it can\n343.52s: merge images from cameras drones remote\n346.759s: sensing satellite imagery sensor data\n349.479s: and microphones it can sort of it's It's\n352.52s: unprecedented and humans cannot do this\n354.84s: on alone what this enables is um\n358.919s: automated monitoring and so through the\n361.88s: use of variety of different sensitives\n364.24s: AI can be used to to monitor\n366.16s: environmental changes and their impacts\n368.479s: near real time this can help to inform\n371.759s: decision-making with useful applications\n374.44s: from monitoring\n376.36s: deforestation monitoring uh species\n379.44s: distribution and even\n382.16s: agriculture AI can also help to optimize\n384.88s: Solutions so being able to sift through\n387.639s: large volumes of data and exam\n389.84s: constraints and Alternatives it can find\n392.319s: Optimal or close to Optimal Solutions\n395.0s: we're seeing this on the manufacturing\n397.199s: floor all the way to the electrical grid\n400.479s: and even applied in traffic\n402.759s: management AI can also build predictive\n405.16s: models and forecasts you all may have\n406.96s: heard this recently being here at leap\n410.08s: when it's trained on abundant data it\n411.919s: can effectively and accurately predict\n414.12s: future outcomes this ranges from weather\n417.16s: predictions to crop yields all the way\n419.36s: to carbon SNS and\n421.28s: fluxes AI can also develop realistic\n424.36s: simulations of the real world known as\n426.759s: digital twins so digital twins are\n429.52s: sophisticated and accurate computer\n431.879s: simulations of an object of a process or\n434.759s: a system AI accelerated digital twins\n438.28s: can allow scientists and stakeholders to\n440.919s: experiment without risk as they explore\n443.28s: the impact of certain actions on\n445.84s: environments we see this being applied\n448.28s: currently from the build building scale\n450.84s: to Coral Reef ecosystems all the way to\n454.199s: the global climate systems digital\n456.28s: digital twin earth also AI uh in this\n460.16s: climate and nature field can help to\n462.24s: accelerate new discoveries and uh sort\n465.36s: of Aid scientific experimentation it's\n468.599s: already uncovering novel Solutions\n470.68s: leveraging its unique ability to process\n473.24s: and digest vast amounts of data across\n475.72s: disciplines and its ability to learn\n478.08s: nonlinear and integrate relationships\n480.24s: between data AI is currently driving\n483.28s: Innovation across a range of Innovations\n486.28s: from uh lower carbon cement um cement\n491.24s: that can ad absorb carbon uh to new\n495.159s: battery designs and also to even new\n498.159s: protein food\n499.919s: sources so with that sort of overview um\n503.039s: thinking about those ways that it can be\n504.72s: applied to these problems I'm going to\n507.24s: provide you several use cases um across\n510.08s: many different Industries this is a\n512.0s: rapidly changing and emerging field so\n514.039s: this is going to be a very highlevel\n517.519s: overview all right so I'm going to start\n519.599s: with food and agriculture that's where\n522.24s: I've worked most of my career so uh AI\n526.519s: in this space is being applied primarily\n528.88s: to Precision agriculture so with the use\n532.6s: of many on the ground sensors uh weather\n536.6s: monitoring unmanned aerial vehicles\n539.44s: remote sensing images smartphones and um\n542.68s: sensors in the soil AI is able to help\n546.76s: improve agricultural decision-making on\n549.2s: the ground to sort of maximize outputs\n551.839s: and maximize yields it's also being used\n555.519s: uh for Pest and disease detection and\n557.68s: I'm really excited to show you an\n559.04s: example in the next\n560.72s: slide\n562.519s: and being able to leverage Ai and its\n565.399s: monitoring capabilities it can help to\n568.12s: improve the timing of\n569.959s: fertilization irrigation uh when to\n572.88s: apply fungicides herbicides insecticides\n575.68s: and help you make decisions on when to\n577.48s: plant so and harvest plant and\n580.839s: harvest uh AI is also being uh utilized\n584.24s: to help predict crop yield based on\n586.2s: location and weather condition to help\n589.04s: inform further decisions about optimal\n590.92s: farming strategies and also to assess\n593.079s: crop suitability to a certain to certain\n595.36s: areas we also see AI being applied in\n597.839s: the food system more broadly it can be\n600.2s: used to better on forecast food Demand\n603.839s: by looking at historical sales data\n605.959s: weather patterns socioeconomic\n608.519s: indicators and it can help to adjust\n611.2s: these\n611.959s: forecasts um and reduce the supply so\n616.399s: that we're not\n617.48s: overproducing and we're not wasting food\n619.959s: this can ultimately lead to a more\n621.44s: efficient supply\n623.279s: chain uh with the supply chain AI\n626.2s: sensors can be used to Monitor and\n628.079s: adjust conditions Within storage\n629.839s: facilities there's a huge amount of food\n632.12s: waste that occurs um from Farm to\n635.6s: Consumer especially in the developing\n637.68s: world and so if we can better under\n641.16s: understand the conditions for storage\n642.839s: and transportation we can improve the\n644.88s: life cycle of perishable goods and\n646.48s: reduce waste and energy consumption this\n648.6s: is critical also to reduce the food\n650.32s: insecurity around the world AI has been\n653.2s: applied for genomics so coming up with\n656.56s: new um new varieties uh with different\n660.44s: flavor profiles nutrition and resilience\n663.8s: they're trying to um embed drought\n666.12s: tolerance or flood tolerance into new\n668.32s: varieties using Ai and it's also\n671.959s: developing and creating new protein\n673.68s: sources so it's not just the the lab\n676.44s: grown meat but even identifying new\n679.279s: proteins that from from legumes that can\n682.36s: be used for vegan cheeses this is also\n685.48s: one of the areas that the Bezos Earth\n686.92s: fund is is is supporting with its\n688.48s: hundred million Grand we also see\n691.12s: applications in livestock so sensor data\n693.959s: can help to detect disease and optimize\n696.88s: food and animal well-being so really\n699.92s: applications across the\n703.0s: board this is an example of how AI back\n706.56s: solutions for agriculture can be used\n708.079s: for decision support so this is using uh\n710.839s: cotton so a non-food uh crop and there's\n714.839s: an input where it detects whether or not\n718.279s: there is a sign significant amount of a\n720.44s: pest if it identifies that the action\n723.56s: threshold has been breached on this\n725.48s: camera trap it can provide\n727.36s: recommendations to Farmers and this is\n729.68s: taking place I believe in India so to\n732.0s: small holder farmers and help to provide\n734.279s: them with um an indication whether they\n736.199s: should act whether they should spray\n737.88s: pesticides or whether they should wait\n739.48s: and watch so I think these are really\n741.279s: cool local um small scale applications\n744.399s: of AI that can hopefully make a big\n745.959s: difference for small holder\n747.8s: Farmers now I'm going to turn to Land\n750.279s: Management so AI is used to measure\n753.24s: carbon and biomass it can monitor land\n756.32s: use change and land cover change it can\n758.839s: monitor ecosystem health and also help\n761.68s: to um to implement and evaluate\n764.24s: restoration and conservation initiatives\n767.279s: currently farming uh forestry agencies\n769.88s: are already using AI augmented mapping\n772.12s: tools to support conservation and\n774.279s: governance so this is an example from uh\n776.92s: one of our partners impact Observatory\n778.839s: who uses deep learning to transform\n780.76s: satellite imagery into land cover maps\n783.6s: to monitor Global uh to change across\n786.72s: the\n789.32s: globe AI is also being used for carbon\n792.56s: accounting um so it can help to improve\n795.16s: the monitoring of carbon sequestration\n797.0s: efforts and the Integrity of the carbon\n799.44s: Market which is critical for climate\n801.12s: change mitigation anytime you see Net\n803.72s: Zero they're really relying on offsets\n806.88s: and some recent Studies have come out\n808.6s: that said offsets really aren't working\n811.48s: so it's really important AI can validate\n813.48s: and enhance the monitoring reporting and\n815.24s: verification for carbon markets to avoid\n817.44s: over accrediting or inaccuracies to\n820.079s: ultimately reduce emissions and enable\n823.0s: more transparent validation so an\n825.639s: example is to validate reforestation\n828.04s: efforts for the voluntary carbon Market\n830.519s: I've also included a screenshot um from\n833.36s: meth methane watch which is an AI backed\n837.44s: um tool and Technology that can track\n839.839s: methane emissions across the\n842.72s: globe one of my other favorite use cases\n845.88s: is for conservation in species so AI is\n849.32s: being used for the real-time monitoring\n850.959s: of wildlife populations to help inform\n853.56s: Wildlife Conservation strategies so this\n856.079s: is primarily taking place through\n857.759s: computer vision and bioacoustics so\n860.519s: through microphones uh here's an example\n863.16s: from conservation xlb demonstrating what\n866.44s: the computer vision training looks like\n868.44s: when they're trying to track um species\n871.24s: of cheetah of leopards and the the\n874.16s: example to the left is Google tidle who\n876.72s: is working to um improve ocean\n879.44s: conservation through sustainable\n882.519s: Fisheries um bioacoustics is really\n886.6s: fascinating and a lot of times you can't\n888.839s: necessarily see the species that you're\n890.88s: tracking but you can hear them and um\n893.8s: there are applications utilizing\n896.16s: microphones to help understand how\n898.639s: degrad lands formally degraded lands are\n901.079s: recovering based on the diversity of\n904.04s: bird species that have come in come into\n906.12s: the area we also see a ton of\n908.6s: applications in oceans and coral reefs\n911.24s: using these\n913.199s: Technologies so another use case for\n915.88s: bioacoustics um and I had a video but I\n918.199s: won't be able to show it but it's uh\n920.759s: it's to help monitor Vector born\n923.04s: diseases such as malaria with\n925.399s: smartphones so there's two organizations\n928.0s: humbug sensor and Buzz out of um Oxford\n931.72s: and Stanford respectively who are using\n934.88s: machine learning to crowdsource acoustic\n937.759s: surveillance of mosquitoes so basically\n940.88s: they are asking for local residents\n944.04s: citizen scientists to record the sounds\n947.399s: of the mosquitoes and send them into\n950.04s: this app who can basically Shazam\n953.56s: mosquito sounds to identify which\n955.639s: species are going to be present we also\n957.959s: know that in a change climate the vector\n960.44s: of pests and diseases are changing and\n963.0s: so we can expect to see more um Vector\n965.88s: born diseases in new areas so this type\n968.12s: of technology is really inform is really\n971.16s: Innovative and you know one of the\n973.0s: things I like so much is citizen science\n974.8s: is a Hu is is an important part of the\n976.88s: AI for climate and nature landscape I\n979.72s: love that we can Empower citizens\n981.92s: without having this massive high\n983.92s: technology lift just with their\n986.759s: smartphones so now I'm going to shift to\n988.92s: renewable energy this is the third uh\n991.399s: area that the Bezos Earth fund is\n993.0s: investing in uh with their $100 million\n995.88s: Grant and um I want to showcase\n999.399s: renewable energy integration so with the\n1001.92s: move to Renewables the power grid is\n1003.8s: becoming more complex renewable energy\n1006.639s: sources are unevenly unevenly\n1008.92s: distributed this is geographically and\n1010.92s: temporally and outputs outputs depend on\n1013.6s: variable environmental conditions so AI\n1016.319s: can enhance the coordination storage use\n1019.279s: and distribution of Renewable Power more\n1021.639s: efficiently and effectively than\n1023.12s: traditional systems we see it being\n1025.559s: applied in smart grids so forecasting\n1028.6s: both renewable and electricity demand in\n1032.12s: planning so optimizing renewable uh\n1035.0s: layout location and production it can\n1038.4s: also optimize grid operations so\n1040.4s: maximizing the output from solar panels\n1042.64s: and WID turbines using weather\n1044.559s: forecasting and it can improve uh\n1047.0s: improve maintenance us digital twins to\n1050.16s: help identify early faults we also know\n1052.72s: that Faults Are One of the causes of\n1055.16s: devastating wildfires we've we've seen\n1057.72s: proliferate so this is really important\n1060.6s: work here's a a an example from the from\n1064.0s: Deep Mind um predicting uh output of\n1069.24s: wind farms and based on weather and then\n1072.559s: identifying the the actual uh the actual\n1075.2s: output so it it's it's being utilized uh\n1077.96s: to improve renewable energy\n1081.88s: integration now for the built\n1083.76s: environment so AI can be used for SM\n1087.44s: smart buildings and\n1089.52s: cities this is including optimizing\n1092.36s: Energy Efficiency for heating ven\n1094.919s: ventilation and air conditioning systems\n1097.039s: this is a huge contributor to greenhouse\n1098.919s: gas emissions in the world uh it can be\n1101.799s: used with digital twins of buildings so\n1103.76s: looking at HVAC systems the thermal\n1106.0s: properties of Windows and energy use in\n1108.48s: order to enable retrofitting and\n1110.799s: optimization to reduce carbon emissions\n1113.44s: it can also Monitor and optimize Waste\n1115.679s: Management processes in cities and water\n1118.08s: utilities I think these are two really\n1119.919s: fascinating examples um there's a\n1122.48s: there's a couple startups that are\n1124.36s: utilizing computer vision in waste\n1127.28s: facility plants to help improve um the\n1131.0s: the recycling and and waste reduction um\n1134.28s: in different cities and also with water\n1136.159s: utilities AI is being used to look for\n1139.039s: leaks in Municipal Water Systems and\n1141.44s: help to for predictive\n1143.88s: maintenance AI is also being used in\n1146.12s: Urban Design to improve Energy\n1148.12s: Efficiency of cement production I have\n1150.76s: this bolded because cement production\n1153.32s: contributes 8% of of global carbon\n1156.76s: emissions which is quite shocking so\n1159.2s: getting that uh getting that right can\n1161.24s: have a huge impact in the world and\n1163.679s: there's a lot of different AI backed\n1165.2s: initiatives that are actually reducing\n1166.76s: the carbon intensity of cement and also\n1169.44s: improving the circularity of other um\n1171.799s: building construction materials it can\n1174.44s: also be leveraged to design and optimize\n1176.24s: Urban layouts and tree placement in\n1178.08s: order to reduce heat stress this photo\n1180.64s: is an example from tree folio NYC that\n1183.48s: has created a digital twin of New York's\n1186.4s: tree\n1188.799s: canopy heat stress by the way is is not\n1192.96s: equally felt across the cities it's t\n1195.88s: tends to be um occupied in in lower\n1198.2s: income areas so it's really an important\n1200.039s: thing to focus on uh Transportation so\n1203.28s: moving right along AI can reduce tra\n1205.679s: reducing traffic is also a huge priority\n1207.679s: to reduce carbon emissions AI is being\n1210.36s: used already to optimize Roots can\n1213.24s: leverage satellite data to to map The\n1215.559s: Roots and networks it can be used to\n1217.919s: reduce congestion and cut weight times\n1220.72s: and even can train change traffic\n1223.0s: signals real time uh or redirect drivers\n1226.559s: to less to less occupied roadways uh\n1229.0s: Google has a project called green light\n1231.52s: that is aiming to reduce the starting\n1234.679s: and stopping of cars in intersections\n1237.2s: where pollution I believe is 29 times\n1239.32s: higher than in other\n1241.28s: areas we're also seeing AI used more and\n1244.32s: more for electric vehicles so this can\n1246.039s: be used to improve existing\n1248.12s: infrastructure but also to optimize the\n1250.28s: placement of new EV charging stations\n1253.0s: based on on roots and enhancing the\n1256.36s: capacity of batteries as I mentioned it\n1258.799s: can accelerate new discoveries and even\n1261.679s: for this um in the to improve renewable\n1265.64s: energy integration into the grid it is\n1268.679s: being utilized to improve and can be\n1270.919s: utilized to improve vehicle to grid\n1272.64s: optimization so giving power back to the\n1275.96s: grid through plugged in cars during\n1278.48s: times of peak\n1279.679s: demand autonomous vehicles of course\n1282.039s: this won't come as a surprise um AI is\n1284.64s: being utilized to optimize Roots\n1286.32s: optimize and improve autonomous public\n1288.72s: Transit which could be a really\n1290.6s: interesting use of of AVS uh AVS\n1294.039s: currently pose the risk of potentially\n1296.159s: increasing traffic on road wage which of\n1298.48s: course would be a perverse incentive um\n1301.24s: but yeah there could be opportunities to\n1303.32s: have more autonomous public transit and\n1305.039s: we're even seeing modular rail transport\n1308.96s: um electrified modular rail transport um\n1312.44s: that is being autonomously driven by at\n1315.32s: least one startup called parallel\n1316.84s: systems which was founded by a bunch of\n1318.96s: X SpaceX Engineers so a lot of different\n1321.919s: use cases in in\n1324.72s: transportation in industry in\n1327.88s: manufacturing we often see it being\n1329.96s: applied to four key areas so process\n1333.159s: optimization this is basically making\n1336.2s: things more efficient so industrial\n1338.96s: actors save money by reducing the use of\n1343.08s: resources so it can have the benefit of\n1345.88s: reducing material use uh reducing waste\n1349.96s: lowering energy consumption costs and\n1353.0s: there are tons of private sector actors\n1355.44s: in this space leveraging AI basically\n1357.799s: for optimization it can also contribute\n1360.32s: to Quality Control support with\n1362.24s: predictive maintenance and um is\n1365.12s: involved in the human robot\n1366.48s: collaboration and\n1367.799s: ergonomics in heavy industry AI is\n1371.12s: playing an important role both in\n1373.4s: optimizing um existing production and\n1376.4s: also discovering new materials for\n1378.559s: placement so as I'd mentioned some\n1380.44s: Innovations in cement also we see some\n1383.159s: Innovations in steel\n1385.88s: making now for the other part that I'm\n1388.919s: sure will be a bit more exciting for you\n1390.799s: folks at least I hope so\n1393.48s: um use case of climate and weather\n1396.159s: forecasting I'm I assume this is why you\n1398.32s: are all here we know that AI based\n1401.679s: weather forecasting is now on par or\n1404.039s: even better thereare I say than\n1406.039s: traditional physics-based forecasts for\n1407.88s: weather\n1409.039s: Google's graph cast came up with a\n1411.08s: 10-day weather prediction that had\n1413.24s: unprecedented accuracy in under one\n1415.4s: minute and could be run on a desktop\n1418.0s: computer AI can also be used for\n1420.96s: monitoring weather events and extreme\n1423.4s: events so we can we're seeing it\n1425.84s: utilized in monitoring floods through\n1428.32s: satellite imagery remote sensing this\n1430.559s: can also be used to support parametric\n1432.799s: insurance so to reduce the risk of of\n1435.2s: folks suffering from from those extreme\n1437.0s: events and also why wildfires which we\n1439.799s: see a uh there's a few different use\n1441.48s: cases which is very exciting um one is\n1444.36s: alert California which is an AI platform\n1446.72s: that provides early Wildfire\n1448.919s: confirmation and actionable real-time\n1451.76s: data to rapidly scale fire\n1454.0s: resources um there's AI that Cal Fire is\n1457.679s: actively utilizing AI to improve its\n1461.159s: monitoring and response and Recovery\n1463.72s: operations so this is like a real live\n1465.799s: use case that I think is very exciting\n1467.72s: because of of course right now we're\n1469.0s: dealing with the fifth largest wildfire\n1471.64s: in California's history I believe not to\n1474.88s: be\n1475.799s: Downer um and climate predictions and\n1478.96s: projections so of course we see that\n1480.88s: this is an emerging field there are a\n1483.24s: lot of challenges but it is increasing\n1485.44s: the speed and accuracy so we're here\n1488.08s: leap is an example Schmid Futures and M2\n1490.919s: lines as\n1492.039s: well some of the challenges when we\n1494.44s: think about using AI for climate\n1496.559s: predictions and Productions is\n1499.2s: really the resolution of global climate\n1501.48s: models and if they can actually be\n1503.88s: useful for local adaptation are they\n1506.559s: granular enough that decision makers can\n1508.72s: act on these models and also how do we\n1511.64s: deal with uncertainty how are we\n1513.799s: quantifying and communicating\n1515.84s: uncertainty if decision makers and\n1518.159s: policy leaders are going to be utilizing\n1520.44s: this information to make\n1524.72s: decisions an example that you may have\n1527.12s: heard in the hallways here um but also\n1529.919s: that we have in our report\n1533.2s: is we we reported on a NASA just um\n1538.88s: question I guess a research question is\n1541.52s: there an opportunity for large language\n1543.24s: models in the co-production of of\n1545.399s: climate impacts of understanding climate\n1547.36s: impacts so is it possible um as a future\n1550.36s: use of AI that we could create a chat\n1552.64s: GPT type query that could um put out\n1557.36s: climate projections and climate\n1558.76s: predictions sort of enabling the\n1560.84s: accessibility of this type of Science\n1562.919s: and data for decision makers who might\n1565.12s: not have this the science the data\n1567.48s: background so lots to explore in terms\n1569.88s: of the\n1571.08s: future and then where I want to end\n1573.84s: we've talked about monitoring we've\n1575.399s: talked about predictions um what happens\n1578.0s: when there is a disaster well AI can\n1580.48s: help to identify communities more likely\n1582.679s: to incur damage from an impending\n1585.559s: disaster event it can also help to to\n1588.72s: expedite damage assessment so utilizing\n1592.08s: um drone Technologies for example\n1594.36s: satellite imagery um and it can identify\n1597.279s: the potential for cascading events and\n1599.72s: better coordinate response efforts so\n1602.08s: here I've given an example of um I guess\n1605.12s: it was a competition called xvw 2 which\n1607.919s: sought to uh basically sought to elicit\n1612.399s: code uh to see who could better identify\n1615.679s: and categorize the severity of of damage\n1617.84s: to build buildings and infrastructure in\n1620.159s: disaster affected areas and it was found\n1622.88s: that through this technology and\n1624.2s: utilizing AI it could it was able to do\n1626.52s: so significantly faster than\n1628.039s: conventional me methods and this was\n1630.24s: actually utilized in response efforts in\n1633.24s: Turkey uh after one of a recent\n1637.24s: earthquake\n1638.799s: so there those are use cases does anyone\n1642.279s: have any question I mean I know this was\n1644.12s: a very highle overview and uh a lot of\n1647.559s: different material any questions before\n1649.2s: I move on to some of the more\n1652.559s: philosophical exploration of this\n1655.52s: talk\n1660.32s: yeah\n1662.039s: sure um I think earlier in the\n1664.6s: presentation you talked about how there\n1666.039s: were like nine boundaries in nature\n1669.0s: something what does that what are the\n1671.799s: are the N I can send you if you look at\n1674.76s: the nine planetary boundaries it's like\n1677.519s: pollution carbon\n1680.72s: Cycles like plastic and ocean that kind\n1683.679s: of like geochemistry um spey e like\n1688.799s: stability I can send you those but it's\n1690.6s: the planetary boundaries so nine\n1692.919s: planetary boundaries research yeah yeah\n1698.559s: very I wonder could you comment on like\n1701.76s: are these kind of proof of concept use\n1704.679s: cases are they like really disrupting\n1707.039s: these industries or\n1709.6s: so that's a a question we've been asked\n1711.399s: many times and because we weren't really\n1714.159s: able to quantify it I think that it is\n1717.12s: it is\n1718.0s: disruptive some are still needing to be\n1722.12s: scaled and and some work in some\n1724.84s: contexts better than others and so I'll\n1727.2s: I'll I'll kind of come back to that um\n1730.12s: but there yeah some areas are more ncent\n1732.96s: but you're already seeing like yeah the\n1735.44s: the wealthy folks who can manage AI\n1737.279s: Precision agriculture\n1738.76s: got it optimization on Industries got it\n1741.36s: you know so it it kind of does vary but\n1744.08s: there's a lot of details in the report\n1745.48s: if you to take\n1746.919s: it and any\n1753.32s: others yes this this is like a fully\n1756.279s: form question but curious if you have\n1758.279s: any opinions maybe like more on the\n1759.84s: social science side on like how you see\n1762.519s: this breaking down like based on like\n1765.399s: different stakeholders cuz you know like\n1767.159s: you mentioned like Urban like building\n1768.799s: new neighborhoods to me that seems more\n1770.36s: like a you know if someone comes up with\n1772.44s: a really good way to build neighborhoods\n1773.76s: then it's like getting policy you're\n1775.44s: like neighborhood councils to agree yeah\n1777.6s: uh but if it's like you know concrete\n1779.36s: then it's about getting like companies\n1781.159s: who produce concrete to adopt those\n1782.679s: things so I'm curious whether you see\n1784.159s: like significant differences between the\n1786.6s: like like in terms of adoption and stuff\n1789.44s: like whether there's some different\n1790.799s: breakdown based on who the like AI\n1794.039s: Innovation or data thing is like\n1795.72s: relevant for cuz yeah the actual clim\n1798.2s: solution needs to be implemented in like\n1799.559s: the physical world right so monitoring\n1801.24s: just tells you what you like should do\n1802.919s: so are there like different challenges\n1804.36s: for you know actually doing whatever the\n1806.76s: like I mean there's hug there's huge\n1808.679s: challenges and this is all new like\n1811.2s: every time I submitted a draft on this\n1813.2s: report I had to redo my chapter because\n1815.399s: things would change it was painful but\n1818.039s: um yeah we'll see there's a lot of\n1820.519s: hurdles utilizing just full AI uh\n1823.559s: especially in a policy context because\n1825.32s: of trust and privacy concerns so like\n1828.48s: that's I think where we see a lot of\n1829.76s: potential but also a lot of stalled\n1831.799s: potential because nobody wants\n1833.88s: everything to be monitored and certainly\n1835.399s: no one wants their AC turned off\n1836.96s: automatically by an AI bot when it gets\n1839.12s: too hot right um I think private sector\n1842.72s: anyone who's set to profit from this and\n1846.36s: has the resources I think we will see\n1848.64s: more adoption um but yeah it's it's an\n1852.84s: emerging field so I think it varies\n1855.639s: right now but I I do think once we can\n1857.48s: get some govern structures in place to\n1859.399s: build the trust of the people will start\n1861.72s: to see get ramp up and as long as it's\n1863.96s: financially\n1865.799s: viable yeah I think when was very much\n1868.2s: sort of aligned with this and you've\n1869.44s: answered part of it I think I I I think\n1872.039s: do can you like draw a straight line\n1874.039s: basically between these sort of\n1875.159s: vertically integrated sorry Industries\n1877.96s: like like something like the the um\n1880.279s: agriculture where there's basically\n1882.039s: someone who has control over both the\n1884.24s: how to like manage the ground versus\n1885.96s: sort of these public cases where I I\n1888.36s: think I agree with Sammy I mean like you\n1890.559s: can optimize the lights all you want in\n1892.72s: New York they will still just run into\n1894.84s: the box and stand there so like what do\n1896.639s: you do like is it not like are there\n1898.72s: more sort of low Tech efficient ways to\n1902.399s: that you weigh against sort of the AI\n1905.48s: I'm gonna that's a good segue if you\n1907.639s: don't mind me\n1909.76s: yeah so um I want to come back to this\n1913.039s: and so now what I'm really passionate\n1915.48s: about and what you know is people are\n1917.36s: asking it so it's not like this is this\n1919.08s: is new but it was a big focus in our\n1920.88s: report to make sure that we weren't just\n1922.559s: saying hey there's these shiny use cases\n1924.919s: everybody and Jeff Bezos put your money\n1927.24s: into\n1928.2s: AI um and this is why I also work in the\n1931.679s: University because I get to ask these\n1933.08s: questions and I don't have to worry\n1934.399s: about my boss being mad about it so um I\n1937.76s: want to talk about ethics Equity\n1939.76s: inclusion governance and\n1941.76s: sustainability so many discussions about\n1944.799s: the responsible use of AI to address\n1947.36s: societal problems consider issues of\n1950.0s: Ethics primarily we see this revolving\n1952.76s: around privacy data privacy intellectual\n1956.24s: property rights transparency of the\n1958.72s: algorithm so understanding how these\n1960.72s: decisions or these outputs are being\n1962.559s: made also accountability if somebody is\n1965.44s: utilizing this or putting a policy in\n1967.6s: place based on an AI recommendation\n1970.0s: who's ultimately responsible and also\n1972.399s: trust and trustworthiness do we want AI\n1975.24s: making all the decisions in our lives\n1976.84s: for us when we think about this from\n1979.679s: nature and climate perspectives we also\n1982.159s: need to zoom out and consider that there\n1984.12s: are ethical considerations on the\n1986.0s: environmental impact of AI\n1988.399s: Technologies and AI if it's being used\n1991.44s: to regulate human interventions what's\n1994.44s: the ethics behind that what if it's\n1996.519s: supporting\n1998.08s: geoengineering that's not a neutral\n1999.96s: undertaking to think\n2001.48s: about so how do we evaluate the ethical\n2004.36s: implications of AI when the core\n2007.36s: principle of defining values and\n2009.279s: creating ethical Frameworks are not even\n2011.6s: neutral if we are thinking about ethics\n2014.2s: from our point of view or from my point\n2016.0s: of view we are promoting Western\n2019.72s: educated industrialized\n2022.679s: ideologies and what happens when we want\n2025.039s: to think about data sovereignty who owns\n2027.519s: this data if we start taking it on\n2030.44s: individuals on communities on indigenous\n2034.159s: populations on species do they get to\n2037.36s: consent\n2038.84s: and what about data colonization we are\n2041.159s: taking data from people especially if\n2044.2s: we're zooming out to the global South\n2046.0s: we're just perpetuating neocolonial\n2048.0s: practices what about\n2049.919s: biopiracy if we're absorbing and and\n2053.48s: benefiting from Rich histories of\n2055.96s: traditional knowledge and utilizing it\n2059.119s: utilizing it through AI you know who who\n2062.359s: has the ethical say in this if we are\n2065.04s: integrating with indigenous cultures who\n2067.2s: are C custodians of lands that were\n2069.28s: trying to conserve and the species on\n2071.32s: those lands were monitoring their use\n2073.839s: we're monitoring their Rich biodiversity\n2076.32s: are they consenting do they want their\n2078.359s: information to be utilized by AI data\n2081.679s: scientists by large corporations so\n2084.2s: there's a lot this is not neutral to\n2086.159s: think about especially for climate and\n2088.839s: nature and sustainable\n2091.639s: development so one of the core focuses\n2095.04s: of our report is really to identify that\n2097.44s: you know AI applications for climate and\n2099.68s: nature must not exacerbate existing\n2102.8s: inequalities so this involves addressing\n2105.8s: biases we've already seen AI because\n2109.0s: it's trained on our data and we have\n2112.24s: inherent prejudices and biases inside of\n2115.119s: inside of us that sort of reproduce\n2117.72s: systemic oppression it is reproducing um\n2121.359s: bias and out and um biased outputs and\n2124.96s: it is perpetuating these inequalities so\n2127.04s: we need to make sure it's not address\n2129.56s: continuing to do that we also need to\n2131.92s: think about equality of access and\n2134.76s: opportunity so across the world we have\n2137.16s: a global digital divide um countries\n2140.24s: like the United States uh the Western\n2142.8s: Nations um different countries across\n2146.52s: Asia have more access to the DAT the the\n2150.2s: compute power the infrastructure and the\n2153.119s: resources and the data there are parts\n2155.599s: of the world where there really isn't\n2157.16s: data and so also if we're creating these\n2159.68s: Solutions based on where there is data\n2162.079s: it's not actually going to fit and work\n2164.599s: across the world and we could risk\n2166.599s: exacerbating inequalities and deepening\n2169.079s: this digital\n2170.2s: divide as we have here from Dr uh ouie\n2173.4s: Stewart from data.org\n2175.44s: infrastructure this is compute\n2177.48s: infrastructure data infrastructure is a\n2180.04s: form of climate\n2181.92s: Justice also we see this concentration\n2184.599s: of powerful AI capabilities and Discord\n2187.8s: es and highly resourced players if I I\n2191.0s: believe there is a stat that the\n2192.4s: majority of the AI citations are Google\n2196.04s: and Microsoft and so if they're cont\n2199.24s: controlling um the tools and the\n2202.96s: conversation what does that mean for the\n2204.839s: rest of us are they representing us\n2206.52s: these are profit-driven\n2208.319s: companies and also to sort of pivot away\n2211.599s: from that you know if we want to\n2213.56s: exacerbate or if we want\n2215.359s: to reduce the risk of a exacerbating\n2218.68s: existing inequalities anytime that we're\n2221.24s: developing a solution for a community or\n2224.96s: for people we really need to have\n2228.319s: meaningful engagement with this\n2229.96s: population we can't just develop things\n2232.319s: as climate data scientists in a silo we\n2235.56s: need to break silos that's how we're\n2237.2s: going to have transformative change is\n2239.2s: actually doing it with and ultimately\n2241.56s: uplifting folks to contribute to their\n2243.96s: their own Futures and\n2245.88s: trajectories so other opportunities um\n2249.359s: you know at the local scale we apply\n2251.56s: these Solutions and build workforces and\n2254.079s: cap capacities with historically\n2256.359s: marginalized and disadvantaged\n2257.68s: communities and globally we invest in\n2260.52s: infrastructure initiatives strong\n2263.2s: institutions and education across the\n2265.2s: global\n2266.2s: South a very hot off the press um\n2269.599s: screenshot that I just got from a\n2271.0s: five-minute conversation with Julius to\n2273.68s: look at the equality of opportunity and\n2276.599s: he said he went to talk recently and um\n2279.72s: there was a presentation of the\n2281.0s: concentration of gpus in the world and\n2285.0s: basically meta and Tesla have the Lion\n2288.4s: Share as well as Leonardo a national uh\n2291.68s: a national entity so this just goes to\n2294.92s: show that there is a high concentration\n2296.92s: of AI capabilities in this world and it\n2300.44s: might not promote equality inclusion and\n2304.72s: equity\n2307.68s: so there's a lot happening in this space\n2309.839s: right now on governance and safety to\n2312.2s: ensure AI is ethical is used ethically\n2315.079s: it needs to exist in an ecosystem of\n2317.04s: govern of technological governance and\n2319.76s: there are governing bodies around the\n2321.48s: world I would say\n2323.319s: scrambling um to to enact such policies\n2326.839s: given the recent pace of uh AI\n2330.96s: proliferation so in the US and the EU we\n2334.0s: have policies and even the United\n2335.52s: Nations General Assembly is starting to\n2337.16s: talk about about you know how do we how\n2339.52s: do we make sure this is moving forward\n2341.119s: in a way that we can control that has\n2343.359s: fewer unintended\n2345.56s: consequences when we're thinking about\n2347.599s: safety from the use cases that I've\n2350.04s: provided here today some of the\n2351.88s: challenges if we're looking at\n2353.839s: applications in the energy or power grid\n2355.72s: could be blackouts it could be\n2357.8s: catastrophic failures worker injuries it\n2361.2s: could be used to widely exploit\n2364.079s: resources can you imagine if highly uh\n2367.4s: fine-tune Precision agriculture wasn't\n2370.2s: taking into account natural limits or\n2373.599s: the need for land to follow or the\n2375.72s: benefit of biodiversity and it was just\n2377.76s: trying to maximize profit and output\n2380.44s: what about data breach by Pro poachers\n2382.56s: you know you have those conservation\n2384.079s: initiatives trying to track and\n2385.64s: understand species what if the wrong\n2387.2s: folks got that what if the wrong folks\n2389.92s: got a hold of a biodiversity Accounting\n2393.839s: in the Amazon rainforest where they\n2395.64s: could identify illegal har to harvest\n2398.24s: Hardwoods so we've got to be really\n2400.319s: careful about this stuff um Biden's\n2403.72s: issued an executive order on safe secure\n2405.72s: and trustworthy Ai and EU has the\n2408.24s: artificial intelligence act in\n2411.0s: place now sustainability and I I think\n2414.48s: this is my my last consideration before\n2416.44s: I go to some of the closing um\n2418.04s: opportunities and remarks so this one's\n2421.04s: tricky uh we know the computing power\n2423.359s: required to process and analyze massive\n2426.079s: amounts of data requires significant\n2428.28s: energy and Water Resources now there is\n2431.0s: a Nuance to this um two two ways to\n2434.04s: think about this if we zoom out and and\n2436.92s: I want to acknowledge that I'm David\n2439.68s: rolu who's kind of the the co-founder of\n2442.079s: climate change AI has informed some of\n2443.92s: my thinking on this based on a recent\n2446.119s: talk um zooming out AI has all these use\n2450.119s: cases for climate and nature this is\n2452.04s: great what is AI being used for right\n2454.92s: now ads it is being being used to drive\n2459.52s: Mass consumption and we really have to\n2462.04s: remember like we are in a climate crisis\n2464.76s: we're in a Tipping Point things are kind\n2466.96s: of bad and so we we do need real change\n2471.68s: on this globe and if we're still\n2473.599s: endlessly consuming we're obviously not\n2475.52s: going to be getting there so AI is\n2478.079s: driving Mass consumption and it's\n2480.119s: actually boosted production in the\n2481.8s: fossil fuel industry by 5% I is is\n2484.88s: according to his stats so that's I think\n2486.72s: a trillion\n2489.119s: um but on the flip side it offers these\n2491.64s: opportunities to mitigate greenhouse gas\n2493.88s: emissions right we I gave you a\n2495.96s: demonstration of several it can conserve\n2497.88s: water um you know there's there's the AI\n2501.8s: every time you query chat GPT it drinks\n2503.96s: a cup of\n2505.079s: water now it'll obviously if we use it\n2508.72s: in all Municipal pipe systems and it\n2510.68s: detects all the leaking pipes it'll\n2512.72s: it'll definitely mitigate that impact\n2516.4s: these using these statistics and I think\n2518.24s: it's right and it's important to think\n2519.76s: that way um but talking about AI in\n2522.4s: terms of energy and energy use and water\n2525.52s: use we also have to think about the\n2527.52s: other things that we do in this culture\n2529.48s: in this Society we consume a lot of\n2531.4s: Television social media those are all\n2534.4s: also energy and water thirsty we uh eat\n2538.079s: a lot of hamburgers so when you think\n2539.92s: about Ai and chaty queries in the global\n2543.0s: system of how we can how we utilize uh\n2546.119s: different resources\n2547.76s: it it it nuances it and it's actually\n2550.119s: significantly less than our Global meat\n2552.559s: consumption\n2554.16s: so kind of zooming back okay so we have\n2556.559s: some challenges with sustainability but\n2558.44s: it is nuanced when we look at it from a\n2560.16s: bigger picture both pros and cons but\n2563.24s: there are opportunities to invest in\n2564.96s: lower cost lower complexity models and\n2567.76s: this was one of the big key points that\n2569.44s: came out of a recent talk I went to on\n2571.44s: AI and for climate in bond it's that you\n2574.48s: know smaller AI tasks with simple smart\n2577.839s: and specific algorithms for specific use\n2581.16s: cases can be more effective than\n2584.0s: building this like Overkill large data\n2587.44s: large Foundation models so really\n2590.16s: smaller and smarter AI could really be\n2593.319s: transformative and in most cases is all\n2595.24s: we need to kind of unlock these climate\n2597.28s: and nature winds um also Edge Computing\n2601.24s: tiny ml um these are other areas that we\n2604.24s: can explore more to sort of reduce the\n2606.559s: sustainability ility impacts of\n2609.119s: AI okay so in the next five or so\n2612.68s: minutes um I just want to end with how\n2615.599s: do we accelerate progress and then what\n2618.119s: what's my big takeaway um coming into\n2620.72s: this sort of as as a newbie into AI\n2623.96s: about a year ago so opportunities for\n2626.88s: transformative change um this is all\n2629.68s: also informed largely of course by my\n2631.96s: wonderful team that that co-produced\n2633.96s: this report and Pier jeantine\n2636.04s: so one of the critical components is\n2638.76s: data we need open data open codes open\n2642.24s: models to really continue to press and\n2644.68s: drive algorithmic and application\n2647.4s: developments um this requires this data\n2650.559s: availability plus centralization and\n2653.24s: Benchmark data sets to sort of be able\n2655.64s: to you know benefit and bring in the the\n2658.4s: computer and scientific Community to\n2660.319s: really I don't know unleash its\n2662.079s: potential for Innovation um the\n2664.28s: materials project is an example of a\n2666.48s: centralized ation Hub um where it is\n2670.4s: using AI to to accelerate the\n2672.2s: development of new materials and weather\n2674.44s: bench of course for for Benchmark data\n2676.559s: sets also it's critical to address this\n2679.24s: issue of data scarcity and inequality\n2681.119s: and the fact that we have um we need to\n2684.04s: have more data in data poor regions so\n2686.839s: that we are not just creating AI\n2688.599s: solutions for already industrialized\n2691.68s: areas and out of this report the other\n2694.24s: two really critical things that came out\n2696.839s: oh am I still here yeah um it's\n2699.599s: Workforce Development and\n2701.4s: interdisciplinarity so we need to invest\n2704.44s: in the workforce and I'm happy to see\n2706.72s: you all here um importantly though\n2709.72s: there's this need for this sweet spot\n2711.839s: this interdisciplinary skills so folks\n2713.96s: who have this deep AI expertise but also\n2717.76s: domain specific knowledge uh deloid\n2720.44s: study from 2022 identified that AI\n2723.2s: Specialists worldwide amounted to just\n2725.24s: 22,000 folks and of course job openings\n2729.16s: are outpacing the supply of skilled\n2731.0s: workers but what's even more um of a\n2734.2s: challenge to kind of engage with is\n2736.16s: thinking about you know who can attract\n2738.72s: these AI Specialists the most we all\n2741.16s: know what Google and meta Microsoft tech\n2744.359s: folks can get paid can do you think an\n2746.88s: NGO trying to advance conservation\n2749.76s: efforts utilizing AI Specialists and\n2753.319s: biologists are going to be able to have\n2754.92s: the same PID there's there's an\n2756.16s: unbalance there\n2757.599s: so it is a challenge we need more AI\n2759.839s: Specialists we need interdisciplinary um\n2762.44s: skills but we also need a way to attract\n2764.64s: folks who are driven by the world the\n2767.48s: problems and who want to make the world\n2768.88s: a better place by applying their their\n2771.359s: their skills their AI\n2773.44s: skills and um we see that these new\n2775.72s: interdisciplinary training programs are\n2777.319s: emerging so right now we have leap of\n2780.359s: course Oxford uelman uh a lot of\n2783.28s: different organizations and academic\n2785.4s: centers are working on creating this new\n2787.8s: Workforce that's capable of tackling\n2790.079s: these critical problems with modern\n2791.88s: tools and to end and it it always in my\n2795.0s: line of work seems it it seems sort of\n2797.359s: trite it's like so obvious but we really\n2800.44s: need cross-disciplinary\n2802.68s: collaboration and it's not just so that\n2804.8s: we can well understand what we're\n2807.2s: talking about but it's really about\n2808.559s: framing the questions and enabling\n2811.2s: people to build Solutions between uh\n2813.92s: domain experts between policy leaders\n2817.0s: and the AI community so there's this\n2819.0s: critical role for for folks who can work\n2822.119s: together and and solve problems\n2823.92s: meaningfully and ask the right questions\n2825.72s: meaningfully we need to break out of\n2827.72s: silos that's another you know I think\n2830.0s: that's another way we're going to see\n2831.359s: transformative change is really breaking\n2833.4s: out of our silos so I guess this is the\n2837.359s: throw back to julius's question then my\n2840.52s: closing remark is AI holds this immense\n2844.2s: potential for driving positive change\n2846.4s: but it is just a tool it's not a penia\n2849.88s: and we all every day that we're\n2852.44s: interacting in this space need to be\n2854.52s: critical and honest about the ways it\n2856.48s: can and can't help solve our crime\n2858.52s: climate and nature Solutions so another\n2861.4s: comment from David Warnick is you know\n2863.8s: we have to avoid technos solutionism AI\n2867.2s: is not always the solution and it should\n2869.559s: not distract from other Solutions it's a\n2872.359s: means to the end and it's not the end in\n2874.48s: itself you know AI being applied\n2877.559s: to um reduce waste and improve recycling\n2882.119s: in in Municipal areas that's useful but\n2886.319s: we still need to reduce our waste and\n2888.92s: reduce the things that are going to\n2891.16s: landfill so my big you know closing\n2894.96s: thought is AI solutions for climate and\n2897.76s: nature must be advocated alongside\n2900.28s: Innovations and policy overhauls that\n2902.92s: actually address the social systems and\n2905.76s: economic paradigms that enable and\n2907.64s: perpetuate the climate and nature crises\n2910.079s: AI can help us do this but we've got a\n2912.4s: lot to do ourselves so thank you so\n2921.96s: much so you mentioned like U energy\n2925.0s: grids and stuff like that you can\n2926.44s: imagine like having I don't know model\n2928.72s: or Vis twin that optimizes for various\n2931.72s: criteria that are beneficial\n2933.799s: toity um and you could also I guess\n2937.079s: think of something that like larger that\n2938.88s: includes also like tariffs or regulatory\n2942.119s: structures that incentivize certain use\n2945.16s: of certain Technologies and so on and so\n2947.4s: forth um but like what if the choices\n2950.52s: that were determined by that sort of\n2952.16s: system uh reduced profit for energy\n2955.64s: companies for Industries or even for the\n2958.4s: AI groups like matter\n2961.2s: bu um like what you know can can these\n2965.4s: companies be necessar trusted to make\n2967.72s: choices that are in the best interest of\n2970.4s: uh public or citizens um do we have to\n2973.0s: view ourselves as essentially having an\n2975.2s: antagonistic role or like a a u kind of\n2979.559s: keeping in check the uh what exactly are\n2982.88s: the interests\n2988.839s: of yeah I mean that's I think it's an\n2991.359s: important question to think about I\n2992.559s: obviously I I don't know if we can trust\n2995.0s: them to act in the best public but I I\n2997.319s: think that's why we have checks and\n2999.16s: balances that's why we have a government\n3002.799s: that creates regulations um that's why\n3005.52s: we have a you know\n3008.76s: non-governmental advocacy groups that\n3011.359s: press corporate actors um it's why we\n3015.92s: have academics in the room who push the\n3018.04s: question I mean I think that what what\n3019.599s: goes wrong is when you don't have a\n3021.28s: government providing those checks and\n3022.839s: balances to make sure that corporations\n3025.4s: are acting in the public good because we\n3027.48s: know historically they haven't been um\n3030.599s: so I don't really have the answer to you\n3032.319s: I think it's just it's a dialogue it's a\n3033.96s: discourse we need to complete constantly\n3036.0s: push and ensure that governments are\n3037.559s: acting\n3039.359s: responsibly\n3043.599s: right this is also a fun one which\n3045.96s: probably doesn't have an easy answer but\n3048.839s: how how do you convince people that open\n3051.359s: source models and open algorithm\n3053.359s: development is important because got who\n3056.96s: view it as a weapon right historically\n3058.76s: they' lock 20 of their best folks in a\n3061.16s: room to develop weapons and not tell\n3062.599s: anybody about them you have companies\n3064.04s: that are profiting off of it yeah and if\n3066.559s: they tell other companies about this\n3068.04s: software they will use that software to\n3070.0s: profit as well yeah so how do what's\n3071.96s: like a good argument for convincing that\n3074.64s: open source modeling is the is the\n3077.119s: future is an assessment I don't know I\n3079.4s: wonder if I can like pivot that in a way\n3081.2s: if Julius has a thought I mean I think\n3082.96s: it's like public you know is it is it a\n3085.68s: public good I I I I again as an outsider\n3088.839s: and a social scientist I've actually\n3090.68s: been like really levitated by\n3094.359s: understanding the computer science\n3096.28s: community and how you have this sort of\n3098.76s: disruptive nature of coming together to\n3100.96s: push the boundaries and co-create in\n3102.68s: this really open source sort of way so I\n3105.2s: I don't know I guess it's kind of like\n3106.52s: we have to look to you all who care\n3109.28s: about wanting to improve things and this\n3111.68s: being a mechanism um and of course\n3114.28s: leveraging the academic Community like\n3116.359s: that's\n3117.119s: one really good thing about us even\n3118.92s: though this is a private institution is\n3120.64s: we're not just solely PIV you know\n3123.4s: profit driven right we're we're\n3124.839s: intellectual driven do you have a do you\n3126.76s: have a thought on how to promote the\n3128.72s: concept of open data sources it's also\n3131.319s: good for profit I mean we see that like\n3133.839s: like all the open development on all the\n3135.359s: tools like there's a reason that that\n3137.04s: they open source that stuff there's like\n3138.48s: free labor of like enthus like I mean\n3140.799s: that's a really pessimistic way to look\n3142.2s: at it but that's part of it for sure um\n3145.0s: and this sort of labor sharing I I think\n3147.72s: for me that's just like creating\n3149.839s: efficiency and like these big companies\n3152.04s: know about that right like not redoing\n3154.04s: the wheel and I think maybe I can pivot\n3156.2s: to my actual question here because I\n3157.64s: think um that is something we're\n3159.68s: actually not very good at as in Academia\n3161.72s: as a whole I think we need to like take\n3163.24s: a look at I think you made like some\n3164.599s: some very good remarks on like the role\n3166.52s: of of academic research um in sort of\n3169.96s: the the system of checks and balances\n3171.76s: which it maybe should work in a\n3173.599s: different way but like the role there is\n3175.88s: very clear and um I think you also asked\n3178.64s: the question where are the people who\n3180.359s: are motivated uh to foro a certain pay\n3183.72s: range and and sort of work for the right\n3185.64s: thing they're all right here like the\n3187.92s: fact that there's people sitting in this\n3189.28s: room right like I I feel like almost\n3191.2s: everyone in this room could like go to\n3192.72s: like the big companies but there are\n3193.839s: still people who sit here and think that\n3196.119s: there's something like additionally to\n3197.92s: be gained but I think a qu my my\n3201.64s: original question is like this creating\n3203.72s: silos that is for me is like a Hallmark\n3206.559s: thing of Academia as it stands right now\n3209.04s: so is the real problem to Breaking this\n3211.48s: up actually academic structure and by\n3213.68s: that I mean sort of the overarching\n3215.04s: structure not necessarily leap which I\n3217.079s: think is going in the right direction\n3218.28s: but we also need to be honest we're\n3219.559s: bumping up against sort of pretty high\n3222.559s: level incentives that don't go this way\n3224.64s: they go the exact opposite way so is\n3226.44s: that really a problem for the future of\n3228.599s: AI in as a public good our\n3232.799s: silos I think silos are well yeah I\n3235.359s: think it's always going to be a problem\n3237.4s: I think I think the academic I think the\n3240.599s: university could play a role um and I'm\n3243.24s: going to borrow some research from some\n3245.72s: really good colleagues who put forward\n3247.92s: an opinion piece but you know the\n3251.4s: university structure and tene structure\n3254.359s: someone having a party somewhere down oh\n3257.28s: nice okay um it it rewards Things based\n3260.68s: on these you know how many Publications\n3262.44s: can you get out how many papers can you\n3264.0s: get out it doesn't always reward this\n3266.88s: community-based science this complicated\n3269.76s: partnership building interdisciplinary\n3271.76s: stuff which just goes slower and it's\n3274.16s: harder to have those traditional metrics\n3276.16s: so I think yes we can it could be harder\n3279.359s: to have those traditional metrics or you\n3281.04s: create new metrics and so I think\n3283.079s: there's a role in the University um and\n3285.68s: maybe some of the funding agencies to\n3287.92s: try to break down um the challenges and\n3290.92s: the rewards and incentive structures\n3293.119s: that sort of perpetuate siloed work and\n3295.68s: siloed thinking\n3296.839s: and you know I want to say there's it's\n3299.16s: really important to have really\n3300.96s: foundational basic science on one small\n3304.119s: thing too we have to have both um but\n3308.88s: yeah I think it that's why it's\n3310.319s: transformative it seems so simple but it\n3313.04s: it could unlock it could be\n3314.4s: transformative if we can do it\n3316.48s: right going me go to the zoom uh group\n3319.319s: here um pite do you want to unmute and\n3321.599s: ask your\n3323.88s: question oh yeah sure I was not expect\n3326.599s: him to be called onto the stage like\n3328.4s: that but sure and I think to some degree\n3332.039s: Geneva has already kind of touched upon\n3334.039s: this but uh just thinking in terms of\n3336.64s: the political economy aspect of the AI\n3340.76s: governance and regulation\n3343.2s: conversation uh I think there's I have a\n3346.24s: concern anyway that you know some\n3349.2s: institutions uh that are tested with\n3351.92s: overseeing and regulating AI you know\n3354.68s: whether we're talking about clent energy\n3357.2s: conservation or some other use case I\n3360.559s: sort of fear that there's going to be a\n3362.96s: combination of capture by uh industry\n3367.039s: forces a lack of expertise Within These\n3370.48s: uh regulatory or institutional bodies uh\n3374.119s: as as well as other maybe perverse\n3375.96s: incentives that are going to kind of\n3377.44s: combine to make it really tough for\n3381.2s: smart governance and oversight to to\n3384.44s: become a reality and I know that's kind\n3386.0s: of pessimistic view of it all but I'd be\n3389.76s: curious to hear Geneva what your\n3391.839s: thoughts are on whether we need certain\n3395.599s: kinds of higher level systems level\n3399.839s: changes institutional changes procedural\n3403.52s: changes uh in order to make these sorts\n3407.079s: of smarter uh regulations and smart\n3410.799s: oversight uh a reality and not just you\n3413.48s: know something that we really want to\n3415.96s: see\n3417.559s: happen so I think I I'm pushing up\n3419.92s: against my political economy knowledge\n3422.76s: base but I think the answer is yes we\n3425.28s: probably do need to look at structures\n3426.72s: but I actually I don't know what they\n3429.079s: are do you may I can I do you have ideas\n3431.799s: about what sort of changes structurally\n3434.119s: we might need maybe maybe perhaps you I\n3436.839s: mean that's I'm not I'm not a political\n3439.64s: Economist by training I know some things\n3442.0s: about political economy but I mean this\n3444.76s: is this is I guess is a million dollar\n3446.72s: question or a trillion dollar question\n3448.319s: depending on how you want to look at it\n3450.16s: I I certainly don't know what that would\n3453.44s: be I wonder if there's models in other\n3456.839s: kind of science policy spheres uh I\n3460.16s: don't I don't know what we could look to\n3462.039s: um I don't know how do how were nuclear\n3464.72s: regulations made probably poorly to\n3466.72s: begin with you know I don't know I\n3467.96s: wonder if there's other models or\n3469.599s: looking to other countries to see if\n3471.2s: they approach regulation differently but\n3473.48s: I don't have an answer for you but I I\n3475.2s: think you're it's right we do have to\n3477.4s: start thinking about other ways of\n3480.319s: looking at this structurally to actually\n3481.92s: ensure we're doing a good job and not\n3483.359s: getting that corporate C\n3485.319s: capture yeah yeah absolutely and I think\n3488.0s: even if we don't have an answer right\n3489.4s: now it's I hope that it's something that\n3490.76s: we all leave today thinking about more\n3492.92s: and maybe asking more in the\n3495.44s: conversations we have on this topic with\n3497.16s: other people so I mean thank you so much\n3499.24s: again for your for your talk I really\n3500.68s: enjoyed it oh good thanks for bringing\n3502.44s: that question\n3504.119s: up I see we have uh I think I think two\n3506.52s: more questions in the room um we're\n3508.16s: coming up on 1 o' so we'll have have two\n3510.2s: more quick questions and then um and\n3512.68s: then we will thank Gena for her time\n3514.2s: Sammy we'll start with you oh yeah I\n3517.76s: this is kind of a very specific question\n3519.0s: but I was just wondering if you could\n3519.72s: tell me more about like the the team\n3521.359s: that was like producing this work\n3522.64s: because I think these are like really\n3523.599s: interesting question so like at the\n3525.92s: climate school like what was the\n3527.24s: structure of like how this work was done\n3529.319s: and what was the relationship with like\n3530.76s: the Bas house foundation and then year\n3533.039s: and stuff yeah okay so um this\n3536.68s: was like commissioned by an in\n3538.52s: collaboration with Bezos so I think they\n3541.799s: directly sought out the both Columbia\n3544.599s: University's engineering school and\n3546.88s: climate school knowing our contribution\n3549.0s: to the space and particularly Pier\n3550.72s: jeanine's leadership as lead author and\n3553.319s: then myself and a colleague in the\n3556.079s: School of Engineering were brought on so\n3557.96s: that it was a three-person team plus a\n3559.64s: partnership specialist at Columbia um at\n3562.28s: AI we or sorry at the University of\n3564.4s: Albany we leveraged their AI Institute\n3568.799s: so we had something like seven I think\n3571.44s: AI Specialists um and and folks who\n3574.28s: thinking about AI for you know cyber\n3576.799s: security um on the team and and you know\n3580.48s: applied uh applied science and then at\n3583.72s: EST we had basically a team of\n3586.48s: geospatial experts so I mean of course\n3589.4s: geospatial and satellite Technologies is\n3591.119s: a huge part of how we can use AI um for\n3594.44s: climate and nature so so that was sort\n3596.319s: of the the core team we brought in some\n3598.4s: brilliant students from Columbia\n3600.599s: engineering um and we liaz quite\n3605.44s: frequently actually with the Bezos Earth\n3607.0s: fund because of course they wanted this\n3609.16s: to inform their the Grand Challenge\n3611.039s: launch and so every month we would\n3613.839s: provide a presentation to their\n3615.64s: president um about what we were finding\n3618.2s: so we'd identify it was a literature\n3620.359s: review so the methodology primarily was\n3622.68s: just a massive literature review\n3625.039s: hundreds and hundreds\n3626.52s: um internet scan of course and then we\n3628.76s: spoke with some 30 odd stakeholders just\n3631.96s: informal\n3633.16s: conversations and ultimately we invited\n3635.88s: I think 15 other expert authors to\n3639.319s: review the sort of work we' put put out\n3641.4s: from a lit review and from conversations\n3643.359s: with experts and then they contributed\n3645.68s: you know that you might be missing this\n3646.92s: or have you thought about that so that\n3648.16s: was leveraging sort of the broader\n3649.96s: Columbia faculty that was the process so\n3653.079s: I don't know if our our page of\n3655.2s: acknowledgement and contributions is\n3657.44s: like I don't know 50 people long or\n3659.559s: something it was that's another talk how\n3662.079s: to write a Google doc with 50 people but\n3664.68s: we'll save that for another day uh last\n3667.599s: question hi so um I wanted to pigy back\n3670.92s: off of uh punit's question because I I\n3673.039s: do have some experience in political\n3674.68s: economy and just want to have some offer\n3677.28s: some comments there so I I would say on\n3679.839s: the regulation question um it's it's\n3683.2s: definitely going to be really quite\n3685.24s: difficult in the Years is moving forward\n3686.96s: because the direction that legal jurist\n3689.16s: Prudence around us administrative law in\n3692.319s: this country has taken has really been\n3694.96s: to sort of Sherk the government's\n3699.0s: obligation to bring on\n3701.28s: Specialists um in regulatory roles\n3704.0s: within the executive branch there was a\n3706.079s: recent Supreme Court case for instance\n3708.24s: that uh overruled something called the\n3710.48s: Chevron Doctrine which was a you know a\n3713.64s: legal sort of a legal principle that\n3716.039s: allowed for the US government to engage\n3717.88s: in this type of very specialized rule\n3720.559s: making that's been gutted by the Supreme\n3723.119s: Court um and then of course depending on\n3725.48s: how the presidential election goes\n3727.4s: things can go one way or another uh on\n3729.68s: that front in terms of our ability to\n3731.559s: avoid things like regulatory capture\n3733.52s: moral hazard perverse incentives that\n3735.2s: sort of thing um the second Point um\n3738.4s: which was to what you were saying about\n3740.68s: sort of this infrastructural investment\n3742.92s: particularly in global South countries\n3744.799s: and expanding equity and access um there\n3748.76s: there's also a lot of challenges in\n3751.0s: terms of just how the International\n3753.48s: Financial political economy structured\n3756.559s: um in the sense that you you have a lot\n3759.079s: of um a lot of these countries that are\n3761.72s: saddled with foreign debts denominated\n3763.76s: in US Dollars um and even for basic\n3768.279s: things like roads and hospitals and\n3770.4s: schools it's exceedingly difficult to\n3772.96s: get foreign aid money to build that type\n3774.76s: of infrastructure let Al Al these more\n3776.799s: complicated you know HPC centers um\n3779.92s: around the world um and uh I I spent a\n3784.039s: lot of time thinking about how to reform\n3786.079s: that international finance structure and\n3788.279s: uh it it's definitely like you know if\n3790.839s: if our local and National politics are\n3793.279s: difficult that's just another level you\n3794.64s: know so it's it's it's definitely going\n3796.319s: to be a a a long haul to be able to\n3799.279s: really restructure that that system to\n3801.96s: allow for these types of Investments to\n3803.559s: occur well please do keep thinking about\n3806.0s: it cuz we need people like you for a\n3808.2s: lifetime thinking about it and pushing\n3810.039s: it and I I mean yeah I think everything\n3812.92s: you've said is is really really\n3814.279s: brilliant and you know I'm a Canadian so\n3816.039s: I can't say this but one option is\n3818.359s: consider who you're voting for when you\n3819.92s: want to think about how you change\n3821.2s: regulatory structures and what future\n3823.079s: governance might look like and you know\n3825.96s: we one day we are the future we are\n3829.279s: going to be the leaders we are going to\n3831.76s: change the narrative we are going to be\n3833.72s: the decision makers we can work in if in\n3836.24s: the international financial institutions\n3837.799s: we can change the way debts are given\n3840.4s: concessional loans grants we can\n3842.68s: alleviate debt loads like this has\n3844.839s: happened and it can happen and so I\n3846.64s: think you know we we don't really have a\n3849.96s: choice we're either going to be living\n3851.4s: in a very very very different world um\n3854.76s: that might be the case or we take some\n3857.119s: actions to change it so you know we\n3858.92s: really don't if we really want to see\n3860.44s: change we have to make it happen so we\n3861.92s: need these big bold ideas and we need to\n3864.119s: dedicate Our Lives thinking about how to\n3865.799s: actually Implement them because one day\n3867.279s: we're going to be in\n3868.4s: charge that's it great note to end on\n3871.68s: thank you so much Geneva"
    },
    {
        "class": "YouTubeVideo",
        "title": "2023 Train-the-Trainer Bootcamp Day 2: Machine Learning for Climate Data",
        "videoId": "Z3MTH5UkCb0",
        "url": "https://www.youtube.com/watch?v=Z3MTH5UkCb0",
        "publishedAt": "2023-01-17T22:40:08Z",
        "transcript": "3.84s: for day two uh so yesterday was awesome\n7.319s: so it's gonna be difficult to be living\n9.96s: up to the standards but I'll try to do\n11.76s: my best today a couple of things before\n15.199s: we get started so we got some really\n17.82s: interesting questions about whether you\n19.5s: could actually still use the Jupiter\n21.6s: hubs moving forward you know and that's\n23.64s: fine you know as long as of course\n24.9s: you're not mining bitcoins you know in\n26.519s: the middle of nowhere that should be\n28.439s: appropriate I think it's part\n39.6s: uh\n41.1s: sort of graduate up to being part of\n43.079s: leap sponsored research there's more\n45.66s: resources available with the in the hub\n47.579s: larger nodes gpus Etc so yeah that's\n51.0s: great part of the design yeah and those\n54.0s: are CPU based at this stage and we would\n56.219s: love to hear for instance if you're\n57.66s: submitting a proposal you've been using\n59.76s: that for a paper please let us know we\n61.98s: would love to report that back to the uh\n63.84s: to the NSF we are being supported by the\n66.24s: National Science Foundation and they\n67.5s: would love to hear those metrics you\n68.939s: know that's we really want to be a\n70.2s: magnet so that people can actually do\n71.7s: their research and we can expand you\n73.2s: know so showing that there's been some\n75.18s: great opportunity for expansion anything\n77.88s: else the only other announcement I\n79.5s: wanted to make is that should all have\n81.18s: been invited to the slack channel to the\n83.46s: uh and there's this there's a boot camp\n85.5s: channel in there and we can use that to\n87.659s: share links and just code and stuff like\n89.939s: that so if you check your email if you\n91.86s: haven't already you should see an invite\n93.299s: join the channel and just you can just\n94.979s: stay on there and stay part of the\n96.299s: community that way great thanks so much\n98.759s: Ryan here\n100.5s: any questions before we get started\n102.72s: though we are good bye\n105.9s: okay\n107.46s: um and so today we are going to talk\n109.439s: mostly about neural networks you know\n111.6s: it's going to be pretty simple what\n113.28s: we'll be covering today so Vanita type\n116.22s: neural network we are going to talk\n117.899s: about convolutional neural network so\n120.06s: including spatial features as well and\n123.06s: then we'll talk about recurrent neural\n124.56s: networks so very much linked to what\n126.719s: we've seen and covered yesterday which\n128.52s: we are talking about images so in space\n130.679s: and then if you remember we had a few\n132.66s: time series so looking at space and time\n134.58s: right so typical geospatial type of data\n137.76s: they are a lot more sophisticated\n139.8s: techniques but just to give you a sense\n141.48s: of some of those basic flavors you know\n143.72s: we will have what we call three Studios\n146.459s: so more like Hands-On exercises so we'll\n149.099s: go together into a neural network and\n151.62s: we'll try to see how those are designed\n153.66s: you know and to make it a little bit\n155.459s: more fun so I created a competition you\n157.62s: know so it's gonna be uh so you will\n159.36s: have to scan that QR code at the end uh\n162.54s: and you will have 20 minutes to actually\n164.099s: get into your neural network get them\n165.78s: most out of it and you will see and try\n167.94s: to get the best results you report that\n170.16s: back into the form and then we see we\n172.5s: won okay so that's gonna be hopefully\n175.68s: fun\n176.64s: any questions we can also share the the\n179.819s: links so those are typical Google forms\n182.16s: so we can share the links in slack you\n183.78s: know if you want\n185.34s: questions\n187.56s: fine\n189.599s: yeah so I don't know we need to ask if\n192.36s: we can get some swags you know from all\n194.76s: the leftover Cheetos\n197.3s: my son will win let me tell you and my\n201.3s: daughter as well yeah\n204.2s: okay so if not let's get started we'll\n206.879s: try to get some some price here I'll ask\n208.86s: ga\n210.72s: um okay so let's get into what a neural\n212.879s: network is so that's going to be pretty\n214.5s: high level but I think that should be\n216.36s: the right uh level of pace that we need\n219.12s: and hopefully that will be and feel free\n221.519s: to stop me anytime if anything is\n223.26s: unclear questions welcome you know we\n225.36s: have a small comedy here small group so\n227.519s: let's take uh use that let's use that to\n230.159s: our advantage here\n231.84s: okay so what is a neural network so\n234.239s: basically long story short is people who\n236.519s: are trying to mimic the brain you know\n238.019s: so that's when the whole story uh\n240.06s: started at the time and they started to\n242.34s: try and mimic neurons you know that's uh\n244.98s: basically what is uh at the heart of um\n247.14s: of our brain system and neurons are\n250.14s: being connected by synapses you know so\n252.06s: we'll talk about that later and\n254.64s: basically the main point was to activate\n256.859s: and transfer uh some information of some\n259.38s: signal there's basically some sort of\n261.0s: action potential so you need to pass\n262.62s: some threshold you know so you have some\n264.56s: activations of neurotransmitter in that\n267.0s: case and when you once you pass a\n268.919s: threshold you will actually transmit the\n270.36s: information down the neural network\n271.8s: right and you can have many many\n273.419s: connections we'll talk about that in in\n275.46s: a minute but a very important concept\n278.16s: here is some sort of idea of activation\n280.08s: threshold right you need to to pass some\n282.78s: level you know you have need to have\n284.28s: some activation and so by definition\n286.56s: what it means is it's vein or linear\n288.6s: right it's a zero or or a step function\n291.3s: right it could be more sophisticated\n292.86s: we'll talk about that in a minute for\n294.84s: neural networks but that's kind of the\n296.759s: idea a very non-linear type of response\n299.639s: right\n300.96s: uh in the in the real world and that's\n303.84s: actually very interesting uh learning\n305.58s: occurs through what we call plasticity\n307.199s: so it's actually not fixed and that's\n310.32s: been kind of I've been fighting with\n312.78s: that with my kids you know it takes\n314.04s: years to train them you know and we\n315.84s: don't train them you know so it doesn't\n317.04s: work actually uh so but when you think\n319.44s: about like a dog for instance it tends\n321.06s: to be a very shallow neural network we\n322.919s: talk about that in a minute pretty easy\n325.02s: to train you know so it's pretty easy to\n326.94s: modify that to basically influence that\n329.22s: plasticity when you have something very\n331.199s: deep it takes a while you know so think\n333.18s: about kids you know it takes years to\n335.34s: have them you know like uh actually\n337.259s: perform a task\n338.759s: uh the human brains had a lot of neurons\n341.039s: so 10 to the 11s but a lot more\n343.08s: connections you know so that's one thing\n344.639s: we'll look at later is that we will see\n346.919s: that there's a lot more connections\n348.3s: typically than the number of neurons and\n350.94s: the connections will be what we will\n352.5s: call the number of degrees of freedom\n354.18s: right so if you remember a little bit of\n356.28s: linear regression you know the weights\n358.919s: that you have in your linear regressions\n360.419s: are going to be\n361.8s: your degrees of freedom in that case\n364.5s: your connection so we will also have\n366.24s: weights and biases those will be the the\n368.94s: number of degrees of freedom\n371.46s: okay and that's basically how it looks\n373.5s: like so you have the synapses so you\n375.3s: have the neurotransmitters here uh if\n377.4s: you take any drugs that's what you're\n378.78s: disturbing here uh and that's basically\n381.3s: how you're actually uh impulsing the the\n383.46s: signal from one year on to to the other\n385.5s: one and then you have a very complex\n386.819s: system and people are very much studying\n388.56s: that and there's a lot of cross\n390.3s: fertilization now between looking at the\n392.699s: human brain so there's the human brain\n394.199s: project and looking at neural networks\n395.94s: and trying to actually make some sense\n397.86s: of that and trying to understand how\n399.3s: people like she learn you know and in\n401.4s: fact there's been some potential very\n403.8s: recent Revolution uh showing that maybe\n406.62s: the way we've been training neural\n408.0s: network is the wrong way so we'll talk\n409.319s: about that in a minute it's okay we call\n411.36s: that back propagation\n413.16s: okay\n414.419s: uh and just to close here so uh the\n417.96s: brain structure so we have different\n419.1s: parts of the brains for different\n420.3s: functions we will see that some neural\n422.28s: networks are kind of doing the same as\n424.56s: well and again we have some level of\n427.74s: plasticity so some areas can change and\n430.68s: we can actually use that to our\n431.88s: advantage as well in the neural networks\n433.56s: right we might want to change some parts\n435.419s: of the neural network by Design because\n437.52s: that could be useful so for instance you\n439.62s: would want to have some sort of\n440.759s: classification task as we'll discuss in\n443.4s: a minute uh and that's something you\n445.38s: could potentially change okay and at the\n448.02s: end of the day we don't really\n448.74s: understand the concept of Consciousness\n450.36s: or thought at this stage you know but\n452.22s: there's a lot of people of course\n453.3s: working on that\n456.24s: uh and just if we look at the history of\n459.539s: that so the idea of neural network\n461.34s: actually even started I I look back at\n463.38s: some papers recently even back in the\n465.0s: 50s you know that those were some of the\n466.62s: early stages and then pretty picked up\n468.599s: in the 80s uh when people really tried\n470.819s: to make the connection with the real\n472.199s: brain started to really pick up in the\n474.539s: 90s actually when I was uh uh in early\n478.259s: 2000 when I was a college student we\n481.139s: also we still had some neural network uh\n483.78s: um courses at the time and then it's\n485.88s: really decayed in terms of popularity\n487.38s: you know you had some fellows like\n489.479s: yandokin and Etc that were working on\n491.699s: neural networks but it didn't really\n493.02s: pick up and then there was a revolution\n495.24s: and that Revolution came from a couple\n497.52s: of things so the algorithmic really\n499.199s: developed very quickly\n501.06s: the hardware infrastructure really\n502.8s: developed so we got the gpus that uh\n505.259s: Ryan was was talking about so we'll talk\n508.08s: about that in a minute and we had a lot\n510.36s: more data that was the Advent of the web\n512.64s: so all of a sudden we had millions and\n514.8s: millions of images millions of videos a\n517.38s: lot of data to chew on and all of that\n519.659s: combined really led to a revolution\n521.279s: right and to what we are witnessing now\n523.2s: like such as we're talking about chat\n525.0s: GPT yesterday which is pretty insane and\n526.98s: pretty exciting at the same time but so\n529.2s: uh so things like that where we are\n531.12s: really witnessing a true Revolution okay\n533.58s: so that's been a relatively recent if\n535.68s: you think about that it's been basically\n537.3s: a decade you know where we've really\n538.62s: seen a Resurgence in the use of neural\n540.72s: networks and really the revolution that\n542.279s: we are talking about every day you know\n544.08s: in terms of using Ai and machine\n545.7s: learning and that's really as part of\n547.5s: leave what we are trying to to harness\n549.3s: and harvest as well right we are trying\n551.04s: to actually leverage that Revolution as\n553.08s: part of climate modeling and and for\n555.18s: climate change\n557.1s: any questions feel free again to stop me\n559.38s: anytime if you have any\n561.0s: I mean that's pretty introductory at\n562.92s: this stage\n564.24s: okay\n565.32s: so let's look first at a very basic\n567.959s: thing so typically and especially for\n569.88s: this class so you could have different\n571.56s: things so you could have what we call uh\n573.959s: unsupervised or supervised type of\n575.88s: learning and supervised mean that we\n577.92s: will not have any type of label data so\n580.62s: you could think of that for instance you\n582.3s: would want to do some sort of\n583.74s: dimensional reduction in your data set\n585.54s: so you have very complex data set you\n587.16s: want to reduce the dimension to a few\n588.6s: Dimensions or you would want to do say\n591.12s: some clustery right you have some pretty\n593.339s: heterogeneous data set and you would\n594.959s: want to do some clustering and you don't\n596.88s: have any type of label you know you\n598.5s: cannot say for instance you have an\n599.7s: image you don't have any classification\n601.74s: to say or label to say this is a tree\n603.66s: this is a building and you want to kind\n605.339s: of do that automatically so we call that\n607.7s: unsupervised learning and we we are not\n610.2s: going to cover that mostly today a\n612.0s: little bit of that but not too much\n613.44s: right the main focus today will be on a\n616.38s: supervised task which means that we will\n619.2s: have labels okay so it means labels that\n621.959s: could be in an image right again trees\n624.54s: buildings or roads if you're looking at\n626.6s: some image or it could be a regression\n630.18s: task right which is exactly a supervised\n633.06s: exercise where you have labels you know\n635.279s: so you have points on your y-axis you\n637.38s: have points and you want to fit those\n638.7s: points that that's what you've been\n640.32s: doing with the linear regression and we\n642.24s: want to regress against that okay so\n644.22s: that's basically the type of concept\n645.779s: that we have we will have some labels uh\n648.36s: typically we will call them y's you know\n651.18s: so that you know think of that as the\n653.04s: y-axis that you add in your linear\n654.6s: regression and we are going to try and\n656.519s: regress onto that when we have a\n658.14s: regression problem and then the other\n659.88s: type of problem for the supervised\n661.92s: learning will be a classification so is\n664.079s: it a cat is it a dog is it a building is\n666.36s: it a road those things right so\n668.64s: typically it's going to be in a sense\n670.5s: some sort of integer right so integral\n672.54s: integer value okay make sense okay\n678.54s: okay so the basic thing that we will\n680.279s: have first is uh thinking of what is one\n682.26s: neuron okay so very simple here so think\n685.44s: exactly as your linear regression you\n687.48s: have some weights right you take some\n689.76s: inputs so it's going to be\n691.16s: multi-dimensional in essence so\n693.3s: everything we are going to do is going\n694.92s: to be multi-dimension\n696.779s: and we are going to have in that case M\n699.0s: input so those are different real valued\n701.519s: uh inputs here X1 to XM we give them\n705.3s: some weights so similar to a linear\n707.459s: regression so we take the sum of that so\n710.04s: x i times the weight okay so that's\n712.38s: basically your linear regression no bias\n714.18s: no Intercept in that case\n716.1s: and we're gonna pass that through a sum\n718.14s: okay so at this stage you should be\n720.6s: familiar that's basically just a linear\n722.22s: regression right so nothing too\n724.079s: complicated and then the only trick here\n727.14s: is going to be that part here right and\n729.66s: that's similar to what we're discussing\n731.279s: before the synapses that we had earlier\n733.62s: right where we have this non-linear type\n736.5s: of response right and we can make it\n738.54s: whatever okay uh so\n741.12s: it looks like a sigmoid function because\n744.0s: that was kind of what people were using\n745.68s: in the early stage they wanted to have\n747.6s: kind of the similar Behavior as what\n749.459s: people have in the in in the brain which\n752.04s: is this activation zero or one right so\n754.86s: and typically if you're a mathematician\n757.14s: you want to have things that are\n758.339s: continuous the derivative are kind of\n760.079s: nicely defined so that's why they use\n762.24s: those sigmoid functions right in fact\n764.279s: what we know now is that they are not\n766.079s: ideal they tend to be a bit too complex\n768.3s: they tend to saturate because they they\n770.279s: are flat on either side so people don't\n772.2s: use them uh so much anymore okay but\n774.72s: just to make the point that we will have\n776.82s: some what we call activation function so\n779.94s: that's going to be very important please\n781.44s: remember that for your competition and\n783.18s: try to find the best one uh and we are\n785.7s: going to apply that to the to the linear\n787.8s: regression that we have right and then\n789.6s: that's going to define the output which\n791.82s: is our best estimate of the regression\n794.279s: problem\n795.12s: makes sense so every time we will have a\n798.18s: hat here it means we we have an estimate\n800.639s: so that's all going to be our prediction\n802.2s: right so we will have on the left hand\n804.3s: side the inputs are sometimes called the\n807.6s: features or sometimes called the\n809.519s: predictors and we are going to have on\n811.98s: the right hand side we are going to have\n813.18s: the output or sometimes called the\n814.86s: predictant or the prediction okay so\n816.899s: those are different terms people use\n818.459s: different uh terminologies depending\n820.8s: especially on the field but that's\n822.48s: basically what we have we have some\n823.86s: inputs here we have some outputs and we\n826.32s: want to predict that to the best of our\n828.0s: ability right so nothing too complicated\n830.579s: at this stage and we are gonna fine tune\n833.519s: or choose different activation functions\n836.579s: any questions\n839.459s: fine okay\n843.06s: the the one thing you can do of course\n845.459s: and very much inspired by a linear\n847.38s: regression is either bias right it\n849.779s: doesn't necessarily passes through zero\n852.48s: right it could there could be a bias in\n854.399s: your data so you need to add a buyer so\n856.38s: that's going to be the simplest type of\n858.6s: what we call a perceptron right the\n860.16s: simplest neuron you can have is a bunch\n862.44s: of Weights uh from one to M so those are\n865.079s: the defense uh connections that we will\n867.779s: have here so the number of degrees of\n870.12s: freedom plus one which is W naught\n873.06s: that's going to be the the the bias\n875.16s: right so we have a number of Weights\n877.38s: here one two M and then we add a bias\n879.72s: okay so that's all we have we need to\n881.519s: have and basically if you remember your\n883.38s: linear regression the advantage is for\n885.839s: linear regression we can actually get\n887.399s: those weights right do does anyone\n890.22s: remember how to get those weights\n893.699s: how do we get that for linear regression\n897.839s: linear algebra 101\n901.8s: maybe this group I'm sure knows they\n904.019s: know algebra quite well yeah\n908.1s: so basically a projection right your\n909.959s: project right that would be another way\n912.0s: to say that right so you have your why\n914.639s: right which could be in a different\n916.019s: space you're working in the Subspace\n918.3s: here which is what we call a span of the\n920.82s: axes right a new project right that's a\n923.459s: linear projection and we know that when\n924.959s: we have a right angle that's basically\n926.94s: your best estimate because it minimizes\n928.8s: the the distance right and if you think\n931.56s: about that minimizing the distance is\n933.66s: minimizing the loss right it's\n935.639s: minimizing the the mistake we're making\n938.399s: in terms of the prediction right within\n940.56s: the Subspace that we have right so it's\n942.42s: just very simple projection right so we\n944.459s: have that like that right just a bunch\n946.68s: of Matrix multiplications that's going\n949.019s: to be more difficult here because it's\n950.699s: non-linear right so it might not be as\n953.339s: simple as what we had for a linear\n955.62s: regression so we will need to actually\n957.3s: project project in a different way right\n961.74s: okay so you can actually write that so\n964.139s: getting back to what you add here\n966.3s: X transpose\n967.94s: W that's basically your projection right\n970.8s: so you're projecting onto the space here\n974.22s: for the different weights onto the\n976.92s: Subspace which is basically the span of\n979.92s: X1 to XM and that's a mathematical way\n983.82s: of actually writing the exact same thing\n985.26s: right so we are basically taking the sum\n987.42s: of the x i times w y and it's basically\n989.699s: a vector X1 to XM and we're taking the\n993.24s: transpose times the weights here so just\n995.519s: the the inner product basically okay in\n998.04s: a product basically it's a projection\n999.899s: right so same thing here okay\n1003.38s: so just a way to write that but the main\n1005.18s: point being that it's going to be a\n1006.8s: bunch of Matrix multiplications here so\n1008.66s: you can use a lot of the linear algebra\n1010.339s: toolkits that you have in the background\n1012.199s: so it's going to be nice especially on\n1014.18s: your on your Hardware\n1016.1s: okay so that's for the right hand side\n1018.86s: now let's look at the left hand side\n1020.42s: which is the activation function\n1022.759s: what we said earlier is we want to have\n1025.28s: some level of nonlinearity here and\n1028.339s: again to mimic the brain what we would\n1030.079s: typically want is we have nothing on the\n1032.36s: left hand side right so if you're below\n1034.1s: some threshold you have no influx or or\n1036.919s: some some some information upstream and\n1040.1s: then you can get to one right you just\n1042.319s: want that typically to be a unit and\n1045.14s: once you pass a threshold so let's say\n1047.179s: when you're above four here then you're\n1048.62s: almost at 100 right so that's basically\n1050.96s: what you would want like some sort of\n1052.64s: activation function kind of the simplest\n1055.1s: type of activation function you could\n1056.96s: have\n1057.799s: which has some level of non-linearity\n1060.14s: and we could always multiply that by\n1062.299s: some weights if we wanted to expand the\n1063.74s: range you know that's no big deal right\n1065.66s: so that if we have uh more range than\n1068.539s: zero to one in terms of the Y output\n1070.52s: here okay and that's going to be a\n1072.32s: typical sigmoid function as I mentioned\n1073.94s: before it's like nicely ba because you\n1075.919s: can also take the derivative it tends to\n1077.96s: be kind of annoying as we'll discuss a\n1080.24s: little bit later so we won't use that so\n1082.16s: much right it can be useful if your data\n1084.98s: is especially between 0 and 1 that's\n1086.84s: kind of nice because it automatically\n1088.58s: puts the data between zero and one but\n1090.86s: beside that we won't use that so much\n1092.66s: right but just to emphasize that this\n1094.82s: was kind of the earlier one that people\n1096.32s: were using because it kind of makes\n1098.059s: sense when we compare that to the human\n1099.919s: brain\n1102.5s: so that's this sigmoid function so\n1106.039s: that's how we write that we're going to\n1107.66s: use tensorflow and especially Keras so\n1110.179s: that's how you actually write that\n1111.559s: activation function in tensorflow here\n1114.02s: that's the shape that we have here and\n1116.179s: at the bottom here is the derivative\n1118.52s: why the derivative you're going to see\n1120.26s: that in a few minutes the derivative is\n1122.24s: actually extremely extremely important\n1123.799s: because it tells you basically how\n1125.96s: sensitive are you in terms of the the\n1128.24s: response of the output to the inputs\n1130.1s: right so that derivative is crucial\n1133.46s: and that's why people kind of moved away\n1135.74s: from that sigmoid function is because\n1137.62s: that derivative is actually going to\n1139.94s: zero on the left hand side and on the\n1141.559s: right hand side so it means that your\n1143.0s: very sensitive close to the you know the\n1145.58s: boundary or the threshold of the\n1146.9s: activation function but you're really\n1148.16s: losing that information on the side what\n1150.74s: this means is that when you're training\n1152.36s: and we'll discuss what it means to be\n1154.16s: training when you're training a neural\n1156.5s: network typically you're losing a lot of\n1158.24s: the information and you can get stuck in\n1160.039s: what we call a local minimum so it\n1161.72s: doesn't work so well those are not ideal\n1163.7s: they tend to be quite insensitive and\n1165.74s: very very sensitive to the initial\n1167.179s: condition and that's why people were\n1169.1s: struggling so much back in the days when\n1170.96s: they were using neural networks okay so\n1172.7s: we won't use them again so much and you\n1175.7s: have kind of a very similar flavor to\n1178.22s: that which is this tangent hyperbolic\n1180.559s: tangents you know very similar it but it\n1182.78s: goes from What minus one to one same\n1185.66s: type of derivative right it goes very\n1188.539s: quickly to zero on the left hand side\n1190.52s: and on the right hand side meaning that\n1191.96s: you're losing any type of sensitivity\n1193.4s: right so you you cannot really tell\n1195.86s: whether the output is going to change\n1198.02s: when you're actually changing the input\n1199.52s: so not ideal\n1201.799s: the one we are going to use a lot is\n1203.36s: actually this one which is uh so simple\n1206.179s: in the end which is this uh Rectify\n1208.64s: linear unit function and it's basically\n1211.28s: very simple right it's a you go from\n1213.26s: zero uh to the left of zero so it's flat\n1216.26s: and then it's a one to one line okay so\n1218.96s: basically you have no response when\n1220.64s: you're below zero and then you just\n1222.559s: follow one to one right so it's like a\n1224.72s: regular regression\n1226.52s: and so it's almost the simplest type of\n1229.34s: nonlinear function you could have right\n1230.9s: it's linear and replicating exactly the\n1233.419s: input when you're to the right hand side\n1234.799s: of zero and to the left there's no\n1236.78s: signal right so it's the simplest type\n1238.7s: of non-linearity you could get uh and\n1241.88s: the derivative of that is basically as\n1244.52s: you would expect zero to the left hand\n1246.62s: side here and then on the right hand\n1249.26s: side is basically one right that's the\n1250.94s: slope right the slope is just one so\n1253.039s: it's again extremely extremely simple\n1254.78s: even for the derivative the advantage\n1257.12s: being that you're always sensitive to\n1259.22s: the input when you're on the right hand\n1260.72s: side right there's never any loss of\n1263.66s: information when you're going to the\n1265.22s: right hand side so that's a big\n1266.66s: advantage\n1268.52s: make sense so that's what people use in\n1272.419s: practice this rectified linear unit uh\n1274.82s: that tends to actually work quite well\n1276.14s: people were worried back in the days\n1278.24s: especially in zero because uh if you\n1280.34s: look at the math I mean it's the\n1281.66s: derivative is actually not non-defining\n1283.46s: zero in practice it doesn't matter okay\n1285.799s: so let's forget about that I was also\n1287.72s: very worried when I looked at that the\n1289.28s: first time but around but it actually\n1291.2s: doesn't matter so let's we'll mostly use\n1293.179s: that okay\n1294.44s: so let's keep that in mind\n1297.14s: yeah\n1301.34s: love quotes about\n1305.059s: things\n1310.34s: exactly yeah\n1313.7s: exactly so so that was made because we\n1316.64s: had those Vanishing gradients so we'll\n1318.08s: talk about that in a minute but because\n1320.299s: of those this sensitivity we are losing\n1322.28s: that sensitivity again on the side and\n1324.86s: here you're only losing that that\n1326.419s: sensitivity on the left hand side and\n1328.159s: you can actually do something about the\n1329.48s: left hand side we'll discuss that also a\n1331.4s: little bit later\n1333.2s: okay so why do you need a\n1336.08s: non-linearities because basically the\n1338.419s: real world is actually non-linear right\n1339.98s: so if you look at some sort of very\n1342.44s: simple clustering here things are not\n1344.659s: just along a straight line right I mean\n1346.28s: you can have Contours that are pretty\n1347.72s: complex so you need to actually capture\n1349.34s: all of that complexity and therefore you\n1351.86s: need to have things that are non-linear\n1353.419s: right to actually capture the real world\n1355.4s: right so if you add here on the left\n1358.1s: hand side a linear activation function\n1360.46s: you could only basically divide that\n1363.08s: world of those two clusters into the\n1365.419s: green here being here and then the the\n1367.34s: red being on the left hand side it\n1369.14s: doesn't work so well right\n1370.82s: in reality what you would need is\n1372.5s: something much more sophisticated that\n1375.08s: tries to go across those different\n1376.58s: clusters okay so make sense that we we\n1379.94s: need some level of nonlinearity whether\n1381.74s: that's for some sort of labeling or\n1384.2s: classification but also if we think\n1386.0s: about a regression problem of course\n1389.72s: okay so uh\n1392.059s: let's look quickly at a couple of\n1394.22s: examples as to what it means you know\n1397.159s: so let's say now that we have uh just\n1399.98s: two Dimensions here X1 and X2 we'll give\n1403.1s: them some weight three and minus two\n1404.6s: here uh we'll explain in a minute how we\n1407.72s: are going to find those weights and then\n1410.419s: at the top you could say remember we\n1411.919s: have this bias right W naught but you\n1414.559s: could say w naught is like w naught\n1416.48s: times one right so I can consider that\n1418.58s: as being another weight right so\n1420.679s: basically you could say I have one X1 X2\n1424.039s: to x n\n1425.299s: multiplied by a bunch of weights and I'm\n1428.059s: gonna pass that into my activation\n1429.919s: function right and that's going to give\n1431.84s: me my answer so let's look at that so\n1434.78s: imagine that you have one three minus\n1437.0s: two so those are the different weights\n1438.799s: so first one being a bias again\n1441.44s: so you pass that through your activation\n1443.539s: function so you will have one plus three\n1446.419s: times X1 minus two times X2 and you're\n1450.559s: going to pass that through your\n1451.7s: activation function right\n1453.32s: so what is that here is that it's\n1455.78s: basically a line right if you remember\n1457.28s: your linear regression so we transform\n1459.62s: this 2D space into a line and we are\n1462.2s: going to act with the activation\n1463.94s: function onto that line so we basically\n1466.28s: reduce the dimensionality when we done\n1468.679s: when we when we did that right so we\n1470.539s: reduce the dimensionality and we are\n1472.1s: going to apply a non-linear function\n1475.4s: ok so that's basically how it looks like\n1477.919s: the space on which we're actually\n1479.6s: working is actually this line and\n1481.82s: whether we actually higher or lower than\n1483.799s: that is going to Define it's basically\n1485.24s: some sort of threshold it's a geometric\n1487.4s: threshold right that we applied right\n1489.5s: depending on on what we have so imagine\n1493.28s: that you have a point here\n1495.2s: minus one and two so you can actually\n1497.78s: compute that you have one plus three\n1499.76s: times minus one minus two times two so\n1503.0s: that's going to be minus six it goes to\n1505.4s: the left hand side of the the activation\n1507.799s: function so we'll be close to zero right\n1509.6s: in that case if we have a sigmoid\n1511.76s: function in particular ok so that's\n1514.7s: basically the idea is that it basically\n1517.039s: is trying to cut the space into two\n1518.9s: parts right what is to the left hand\n1520.76s: side of the activation function and what\n1522.62s: is to the right hand side of the\n1523.82s: activation function so really not more\n1525.74s: than that\n1528.679s: okay so what we can do now is we can\n1531.799s: actually start putting a bunch of\n1533.72s: neurons together so again let's consider\n1537.08s: that as being a bunch of weights\n1539.059s: multiplied by the inputs plus again\n1541.58s: these bias so let's consider that as\n1544.179s: being an input of value one pass that\n1547.7s: through a sum activation and function\n1549.44s: and we can start stacking neurons\n1551.6s: together okay and we're gonna see what\n1553.159s: happens that's going to be the idea\n1556.4s: okay so that's the simplest we can have\n1558.38s: just one single neuron so the neuron is\n1561.5s: going to be again these bias plus the\n1564.02s: the sum we are going to apply the\n1565.64s: activation function and now we are going\n1567.08s: to stack them together to see what's\n1569.0s: going to happen\n1572.9s: so the first thing we can do is\n1574.4s: basically what we call a first a a\n1578.0s: single hidden layer so typically the\n1581.299s: wording that we have is we have what we\n1582.86s: call the input layer here so that's\n1584.96s: going to be the inputs here we're gonna\n1587.539s: have what we call the hidden layer in\n1589.52s: between and then we are going to have\n1591.62s: the output layer on the right hand side\n1593.9s: so typically if you have one hidden\n1595.94s: layer in total you already have three\n1598.22s: layers when you when you're counting\n1600.38s: right so that hidden layer is going to\n1602.779s: be basically the number of latent\n1605.0s: variables that we can adjust to actually\n1606.62s: best fit the data right those are things\n1609.08s: that we can change that are going to be\n1611.179s: in the middle right the input layers and\n1613.7s: the output layers we are not really\n1614.96s: changing right because that's what we\n1617.0s: want to predict and those are the data\n1619.4s: sets or those are the data that we are\n1621.08s: trying to use so we are not really\n1622.159s: changing that so much where we are the\n1624.5s: flexibility is going to be at the core\n1626.12s: here\n1627.32s: in terms of the Hidden layers okay\n1630.02s: and so we can stack multiple hidden\n1633.14s: layers so that's going to be one example\n1634.82s: here with one hidden layer and we are\n1637.7s: going to stack also a bunch of neurons\n1639.5s: right so you're gonna see in the\n1641.539s: notebook we will have basically we could\n1643.58s: adjust the number of neurons and the\n1645.26s: number of hidden layers what we mean by\n1647.299s: the number of neurons is basically the\n1648.799s: width of the of the neural network\n1651.919s: and by the number of hidden layer what\n1653.9s: we mean is the depth of the neural\n1656.0s: network right so width and depths right\n1657.559s: then you could change that to C and\n1659.48s: basically to adjust the number of\n1660.74s: degrees of freedom\n1662.299s: and the important Point here is that you\n1664.94s: can see those are the connections right\n1666.98s: so remember the synapses that we had\n1668.659s: before so here we have three inputs here\n1671.919s: four neurons in that particular example\n1674.659s: but look at the number of connections\n1676.46s: that we have right we have a lot of them\n1678.38s: right it's combinatorial right so you\n1680.9s: have the first neuron that passes\n1682.88s: through all of those four plus this one\n1685.22s: through all of those four and then this\n1686.96s: one through all of those four as well\n1688.46s: right\n1689.24s: and same goes to the output as well\n1691.58s: right so those neurons are connected to\n1693.919s: all of the outputs as well so what it\n1696.08s: means is that when you're starting to\n1697.88s: add a bunch of hidden layers you will\n1700.88s: have a lot and lot of Dimensions right a\n1703.52s: lot a lot of connections right and it's\n1706.58s: pretty obvious as well that a lot of\n1708.08s: them are going to be redundant right in\n1710.179s: some ways right especially when you\n1711.44s: start getting really deep you might\n1713.0s: actually go from the input to the\n1715.159s: outputs from many many different ways\n1717.02s: right and we'll try to find a mechanism\n1719.24s: to avoid that right there might be a lot\n1720.919s: of riddance redundancy actually built\n1722.96s: into into your neural network\n1725.779s: okay so basically what we love is that\n1728.96s: we will have a neural network here\n1731.659s: so what this is actually just a valued\n1734.96s: function here right so let's call that z\n1737.0s: i so that's going to be the neuron here\n1739.4s: so let's say Z3 for instance\n1741.559s: it's going to be the same as before\n1743.12s: right so some weights uh so some some\n1746.72s: bias here W naught for that particular\n1749.72s: case so let's call that three\n1751.82s: plus some specific weight so the weights\n1754.82s: that are connected from the input here\n1757.1s: to that neuron here so we have three of\n1759.799s: them\n1760.52s: they will have some specific weights so\n1763.1s: w one two three\n1765.799s: to that neon number three times the\n1768.559s: inputs right so we have specific weights\n1771.26s: here connected from the left hand side\n1773.779s: to that particular near and that's true\n1776.899s: for each of them right so no all of a\n1779.12s: sudden what we did is we basically built\n1780.919s: we just built uh a metrics here right of\n1784.279s: Weights we have a matrix that depends on\n1787.22s: the size of the input and the size of\n1791.0s: the number of neurons in the hidden\n1792.74s: layer right so it's basically 2D right\n1794.84s: 2D because you have one dimension here\n1797.059s: another dimension here and that's going\n1799.76s: to be true across right so we are going\n1801.86s: to have a matrix here another Matrix\n1804.32s: here if we have some another hidden\n1806.24s: layer etc etc etc right so you will have\n1808.88s: a bunch of Matrix multiplications at the\n1810.62s: end of the day\n1811.94s: does that make sense\n1813.98s: okay and if you remember what we had\n1816.679s: before we had an inner product right we\n1818.299s: had x j times WJ so you could do the\n1821.059s: exact same thing you could write that as\n1822.679s: a vector X transpose and then you have\n1825.74s: basically instead of having just some\n1827.179s: weights you will have a matrix right so\n1829.52s: it's exactly the same except that we\n1831.26s: transform that into a matrix form okay\n1833.659s: so that's what you will have on the\n1835.58s: right hand side\n1836.539s: and now the only subtlety here is that\n1839.299s: we are going to have again this is\n1840.98s: similar to a linear regression right\n1842.6s: this is exactly a linear regression and\n1844.88s: then each individual neuron we are going\n1847.039s: to add this activation function\n1849.26s: typically just to make things simple we\n1851.6s: always use the same activation function\n1853.039s: because it will be a nightmare right you\n1854.48s: could change that across but that's\n1855.62s: going to be a disaster so we typically\n1857.539s: use the exact same activation function\n1860.179s: on each individual neuron so once you\n1863.0s: choose one so let's say rectified linear\n1866.24s: unit use that across right because\n1867.799s: otherwise it's just intractable right\n1869.659s: you don't know what's going on\n1871.52s: make sense\n1873.62s: and then typically at the end what we do\n1875.899s: is very standard practice for a linear\n1878.48s: regression is not to have this uh\n1882.2s: nonlinear activation function but to\n1884.24s: just have a linear regression why\n1886.46s: because we just want to scale the data\n1888.62s: at the end right it could go from say\n1890.299s: minus 20 to 30 or from some other range\n1894.38s: rate but it doesn't always go from zero\n1896.72s: to something right it's not always\n1898.279s: positive right so that's why we\n1900.5s: typically just at the end it's very\n1901.88s: standard practice again to just have a\n1904.22s: linear function right so what we do is\n1906.44s: we basically remove that activation\n1908.899s: function at the end and we just say it's\n1911.36s: going to be just some bias plus some\n1913.399s: weights times the last hidden layer okay\n1916.88s: so what to summarize we'll have a bunch\n1919.64s: of activation functions at the core of\n1921.74s: that so in the heater layer and in the\n1924.02s: last layer just for the output here we\n1926.36s: are not going to use any type of\n1927.799s: activation function just a linear\n1929.84s: regression it makes life much easier\n1932.059s: okay just it scales the data\n1935.539s: does that make sense oh\n1939.2s: fine I'm not using anyone\n1941.779s: Okay so\n1943.82s: now a quick thing is what happens is if\n1946.94s: I transform Gene to a just a linear\n1949.399s: function so remember what we had we we\n1951.62s: said we have\n1954.679s: those G's here but one thing I could do\n1957.44s: is I could actually transform that into\n1960.14s: just a linear function right and you\n1961.88s: will see in the notebook that we have at\n1964.1s: the end what we did is we transformed\n1966.14s: that activation functioning just linear\n1968.899s: so what this means by definition is that\n1972.08s: we are transforming that g to become\n1974.539s: basically\n1976.52s: the identity right so there's nothing\n1979.279s: right so you have your linear regression\n1981.679s: you go to the next pass which is after\n1984.799s: the activation function and this is just\n1986.419s: identity so you can basically get rid of\n1988.34s: that\n1989.299s: so what this means is that it's also\n1992.059s: very standard practice you take your\n1993.32s: neural net\n1994.64s: and you have your activation function\n1996.26s: and you can always transform that back\n1998.179s: into a linear regression right and it's\n2000.399s: super easy to do what you do is you just\n2002.2s: say I take manual net which was pretty\n2004.419s: complex and I just transform my\n2006.94s: activation function and I transform that\n2008.559s: into a linear activation function\n2011.08s: and what it will do implicity is that it\n2013.72s: will put a bunch of Weights here\n2016.48s: a bunch of biases stack them together\n2019.299s: and just take the sum of that and it's\n2021.46s: just a linear regression right so the\n2023.2s: output is going to be a linear\n2024.34s: regression of your input okay but it's\n2026.86s: it's a good way to always check whether\n2029.38s: you're seeing any type of improvement by\n2031.179s: going into a non-linear world right so\n2033.279s: instead of just doing your linear\n2034.96s: regression you could also project as we\n2036.519s: discussed before but that's an easy way\n2038.019s: to check you know you could actually\n2039.039s: have your linear regression so that's\n2040.659s: very standard practice you take your\n2042.64s: neural net and then you just change your\n2045.159s: activation function into a linear one\n2048.399s: makes sense\n2050.679s: any questions so far\n2054.639s: shouldn't be too yeah all right\n2057.7s: it might be just depends in the language\n2059.5s: that we use in social sciences can you\n2061.78s: go back to the image with the inputs\n2065.139s: later\n2068.08s: yeah can you then what's the difference\n2070.839s: between the latent structure you can\n2072.52s: identify and uh\n2074.98s: the outputs\n2076.54s: so the output is what we want to predict\n2078.94s: right so those could be a classification\n2081.58s: problem we want to predict like roads\n2083.5s: and buildings and trees you know on an\n2085.839s: image or it could be a regression we\n2088.06s: want to predict say the temperature in\n2089.679s: New York in 2080 which is what we are\n2092.08s: going to do later\n2093.28s: uh so that's what that's the task right\n2095.679s: that's what we want to predict the input\n2097.9s: is going to be in our particular case\n2099.64s: it's going to be the concentration of\n2101.32s: carbon dioxide\n2102.76s: and then I will have a bunch of things\n2104.74s: and frankly I have no idea what it is\n2107.02s: but we are going to learn that and\n2109.3s: that's why people sometimes don't like\n2110.859s: neuron that's because they said it's a\n2112.359s: black box because we have no idea what\n2114.52s: those neurons are in fact you could\n2116.26s: actually check into that and get into\n2117.64s: the gut we call that\n2119.92s: um trying to get into explainable AI\n2121.96s: trying to get into the gut of your\n2123.64s: neural net and why you got that\n2124.96s: prediction for what reasons but\n2127.06s: typically we don't know we will have\n2128.56s: just a bunch of values that are changing\n2131.619s: as a function of the inputs right\n2133.359s: remember that here those are dependent\n2136.72s: on the inputs right so they are going to\n2138.339s: vary as we've vary the the CO2\n2140.98s: concentration or the methane\n2142.72s: concentration here and we are going to\n2144.76s: add different basically prediction for\n2146.5s: the temperature in New York as a\n2148.42s: function of the time or as a function of\n2150.4s: the concentration\n2151.54s: and that's because those values are\n2154.06s: going to change right they are changing\n2155.5s: because they have weights that are being\n2157.42s: applied but also because we are passing\n2159.4s: sometimes those activation functions as\n2161.2s: well so things can be quite non-linear\n2162.88s: as well\n2165.4s: does that make sense\n2167.26s: but typically we don't know what those\n2168.94s: are so they are just a bunch of and what\n2171.7s: will\n2172.48s: so those values we typically they\n2176.14s: rarely actually look at the values here\n2178.119s: but what we'll try to focus on are going\n2180.7s: to be the weights here okay that's going\n2182.68s: to be the primary thing we'll be\n2184.119s: focusing on today is getting those\n2186.099s: weights so the weights are not going to\n2188.5s: change right so the weights here they\n2191.079s: are they are fixed right once we've\n2193.48s: trained the neural net they are going to\n2194.92s: be fixed what's going to change uh to\n2197.74s: get back to your pen it's going to be\n2198.88s: the inputs right different types of\n2200.8s: images different types of CO2\n2203.14s: concentration so that's going to be the\n2205.0s: thing that changes right and maybe\n2207.22s: that's one thing that's typically a bit\n2209.2s: unusual when we think about neural\n2210.76s: networks is that\n2212.14s: typically we wanna\n2214.06s: fit some regression as a function of the\n2216.52s: input right here what we are trying to\n2218.98s: really fit are the weights right similar\n2221.8s: to a linear regression right we are\n2223.359s: trying to find the right weights or the\n2225.16s: right angle right and that's really at\n2227.92s: the core of the neural network right the\n2229.96s: input sensitivity we don't care so much\n2231.82s: right and that's why\n2233.74s: people never really I mean not directly\n2236.38s: look at the input the sensitivity of the\n2238.359s: output to the input right it's they they\n2240.28s: really care about the sensitivity to the\n2242.2s: weights\n2245.079s: does that make sense yeah\n2255.88s: better with us we are going to see that\n2259.24s: yeah uh so so long story short you know\n2263.32s: um\n2264.04s: so there's actually a theorem that tells\n2266.14s: you that if you have um pretty much an\n2268.0s: infinite number of neurons\n2270.16s: uh even with one hidden layer you can\n2273.339s: basically mimic or replicate any type of\n2275.38s: function you know even the most\n2276.88s: complicated function you know so you can\n2278.44s: actually show in the limit you can you\n2280.18s: can reach that\n2281.32s: and so that's why in the early stage\n2283.78s: especially in the in the 80s and 90s\n2286.18s: people invested a lot of time in like\n2288.22s: expanding the the widths of the of the\n2290.38s: neural network\n2291.579s: uh it's going to be very clear when we\n2294.339s: we are going to look at images you know\n2296.26s: that this is the wrong thing to do\n2297.7s: actually it tends to to lead to very\n2301.48s: overfitted neural Nets and the best\n2303.94s: approach is to actually increase the the\n2305.619s: depths of the neural network and why is\n2308.14s: that is because every time you go\n2310.18s: through another hidden layer you\n2312.46s: actually increase kind of the\n2314.52s: uh the the the the degree of um\n2317.98s: abstraction you know so you can think of\n2320.26s: that like it's very clear in the image\n2322.18s: you know you get from like like some\n2324.16s: diagonals or some crosses or you know\n2326.56s: some squares you bring them together it\n2329.5s: becomes like a near a nose you know and\n2331.72s: then you bring them together it's a face\n2333.22s: you know and then you can change like a\n2334.9s: bunch of faces you know but it's very\n2336.22s: clear that you have a degree and level\n2338.14s: of abstraction that builds in across the\n2340.48s: different layers you know and you become\n2342.28s: more and more abstract you know very\n2343.66s: very low level on the left on the left\n2346.06s: hand side and very very high level on\n2347.8s: the right hand side and so that's why\n2349.839s: people not prefer having you know so\n2351.76s: that's why that was kind of the\n2353.26s: revolution of deep learning right uh\n2355.599s: actually having very deep neural\n2356.92s: networks I mean there's nothing\n2358.74s: sophisticated about deep learning it's\n2360.76s: just a neural net that's deep and what\n2362.859s: is deep you know everyone has different\n2365.2s: uh uh uh um can I say criteria for that\n2368.619s: so I I I'm not a big fan of deep\n2370.839s: learning as a world but anyways the main\n2373.0s: point being that it means that there's\n2374.56s: some degree of abstraction that is built\n2377.2s: in\n2380.8s: any other questions\n2384.64s: fine okay\n2387.46s: okay so basically then the idea is that\n2390.4s: you can extend that right there's\n2392.02s: nothing that prevents you from getting\n2394.18s: back to your opinion so you have again\n2396.16s: this uh hidden layer here and we can\n2398.8s: basically stack a bunch of them right\n2400.48s: it's uh\n2402.52s: as easy as it gets you know and so\n2405.28s: the way it's going to be done in chaos\n2407.56s: we are going to see that later is we are\n2409.18s: going to call that a dense layer why\n2412.599s: because it means we are connecting every\n2414.64s: neuron on the left hand side to every\n2416.92s: neuron on the right hand side right so\n2418.48s: there's a connection here\n2420.52s: going from that particular neuron to all\n2424.0s: the neurons in the later uh hidden layer\n2426.88s: right so that's what we mean by dense\n2428.8s: right we are connecting everything\n2430.9s: from the layer ahead to the layer uh\n2434.44s: after that right\n2435.88s: make sense\n2437.32s: so dance is something we should remember\n2439.78s: we are going to use that okay and in\n2442.119s: fact in Keras you're going to see it's\n2443.44s: very simple we are going to Define that\n2444.82s: as a model we are going to just add\n2447.04s: layers and we're going to say that's\n2448.42s: going to be a dense layer and it's going\n2450.94s: to take us input the previous layer and\n2453.94s: the output is going to be the next layer\n2455.619s: right so it's going to be really really\n2456.88s: easy to build right it's almost like\n2458.52s: geometric you know you would see\n2462.099s: and you can stack a bunch of them right\n2464.859s: so now you could have as many hidden\n2468.4s: layers as you want right I mean nothing\n2470.619s: prevents you from doing that and again\n2472.48s: you will actually have higher and higher\n2475.0s: levels of abstraction as you get to the\n2477.76s: right hand side\n2478.96s: now of course I mean it's a trade-off\n2481.359s: right I mean it depends on the size of\n2482.74s: your data set like think of that like\n2484.839s: every connection here is basically one\n2486.64s: weight right plus the bias but let's\n2488.8s: mostly focus on the weight it's\n2490.72s: basically one degree of Freedom right so\n2492.46s: remember your linear algebra when you\n2495.16s: have a linear regression if you have a\n2497.8s: data set of Dimension 10 you have 10\n2499.599s: data points not sure you want to get to\n2501.579s: more than Dimension 10 right because you\n2503.5s: cannot refit those weights right so it's\n2505.78s: a trade-off right like what is the\n2507.28s: dimension of the neural net that you're\n2509.74s: going to use it also depends on the size\n2511.54s: of the data set right\n2513.16s: and so that's going to be a lot of the\n2515.5s: trade-off that we we have we'll also\n2517.72s: discuss that in a minute is how can we\n2520.24s: actually find those weights and that can\n2522.579s: be a one of the roadblocks that we have\n2524.44s: okay so that could be also an issue\n2529.66s: okay and so that's one example I I gave\n2532.48s: in my class is that you know you could\n2534.22s: have some very simple predictors like X1\n2536.44s: is the number of lectures you attended\n2538.18s: the number of hours that you spend on\n2540.28s: the final project and then those are the\n2542.68s: that's the data set that you have right\n2544.42s: and so one thing that's actually very\n2546.579s: important in uh machine learning is that\n2549.28s: we are reversing the approach right in\n2552.22s: the sense that you know back in the days\n2553.96s: people were cutting say you know if I\n2557.2s: pass through that then do that you know\n2558.94s: those were a bunch of if statements you\n2560.619s: know that's where where you know\n2561.7s: especially in chess you know people say\n2563.14s: if the king does that or if the queen\n2565.3s: does that then do that right that's how\n2567.46s: people were actually playing chess right\n2568.9s: or they were programming uh video games\n2572.2s: what we are doing here is the converse\n2574.3s: we are saying I've seen some data or\n2577.359s: I've being exposed to some particular\n2579.76s: examples of Chess or the go games where\n2582.46s: revolutions with machine learning\n2584.02s: because people never train the machine\n2586.96s: to actually play chess right there was\n2589.119s: no code saying you know if the king or\n2591.4s: the queen does that you do that right\n2593.079s: but instead they said let's look at some\n2595.3s: game and let's learn from the game right\n2597.76s: and that's what we are trying to do we\n2600.04s: are looking at some data and we want to\n2602.14s: learn the game right we want to learn\n2603.7s: the code we want to learn the script\n2605.26s: right so we are reversing the approach\n2607.599s: right we are not imposing the script we\n2609.7s: are learning directly from the data so\n2611.2s: it's really a reverse engineering things\n2613.0s: right and people showed that it's\n2615.46s: actually way more powerful because\n2617.099s: oftentimes you don't know the rules\n2619.06s: right for instance the Go game is\n2620.92s: actually very very complex right you\n2622.359s: cannot code all of the cases you've\n2624.099s: never seen that you will never see that\n2625.54s: in your life but you can actually learn\n2627.819s: from the data right so maybe if you've\n2629.619s: seen a lot of games and what you can\n2631.78s: even do is actually have uh computers\n2634.66s: placed against computer so you can\n2636.339s: generate data but in that case you're\n2638.859s: actually being exposed to data and you\n2640.66s: want to learn the rules based on just\n2642.46s: seeing the the data you know that's what\n2644.38s: we are doing with machine learning\n2645.579s: you're seeing data you want to learn the\n2647.619s: the the code you want to learn the\n2649.48s: script based on the data so in that case\n2651.46s: the simplest case you want to learn the\n2653.8s: Clusters based on the data right you\n2655.48s: have something data you want to learn\n2657.16s: the rule right and you don't know the\n2658.78s: rule a priority okay so that's basically\n2661.359s: the data set that we have this is what\n2662.859s: we will call our training data right so\n2665.02s: we have some fading here some students\n2668.079s: that pass and we want to basically kind\n2670.599s: of do some sort of classification here\n2673.9s: so let's say that we have a point here\n2676.72s: four five we want to say that this is\n2679.54s: going to be a pass right because it's\n2681.28s: within that cluster right but how can\n2683.68s: you do that that's going to be the\n2684.819s: question right how can you infer that\n2686.859s: just by seeing the data here is going to\n2689.98s: be the main question we're trying to\n2691.48s: address\n2694.42s: okay so how can we can we do that\n2698.14s: we have this new data point here four\n2700.24s: five so you can think of that those are\n2702.76s: two inputs right X1 and X2\n2705.04s: we pass that through some neural network\n2707.079s: the dimension doesn't really matter here\n2709.359s: and we are making a prediction\n2711.04s: prediction is very simple here it's\n2712.78s: binary zero or one zero you failed one\n2715.599s: you pass the class right\n2717.52s: and what we are trying to do is like you\n2720.099s: could say I passed that through my\n2722.26s: neural network\n2723.579s: remember that my neural network has a\n2725.56s: bunch of Weights let's assume that they\n2727.18s: are given to us right we don't know\n2729.099s: anything at this stage but we have a\n2731.079s: bunch of Weights we pass that through\n2732.52s: that we have some nonlinear activation\n2734.5s: function and the prediction we are\n2736.66s: getting is 0.1 right\n2738.94s: it's not that great right because if we\n2741.4s: look at the Clusters nearby right we can\n2744.099s: look and it looks more like a pass right\n2745.9s: so it looks more like a one right so we\n2747.76s: would want to minimize\n2749.68s: some sort of distance right we want to\n2751.96s: minimize the loss we want to be as close\n2753.64s: as possible to one right so that's going\n2756.099s: to be the primary thing we want to do\n2758.14s: here\n2759.28s: okay so it means that we first need to\n2762.76s: do one thing which is to define a loss\n2764.92s: that's going to be very important same\n2766.9s: goes for the exercise that we will be\n2769.3s: doing later we Define a loss which is\n2772.66s: some sort of distance\n2774.46s: between\n2775.78s: the prediction that we have so the Y hat\n2778.06s: we go that's a complicated way to put it\n2780.94s: so it's a function of the input here of\n2783.28s: the weights as well those are some\n2784.66s: parameters right they are the parameters\n2786.4s: of the neural net and we are looking at\n2788.8s: a distance compared to the actual I\n2791.5s: don't want to call that a distance\n2792.579s: because you know if you get into the\n2794.38s: weeds sometimes they don't have a\n2795.819s: property of a distance but but the main\n2798.22s: point being it's a loss right it's we're\n2800.02s: trying to measure the discrepancy\n2801.76s: between the prediction and the actual\n2803.619s: value right and of course what you would\n2805.96s: want to do is you would want to minimize\n2807.579s: that right so typically we want to\n2809.26s: minimize the loss we want to actually\n2811.24s: try and mimic the data set as close as\n2813.88s: we can as possible\n2815.8s: make sense so what can we do in that\n2818.859s: case right so it means that first the\n2821.26s: neural network that we had was not great\n2822.76s: right it's a pretty bad model it's a bad\n2825.46s: predictive model right so what can we do\n2827.68s: to improve that\n2830.619s: sorry\n2832.06s: oh you're too fast yeah yeah so what do\n2834.819s: we need to do\n2839.319s: exactly we need to change those weights\n2841.359s: right so it means that think of a\n2843.22s: regression problem right so you have\n2845.26s: some weights the weights were not great\n2847.119s: right they were not really the right\n2848.68s: ones so we need to adjust those weights\n2850.42s: so that's going to be what we will call\n2851.98s: the training right so the training\n2854.38s: depends importantly on a loss right we\n2856.66s: need to define a loss that's the\n2858.4s: objective function we want to minimize\n2859.96s: once we have that we are going to try\n2862.54s: and use the weight\n2864.099s: the important thing here is that\n2866.02s: sometimes people are confused in the\n2867.94s: sense that\n2869.02s: we are going to be exposed to a bunch of\n2870.94s: data sets right so the X's are going to\n2872.98s: change right so we'll have multiple\n2874.96s: points for the loss right so not just\n2876.579s: one point but many losses or lost terms\n2879.76s: and the one thing we're adjusting are\n2882.099s: not the inputs right the input is given\n2884.319s: to us again that's part of our data set\n2886.06s: we have some labeled data where we have\n2888.22s: the output and we have the inputs right\n2889.839s: we know if it's a path or fell and we\n2892.42s: know how many hours they spent right but\n2895.42s: the only thing we can change is the\n2896.92s: inner gut of the neural network right we\n2899.98s: can only change the weights here\n2902.92s: make sense so we are not changing the\n2905.2s: input and the output right so not the\n2907.3s: x's and the Y's we are just changing the\n2909.28s: weights we are tuning the regression\n2912.04s: right we are tuning those slopes right\n2913.78s: and we need to do that in an efficient\n2916.0s: way okay and that's basically one of the\n2918.52s: revolution of you know that of a machine\n2920.5s: learning\n2921.7s: makes sense or any questions here\n2928.18s: okay so so basically another way to\n2931.96s: frame that is that we have a loss that\n2935.8s: depends on the weights right so that's\n2937.48s: really what what what what we care about\n2939.46s: right that loss is going to be depending\n2941.319s: on the weights and you can call that in\n2944.44s: many many different ways like it's an\n2946.06s: objective function it's a loss it's a\n2948.52s: cost function sometimes it's called\n2950.02s: empirical risk in economics and\n2952.78s: basically we're looking typically at\n2955.66s: the mismatch right so that's a loss and\n2958.54s: typically the mean value of that so\n2960.64s: could be squared of the error and we\n2963.7s: take the mean of that or it could be the\n2966.16s: absolute error right so depending on\n2967.96s: what you care about or it could be the\n2969.819s: accuracy you know depending on what you\n2971.5s: what you want to look at you know\n2972.94s: depending on the type of problem but the\n2974.74s: main point is that\n2976.119s: we will have a bunch of label data and\n2980.14s: this is our initial prediction point one\n2981.94s: that's the truth one here's our second\n2984.579s: prediction point eight for another data\n2986.8s: point which is two one\n2988.54s: and the result here is zero then the\n2991.06s: third one that we have is five eight and\n2993.28s: then we want to predict 0.6 or we want\n2995.38s: to predict one and we got point six\n2996.7s: right so let's tune those weights to\n2998.92s: best match\n3000.119s: the the actual observations here\n3003.119s: make sense so that's going to be the\n3005.46s: goal here is trying to actually reduce\n3007.98s: the mismatch between the prediction that\n3010.14s: we have here and the actual one okay so\n3013.02s: trying to improve the prediction that we\n3014.94s: have with the neural network\n3020.06s: okay so in that particular example no\n3024.3s: need to get into the weeds but this is\n3027.0s: what we call the cross entropy so when\n3028.68s: you have a classification task that's\n3031.56s: the typical type of uh of uh loss that\n3035.46s: you use\n3036.359s: and that's coming from information\n3038.16s: theories and no need to think too much\n3039.96s: about that that's kind of like a\n3041.28s: probability log of the probability so\n3043.319s: that's what we are trying to minimize we\n3044.94s: are trying to minimize the mismatch in\n3047.339s: terms of how frequently we got those\n3049.859s: correctly or incorrectly right so we\n3052.02s: have that here so this is the prediction\n3056.22s: here oh sorry that's the actual here\n3058.559s: this is the predicted here so it's like\n3060.839s: probability log of probability and we\n3063.42s: want to also get the converse right not\n3065.04s: just the truth but also what was\n3066.54s: mistaken right so the false\n3068.88s: classification so we also do one minus\n3071.52s: the actual log of 1 minus the prediction\n3074.579s: okay\n3075.72s: don't need to think too much about that\n3077.4s: but basically what it means is that when\n3079.619s: it's binary between zero and one you can\n3081.18s: think of that as a probability and we\n3083.52s: are trying to basically\n3086.18s: maximize uh the the the prediction as\n3089.819s: much as possible and you can mimic\n3091.619s: basically what we Define as the entropy\n3094.2s: in uh information Theory which is minus\n3097.2s: the probability or log probability this\n3099.0s: is the entropy so we are trying to\n3100.2s: minimize the entropy of the system\n3102.78s: okay no need to get too much into that\n3104.64s: yeah\n3115.559s: yeah so uh so the prediction is going to\n3119.099s: change as a function of the weight and\n3121.559s: same here right so that's for the actual\n3124.14s: prediction in the mismatch here so we\n3125.76s: are trying to improve the accuracy in\n3127.26s: that case and what we are trying to do\n3129.24s: is we are trying to minimize that loss\n3131.16s: by adjusting those weights okay so we\n3133.619s: are trying to get the best match to the\n3136.14s: to the observations using those\n3138.059s: predictions\n3141.72s: for another mix of data is this the same\n3145.8s: subject to generalize\n3147.66s: so that's a great question so we are\n3150.059s: gonna talk about that a little bit later\n3152.16s: but so\n3153.3s: that loss is you're right on that\n3155.64s: particular data set and typically what\n3157.68s: we will do is we will\n3159.24s: take the entire data set we will split\n3161.46s: that into some fraction which which will\n3164.46s: be called training data typically 80 or\n3166.74s: 70 and then the rest which will be\n3169.2s: called validation\n3170.7s: and we'll use that to make sure we are\n3172.559s: not overdoing the job right because it\n3174.359s: will be super easy to go through every\n3175.92s: single point right but then you might\n3178.079s: and we talk about that later but you\n3179.64s: might be overfeeding and so that\n3181.74s: validation is test is uh test set is\n3185.16s: going to be used to check that we are\n3186.54s: not overheating too much yeah that's a\n3188.4s: great point\n3189.3s: but you're right we'll assume that we\n3191.4s: are Computing that loss on\n3193.98s: some fraction of the entire data set\n3195.96s: which will be called the training data\n3200.24s: uh just to conclude very quickly so in\n3204.48s: the end it's very easy to do actually in\n3205.859s: tensorflow right so there's no need to\n3207.359s: compute these compute a very complex\n3209.04s: laws if you have a classification\n3211.319s: problem you're going to use this soft\n3213.24s: Max cross entropy so that's what I meant\n3215.339s: is that when you have a classification\n3217.319s: task we are going to use that type of\n3219.42s: loss so we want to make sure we are\n3220.859s: getting the classes right\n3222.66s: and we are going to get just the mean of\n3224.579s: that right the average across the entire\n3226.44s: data set so that's the way you write\n3227.88s: that okay so that's going to be your\n3229.2s: loss between the model Y and the model\n3233.52s: prediction so model Y is actually the\n3235.74s: label data\n3237.0s: and model prediction is the prediction\n3238.92s: right so that's basically the loss we\n3241.2s: are trying to minimize here the average\n3243.18s: cross entropy between the actual label\n3246.54s: data and the prediction right the\n3248.099s: mismatch\n3249.119s: and when it's a regression we are going\n3250.98s: to replace that by the mean squared\n3252.78s: error typically right what is the\n3254.819s: basically the the the the difference\n3256.74s: that we have along the y-axis okay so\n3259.319s: that's going to be pretty simple\n3261.9s: okay so for regression problem that's\n3264.059s: going to be that you have the actual\n3266.22s: value here you have the prediction there\n3268.02s: so that's your y hat if you will which\n3270.359s: is on the right hand side here in that\n3272.4s: case it can take any type of values\n3274.079s: right any type of real value uh\n3276.78s: characteristics here so that could be\n3278.22s: for instance the final grade that we are\n3279.9s: trying to predict so we are trying to be\n3281.28s: a bit more granular the prediction here\n3283.5s: is 13 so 90 80 instead of 20 85 in terms\n3287.579s: of 95 and we want to optimize that right\n3290.099s: we want to minimize the distance here\n3292.38s: and the typical one we are going to use\n3294.96s: is going to be the mean Square there so\n3296.94s: the distance here so this is the error\n3299.76s: and we don't care whether it's a\n3301.38s: negative or positive value right so\n3303.359s: that's why we take the square of that\n3305.28s: and we take just the average right we\n3307.26s: just want to take the average mistake\n3309.42s: right and so that's basically how we\n3311.579s: we're going to do that so that's going\n3312.9s: to be the mean of the mean Square there\n3314.94s: in fact there's a even an easier way to\n3316.8s: write that so that's the mean squared\n3318.78s: error between again the prediction and\n3321.18s: the model uh the the model label data\n3324.059s: okay so that's what we are trying to\n3326.099s: minimize Z of our regression problem and\n3327.9s: again when you have a classification\n3329.7s: task that's going to be just that here\n3331.8s: okay so we are mostly going to focus on\n3334.2s: those two and that's going to be the the\n3336.54s: last is we want to minimize\n3339.839s: make sense okay so now the rest of the\n3343.619s: class really is going to be\n3346.2s: how we actually get those weights right\n3348.72s: right so the prediction is bad and so\n3351.3s: what we want to do is we want to improve\n3352.68s: the prediction right that's kind of the\n3354.24s: ultimate objective here\n3356.16s: and so you can write that in\n3358.88s: mathematical terms what we want is we\n3361.2s: want to find the best weights right and\n3364.079s: the best set of Weights typically we\n3366.359s: call that in mathematical forms as W\n3369.54s: star which are the ways that are\n3372.78s: minimizing the loss however we Define\n3374.819s: our loss\n3376.14s: and we we typically write that as admin\n3378.96s: right the weights that are minimizing\n3380.76s: the loss that's what we want right so\n3383.64s: first word of conscious conscious here\n3386.7s: is that question here is that\n3389.7s: the there's not one single set of w\n3392.88s: store okay so that's the typical mistake\n3394.98s: people say oh I have the best new on\n3396.48s: that that's wrong okay it doesn't exist\n3398.88s: okay uh so typically what you'll find is\n3401.64s: that you'll retraining on your net and\n3403.38s: you'll get different weights and they\n3404.94s: are equally good in terms of the loss\n3407.4s: and again why is that is because if\n3409.5s: remember there's a lot of connections\n3411.359s: right and so there's a lot of redundancy\n3413.819s: so you can get the same results for many\n3416.04s: different reasons right uh and so that's\n3418.859s: why you always need to be careful\n3420.72s: because it means that when you want to\n3422.099s: explain your results you could actually\n3424.02s: get the same response for many different\n3426.079s: uh reasons right so that's the\n3428.819s: unfortunate truth about neural networks\n3430.559s: right so that's one thing to to put in\n3433.38s: mind is that it's a beautiful way to\n3435.359s: write it but it's wrong in a sense\n3436.859s: because there's not a single uh set of\n3439.38s: Weights that's better than the other\n3440.579s: ones\n3441.359s: and why is that is that typically if you\n3445.26s: look that's typical shape of a loss\n3448.26s: function it's actually a real one here\n3450.359s: just in two Dimensions right and you can\n3453.0s: see it's already pretty complex and what\n3454.559s: we want remember this is the loss here\n3456.96s: as a function of those weights on a\n3459.119s: particular data set here so that's to\n3461.16s: get back to your point that's on a\n3462.42s: particular data set on the training data\n3464.099s: that's the shape of your loss and those\n3466.92s: are the minimal points right so they are\n3468.78s: almost equally good right\n3471.24s: but the main point is that we are in two\n3472.859s: Dimensions only right typically we will\n3474.72s: have to deal with millions of degrees of\n3476.28s: freedom and so you can imagine the\n3478.5s: complexity of this loss function right\n3480.54s: and what we will want to do is we'll\n3482.099s: just want to get to that minimal value\n3485.04s: here okay\n3486.18s: okay and we'll see that we have many\n3488.28s: many uh good Minima that can actually\n3491.28s: minimize this loss that's going to be\n3493.02s: the trouble\n3494.52s: it's not typically an issue but you know\n3496.74s: it means that the best neural networks\n3499.38s: are typically non-unique right you have\n3501.059s: many many neural networks that are\n3502.619s: equally good right and sometimes you're\n3504.42s: lucky and sometimes you're not right you\n3506.46s: run your algorithm and sometimes you get\n3508.02s: a great result so keep it you know and\n3510.18s: sometimes it doesn't work you know it\n3511.74s: just fails you can never train in just\n3513.839s: bad luck right so at least part of that\n3515.819s: right\n3517.799s: okay so now what we want to do is that\n3520.799s: basically if you look at that shape what\n3522.54s: we want to do is we want to get there\n3523.799s: right this is the minimum that's\n3525.9s: basically the point that's minimizing\n3528.42s: the loss so we want to get to this\n3529.859s: weight here and to that weight here\n3532.02s: right\n3533.099s: and imagine we are starting at the top\n3535.38s: okay so that's where we are going to get\n3537.18s: started so we are starting here\n3539.22s: so how do we get down here\n3542.46s: and people who know uh neural networks\n3544.92s: please don't answer\n3547.2s: so how do you get down\n3555.059s: any idea\n3557.339s: so again what we want to do is we want\n3559.92s: to minimize the loss\n3562.799s: how do you minimize something\n3566.7s: that would be\n3569.04s: derivative 101 yeah\n3574.02s: exactly\n3575.819s: so that's right yeah so I'm taking the\n3578.339s: gradients here but it goes up right so\n3580.98s: that's the gradient of the weight right\n3582.599s: and it's in 2D right we write it this\n3585.0s: way so that's the gradient of the loss\n3587.28s: with respect to the weights but dww is a\n3590.52s: vector so if you've done that does it if\n3592.319s: you've never done that doesn't really\n3593.7s: matter but it's in 2D right you take the\n3595.26s: gradient along W naught and the gradient\n3597.96s: along W one and it's in 2D right you can\n3600.72s: do it in N dimensions\n3603.0s: but now you're not going going to the\n3605.099s: right direction right\n3606.839s: so what you do now\n3613.559s: sorry\n3614.88s: yeah you go the other direction\n3617.04s: sounds simple\n3618.96s: but no you're too fast right so what do\n3621.18s: you do it's actually written here\n3624.9s: so\n3628.5s: Yeah so basically that gradient\n3630.54s: typically is too big right the error if\n3632.579s: you look at that because we're just at\n3634.619s: the very top here but you know when you\n3636.42s: get to the bottom here you know you need\n3638.52s: to go kind of slow or write them it's\n3640.26s: like descending along down a battery I\n3642.42s: mean you can start running but at the\n3643.619s: end you better be careful you're going\n3645.0s: to be falling into the river so you want\n3646.98s: to decelerate right so typically you\n3649.92s: want to go down but you want to go down\n3652.14s: not so fast right otherwise you're gonna\n3654.059s: be jumping back and forth right so\n3656.339s: that's typically the thing is that you\n3658.319s: go to the opposite direction and you\n3661.559s: don't go the full way which is going to\n3663.72s: be one you take a fraction of one and\n3666.18s: that fraction is going to be to be what\n3668.04s: we will call\n3669.18s: so that's going to be this parameter\n3670.859s: here we are going to call that the\n3672.9s: learning rate very important for the\n3675.0s: competition later so pay attention to\n3677.22s: this guy a learning rate is really\n3679.14s: important right so it's basically how\n3680.7s: quickly you descend if you're too fast\n3682.98s: you're going to be bouncing back and\n3685.74s: forth right so sorry we're gonna oh\n3689.579s: if you go too fast imagine I take a\n3691.619s: really big learning rate so I will be\n3693.18s: going down and then I bounce back I will\n3695.46s: be bouncing back and forth if I'm too\n3697.92s: slow you know it takes forever you know\n3699.839s: so when I start my algorithm I might\n3702.48s: stop here you know I never managed to\n3704.16s: actually get down the battery right so\n3705.66s: there's some threshold right there are\n3707.88s: some better value and it depends on the\n3709.619s: type of problem you're looking at and\n3711.0s: the complexity\n3717.359s: so what it means is that the learning\n3719.46s: rate is going to be what we will call a\n3720.96s: hyper parameter it's something that we\n3722.88s: need to tweak and tune and that's\n3724.2s: something we are going to do in the\n3725.46s: notebook and that's going to be\n3727.619s: affecting the quality of your results\n3729.24s: and actually that's an important comment\n3731.339s: is that when people say oh I I managed\n3733.98s: to fit this neural net to me it means\n3735.839s: nothing right okay give me a neural net\n3738.0s: it means nothing right what is the\n3739.92s: number of neurons that you used what is\n3741.72s: the number of hidden layers that you use\n3743.339s: what is the learning rate those are the\n3745.68s: what we call the hyper parameters what\n3747.24s: is the activation function that you use\n3748.98s: those are the important points someone\n3751.02s: reporting in a paper on your network and\n3753.839s: say oh I figured that your network to my\n3756.359s: data I mean to me I would reject the\n3758.819s: paper it doesn't mean anything okay what\n3761.64s: is useful is knowing what is the\n3763.5s: structure of your neural network what\n3765.299s: were the hyper parameters so those hyper\n3767.52s: parameters again the number of neurons\n3769.619s: number of hidden layers the learning\n3771.18s: rate\n3772.5s: um\n3773.579s: even the activation function and the\n3775.799s: activation function those are the things\n3777.42s: you can change to best fit your data\n3779.52s: okay and those are the things you report\n3781.2s: in the paper okay you can actually\n3784.14s: automatize that you can actually find\n3786.059s: the optimal one so there are some really\n3787.92s: nice toolboxes one is called up tuna and\n3791.04s: they try to do the job for you to find\n3792.9s: those hyper parameters so the best\n3794.4s: number of neurons the best number of\n3796.44s: hidden layers best learning rate etc etc\n3799.44s: we are not going to use that today\n3800.76s: otherwise you will be winning of course\n3802.44s: the competition yeah\n3809.22s: idea of the\n3813.66s: solitude\n3815.819s: I imagine you could also\n3825.42s: yeah so so\n3827.579s: that was a lot of the issues in the\n3829.799s: early\n3830.76s: um early stage especially when people\n3832.619s: are those Sigma activation functions\n3835.68s: right they could actually typically\n3837.66s: things were extremely dependent on where\n3840.059s: you were starting from from the initial\n3841.74s: condition right and that led to a lot of\n3844.2s: stochasticity so so you had a bunch of\n3846.059s: papers looking at the the impact of\n3848.46s: initial condition in your network for\n3850.2s: the training but a lot of that is gone\n3852.48s: now that people use those rectified\n3854.52s: linear units they are way more stable so\n3857.4s: it means that you'd better be pretty\n3859.74s: unlucky to not fit correctly your data\n3861.78s: if you do it the right way in terms of\n3863.46s: like learning rate Etc but typically you\n3865.859s: will get a fit every single time a\n3867.78s: pretty decent one you know I mean\n3869.04s: sometimes you can be unlucky you know\n3870.599s: I'm sure way way will complain if I say\n3872.7s: that every time you get a good fit but\n3874.46s: uh but but most of the time it works\n3877.14s: right whereas back in the days before\n3879.119s: people were running a bunch of them and\n3881.04s: that was adding to the cost no it\n3883.14s: doesn't work so I mean we don't really\n3884.819s: have that issue because we are never\n3886.559s: getting those The Vanishing gradients as\n3889.2s: we'll discuss in a minute\n3891.96s: okay but but uh long story short it's\n3894.599s: very important to get those hyper\n3895.92s: parameters right so number of neurons\n3897.54s: again hidden layers activation function\n3899.819s: and learning rate okay so those are the\n3901.92s: at least the four that you should pay\n3903.42s: attention to\n3912.42s: up tuna o p t u n a there's another one\n3917.04s: actually from a collaborator at UC\n3918.78s: Irvine\n3919.859s: um so I'm blanking on the name now\n3922.46s: ah oh I'll remember but that's for pie\n3925.859s: torch optimize typically typically for\n3927.96s: tensorflow\n3930.24s: uh there's another one also uh uh yeah I\n3933.66s: can send you a bench there's like three\n3935.28s: or four now that are very typical to\n3937.5s: actually optimize those yeah\n3941.46s: uh okay so let's try to just to make\n3945.119s: sure we have time so basically the way\n3947.28s: it works is you initialize your weight\n3948.96s: to get back to your power engineers\n3950.28s: right you initialize your weight that\n3952.319s: used to be very important it's not so\n3954.599s: important anymore uh\n3956.64s: and then what you do is you start from\n3958.619s: there you will have a big mismatch of\n3960.48s: course right because it's a completely\n3961.799s: random neural network right so you're\n3963.48s: off and now you're trying to reduce your\n3966.059s: offset right to your mismatch and you do\n3968.88s: that by first Computing your loss\n3971.64s: and you compute the gradient to the loss\n3973.92s: right what if you were going in that\n3975.66s: particular direction along the weights\n3977.64s: will that increase or decrease your\n3979.559s: weights and then you multiply\n3982.26s: that gradient by a learning rate and you\n3985.44s: will adjust your weights okay so you go\n3987.78s: down gradient of that that\n3990.359s: um\n3991.92s: function that we saw here we just\n3994.44s: multiply the initial weights by some\n3997.319s: learning rate and we add that and we\n3999.599s: will try to get here okay that's just\n4001.64s: what we do okay so in the end it's\n4004.76s: actually not that complicated right so\n4006.26s: we what we are trying to do is we take a\n4008.72s: gradient of the loss that depends on the\n4011.66s: weight multiply that by a learning rate\n4014.059s: add that to the weights and that will be\n4016.76s: the update of the weight we recompute\n4018.74s: the loss and we do that again and again\n4020.539s: and again until we are satisfied right\n4022.7s: and what we mean by being satisfied is\n4025.039s: we see that the loss basically is\n4026.96s: splattering there's no change so there's\n4029.24s: no need to bother continuing the process\n4031.039s: right so we just start right I mean we\n4033.26s: can be basically within the noise or it\n4035.18s: means that we cannot exactly exactly fit\n4037.7s: the data with the neural network so\n4039.38s: let's just stop okay\n4042.14s: fine\n4043.579s: so what is complicated here\n4048.619s: so what's the main trick here or what's\n4050.539s: the main issue now\n4052.64s: so we know how to get down right so we\n4054.799s: know we have this algorithm here so\n4056.66s: pretty simple in the end\n4058.339s: but what is complicated\n4061.94s: sorry\n4063.68s: we said that sorry\n4066.14s: yeah that's true the dimensions are\n4068.119s: pretty uh complex you can have millions\n4070.039s: of degrees of freedom so in fact the\n4071.42s: weights here are not just two Dimensions\n4073.16s: I showed you 2D but in fact typically\n4075.38s: you have millions of degrees of freedom\n4077.18s: right so what is an issue\n4080.72s: that's why we do mini batch\n4083.059s: yeah\n4087.68s: but\n4089.9s: what about that\n4095.059s: yeah but\n4096.199s: even simpler than that how do you get\n4098.48s: that\n4101.48s: I mean it's it's a gradient right\n4104.06s: but it's complicated right I mean\n4106.699s: it's a gradient of something remember\n4108.38s: like I mean we have to\n4110.96s: I mean I don't want to be annoying here\n4113.06s: but you know\n4114.56s: let's imagine I'm the first neuron\n4117.259s: I want to know the dependent\n4120.799s: at the end here as a function of the\n4123.44s: weight of the in the early stage right\n4125.42s: kind of annoying right\n4128.06s: right so we need to have a trick to\n4129.799s: compute those gradients right they are\n4131.66s: actually complicated but there's a nice\n4133.699s: trick which was just mentioned now which\n4137.12s: is to use chains row right so\n4140.12s: how does it work we want to minimize\n4142.219s: that plus\n4143.42s: remember the loss is just a function of\n4145.699s: the prediction y hat right so can be the\n4149.54s: mean Square there again this cross\n4151.04s: entropy doesn't really matter that much\n4153.739s: but that y hat will depend on a bunch of\n4156.98s: weights right\n4158.48s: and what we can do is we can actually do\n4160.46s: that backward right we can say in fact\n4162.319s: my prediction here depends on the last\n4164.839s: neuron I saw right and there was a\n4168.02s: weight here connecting Z1 to Y hat and\n4171.14s: it had a way to W2 right so there's a\n4173.779s: sensitivity here\n4175.219s: and then before that there was a way W1\n4178.94s: that was affecting that Z1 right so if I\n4181.94s: want to know first the sensitivity to W2\n4185.48s: right\n4186.679s: it's pretty straightforward right so I\n4189.14s: want to know in that particular case\n4190.64s: because I need to tweak and tune and get\n4192.799s: that gradient here what's the\n4194.78s: sensitivity of the loss to W2 okay so\n4197.66s: just change row right uh very simple\n4200.48s: because uh did the loss depends directly\n4204.8s: on the prediction so this is something\n4206.48s: we know right it's the shape right of\n4209.0s: the of the loss\n4210.38s: mean Square there so it's two times the\n4213.199s: absolute value of y minus y hat so we\n4215.48s: know that right so it's straightforward\n4216.92s: to find we can know that actually\n4219.14s: analytically right straightforward\n4221.54s: and then we just need to get the\n4223.219s: gradient of Y hat to W2\n4226.04s: okay but remember we are almost like a\n4228.62s: linear regression right especially if we\n4230.179s: use a Rectify linear unit\n4232.159s: if we are to the right of zero\n4235.46s: y hat and the sensitivity to W2 are just\n4239.179s: going to be Z1 right\n4241.82s: and then if you're to the left of that\n4243.679s: the sensitivity is zero right so it's\n4245.36s: really straightforward to get that it's\n4247.04s: just the activation function right so\n4249.44s: this uh\n4251.54s: gradient or sensitivity is actually\n4253.28s: really straightforward right so it's\n4255.38s: just uh just this zero or one right\n4260.12s: and then we can actually go forward\n4262.4s: right we could say let's look at the\n4264.14s: sensitivity to W1 which is ahead of that\n4266.42s: and we can just continue right it's\n4268.699s: going to be the same d y hat dz1 and\n4272.96s: then dz1 to D what uh W1 right so I can\n4278.12s: do the exact same thing I just split\n4280.64s: my Dy hat to dw1 so the sensitivity of\n4284.54s: the output to my neuron to my weight\n4287.36s: which is way ahead right and I'm gonna\n4289.76s: split that right it's like the same as\n4291.679s: Dy hat divided by dz1 and dz1 divided by\n4295.219s: d y one one so I just split into the in\n4298.219s: terms of the middle hidden neuron right\n4302.179s: and that's what we have right so it's\n4303.56s: the same as that right\n4305.239s: remember I just broke the right hand\n4307.34s: side here into those two pieces right\n4310.159s: and now that's straightforward right\n4311.84s: it's the same as what we just computed\n4313.28s: before we know how to compute that and\n4316.1s: now it's the sensitivity it's the same\n4317.719s: right it's just the activation function\n4319.4s: that we had before right if you're to\n4321.739s: the left of 0 it's going to be zero if\n4323.78s: you're to the right of zero is just\n4325.88s: going to be X in that case or X1\n4329.84s: right so straightforward right so in the\n4333.5s: end what it means is that we can almost\n4334.94s: analytically compute all of those\n4337.159s: radians it's really straightforward and\n4339.44s: that's been a revolution\n4340.94s: and that's also why it's so much more\n4343.239s: competition efficient to use the radio\n4345.44s: functions right because all of those\n4347.659s: gradients you know if you use the sign\n4349.46s: you know it's kind of annoying right\n4350.78s: remember you need to get this sign you\n4353.179s: know in between if you use a radio it's\n4355.52s: like zero or one right so why bother\n4358.46s: right it's so much simpler right so you\n4361.04s: can compute that analytically and in\n4362.48s: fact that's what you have in the guts of\n4364.64s: tensorflow and Keras and pytouch\n4366.92s: everything pretty much is analytical in\n4369.199s: terms of the gradients and that makes\n4370.94s: things way way way faster okay that's in\n4374.48s: fact that's part of the Revolution it\n4376.219s: sounds like nothing but this chains role\n4377.78s: is actually really really important\n4379.82s: okay so the whole process here we call\n4383.42s: that actually back propagation what we\n4386.54s: mean by that is that we are trying to\n4388.699s: minimize the loss\n4391.179s: by adjusting a bunch of neurons and we\n4393.98s: go from the end to the beginning right\n4395.659s: so we are going backward we are going to\n4398.0s: back propagate we propagate the loss all\n4400.58s: the way to the end now there's one thing\n4403.52s: that's very clear is that as we move\n4405.14s: further and further down you know if we\n4407.42s: have many many many layers\n4409.64s: and then any of those sensitivities\n4411.8s: become zero then there's no sensitivity\n4415.159s: at the output right and that's this\n4417.98s: issue of Vanishing gradients that we\n4419.54s: mentioned before and that's also why\n4421.04s: those sign uh sinusoidal functions are\n4423.86s: not ideal because they tend to actually\n4426.08s: get to zero so you're losing a lot of\n4428.659s: sensitivity so it means that a lot of\n4430.699s: neurons are dead okay they are not\n4432.679s: active they are not participating so\n4434.36s: they are pretty useless so you typically\n4436.46s: need to expand the dimension to levels\n4439.159s: that are Beyond necessary and that's\n4441.32s: also why we typically don't use those\n4443.54s: activations function and we keep the\n4445.34s: value because they don't have that of a\n4448.94s: few dead neural networks\n4451.04s: make sense\n4452.36s: okay but that's also why you can get\n4455.0s: that way this uh pretty implicitly using\n4457.88s: this neural net\n4459.14s: that is back propagation sorry okay just\n4462.56s: for fun uh to show you a real activation\n4465.8s: function again 2D\n4467.54s: it's pretty crazy right\n4469.52s: uh so and we are trying to get that guy\n4472.04s: here right\n4473.179s: you can get those spikes you know it's\n4475.159s: like it's pretty beautiful yeah and just\n4477.32s: 2D again so think of that one million\n4480.08s: Dimensions good luck right so better\n4482.36s: have a good algorithm right so that's\n4484.64s: why this back propagation you're gonna\n4486.38s: love it you know it's gonna do it the\n4487.88s: right way okay but the main point being\n4490.1s: that this is what we want to get it's\n4492.199s: not trivial because of all of those\n4494.02s: non-linear activation functions and that\n4496.64s: that also depends on the data set that\n4498.62s: you have can be very complex right so\n4501.14s: you should not underestimate the\n4502.699s: complexity that you have in the gut of\n4504.62s: that\n4506.0s: okay\n4507.38s: so quick summary what we are trying to\n4509.78s: do minimize some weights okay we do that\n4512.719s: through back propagation and we have\n4515.42s: this very important parameter which is\n4517.159s: how quickly we are going to descend\n4518.659s: through that uh uh uh landscape right\n4522.32s: and so\n4524.179s: ETA which is this learning rate is going\n4526.04s: to be very crucial\n4527.659s: again we can visualize that this way we\n4530.42s: say\n4531.8s: we are starting here the best loss this\n4535.159s: is just in 1D just to make I mean\n4537.02s: visually we can only visualize 1D or 2D\n4539.719s: so just to make it simple this is the\n4541.82s: optimal value here we want to descend\n4543.62s: here right so let's optimize that right\n4546.14s: so we're starting\n4547.82s: on the left hand side here that's the\n4549.62s: initial guess\n4550.699s: and so if we have a small learning rate\n4552.5s: it's going to be very very slow to get\n4554.239s: there\n4555.38s: and maybe by the end of the algorithm\n4557.3s: we'll be just stuck here right\n4559.219s: if we're going too fast again\n4561.8s: we may be bouncing back and forth right\n4563.719s: so there's some sort of threshold that\n4567.32s: will be appropriate for the type of data\n4569.659s: set that we have it's going to be data\n4571.46s: set dependence right it's not something\n4573.44s: it's not a one fit all type of approach\n4575.42s: right there's it's going to be actually\n4577.58s: dependent on the type of data set okay\n4579.199s: so that's something we need to be\n4580.46s: careful about\n4583.219s: okay uh so now the question is how do\n4587.6s: you find this learning right right and\n4589.52s: you could say you know what I'm just\n4590.96s: gonna try a bunch right so that could be\n4593.78s: okay you know uh but typically it's not\n4597.02s: so great right because when you think\n4599.0s: about it\n4600.44s: you know if I started on the right hand\n4602.3s: side here I would rather want to go like\n4605.06s: really fast at first right I'm gonna get\n4607.04s: to the bottom of the of the mountain to\n4608.96s: the valley and then once I'm here you\n4611.659s: know I want to be pretty fine grained\n4614.0s: right I want to go really slowly here\n4616.28s: because I want to just really adjust to\n4617.96s: make sure I'm not getting this one I'm\n4620.06s: not getting that one I want to make sure\n4621.8s: I'm not getting this false one here\n4623.96s: neither right so ideally your algorithm\n4627.92s: should be what we call adaptive right it\n4630.56s: should actually go fast first and then\n4633.14s: go really slowly to make sure you're\n4634.94s: getting into the right Minima right yeah\n4637.94s: yeah have a comment because usually the\n4640.52s: learning rate depends on the time\n4643.159s: right yep\n4651.32s: on the web sorry\n4657.08s: what do you mean the laws sorry\n4662.78s: uh so you can actually make it depend\n4667.82s: ing yeah so you can actually accumulate\n4669.8s: that yeah so we're gonna talk about that\n4671.659s: in a minute\n4672.62s: okay and that's what we are going to do\n4674.3s: okay so basically in a sense another way\n4677.659s: to say that when it's very steep terrain\n4680.3s: so steep loss we know that we are\n4683.12s: Computing the loss you want to go fast\n4685.88s: when the terrain is actually pretty flat\n4688.4s: so meaning the loss is actually close to\n4690.98s: zero you want to go slow\n4692.96s: so it means actually that it's kind of\n4694.94s: funny like the learning rate should be\n4696.679s: adaptive as a function of the loss\n4698.6s: itself right so typically what we do is\n4700.82s: we keep a little bit of memory of what's\n4702.44s: been going on right when we are going\n4704.6s: really fast for a couple of time steps\n4706.28s: we say let's continue to go fast right\n4708.199s: when we are starting to slow down we say\n4710.48s: okay let's put the brakes right let's go\n4712.82s: slowly right and what that's what we are\n4715.28s: going to do\n4717.62s: okay so we are going to do what we call\n4719.78s: uh adaptive learning rate okay that's\n4722.84s: what we are going to use today we are\n4724.58s: going to use the Adam uh adaptive\n4727.219s: learning rate which is going to go fast\n4729.02s: at first and then slowly decrease right\n4731.54s: we are going to be adjusting that right\n4734.06s: but one thing to keep in mind is that we\n4736.699s: will always Define the initial learning\n4738.8s: rate right how quickly we are going to\n4740.3s: descend at first right then based on\n4742.58s: that we are going to adjust okay but but\n4744.38s: the initial one same as the initial\n4745.94s: conditions for the weight we are going\n4747.679s: to Define that and that's going to be\n4749.0s: the hyper parameter we are going to to\n4750.98s: to to to trick okay so we talked about\n4754.219s: that so no need to get into that okay\n4757.219s: just for reference you have that so\n4759.38s: those are the different types of\n4761.659s: algorithms that are kind of trying to\n4764.44s: accommodate the the fact that the\n4766.28s: landscape is changing and we want to\n4767.78s: adjust the the learning rate the one we\n4770.6s: are going to use is Ada you know it has\n4772.28s: kind of the good properties of each of\n4773.9s: them uh it has a little bit of what we\n4776.179s: call Momentum you know you want to carry\n4778.04s: some weight you know you don't want to\n4779.36s: be too fast you know and bouncing around\n4780.98s: uh you want to also have some drag right\n4783.5s: as you're getting down you want so it's\n4785.42s: trying to get those two things some\n4786.8s: momentum you know you're keeping some\n4788.42s: memory and some drug right as you get\n4790.94s: down the valley you are actually getting\n4792.5s: some drug\n4796.1s: okay so that's kind of the idea of the\n4798.739s: momentum is that if you go too fast\n4800.42s: you'll be bouncing around right uh and\n4803.36s: so what you want is you want to carry\n4804.86s: some momentum you could want to have\n4806.239s: some memory or you know of what's going\n4807.8s: on you know so that's one thing you can\n4809.719s: actually uh include in your process\n4814.28s: I'm just gonna go a bit quicker here so\n4817.04s: those are the different algorithms so\n4819.08s: but that's the one we are going to use\n4820.28s: is that it has kind of all the flavors\n4822.679s: it has this momentum approach which is\n4824.84s: like a a ball running down a slope uh\n4828.02s: and it also has this idea of friction we\n4829.88s: know you want to basically drag things\n4831.62s: and you want to slow down when things\n4833.719s: are actually going slower right so it's\n4835.28s: this idea of friction and momentum right\n4837.34s: and so it prefers to have like a flat\n4839.84s: minimum uh in terms of the of the errors\n4843.44s: ok so maybe that's the best way to\n4846.14s: visualize that is that you know those\n4848.12s: are different ways you can actually get\n4850.58s: down so either with momentum you could\n4852.679s: have those different flavors and then\n4854.719s: you have this uh item algorithm here and\n4858.32s: you can see some of them they go fast\n4859.76s: really really quickly but they don't get\n4861.199s: like the blue one doesn't really get to\n4863.54s: the end very quickly or this one here\n4865.88s: like the red one you know in the end it\n4868.28s: stops pretty far from the optimal value\n4870.8s: right so what we want is we want\n4872.719s: something that goes fast first and that\n4875.36s: will also be going close so if you look\n4878.42s: at the yellow one it's getting close to\n4880.58s: the truth pretty efficiently right goes\n4883.46s: down quickly first and then we'll\n4885.44s: fine-tune as we get closer and closer\n4887.42s: and closer right so that's the type of\n4889.52s: algorithm we will use today right so we\n4891.86s: are adjusting the learning rate again to\n4893.9s: go fast first and then to basically\n4896.42s: adjust\n4897.98s: make sense\n4899.48s: no need to get too much into the wheels\n4901.28s: but I think that's just the idea that we\n4903.8s: want\n4904.88s: okay so that's basically what we we're\n4908.48s: going to do today is we are going to\n4910.699s: compute those gradients we are going to\n4912.08s: get down using this Adam algorithm here\n4914.84s: and then we are trying to minimize that\n4917.0s: and we are going to iterate until we\n4918.62s: stop and that's going to be the end okay\n4923.12s: uh one thing we can do is that so maybe\n4926.9s: let me go back just quickly to that is\n4929.3s: that\n4930.199s: one issue could be that sometimes you\n4932.96s: can get stuck here right if you're going\n4935.36s: fast here and then stop yeah you have a\n4938.78s: and then you you're being stuck here so\n4941.78s: that could be an issue right you would\n4944.12s: want to have a little bit of likelihood\n4945.5s: to actually get get up and go here right\n4948.56s: so if you maybe done a little bit of\n4952.46s: um\n4953.12s: minimization or some programming there's\n4955.64s: this one thing we call simulated\n4957.02s: annealing you know have you heard about\n4958.699s: that\n4959.84s: so you're trying to minimize something\n4962.3s: like a function but what we do it's\n4964.58s: actually inspired by statistical\n4965.96s: mechanics right you give some uh\n4968.78s: likelihood to the molecules to actually\n4970.58s: get out of the system right so it's like\n4973.159s: some activation right some energy right\n4974.96s: so it's dependent on some temperature\n4976.699s: and depending on the kinetic energy of\n4978.62s: those molecules they can get out right\n4980.719s: and that's the same idea we want to give\n4983.239s: some likelihood to actually get out of\n4985.34s: that because we don't want to be stuck\n4987.44s: in a local minimum right we want to get\n4989.239s: the best best uh minimum that we can and\n4992.9s: so we want to get this one here and not\n4995.42s: that one\n4996.44s: so one thing is that if we were to use a\n4999.86s: deterministic descent\n5001.659s: it will not work so well right because\n5003.699s: we could get stuck here and in fact your\n5005.98s: gradient is zero right so locally you\n5008.62s: have no way to say that it's a bad point\n5010.42s: right\n5011.26s: but if you had a mechanism by which you\n5014.44s: could get out sometimes you could be\n5016.84s: actually lucky enough to see that this\n5018.88s: one is actually better and you will see\n5020.679s: that this loss is actually a little bit\n5022.9s: lower than the other one and that would\n5024.58s: be preferable right\n5026.26s: so\n5027.46s: one easy trick to do that and it's\n5029.679s: actually computationally even more uh\n5032.679s: useful is to say you know when we\n5035.56s: compute that loss so to get back to your\n5037.84s: earlier points and is you know we can\n5039.94s: say you know when we compute that loss\n5042.159s: we could actually split the data and we\n5044.98s: could say I compute that loss not on the\n5047.38s: entire data set but on what we call\n5050.08s: batches you know and the batches are\n5052.84s: typically we call that a mini batch\n5055.0s: they are typically very small size 128\n5058.54s: to 56 or something and we compute that\n5061.48s: loss just on a subset and what it means\n5064.6s: is that that loss will not be exactly\n5066.52s: always the same right it will slightly\n5068.86s: vary just by luck you know because\n5070.48s: sometimes you're seeing one part of the\n5072.82s: data says sometimes you're seeing\n5074.02s: another part of the data set the other\n5076.36s: Advantage is that you're always dealing\n5077.98s: with small chunks of data right 128\n5081.219s: points are tend to be very small in\n5082.9s: memory right so it's pretty easy to\n5085.48s: actually transform that computation of\n5087.219s: the gradient in terms of just Computing\n5089.26s: over a few points as opposed to like\n5090.82s: millions of data points right\n5093.1s: so we typically replace that by that\n5097.54s: we compute the gradient over what we\n5100.719s: call a batch we will have a bunch of\n5102.58s: batches depending on how big the data\n5104.739s: set is so if you have millions of data\n5107.26s: points you split that into chunks of\n5109.42s: size 128 or 256 you can choose that it's\n5112.3s: also hyper parameter and then you\n5114.52s: compute those gradients there right it\n5116.62s: will just give you a little bit of\n5117.76s: flexibility a little bit of\n5118.84s: stochasticity which is natural which is\n5120.52s: just due to the data set itself give you\n5122.92s: a little bit of a chance to actually get\n5124.54s: out you know to provide some\n5126.52s: stochasticity plus the advantages you\n5129.1s: also have the benefit of\n5131.1s: chunking or cutting your data in very\n5134.62s: very small chunks right very beneficial\n5136.6s: right I mean we talked about gpus before\n5138.42s: you they are very small in memory so you\n5141.04s: can actually do that in parallel right\n5142.36s: you can compute all of those weights or\n5144.4s: all of those gradients in parlor gather\n5146.679s: the information back you know and then\n5148.719s: process and move forward right very very\n5151.36s: beneficial from two standpoints you have\n5153.58s: stochasticity Plus at the same time\n5156.04s: small chunks of data perfect right so\n5158.8s: you tackle two things at once\n5162.04s: killing two birds with one stone so\n5164.199s: that's way ways paper on carbon cycle\n5167.62s: okay so last thing so basically long\n5171.4s: story short those mini batches are very\n5173.199s: useful stochastic C3 plus very small in\n5176.26s: memory great uh the hardware people love\n5178.659s: you you know they they great you can put\n5180.58s: that on gpus gpus that's what you need\n5183.699s: and it works better you will get a bet\n5185.44s: on your net at the same time\n5187.48s: now the last thing we need to talk about\n5190.12s: is and that's typically the one thing we\n5193.54s: want to focus on is overfeeding okay\n5196.6s: that's typically the issue with neonats\n5198.88s: they are greedy and they want to they\n5202.239s: want to chew on everything okay they\n5204.34s: want to swallow everything they are so\n5206.26s: strong so powerful that they want to\n5208.0s: basically pick up everything okay and we\n5210.34s: need to slow them down we need to say\n5212.199s: you know that's too much we need to\n5214.42s: reduce the dimensionality we need to\n5216.219s: limit over feeding so and the typical\n5219.1s: thing is that if you have a data set\n5220.96s: here so again a regression you have a\n5223.12s: bunch of points\n5225.28s: what the typical neural network will do\n5227.56s: like Brute Force you know will actually\n5229.12s: be that feeding every single data point\n5231.159s: right you you have millions of degree\n5233.26s: degrees of freedom so why not right you\n5235.3s: can do it if you want right\n5237.46s: uh but it's not great right I mean it's\n5240.219s: pretty obvious that if you wanted to\n5242.44s: predict you know let's say you're taking\n5244.6s: another data point say\n5246.76s: on the right hand side here so I'm\n5248.679s: slightly extrapolating you know I would\n5250.9s: expect that this data point would be\n5252.4s: around here right\n5254.139s: no or even in the middle like if I have\n5256.3s: a data point I would expect that this\n5257.62s: data point fits is is about here right\n5259.96s: now if I add all of those Wiggles you\n5262.42s: know maybe my prediction will go bananas\n5264.88s: here it will go crazy right\n5266.92s: and so that's going to be an issue\n5269.679s: at the same time if you have a very\n5271.42s: lower dimensional system you may be\n5273.58s: under feeding right think of that you\n5276.159s: have a parabolic shape you use a linear\n5278.199s: regression prediction is going to be\n5279.94s: pretty bad right outside of the training\n5282.4s: sample even within the training sample\n5284.44s: itself right\n5285.76s: so what we would want is something in\n5288.52s: between right we want to have the ideal\n5290.32s: fit\n5291.28s: and what we mean by that is that we want\n5294.04s: to actually fit the data well\n5296.08s: we want to also have a good capacity to\n5298.9s: journal generalize well two data sets\n5302.26s: that we haven't seen right so that's\n5303.76s: going to be a lot of the Focus right and\n5305.98s: pay attention today for the competition\n5308.38s: we are not going to be uh using what we\n5311.98s: call the training loss which is on the\n5314.739s: training data set that you use but what\n5316.36s: we will call the validation loss right\n5318.219s: on this data set that you've not seen so\n5320.44s: that's gonna going to be the one used\n5322.179s: for the competition\n5325.96s: okay so uh to reduce that we need a\n5329.32s: bunch of Tricks basically and we call\n5332.5s: that typically a regularization okay we\n5334.78s: need to basically slow down the the the\n5337.239s: neural network we need to reduce the\n5339.28s: dimension ID as much as we can and we\n5341.56s: need to do that in in a couple of ways\n5343.719s: okay\n5345.159s: the first method that we have is what we\n5347.02s: call dropouts okay uh I used to really\n5349.239s: like it I mean it depends on sometimes\n5352.06s: it just doesn't work at all uh but when\n5355.78s: you have a very high dimensional neural\n5357.52s: net that tends to be pretty useful so\n5360.52s: the idea is very simple we have a neural\n5363.34s: net and we discussed that before it's\n5365.739s: very redundant right remember that we\n5368.02s: are connecting every single neuron here\n5370.06s: to every single hidden layer here to\n5373.0s: every single hidden layer in the next\n5375.4s: layer right so it's extremely extremely\n5377.679s: redundant right and we can actually get\n5380.26s: to the same answer in many many\n5381.58s: different ways right so we want to\n5384.219s: basically avoid that right\n5386.56s: straightforward ways to say let's cut\n5388.54s: some some of those links right they are\n5390.4s: redundant there might be some randomness\n5393.1s: there and so what we can do is we can\n5395.08s: and typically it's completely arbitrary\n5396.699s: we say we drop 50 of the links 50 of the\n5400.12s: connections\n5401.26s: and we just cut them right so we cut 50\n5404.8s: of the connections here\n5406.9s: and what it does is it really try it's\n5409.42s: trying to reduce the dimensional ID of\n5411.159s: the neural net right trying to avoid a\n5413.32s: lot of the overfitting and trying to\n5414.88s: avoid a lot of the redundancy that are\n5416.8s: built into the neural network okay\n5419.86s: straightforward to doing Chaos you just\n5422.199s: say after one day you're here you say\n5424.48s: I'm gonna add a Dropout layer we call\n5427.6s: that a layer but it's really we are\n5428.98s: cutting the connections and with a given\n5431.38s: probability so in that case 50 we have\n5433.48s: we are cutting 50 of the links and fifty\n5436.78s: percent of the connections okay so\n5438.52s: straightforward to do we will add a\n5441.28s: layer after that layer we say drop out\n5443.44s: cut some of those connections it's too\n5445.36s: much and typically again\n5447.699s: for consistency we don't do it in one\n5450.219s: layer and not in the other ones we do\n5451.719s: the same across all layers you know just\n5453.52s: like in that picture here we cut 50 of\n5456.04s: the links across you know because\n5457.6s: otherwise we don't know what we really\n5459.219s: did you know so that's an easier way to\n5460.719s: do it\n5461.5s: you could look at the dimension of the\n5463.48s: neural net at the end it will be way\n5464.86s: smaller right we've reduced the\n5466.42s: dimension ID so that's a good thing\n5467.739s: right it means that we were trying to\n5470.44s: basically achieve the same type of loss\n5472.54s: without overfilling too much so that's\n5474.639s: that's good news right typically it\n5476.02s: works quite well especially when you\n5477.82s: have a high dimensional system okay and\n5480.34s: it's random right because it's a\n5482.44s: probability so if I do one Dropout one\n5485.44s: time I will get that\n5487.06s: another realization of my droplet will\n5489.219s: give me another realization right\n5490.9s: sometimes it works well sometimes it\n5492.88s: doesn't work as well you know it depends\n5494.32s: you know so there's some Randomness\n5496.06s: there okay so that's one strategy one\n5498.639s: could use okay\n5500.08s: okay the other one and that's the one we\n5501.82s: should always use you know this one is\n5503.62s: what we call Early stopping\n5505.659s: and what we mean by that is that we take\n5509.26s: our data set\n5510.639s: we split that to get back to your\n5512.62s: earlier Point typically in terms of 80\n5514.9s: or 20 or 70 and 30 depending we\n5519.46s: typically use still the bulk of the data\n5522.04s: set for training and we used\n5524.86s: that percentage so 70 or 80 for training\n5527.92s: those weights okay we are using the data\n5529.719s: sets we potentially use the mini batches\n5532.06s: or whatnot and we use that to adjust the\n5534.58s: weights okay so we are training and\n5535.96s: training and training and then we have\n5537.639s: the best neural net that we have and\n5540.52s: then we evaluate the neural network on\n5543.76s: some data set that the neural network\n5545.199s: has not seen and we call that the\n5547.54s: validation loss right so we re-evaluate\n5550.0s: that loss we don't train there you know\n5552.04s: on that loss we don't train again so the\n5554.5s: weights are not changing and we are just\n5556.78s: checking what is the mismatch that we\n5558.88s: have okay so it will look like that\n5561.28s: right as a function of time it's\n5564.4s: actually not time it's iteration right\n5566.199s: so we iterate through the through the\n5568.06s: weights we are getting down the loss\n5570.1s: that's going to be the training loss\n5571.78s: right it's always going down always\n5573.34s: going down otherwise we are making a\n5575.08s: mistake right if it's going up sometimes\n5576.88s: just because of natural stock assist you\n5578.62s: can have some variations you will see in\n5580.78s: the data some wiggles from time to time\n5582.34s: but that's that's okay that's normal but\n5584.5s: on average for over a long period of\n5586.239s: time it goes down right makes sense\n5587.62s: we're always trying to minimize minimize\n5589.3s: and minimize\n5590.8s: and then what happens is that\n5594.34s: the validation so on the other data set\n5597.159s: that we have not seen where we are again\n5598.719s: not adjusting the weights we are just\n5600.76s: testing the values eventually what will\n5603.52s: happen is it will start going up again\n5605.98s: and so what it means is that we are\n5608.5s: trying to overfill the data we are\n5610.239s: starting to learn the noise in the data\n5612.04s: like to to a crazy amount right so we\n5614.32s: are trying to say okay I know that that\n5616.42s: data set so well and I can reproduce the\n5618.94s: data set so well but you have no\n5621.04s: predictive power right you're losing\n5622.719s: predictive power because you're learning\n5624.159s: even the noise in the data set right so\n5625.9s: that's a mistake\n5627.34s: and so what you should do is you can\n5629.5s: actually include this what we call Early\n5631.0s: stopping you can say you know once I see\n5634.0s: that the validation loss is not being\n5636.46s: reduced anymore I stop you know and you\n5638.679s: can do that after a couple of iterations\n5640.96s: it's a parameter like one to ten or what\n5643.48s: not\n5644.26s: yep\n5648.04s: yes you can you can combine them of\n5649.96s: course of course yeah\n5660.34s: you're not training on the validation\n5662.32s: yes you're just using that as a dag it's\n5664.719s: a diagnostic right it's just a\n5666.34s: diagnostic where and you will see when\n5668.38s: it's actually going not going down\n5670.179s: anymore you you want to stop right\n5672.639s: one thing as well is that and please use\n5675.52s: that for the competition is this\n5678.82s: validation loss is also very useful to\n5680.8s: let you know whether you were over\n5682.659s: fitting or not right so imagine you have\n5685.84s: a very very deep neural network\n5688.0s: you will see very quickly that your\n5689.8s: validation loss is actually going up\n5691.36s: very quickly so it means that your\n5693.58s: dimension your initial dimension of the\n5695.44s: neural network was too big right because\n5697.179s: your validation loss is so much bigger\n5700.12s: than the training loss right so if\n5701.739s: there's a big mismatch between the two\n5703.42s: it means that your dimension is too big\n5705.58s: right it means you are trying to fit the\n5708.52s: data set so well you know and that's a\n5710.62s: mistake right you're trying to fit\n5712.3s: exactly the noise in the data and we\n5714.639s: don't want to do that right so if you\n5716.139s: see that there's a huge imbalance\n5717.76s: between the validation loss and the\n5720.46s: training loss shrink the size of your\n5722.08s: data of your neural network reduce the\n5724.719s: number of neurons reduce the number of\n5726.76s: hidden layers you were overfeeding right\n5728.86s: because there's too much discrepancy\n5731.38s: every time you're seeing a new data\n5732.88s: point you're generalizing and you don't\n5735.1s: know what to do right so there's too\n5737.02s: much mismatch okay so always looking at\n5739.9s: this validation loss and training loss\n5741.639s: is very very useful you know that's\n5743.139s: something you should always look at\n5745.12s: if there's too much discrepancy again\n5746.92s: too big of a dimension if you're\n5749.26s: increasing too fast you should stop\n5750.94s: early you know so those are really great\n5752.739s: indicators of overfilling it's almost\n5754.54s: the best indicator that one could use\n5756.159s: always visual right\n5758.52s: and here you will see at the bottom so\n5761.56s: training iterations here we typically\n5763.54s: call that Epoch okay that's the jargon\n5766.0s: here what does it what does it mean so\n5768.639s: one Epoch means you went through the\n5770.139s: entire data set once so typically you go\n5772.42s: to like 200 epochs you will hear people\n5774.46s: saying that oh I went I stopped after\n5776.139s: 200 Epoch so it means you went through\n5778.0s: the entire data set 200 times\n5780.04s: why not just once just because it takes\n5782.199s: time okay uh there's no magic there but\n5784.9s: it's kind of absurd you need to go\n5786.34s: through the same data set 200 times but\n5788.08s: again remember that you're taking those\n5790.36s: batches that are random right so they\n5792.28s: are stochastic so you're not exactly\n5794.02s: seeing the same behavior every single\n5795.82s: time right there's a little bit of\n5797.02s: stochasticity in there so that's okay\n5799.239s: okay we can go through the data set 200\n5801.1s: times\n5801.88s: okay and that's also kind of the limit\n5804.28s: right because 200 times means that this\n5806.92s: might be because of computational powers\n5808.54s: where they we have a lot of luxury today\n5811.42s: uh thanks to Ryan Julius but sometimes\n5814.9s: you need to stop right because of your\n5816.639s: compute power right maybe you're running\n5818.38s: that for instance a lot of people in my\n5820.42s: group were running that on some HPC and\n5822.639s: we have 12 hours right so after 12 hours\n5824.98s: we need to stop so we'd better be close\n5826.6s: to the to the end after 12 hours right\n5828.88s: so that's also why you need to be\n5831.219s: careful right too big a dimension could\n5833.199s: be an issue because you might not even\n5834.76s: get to the actual optimized value by the\n5838.06s: end of your allowed time right so that\n5840.46s: could be a concern\n5848.739s: basically that loss there doesn't reach\n5852.219s: for example a local Minima\n5854.5s: yeah you're right so um in fact it often\n5857.62s: does right and you could actually reach\n5859.48s: a local minimum here\n5861.159s: and maybe that's something you want\n5862.719s: sometimes you know so\n5864.4s: and I don't know it's not I don't know\n5866.32s: if that's stand-up practice or not so\n5867.699s: what I do you know and I think Huawei\n5869.679s: actually does the same now is I I run uh\n5872.92s: not just one neural net but I run like\n5874.719s: five because it's just me just because\n5877.3s: you can get good luck bad luck right so\n5879.82s: I take five uh and that will give really\n5883.06s: give me a good sense as to whether my\n5884.739s: hyper parameters work or not so I say\n5887.199s: take the same architecture same number\n5889.239s: of neurons same number of hidden layers\n5891.04s: run the the the optimization five times\n5894.219s: and that gives me a little bit of a\n5896.139s: sense of a sample you know and I can\n5897.58s: look at the median value what is the\n5899.199s: median loss and I would say you know on\n5901.6s: average it behaves this way you know and\n5904.0s: you know that would kind of avoid this\n5905.739s: right like a just bad luck you know or\n5907.54s: good luck you know so removing a little\n5910.06s: bit of the just like initial condition\n5911.62s: or good luck or with the with a local\n5914.679s: loss okay so that's my trick tends to\n5917.199s: work quite well especially when we want\n5918.52s: to do hyper parameter tuning my personal\n5921.219s: experience is that those hyper permanent\n5923.8s: tuning tool boxes don't work\n5926.139s: when we only use one neural net you know\n5928.54s: and so that's my trick is I run them\n5930.46s: five times and that's way smoother\n5932.679s: because then it means again because it's\n5934.84s: that validation loss is so erratic so\n5937.96s: doing it five times helps a lot you know\n5940.06s: I feel\n5941.62s: provide some smoothing\n5944.139s: okay we\n5945.82s: are almost perfect on time uh last trick\n5949.6s: another regularization if you've done\n5951.94s: any type of regression we have what we\n5954.28s: call Ridge and lasso regression who\n5956.5s: knows that\n5957.639s: region lasso no one L1 L2 regularization\n5962.44s: Yeah so basically what you can do is you\n5964.659s: minimize your loss and you can add one\n5967.3s: term on the right hand side of the loss\n5969.219s: which is plus some coefficient which is\n5972.46s: whatever you can tune that it's also a\n5974.92s: hyper parameter times either the\n5977.5s: absolute value of the weights or the\n5979.36s: squares of the weights why do we want to\n5981.52s: do that is because\n5982.9s: we don't want one way to take over right\n5985.0s: we don't want just the neural network to\n5987.04s: be absurd and just go in One path right\n5988.96s: we want to be on your network to be\n5991.239s: ready to be well balanced right that the\n5993.699s: the response that we are getting is\n5995.02s: actually due to a bunch of neurons that\n5997.0s: are sharing their growth like equal vote\n5998.62s: right like basically you want your your\n6000.54s: net to be democratic\n6002.52s: uh and so that's what we do is we call\n6005.28s: that L1 and L2 regularizations we just\n6008.82s: add to your loss what we call a\n6011.159s: regularization just again we add some\n6014.12s: some some some some weighting of the\n6016.86s: weights right we want the weights to be\n6018.54s: as you know homogeneous as possible and\n6021.9s: again why do we want to do that to make\n6023.46s: sure that one doesn't take over okay so\n6025.92s: that's typically very useful tends to\n6028.56s: provide an an answer that's way smoother\n6031.8s: you know so you will not get spikes uh\n6034.86s: and you will see that especially if you\n6036.78s: look at an image typically your image\n6039.06s: will tend to be a little bit blurry and\n6041.28s: that makes sense because you want things\n6042.42s: to be a bit more homogeneous if you want\n6044.159s: very sharp and abrupt Contours that will\n6048.239s: not be the right way but if you want a\n6050.88s: regression that's very smooth that would\n6052.679s: be the right way okay so that's a good\n6054.36s: way to also avoid overfeeding and spikes\n6057.179s: and and things that are very contrasting\n6059.88s: okay so I'm done and I think I'm exactly\n6062.28s: on time great\n6064.32s: uh and now we are going to get into the\n6066.78s: competition so we are going to get into\n6068.4s: the netbooks uh and that's gonna be so\n6071.4s: you can it's a QR code you can scan it\n6073.26s: with your\n6074.159s: uh phone hopefully and that should lead\n6077.219s: you to a form and then what we are going\n6079.26s: to do is we are going to basically get\n6081.36s: through a notebook during the studio\n6082.98s: together and then I'm gonna show you how\n6085.38s: we can code on your network and you're\n6087.6s: going to adjust yourself and your\n6089.04s: network to try and get the best loss\n6092.46s: possible so you're going to try to\n6094.08s: minimize the loss and remember the loss\n6097.08s: that we want is actually not\n6099.78s: this one here\n6101.52s: which is the training loss we want to\n6103.679s: minimize the validation loss we will try\n6105.6s: to have a competition where people will\n6107.94s: win when the validation loss is the\n6109.739s: minimal one okay\n6118.92s: so let's get back to uh so similar to\n6121.86s: what we've done yesterday right so we\n6124.44s: are going to log first into GitHub so\n6126.3s: remember our good bootcamp 2023\n6129.54s: and there's going to be one thing\n6130.92s: important is that we need to select\n6134.94s: the so we have different options here in\n6137.28s: terms of the servers\n6139.02s: we need to use the pangeo tensorflow ml\n6142.86s: if you don't use that it's not going to\n6144.6s: work it's going to have everything\n6146.58s: loaded there especially related to\n6148.92s: tensorflow which is the primary tool we\n6151.5s: are going to use for machine learning\n6152.88s: right so please use that make sure you\n6154.8s: know you have different options make\n6155.94s: sure you take the medium one so slightly\n6158.46s: larger uh RAM so it's a CPU uh and use\n6162.659s: the pengo tensorflow one\n6165.36s: sorry\n6169.38s: uh\n6173.58s: uh yeah I don't know depending on your\n6176.4s: status Within\n6178.739s: me okay\n6185.219s: research may see other options on this\n6187.5s: is not relevant\n6189.54s: yeah thanks Ryan yeah\n6192.78s: so jealous\n6195.42s: so medium everyone can get that fine\n6199.02s: okay so let's run that should be fast uh\n6202.8s: a couple of days ago it was taking a few\n6204.719s: minutes but uh uh we got the agreement\n6207.6s: to get that running faster so thanks for\n6210.179s: that\n6212.94s: yeah so this is this one please use this\n6215.94s: link at the bottom day too\n6218.94s: so if you click that it will just\n6220.92s: directly clone the GitHub repository\n6224.219s: into the jupyter Hub so you can just\n6226.32s: start working immediately yeah you\n6228.96s: should have everything ready here\n6236.3s: can you all see that and can you see the\n6238.8s: same facts as well\n6241.38s: yeah neural networks as well you're\n6243.3s: seeing that\n6244.739s: okay fine for everyone just to make sure\n6248.04s: anyone struggling here or fine in your\n6251.28s: nets right\n6253.619s: thumbs up we got it\n6256.02s: yeah maybe wait wait if you could check\n6257.94s: as well with the group b awesome\n6272.6s: we're good yeah fine\n6276.119s: thanks\n6281.34s: hey it's running yeah okay let's wait a\n6283.8s: little earlier\n6287.639s: you're getting it as well\n6291.119s: still running for you okay\n6293.219s: hmm\n6294.48s: it's kind of slow usually it's fast now\n6297.239s: you got it uh everyone got it yeah\n6301.92s: you got it there\n6303.719s: fine\n6304.92s: thumbs up\n6306.96s: here\n6309.239s: you're serving the world already\n6313.09s: [Music]\n6315.42s: yeah boot camp click on that boot camp\n6318.96s: codes\n6322.199s: day two\n6323.699s: neural net yeah okay\n6330.42s: you got it fine fine oh you're loading\n6332.699s: as well oh\n6342.199s: for how long has it been a few minutes\n6344.94s: yeah\n6346.49s: [Music]\n6347.76s: he's the same in the bracket\n6350.4s: still running for you still loading\n6354.239s: oh it's oh is this in there\n6357.96s: fail\n6358.98s: so can you try again maybe close this\n6361.32s: one and then\n6362.82s: redo it from GitHub yeah\n6365.88s: Maybe\n6367.86s: okay thanks\n6369.84s: okay\n6371.219s: so\n6372.96s: in the way way there's someone also in\n6376.38s: the back there that has an issue thanks\n6377.76s: a lot okay so let's look at what we got\n6381.54s: here so\n6383.28s: let me make it a bit bigger for you is\n6386.82s: that fine because it's a bit blurry so I\n6389.159s: hope yeah\n6392.58s: maybe like this should be fine\n6395.46s: in the back you can see okay\n6398.34s: so what we are going to do is basically\n6400.98s: very similar to what we've done\n6402.179s: yesterday x-ray we got the like the king\n6405.6s: of X-ray here so we we got that\n6407.699s: yesterday right so uh pandas we talked\n6410.4s: about that yesterday that's what data\n6412.199s: sets uh\n6414.06s: and then now the only difference two\n6417.06s: days we are going to use tensorflow\n6418.44s: right\n6419.34s: and we are going to use a slightly\n6421.44s: higher level API than tensorflow which\n6423.84s: is called Keras uh long story so they\n6426.48s: used to be independent Kara's got\n6428.219s: absorbed with in tensorflow tensorflow\n6430.56s: the original version was a bit of a\n6432.48s: nightmare so I I went through that to\n6435.179s: run but Keras is way simpler okay so\n6437.88s: Keras is basically a bunch of sequence a\n6440.04s: bunch of lines of codes you build your\n6441.9s: network gonna be really straightforward\n6443.639s: you can run that uh tensorflow is more\n6446.219s: like based on a graph it was a bit more\n6447.84s: annoying but so Keras is going to be\n6449.52s: really easy and that's what we have here\n6451.38s: right uh and what we are going to use is\n6454.8s: going to be what we call we are going to\n6457.26s: import what we call sequential\n6459.3s: and sequential refers to basically the\n6461.94s: fit forward neural networks that we've\n6463.56s: seen before like the bunch of hidden\n6465.119s: layers that we have right it's a\n6466.86s: sequential neural net so that's what we\n6468.78s: are going to use now okay\n6471.719s: we are gonna and I don't want to spend\n6474.06s: too much time here because that's not\n6475.38s: really the interest today we went\n6476.88s: through that in details yesterday we can\n6480.0s: download the data from the pengo\n6482.04s: platform that's fantastic right it's\n6484.139s: amazing how easy it is and that's\n6486.36s: basically what we are doing here we are\n6488.639s: going to download uh different data sets\n6491.219s: different scenarios we could use\n6492.719s: different climate models output it's\n6495.179s: beautiful so we will be looking at some\n6497.219s: air temperature data uh as a function of\n6500.82s: some greenhouse gas concentration and we\n6502.98s: can download all of that from the cloud\n6504.719s: beautiful\n6506.82s: and so what we are going to do so this\n6510.06s: is basically where we are going to pick\n6511.56s: up the data so no need to really get\n6513.3s: into that\n6514.32s: and we are going to be looking at what\n6515.94s: we call uh different scenarios so what\n6519.179s: are those\n6520.86s: um they are basically Julius mentioned\n6523.679s: that yesterday they are basically what\n6526.92s: we call emission scenario so we are\n6528.54s: trying to predict what's going to happen\n6530.52s: in the future and we are prescribing the\n6533.28s: concentrations of carbon dioxide\n6535.5s: methanes and a few important greenhouse\n6537.78s: gases and also aerosols if you wanted to\n6540.119s: know in the future\n6541.86s: and we have different scenarios here so\n6544.56s: one two six are very optimistic wrong\n6547.679s: basically at this stage SSP 370 a\n6550.92s: slightly also optimistic and SSP s uh\n6555.42s: 585 which uh is very pessimistic you\n6559.02s: know so we believe we are not on track\n6560.219s: for that so basically those are\n6561.36s: different range of scenarios so low\n6563.58s: concentration low medium and very high\n6566.28s: concentrations you know uh and also on\n6570.719s: the left hand side is what we call\n6571.98s: historical so everything pre-2015 which\n6575.76s: is the initial day that people use to\n6577.619s: predict the scenarios because that was\n6579.06s: run in 2015 at the time or 2014 so they\n6581.82s: wanted to predict from 2015 on right so\n6584.88s: all of the scenarios what we call SSP so\n6588.179s: um\n6588.78s: shared social economic pathways ssps are\n6592.92s: going to be from 2015 on so we have\n6594.78s: three of them defining three different\n6596.639s: concentrations and different climate\n6598.8s: realizations and then historical okay\n6601.5s: and for each of them different groups\n6604.5s: ran different climate models you know we\n6606.48s: talked about that yesterday for instance\n6608.52s: in France we have APR cell here in the\n6610.8s: US we have CSM which is they are\n6613.08s: collaborating with the lipids and car\n6615.48s: you have NASA also running one so we can\n6617.94s: actually select one of the models that\n6619.56s: we want we are just going to use one\n6621.06s: single model in that particular case\n6624.54s: and the advantage is because we have\n6626.82s: many scenarios we can actually split the\n6628.619s: data into two we could have for training\n6631.8s: here those scenarios and we can use a\n6634.32s: completely different scenario for\n6636.54s: testing right which is nice you know we\n6638.52s: can have very independent data set we\n6640.44s: rerun a full climate model with\n6643.199s: different concentrations so that's this\n6644.82s: concentration which we call 245 we\n6647.1s: believe we're on track for for that if\n6649.08s: you're interested which corresponds to\n6650.82s: roughly 2.6 2.7 degrees of warming in 20\n6654.119s: in 2100 okay so that's basically what is\n6657.36s: going to be our test that's where we\n6659.46s: will want to test our model uh\n6661.56s: completely independent from the training\n6663.06s: data okay very straightforward again\n6665.46s: using the pendulum infrastructure that\n6667.8s: we have we are going to say we want to\n6669.9s: select a model\n6671.4s: we want to select a bunch of scenarios\n6674.159s: the model we select here is the\n6676.02s: Norwegian model here no esm okay so\n6679.02s: that's just one of them no particular\n6681.06s: choice why that's the one but we are\n6682.92s: using that one\n6684.3s: and what we are going to to get from\n6686.699s: that model is we are going to get\n6688.739s: some CO2 concentration\n6691.26s: some methane concentration CH4 and we\n6695.159s: are going to try and predict uh surface\n6697.679s: air temperature we could predict some\n6699.36s: other things precipitation or whatnot\n6701.1s: but the input predictors we are going to\n6704.04s: have are going to be CO2 and methane and\n6706.98s: we want to predict temperature so\n6708.54s: basically what we are trying to do here\n6710.28s: we are replicating a climate model it's\n6712.92s: neat right I mean you can actually get\n6714.42s: that in a fraction of seconds right we\n6716.219s: could actually get a climate simulation\n6718.139s: once we've trained a neural net in a\n6720.179s: fraction of seconds right that's great\n6723.06s: okay so just to give you a sense uh\n6726.6s: those are you could actually plot those\n6728.46s: again I don't want to get too much into\n6729.9s: that those are the different\n6731.639s: concentrations that I mentioned before\n6733.199s: so this is the historical time series\n6735.3s: here stopping in 2015.\n6737.76s: that's one of the scenarios as we call\n6739.92s: it but it's really just the past and\n6742.02s: then we have four different scenarios\n6743.639s: here based on how we believe emissions\n6745.619s: are going to be so optimistic slightly\n6748.139s: less optimistic 245 the one we are going\n6750.96s: to use for testing this one uh oh sorry\n6754.02s: uh not the conversion this one is for\n6756.179s: testing this is also used for training\n6758.04s: 370 and then five eight five okay those\n6760.92s: are used for three\n6762.54s: and that's for CO2 so that's basically\n6766.08s: the input of the data and same for CH4\n6769.56s: right so methane okay so those are the\n6771.78s: inputs here and we are going to try and\n6773.94s: predict temperature so\n6776.4s: Julius mentioned some of that yesterday\n6778.02s: so how does a climate model work we\n6780.78s: prescribe it depends you have different\n6782.04s: ways of doing that you could prescribe\n6783.6s: the emissions so a flux very few models\n6785.94s: are actually running this way they are\n6787.139s: getting more into that which is a bit\n6788.76s: frustrating if you ask me uh but\n6791.699s: typically what they do is we prescribe\n6793.92s: the concentrations directly right so we\n6795.9s: prescribe concentrations of CO2 methane\n6798.54s: in all of the greenhouse gases we run\n6800.58s: the climate model with the different\n6802.5s: physics Etc so clouds oceans Etc and\n6805.8s: then we predict the future of many\n6807.179s: different things temperature\n6808.46s: precipitation humidity things that was\n6811.5s: used where I use the essay by Judas when\n6813.6s: he was looking at the wet bulb\n6815.34s: temperature right he was predicting\n6816.659s: temperature and he was predicting\n6818.76s: relatively meat but to run that he needs\n6822.3s: to have some input right and that's what\n6823.56s: we call the boundary condition right so\n6825.6s: those conditions are basically the\n6827.52s: greenhouse gases right so those are\n6829.38s: going to be the input of the climate\n6830.82s: models you run that and then you want to\n6833.04s: predict things okay\n6834.659s: and we are going to use the climate\n6837.0s: model output which is the air\n6838.38s: temperature in that particular case and\n6839.94s: we're going to use that as our\n6841.8s: prediction right so that's going to be\n6843.06s: the Y that we had before and CO2 and CH4\n6847.02s: are going to be the axis right the\n6848.76s: inputs the two dimension of inputs and\n6850.98s: we are going to be predicting the\n6852.36s: temperature\n6853.679s: make sense\n6856.139s: so that's what we have\n6858.36s: we can plot that as well so this is the\n6862.199s: prediction we want to make right Global\n6864.84s: temperature right so we want to predict\n6868.679s: that temperature here it's a Time series\n6870.9s: so that's for the historical case and it\n6873.6s: varies depending on the CO2\n6874.98s: concentration as well as you would\n6876.3s: expect the more greenhouse gases you\n6878.46s: have the higher the the temperature\n6880.98s: importantly you can see that there are\n6882.78s: some variation here right and that's the\n6885.239s: natural variation in the climate system\n6886.92s: you have some what we call internal\n6888.42s: viability year to year viability\n6890.04s: actually Ryan talked about that\n6891.84s: yesterday such as El Nino right and Nino\n6894.3s: is actually creating that viability a\n6895.98s: lot of the variability we see here is\n6898.26s: going to be El Nino right\n6900.48s: but we are going to use that as part of\n6902.4s: our training data right we are going to\n6903.84s: see different CO2 concentration and you\n6907.38s: could think of that as the system is not\n6909.42s: deterministic right there's some noise\n6911.28s: there's some stochasticity and in a\n6913.139s: sense it's great you know because the\n6915.179s: more noise and more circuits you have\n6916.739s: you have the the better it is because\n6919.139s: you're trying to actually get into this\n6920.699s: Global minimum not just like a very\n6922.32s: simple uh deterministic values okay\n6925.44s: the other thing important is we're going\n6927.06s: to use those different lines right we\n6928.8s: are going to use again those three lines\n6931.08s: this one that one and that one\n6933.54s: as a function of CO2 methane and we want\n6936.78s: to predict that right so in a sense we\n6939.06s: on top of having this internal\n6940.8s: variability we have three different\n6942.119s: realizations so three different time\n6944.04s: series of CO2 and methane corresponding\n6947.159s: to time series of of temperature right\n6949.32s: so we can use those three and we will\n6950.88s: use those three together to predict\n6953.159s: temperature they could actually give you\n6955.08s: different answers right even for the\n6956.639s: same combination but we are going to use\n6958.32s: them together okay so just one thing to\n6960.719s: keep in mind\n6961.679s: in reality they will give you a little\n6963.54s: bit of difference because if you look at\n6965.159s: methane here even for the same CO2 the\n6968.219s: methane concentration is going to be\n6969.659s: different so they will not exactly be\n6971.159s: the same there will be a little bit of\n6972.84s: difference between those different data\n6974.28s: sets okay but you could have the same\n6977.52s: CO2 concentration leading to different\n6979.639s: temperatures right and that's also is\n6982.44s: because of this adjustment in in methane\n6984.78s: and also because in your data set\n6986.159s: there's some viability okay so that's\n6987.9s: okay\n6989.699s: and you could say we might do a terrible\n6992.219s: job and we won't do it a terrible job\n6995.04s: okay so this is the global average so we\n6998.28s: we're plugging that yesterday actually\n7000.02s: that's exactly what we've done yesterday\n7001.82s: so that's why I don't want to get back\n7003.139s: into that we've done exactly the same\n7004.76s: thing plotting a Time series The only\n7007.4s: change here is that we are doing that\n7008.78s: for different scenarios but it's the\n7010.34s: exact same thing right so no need to get\n7012.02s: back into that\n7013.4s: now the only thing is that we are now\n7016.46s: plotting that also and we've done some\n7017.96s: of that for El Nino we are planning that\n7019.46s: also in space right again same thing so\n7022.46s: then no need to get into that and we can\n7025.1s: do it at different times right so I'm\n7027.56s: doing that plot using exactly the tools\n7029.6s: we've seen yesterday planning that in\n7031.639s: 1900 1950 and 2000 right we can plot\n7036.199s: those images so it's not just a Time\n7037.58s: series but we can add that on every\n7039.44s: pixel of the globe right so exactly the\n7042.199s: same at what what we've done yesterday\n7043.46s: for El Nino for instance\n7045.619s: okay so now comes what we want to do\n7048.8s: here today and we can do that in the\n7050.599s: future as well\n7051.98s: 2020 2050 2100 okay and what we want to\n7056.179s: do is we want to replicate that okay\n7058.099s: that's going to be the objective here we\n7060.619s: will have some carbon dioxide some\n7064.099s: methane and then we will try to predict\n7066.44s: maps of global air temperature so not\n7069.5s: just a global mean we want to predict a\n7071.96s: full map okay that's great because if\n7074.239s: you're in New York maybe the temperature\n7075.739s: is going to be different than say if\n7077.96s: you're in the Mediterranean or if you're\n7079.639s: in Northern latitudes right so we want\n7081.56s: to predict basically the evolution\n7083.36s: across the globe at all times okay and\n7086.599s: we are going to do that it's going to be\n7088.159s: a yearly prediction one value per year\n7090.139s: okay we could be more granular you could\n7091.94s: include season we don't want to get into\n7094.099s: that but just one value per year uh and\n7097.219s: we are going to do that across space\n7099.619s: okay so we are going to predict\n7103.58s: for all of the CO2 concentrations that\n7106.099s: we have and all of the methane\n7107.48s: concentrations that we have all of those\n7109.099s: uh\n7111.08s: I don't even remember like a true value\n7113.78s: uh inputs and then we are going to have\n7116.599s: a number of latitude stem longitudes\n7118.88s: right depending on the resolution of the\n7120.679s: model times the number of time steps\n7122.599s: that we have okay that's what we are\n7123.92s: trying to predict\n7125.719s: okay so uh the first thing we are going\n7129.32s: to do is that we are going to prepare\n7131.3s: the data\n7132.619s: so no need to get too much into that but\n7135.32s: we are going to use all of the\n7136.94s: historical data and as I mentioned\n7138.5s: before the three different scenarios\n7141.159s: ssp1226 SSP 370 and SSP 85858\n7148.699s: uh and we are going to split that into a\n7150.92s: training data set and a test data set\n7152.96s: right and that's actually part of the\n7154.82s: the utility so if you look at this\n7157.52s: function here\n7158.9s: this is how we are preparing the data\n7161.06s: really nothing super important we are\n7162.92s: just concatenating all of those data\n7164.42s: sets because you have different\n7165.739s: scenarios with just stacking them\n7167.599s: together okay so there's really nothing\n7170.06s: super interesting gear we are just\n7172.099s: concatenating here all of that okay and\n7174.26s: appending all of that right so we just\n7176.179s: add the different data sets together we\n7178.28s: don't care whether they are coming from\n7180.26s: different scenarios that's not really\n7181.699s: our issue here okay we just tag them all\n7184.159s: so we'll have a bunch of CO2 and methane\n7188.0s: uh data sets and corresponding maps at\n7191.78s: every single CO2 and methane values\n7193.94s: different Maps right so that's basically\n7195.619s: how we are stacking all of the data\n7199.639s: okay and now\n7202.219s: um\n7203.36s: that's basically going to be the core of\n7205.88s: the things so we can look at those\n7207.139s: things so you could look at the training\n7209.119s: data that's how it looks like right so\n7211.52s: you will have some CO2 values and you\n7213.86s: will have some methane values to those\n7215.54s: are the ones that we have here\n7218.0s: okay so again nothing super uh super\n7221.179s: important\n7222.38s: okay\n7224.119s: now that's basically the core of the\n7227.119s: development of the neural network so one\n7229.099s: thing we didn't mention is that\n7230.659s: typically we always want to standardize\n7233.54s: the data so you take your input so X\n7237.92s: and you always want to basically make it\n7240.98s: between zero and one typically or like\n7243.08s: within number three minus one and one\n7244.699s: why because if you remember we\n7247.04s: initialize some weights right when we\n7249.02s: start getting into the gradient descent\n7251.239s: we have some initial weights and we say\n7254.0s: we need to randomize them and typically\n7256.28s: we take them from a gaussian\n7258.32s: distribution you know with mean of zero\n7261.08s: and standard deviation of one so it's\n7263.06s: better if all of your data is actually\n7264.86s: normalized okay and the typical way of\n7268.82s: normalizing that so it's like a z-score\n7270.619s: you know maybe you've seen that before\n7271.88s: if you believe that your distribution in\n7274.4s: gaussian you take rid of the mean and\n7277.159s: you normalize that by the standard\n7278.599s: deviation another approach is you could\n7280.94s: get rid of the minimum value and\n7283.76s: normalize that by the max minus the\n7285.8s: minimum of the of the data set different\n7288.02s: flavors doesn't matter that much you\n7290.179s: know but the main point being that you\n7292.04s: want your data input data to be roughly\n7295.159s: between minus one and one roughly it\n7297.199s: doesn't need to be exact but profits\n7299.3s: that they are basically normalized why\n7301.88s: because you know it's the same thing\n7303.92s: like if you want to compare say some\n7306.32s: humidity as we had yesterday between\n7308.119s: zero and a hundred percent to a\n7309.92s: temperature that maybe either in Celsius\n7311.719s: or kelvin they have different units\n7314.179s: right so that's going to be annoying if\n7316.34s: you talk about methane that's going to\n7317.96s: be in part per billion if you talk about\n7319.94s: CO2 part per Millions you know how to\n7322.46s: compare upper and uppers and oranges\n7324.5s: right better to normalize the data looks\n7327.32s: very similar and you can see now like\n7329.78s: your methane and CO2 concentration are\n7332.36s: going to be roughly between -1 and 1 and\n7334.699s: we are going to ingest that into the\n7336.08s: neural net so that's much more\n7337.46s: convenient\n7339.199s: okay so that's super simple take the\n7341.96s: mean in your data so dot mean we've done\n7344.06s: that yesterday as well\n7345.739s: and you can take dot standard deviation\n7347.96s: right standard deviation in your\n7349.46s: training data and you just normalize\n7352.639s: your data so remove the mean\n7355.099s: divide by the standard deviation and\n7357.199s: that's going to be your data\n7359.42s: one important point is that I took the\n7362.239s: mean here and standard deviation in the\n7364.46s: training data never never ever do that\n7367.219s: in the validation and test set it's\n7369.199s: called a data leakage you've seen your\n7372.4s: validation or test set because maybe the\n7375.739s: mean has changed right there might have\n7377.3s: been a shift in the distribution and you\n7379.4s: actually included that and you think\n7380.78s: that you actually did a great job you\n7382.699s: know so in fact there's this history of\n7384.619s: people trying to predict the stock\n7386.42s: market and they were actually doing this\n7387.92s: kind of trick they were using the mean\n7389.3s: of the new data say oh we can predict\n7391.28s: the stock market and that was wrong\n7392.599s: right so be careful about that it's a\n7395.54s: very uh\n7396.86s: typical data leakage as we call it we\n7399.199s: use data that we should not have seen\n7401.179s: and we're actually using that yeah\n7409.58s: the why we\n7412.58s: the shape of that is going to be\n7414.58s: latitude times longitude yeah yeah we're\n7417.26s: gonna see that in a minute and\n7419.78s: to your point uh we didn't normalize the\n7422.36s: the whys you know and in a sense you\n7425.06s: could say you know if it's only a single\n7427.04s: value which is only air temperature you\n7429.02s: don't need to right you're just\n7430.639s: predicting one thing remember we have\n7432.56s: this linear activation function and\n7434.54s: that's going to be taking care of that\n7435.92s: waiting and scaling for you so you don't\n7438.139s: need to actually renormalize the output\n7440.119s: but you shouldn't normalize the inputs\n7442.219s: okay that's the important point\n7443.9s: here I got I got a question about this\n7445.46s: work yeah so we're looking at it\n7447.86s: maybe I'll sound like a broken\n7451.94s: record now we're going x-ray to pay\n7455.719s: yeah you could bypass that yeah yeah you\n7457.699s: could bypass that yeah\n7459.199s: yeah yeah yeah for the normalization\n7461.239s: yeah but you're right yeah yeah I was\n7462.739s: thinking about that yesterday we could\n7463.94s: discard that it was discussing that\n7465.5s: actually with the way way that way we\n7467.48s: don't need pandas anymore that's a good\n7470.119s: train uh next iteration yeah\n7473.119s: okay so that's basically what we have\n7475.639s: right\n7476.659s: uh that's the neural network that we\n7478.82s: have two inputs here\n7480.92s: we are going to be changing that so\n7482.54s: that's going to be the competition we\n7483.92s: are going to change the architecture\n7485.119s: here and what we want to predict is\n7487.52s: basically an image it has a shape of 96\n7491.0s: by\n7492.159s: 144. 96 is going to be the number of\n7495.619s: latitude standard number of longitudes\n7498.139s: right so that's it's a basically an\n7499.82s: image right\n7501.02s: uh and every single neuron of the image\n7504.5s: is basically one pixel of the image so\n7506.599s: the air temperature at that particular\n7508.28s: pixel for one particular CO2 and methane\n7512.06s: concentration the time series is going\n7514.52s: to be straightforward those are\n7515.78s: different inputs right you very co2d\n7518.84s: very methane you're gonna vary the image\n7521.3s: you're going to vary the temperature in\n7522.739s: the image in the output okay and we're\n7525.32s: going to use the training data so we are\n7527.119s: going to use those pairs right of CO2\n7530.659s: and methane and images coming from the\n7533.48s: climate model and we want to replicate\n7535.099s: that use that for the training data and\n7537.44s: we're going to check how it does for the\n7540.199s: test set right\n7542.32s: uh we are going to discuss that later\n7544.639s: today but it's what we are doing here is\n7546.8s: absurd right why because we are trading\n7550.04s: all\n7551.36s: pixels as being independent and they are\n7553.639s: not of course right there's a lot of\n7554.96s: spatial structure in the data and we're\n7556.88s: going to talk about convolution but\n7558.32s: let's forget about that one okay keep\n7560.179s: that in the back of your mind\n7561.92s: okay so that's what we have so let's uh\n7564.5s: have fun now so\n7565.88s: uh\n7566.9s: go to line 17 okay that's what we are\n7570.08s: going to do now we are going to start\n7572.3s: building on neural network ourselves\n7574.099s: right so I have a more sophisticated\n7575.84s: version here but we are not going to\n7577.46s: start here okay so what we are going to\n7580.4s: do so are you all on\n7582.5s: a cell 17 yeah\n7595.48s: let's forget about that for now I could\n7597.92s: actually we are going to touch based on\n7599.659s: that in in a moment here if you don't\n7602.06s: mind let's go simpler for now okay\n7605.42s: so in fact we are not even using those\n7607.099s: hyper parameters when I could even go\n7608.659s: above that okay so one thing we are\n7612.199s: going to do is we are going to build a\n7613.94s: model and the model is going to be a\n7615.98s: feed forward uh neural network right so\n7618.32s: in the Keras welding remember we call\n7620.36s: that sequential that was at the very top\n7623.179s: here we said we are going to build a\n7626.42s: model that we're importing from Keras\n7627.92s: it's actually a tensorflow Keras model\n7629.599s: which is called sequential right I mean\n7631.639s: we are importing that right so that was\n7633.56s: here\n7634.58s: okay so we could have a tensorflow.keras\n7638.3s: sequential but we are just going to use\n7639.92s: sequential that's the way we Define that\n7641.599s: and we are going to build that model so\n7644.48s: as simple as it is you just write\n7646.639s: sequential here\n7648.26s: and what it means here is we Define the\n7650.719s: model okay we are defining the fact that\n7653.48s: it's going to be a model where things\n7655.159s: are going to be in sequence it's going\n7657.199s: to be a a neural network a feed forward\n7660.44s: neural network right hidden layers are\n7662.599s: going to be connected sequenced\n7665.42s: and we are going to do one thing right\n7667.28s: so we are going to say uh we have a\n7669.5s: bunch of hidden layers right\n7671.9s: and we are going to start with basically\n7674.42s: a bunch of neurons okay so it's\n7677.42s: arbitrary for now we could start like\n7679.82s: this here let's use 64 right we will\n7682.639s: have 64 neurons completely arbitrary I\n7684.86s: mean there's nothing specific about 64.\n7686.9s: we like having uh uh powers of two just\n7690.739s: you know like it's computer world like\n7692.48s: 32 64 128 but that's what we are going\n7695.78s: to do right so the way it works is we\n7698.0s: are going to say we are going to do\n7699.26s: model add dot add right what it means is\n7702.56s: we we have our model and we are going to\n7705.199s: add because it's sequential we are going\n7706.94s: to add one layer right and we're going\n7709.28s: to do that one at a time okay so one\n7711.08s: hiddenly\n7713.44s: uh okay and that's gonna be what type of\n7717.199s: layer we are going to see there are more\n7718.94s: sophisticated layers we're going to use\n7721.04s: a dense layer we are connecting every\n7723.739s: single neuron ahead of us to every\n7726.26s: single neuron behind us right so that's\n7728.48s: a dense layer\n7730.52s: which will have a given number of\n7732.44s: neurons so just again completely\n7735.38s: arbitrary let's make it 64. okay\n7739.639s: okay\n7740.96s: we will have\n7742.82s: a given activation function right\n7746.119s: I told you I like value so let's use\n7749.06s: radio for now you\n7750.98s: I could be programmed wrong we can use\n7753.02s: another one later\n7754.96s: and it will have a given input shape\n7760.639s: and the input shape actually that's here\n7763.46s: at the bottom that's going to be the\n7764.78s: shape here is just it's a vector of size\n7767.3s: 2 sorry\n7770.739s: and that's this right so that's the\n7773.06s: shape of the input Vector which is of\n7774.619s: size two so it's very simple x train dot\n7777.5s: shape one so that's the First Dimension\n7779.54s: here which is of size two okay so that's\n7781.76s: what we have okay so that should already\n7785.06s: be good to go so that's the first hidden\n7787.94s: layer that we've developed here it has\n7790.28s: an activation function which is a radio\n7792.099s: taking the input layer so we basically\n7794.96s: build up this first hidden layer right\n7798.26s: so we we are here okay one thing I like\n7801.56s: doing uh just me because I like\n7803.78s: sometimes looking at the weights I can\n7805.699s: give it a name okay like you could give\n7807.679s: it a nickname so you could say uh\n7811.159s: I can have also here name equals uh\n7819.5s: hidden uh\n7822.44s: layer\n7823.88s: what okay\n7825.679s: for instance okay just me but I like\n7827.96s: having a name because then you can get\n7829.46s: into the data set and the model and say\n7831.739s: dot in the hidden okay\n7834.8s: now I'm going to add another one here\n7837.98s: I'm going to add another layer right we\n7840.56s: could say I'm going to add a second\n7842.78s: layer I want to basically replicate the\n7845.239s: schematic I have I have here and so\n7847.04s: that's what I meant yesterday so\n7848.599s: building a neural net is almost like\n7850.219s: designing right at this stage it's so\n7852.199s: straightforward now that it's almost\n7853.699s: designing we don't have to debug the\n7855.38s: gradient descent and all that you're\n7857.239s: just designing the infrastructure and\n7858.98s: the structure so it's very convenient\n7861.679s: uh and so you do the same\n7865.58s: I think again a dense layer so I'm\n7867.98s: connecting all of the neurons that I had\n7870.92s: here\n7872.36s: to all of the neurons that are here\n7874.639s: right so that's what I should add\n7879.56s: uh 64.\n7884.84s: uh I will do the same right activation\n7887.599s: function here\n7890.599s: a value\n7894.679s: and I will give it a different name\n7900.679s: it will be layer 2 right\n7904.099s: make sense all of you have that okay\n7909.08s: um so again activation function and I\n7911.54s: just want to again replicate whatever I\n7913.099s: add here so a hidden layout three right\n7916.699s: so I'm gonna have a third layer again no\n7919.219s: particular choice no reason for that\n7920.9s: just often\n7923.02s: to make it a bit more complicated so I'm\n7925.76s: gonna copy paste that and I'm gonna just\n7928.159s: add three okay uh itakshi chaos actually\n7930.739s: learned which is kind of conveniently to\n7932.3s: learn the the right shape in between\n7933.679s: right it learned how many shapes there\n7935.659s: were so you don't need to actually uh\n7937.52s: input that okay but you need to do it\n7940.099s: first right because you need to know\n7941.3s: what is going on at the in the first\n7943.34s: layer and you also need to do it at the\n7945.5s: end right to know what is the what is\n7946.94s: the shape that okay\n7948.739s: then uh so hidden layer three and now we\n7952.219s: are gonna basically add the last layer\n7954.26s: right\n7955.219s: oh sorry\n7958.82s: and the last layer is going to be again\n7960.679s: a dense layer right\n7963.5s: uh\n7964.88s: uh and now that's the only thing is that\n7967.099s: now it has a different shape right it\n7969.56s: has the shape that we want to predict\n7971.119s: which is the shape of the of the image\n7973.699s: right uh you don't need to look into\n7975.739s: that but it's the number of longitude\n7977.48s: times latitude which is directly given\n7979.579s: by the training data so that's going to\n7982.28s: be uh y train dot shape\n7987.079s: what similar to what we had before okay\n7990.26s: uh yeah\n7992.78s: and again what we said is that remember\n7995.36s: the last activation function if it's a\n7997.639s: regression better to make it a linear\n7999.44s: function right just because you're just\n8001.719s: rescating the temperature can go from if\n8004.179s: it's in kelvin from say to 50 or roughly\n8007.179s: to 350 you know so so you you just want\n8010.179s: to learn that I mean no need to actually\n8011.5s: so activation\n8014.139s: equals\n8016.42s: linear so that's a linear one and I like\n8019.3s: again giving it a name so that's the\n8020.92s: output layer just my taste you know\n8023.8s: equals\n8029.079s: layer\n8030.82s: and that should be good\n8034.78s: okay you got that\n8037.179s: I'm sure I made a mistake every time I'm\n8039.159s: typing on the screen or on the\n8040.84s: Blackboard I always make a mistake\n8043.239s: but that should be fine right so we are\n8045.099s: very simple we have a model it's\n8047.32s: sequential we added a bunch of layers so\n8049.659s: three hidden layers with 64 neurons\n8052.5s: activation is going to be a value so\n8054.699s: non-linear in the core right we gave it\n8057.28s: a bunch of names uh and then we have the\n8060.04s: output which is a shape number of\n8062.86s: longitude times latitude\n8065.139s: uh and then the activation is going to\n8067.96s: be linear and we are going to predict\n8069.699s: the output\n8072.099s: okay\n8073.32s: uh and now\n8075.639s: is\n8076.84s: the kind of the core of the algorithm\n8078.639s: right we need to say how are we going to\n8081.699s: get those gradients so first of all we\n8084.579s: need to get a loss right we need to say\n8086.5s: what is the minimization that we or what\n8088.659s: are we trying to minimize right so we\n8090.099s: are going to do multiple compile so\n8092.44s: that's the way we are going to compile\n8093.94s: the laws\n8095.139s: we are going to compile the model we are\n8097.3s: going to give it a loss so now it's also\n8099.76s: as straightforward as that if it were a\n8102.639s: classification I would put cross entropy\n8104.56s: here I just need to do MSE mean Square\n8107.32s: there so even simpler than what I showed\n8109.54s: you even before we we used to do tier\n8111.699s: dot mean you know reduced mean Etc we\n8114.82s: don't need to do that anymore right so\n8116.56s: you could have mean squadero\n8118.54s: or you could have mean absolute error if\n8121.119s: you wanted to just have the the absolute\n8123.28s: value as opposed to the squares you\n8124.84s: could just do m a e okay yeah\n8132.46s: uh what do you mean\n8141.52s: yeah so that's a good point so uh yeah\n8144.52s: so that's a great one\n8147.219s: we are predicting the laws across all of\n8149.98s: those right so the dimension on the\n8151.54s: right hand side is very big right so we\n8153.699s: have uh uh yeah we have uh 13\n8157.179s: 000 points right there are fourteen\n8158.8s: thousand roughly that we are trying to\n8160.179s: predict and the mean Square there is\n8162.099s: across all of those pixels right so we\n8163.96s: want to get the mean Square across all\n8166.719s: of the pixels together you're right so\n8168.699s: we are going to take a batch typically\n8170.32s: so we'll take a bunch of those images\n8172.32s: look at the means the square there the\n8175.54s: sum of them across the image and take\n8177.76s: the mean of that and we want to reduce\n8179.38s: that okay\n8181.0s: what is the implicit assumption we are\n8182.92s: making here\n8186.28s: exactly and that's wrong right\n8188.5s: completely wrong right\n8190.42s: uh we are saying that all of the pixels\n8193.24s: here are I mean another way to put it\n8195.76s: IID\n8197.08s: identical identity distributed and\n8199.54s: that's wrong right we know it's wrong\n8201.7s: because the data is organized in space\n8203.8s: and time right they are C Surface\n8205.84s: temperatures we talked about El Nino and\n8207.7s: Nino is the proof\n8209.399s: that to to tell us that those things are\n8212.439s: not independent right if there's an El\n8214.24s: Nino there's a very strong Independence\n8215.679s: we talked about that yesterday right and\n8217.84s: that's why it's wrong right it's okay\n8220.0s: that's what we typically do but you\n8221.74s: should keep that in mind right there's a\n8223.66s: lot of spatial and temporal organization\n8225.28s: in the climate system so when we do that\n8227.679s: and when we use a mean Square there\n8229.859s: implicitly and we you might have seen\n8232.0s: that when you are doing a regression\n8233.74s: linear regression means clader assumes\n8236.26s: that the errors are independent right\n8238.54s: and typically maybe you've done that for\n8241.179s: regression you look at the shape of the\n8242.74s: residuals right you want to make sure\n8244.54s: that there's no particular behavior in\n8246.639s: the residuals right that's a good way to\n8248.139s: check whether there's something going\n8250.0s: wrong right\n8251.2s: makes makes sense so that's implicit\n8253.359s: right yeah\n8268.78s: locality yeah the sharpness yes you will\n8271.54s: see that we can be pretty sharp yeah\n8273.16s: yeah you will see yeah we can be\n8275.08s: surprisingly shocked yeah now to your\n8277.719s: point like the loss here you know um you\n8280.78s: could actually add as part of the loss\n8282.399s: regularization we can actually easily\n8284.26s: add here regularization which will try\n8286.42s: to spread out the weights\n8288.519s: and I've done that actually exactly on\n8290.74s: those images and what it does is it it\n8292.66s: makes the the feel really smooth and\n8295.359s: kind of blurry and that's that's what we\n8296.92s: want in that particular case so we are\n8298.42s: not going to do that today but that's uh\n8300.46s: that's a good point yeah uh but you're\n8302.38s: right I mean we are treating all pixels\n8304.96s: the same way and we are trying to\n8306.639s: minimize things across and we are trying\n8308.26s: to use those weights to best predict\n8310.179s: that\n8311.679s: makes sense but they are all 3D equal\n8314.32s: okay but also assume to be independent\n8316.78s: which is wrong\n8318.939s: uh okay so that's the loss we could use\n8322.54s: something else it doesn't really matter\n8325.0s: um an Optimizer now we are going to\n8327.399s: define the optimizer let's say in that\n8330.58s: case that we are going to use\n8332.8s: um\n8333.88s: what I mentioned before which is Adam\n8335.439s: right I told you it's kind of great you\n8337.66s: know uh people most people actually use\n8339.639s: Adam you know so we are going to use\n8340.96s: that okay we are not going to change\n8343.0s: that today if you're curious feel free\n8345.099s: to\n8345.82s: to do that and we are going to Define\n8348.28s: here\n8349.96s: a learning rate okay that's going to be\n8352.12s: the important one so we are going to\n8353.439s: defining be defining the initial\n8355.479s: learning rate right then there's some at\n8357.46s: that adaptation right adaptivity of the\n8359.8s: learning rate we are just going to\n8360.939s: Define the initial learning rate right\n8362.8s: that's the hyper parameter that we have\n8365.439s: so the learning rate here uh yeah let's\n8368.5s: say\n8369.399s: um 0.001 transform fun uh and I think\n8374.439s: we're done\n8376.059s: right so quick summary\n8378.82s: again we have these a bunch of dense\n8381.28s: layers we stack them together we are\n8384.219s: trying to minimize a mean Square there\n8386.32s: again on the image and oh I made a\n8389.56s: mistake\n8391.57s: [Music]\n8394.3s: and that's why I said when I'm on the\n8396.46s: ball cheer.care is optimizers we are\n8398.68s: using the Adam Optimizer with a given\n8400.479s: learning rate which is 10 to the minus\n8402.1s: 3. why 10 to the minus three\n8404.62s: why not okay so we are going to use that\n8407.68s: and we are going to use some of that so\n8409.899s: in the competition you will have to\n8411.64s: change\n8412.54s: the number of neurons\n8414.64s: you could change the activation function\n8416.62s: here\n8417.76s: you could change the learning rate\n8419.979s: and you could change the number of\n8422.26s: layers okay we are going to discuss that\n8424.78s: in a minute\n8426.34s: so I can run that oh sorry\n8431.22s: let me\n8434.08s: yeah yeah sorry sorry I need to rerun\n8436.06s: that\n8437.08s: okay let me run my script\n8446.02s: okay\n8451.2s: this one is not really needed\n8454.479s: I'm gonna run it anyways and this should\n8456.939s: be let's see\n8458.62s: okay so it's as simple as that you know\n8461.2s: so that's kind of the advantage of using\n8463.0s: Keras it's really just a few lines of\n8465.22s: code you know when you look at look at\n8466.72s: it it's so simple you know back in the\n8469.24s: days people were even coding the\n8470.8s: gradient descent you know like the\n8472.18s: squares you know like The Descent you\n8473.859s: know all of that you know now it's all\n8475.18s: in the background\n8476.859s: uh I made a mistake of course\n8481.42s: what did I do\n8483.22s: oh yeah I forgot yeah I that's what I\n8485.62s: said yeah I always make a mistake\n8491.399s: uh and I'm\n8494.859s: friends yeah somewhere and I don't see\n8497.56s: that\n8499.2s: uh\n8501.18s: here right\n8505.319s: here yeah\n8507.28s: I think I was missing this one and here\n8512.02s: yeah sorry I was missing those brackets\n8514.24s: and here\n8520.18s: yeah after dance there was a bracket\n8522.52s: sorry about that\n8525.22s: oh\n8526.84s: uh where is that\n8530.38s: here\n8533.8s: yes uh I uh yeah sorry oh\n8538.899s: we'll get it yeah thanks\n8542.5s: and no something happened\n8545.439s: okay let me rewind that\n8556.479s: yeah it should work okay\n8558.76s: okay\n8560.46s: let's wait for that so then one thing we\n8564.16s: can do is we can look at one thing\n8565.72s: that's very convenient is we can look at\n8567.52s: the summary of the model\n8569.56s: okay and what we can do is we can\n8572.859s: actually see basically the layers with\n8575.26s: the name you know like I gave them some\n8577.3s: names you know like hidden layer one etc\n8579.52s: etc to the output layer\n8581.2s: gives you the shape so the number of uh\n8584.08s: neurons Etc and then the advantage and\n8587.02s: the the weights here uh and then the\n8589.06s: advantage is it can compute the total\n8591.1s: number of weights and biases okay so\n8593.02s: that's very convenient it gives you\n8594.28s: basically the number of degrees of\n8595.78s: freedom in your full model and that's\n8598.12s: very convenient because you can know\n8599.38s: like in that case for instance I will\n8601.12s: have one million roughly number of\n8604.3s: parameters so that's a lot of parameters\n8605.8s: that I need to to tweak right\n8608.02s: uh so that's actually and it tells you\n8610.479s: where they are coming from in which\n8611.92s: layer you know so you could see in that\n8613.3s: particular case it's actually in the\n8614.56s: last layer in the output layer that I\n8616.06s: have most of them\n8623.68s: I don't know what's going on\n8627.04s: and the metric I'm optimizing for is MSC\n8629.5s: means Squad era\n8634.6s: maybe I need to rerun the\n8638.02s: yeah I think it's because it's the the\n8639.88s: one for me last night actually let me\n8643.06s: get back to this sorry\n8646.899s: sorry\n8648.399s: um\n8654.22s: oh and I need to recode everything oh no\n8674.08s: I should still have the\n8678.34s: foreign\n8682.96s: okay\n8685.0s: so uh maybe we'll take a break uh so\n8689.08s: what we are going to do next is we are\n8690.819s: going to\n8691.84s: fit the model so so far we just build\n8694.0s: the model right it's like designing\n8695.62s: architecture and now we are going to fit\n8697.6s: that and we are going to keep track of\n8699.76s: two things remember we wanted to look at\n8701.5s: early stopping of overfilling we're\n8703.96s: gonna keep track of the training loss we\n8706.06s: are going to keep track of the\n8707.26s: validation loss right and then what we\n8710.319s: are going to do is we are going to look\n8711.76s: at also networked here so you can see in\n8715.72s: the particular case we built together so\n8717.52s: we had three hidden layers\n8719.56s: we are the output layers total number of\n8722.08s: parameters so it explodes pretty quickly\n8723.939s: right 900 000 parameters so if you're\n8726.399s: used to linear regressions that's a lot\n8728.979s: right so that's why you need to have a\n8730.359s: good technique to actually find all of\n8732.1s: those weights and remember like when we\n8734.319s: looked at the shape of the loss right we\n8737.08s: only had two Dimensions right good luck\n8738.939s: trying to get a sense of that in uh with\n8741.34s: 900 000 Dimensions right so and most of\n8745.6s: them are actually in the last layers\n8747.88s: right it's the last layer that's\n8749.8s: contributing most of the way type\n8751.12s: remember we are trying to predict the\n8752.439s: full image based on just two inputs\n8755.56s: right CO2 and methane right so that's\n8757.6s: why you have so many uh degrees of\n8759.52s: freedom at the end okay we are going to\n8761.68s: change that we are going to play with\n8763.479s: the structure and then the the one thing\n8765.64s: we are going to do is we are going to\n8766.72s: just fit that see how that's going to\n8769.06s: behave when we change the structure okay\n8770.68s: that's what we are going to do after we\n8772.12s: we pray okay everyone has that model\n8775.18s: summary just to make sure worked for\n8776.979s: everyone yep any issues and sorry for\n8781.06s: the brackets yeah and things I'm always\n8783.28s: struggling on the on the ball works for\n8785.62s: everyone\n8786.46s: got that\n8788.14s: perfect okay so let's have a break and\n8790.479s: let's compete you know with the neural\n8792.46s: Nets yeah\n8798.28s: so we'll uh\n8800.2s: reconvene at 12 45 okay we have 40\n8802.72s: minutes\n8806.26s: maybe some wedding music or some rock\n8808.78s: music you know it depends on the mood I\n8810.46s: guess\n8815.98s: [Music]\n8825.64s: is everyone back\n8833.14s: so I'm just gonna refill my coffee\n8841.479s: sorry\n8842.979s: I didn't know\n8850.24s: okay\n8853.0s: so let's get back to\n8855.04s: business so we're debating a little bit\n8857.62s: from the original plan so we are\n8860.14s: spending a little bit more time now on\n8861.52s: the studio as opposed to the to the\n8863.319s: lecture I don't think you will complain\n8865.38s: uh and then we'll get a little bit later\n8867.76s: into like in 30 minutes we'll get into\n8869.56s: the convolutional neural net you know\n8871.06s: that's going to be relatively\n8872.8s: straightforward\n8874.42s: Okay so\n8876.16s: what were we doing before lunch we\n8878.68s: basically built a very simple\n8880.56s: architecture here again fit for neural\n8883.84s: network a bunch of hidden layers we have\n8885.88s: three of them we have the output here\n8888.28s: learning rate Adam Optimizer and we are\n8891.88s: minimizing the loss okay again at this\n8894.819s: stage we haven't done anything no\n8896.68s: training anything is just the\n8898.42s: architecture right\n8900.34s: we looked at the summary just diagnostic\n8903.7s: I mean we are not doing anything here\n8905.08s: just a diagnostic to get a sense as to\n8907.42s: what is the dimension that we have here\n8909.58s: 900 000 degrees of freedom so it's a lot\n8913.08s: but that's potentially what we will need\n8915.58s: okay\n8916.62s: one thing I wanted to got a nice\n8919.3s: question during the break you know\n8921.46s: remember here those are different pixels\n8924.1s: right\n8925.12s: and remember those are latitude and\n8928.18s: longitude and depending on how we\n8929.74s: actually uh basically convert that to a\n8932.439s: vector you might have all of the lower\n8934.6s: latitudes at this like kind of stacked\n8937.479s: together right so for instance all of\n8939.28s: the lower latitudes will be here\n8941.26s: but it doesn't matter right you could\n8944.08s: have\n8945.22s: a high latitude point\n8947.5s: close to a lower latitude plots right\n8950.439s: you could have the Amazon here close to\n8952.78s: the poles right it doesn't matter at all\n8954.819s: and in fact it will not change the\n8956.5s: quality of the prediction right there's\n8958.479s: no sense of organization here so that's\n8960.46s: something to keep in mind there's really\n8962.62s: no sense of spatial structure here we\n8965.319s: could shuffle all of those pixels across\n8967.96s: doesn't matter as long as of course as\n8970.3s: we are keeping the same structure uh\n8972.819s: when we are training but it doesn't\n8974.62s: matter where those pixels are right we\n8976.66s: can replicate that anywhere okay that's\n8979.18s: actually very important remember and\n8980.62s: that's\n8981.399s: related to the point we made earlier\n8983.2s: that we assume that those pixels are\n8985.359s: independent right we are training them\n8986.859s: independently right or\n8989.319s: like yesterday for instance we talked\n8991.0s: about El Nino we could actually take\n8992.68s: just a subset of the image that could be\n8994.42s: actually kind of fun we could predict\n8996.04s: just an email maybe we will do a better\n8997.78s: job by just restricting ourselves to a\n9000.54s: region right that's something we could\n9001.979s: do you know if we wanted to just predict\n9004.2s: the linear potentially okay\n9006.84s: so again no sense of organization here\n9009.18s: any all pixels are independent\n9012.56s: ah okay so now that's going to be the\n9015.66s: core of the uh of the training so we are\n9018.0s: going to do two things\n9019.5s: we are going to remember we wanted to\n9021.84s: limit\n9022.88s: uh uh overfilling so we are going to do\n9025.62s: this early stopping thing right\n9027.72s: so we don't do going to do\n9029.84s: keras.callbacks dot early stopping so we\n9032.64s: are monitoring the laws you know we are\n9034.859s: going to plot that don't worry\n9036.66s: and we are going to say we are going to\n9038.52s: do early stopping on something and the\n9040.26s: something is going to be the validation\n9041.939s: loss we could choose any of those right\n9044.939s: we could um where was my\n9048.24s: I think I closed that uh\n9055.26s: sorry it just go back to\n9058.68s: where I was\n9064.68s: uh yeah here okay if you remember here\n9067.62s: uh we had\n9069.84s: training iteration\n9071.64s: validation loss and for the early\n9074.58s: stopping we don't really care so much\n9076.2s: about the training loss right we want to\n9078.54s: care about the validation law so that's\n9080.1s: why we are saying look at the validation\n9082.14s: loss for the early stopping right that's\n9084.18s: what we want to do right so but we need\n9086.88s: to specify that I mean tensorflow or\n9089.1s: Keras doesn't know that a priority\n9092.72s: uh where are we\n9097.62s: survive Firefox issue okay uh and an\n9102.84s: important parameter here is and I got\n9105.3s: the question before uh we are going to\n9107.52s: use what we call patience okay patience\n9109.56s: is just a parameter a simple name makes\n9112.62s: sense we are waiting for a few epochs so\n9115.439s: we are going through the whole data set\n9118.08s: couple of times in that case 20 times\n9119.819s: because it could happen that you could\n9121.859s: have a little bit of spikes you know in\n9123.66s: the loss so your validation loss you\n9125.76s: know the plot that I had was very very\n9127.319s: smooth in reality it's not like that\n9129.0s: right you could have spikes so we just\n9131.04s: say let's wait for 20 iterations and\n9134.58s: after those 20 iterations if we see no\n9136.62s: improvement whatsoever we're gonna stop\n9139.02s: but at the initial point right before\n9141.479s: those 20 uh patients uh epochs right so\n9146.34s: we are just gonna wait for 20 time steps\n9148.2s: basic\n9149.76s: and then as simple as that we are going\n9152.88s: to train the model right so uh in\n9156.06s: tensorflow it's called train uh here in\n9159.319s: tensorflow it's called fit\n9162.12s: and we are just gonna train those neural\n9164.58s: networks right and remember what we are\n9167.1s: doing here is feeding the weights we\n9169.5s: have some input data some label data so\n9172.26s: it's supervised learning a regression\n9174.54s: problem and we are trying to actually\n9176.58s: fit that right\n9178.62s: so the input is going to be some data\n9182.1s: set that we call X strain right that the\n9184.26s: one we prepared above with the different\n9186.06s: scenarios\n9187.319s: why Train That's the prediction right\n9190.56s: uh so those are the labeled images of\n9193.439s: temperature at different CO2 and methane\n9196.2s: concentrations\n9197.64s: we can change and we talked about that\n9199.56s: before the size of the mini batch okay\n9201.899s: we had that question earlier right so 32\n9204.66s: 64 128 that's a hyper parameter that one\n9208.02s: can tune let's use that so here I had\n9211.2s: selected 64 doesn't really matter for\n9214.5s: that purpose and for how long we are\n9216.479s: going to run right we need to be\n9218.1s: reasonable here right we have some\n9219.66s: limited compute power if you're doing\n9221.64s: that on the cloud and you're paying for\n9223.859s: that you know better want to be careful\n9225.66s: so you're going to be specifying a\n9227.76s: number of epochs so in that case the\n9229.74s: maximum number of epochs we are going to\n9231.6s: uh to to to run the model for is going\n9234.54s: to be 50. okay it's not super\n9236.28s: complicated so 50 should be roughly\n9238.26s: raise number but that's when we are\n9239.939s: going to stop right we don't want to go\n9241.26s: forever and potentially the early\n9243.66s: stopping will stop even earlier right so\n9245.7s: earlier than the 15 you know if we have\n9247.56s: anything that's working well\n9250.26s: okay and uh and that's it right and then\n9253.859s: uh the only thing is that typically when\n9256.8s: we do this\n9258.18s: um training and validation we need to\n9260.28s: split the data as I mentioned earlier so\n9262.62s: we take the whole data set and we say\n9265.38s: we'll split that into one part that we\n9267.899s: are going to use to tune the weights and\n9270.6s: the other one that we are using to\n9272.34s: validate the model right and on that\n9275.04s: validation data set we are never\n9276.78s: retuning the weights right we are just\n9278.46s: using that to evaluate the loss but we\n9281.34s: don't have the step where we re retune\n9283.68s: the weights right so the tuning of the\n9286.02s: weights is just in the validation set\n9287.7s: and not in the training in a sorry just\n9290.76s: in the training set sorry oh I apologize\n9292.46s: we are just training the weights in the\n9295.5s: training set and we are using the\n9297.24s: validation just as a diagnostic right so\n9299.58s: no tuning whatsoever okay in that case\n9302.28s: we say 20 of the data is going to be\n9304.56s: used for validation so that's the point\n9306.06s: twenty percent\n9307.8s: so let's use that so if you could try\n9309.6s: that you just need to click here run\n9311.76s: that cell\n9313.14s: and that's starting okay so we are\n9315.12s: training so what are we doing we are\n9318.0s: actually doing back propagation\n9319.8s: with Adam strategy right starting with\n9323.52s: the given learning rate that we had\n9325.08s: learned we as we had selected before we\n9328.02s: are doing that on batches like small\n9330.359s: battery switch stochastic right mini\n9332.52s: batches of a given set which was 64.\n9335.72s: uh and that's we are looking at that\n9338.58s: across different Epoch so one Epoch is\n9340.62s: again we are going through the entire\n9342.42s: data set once twice etc etc\n9345.899s: what should happen is that the loss\n9348.24s: which is here the training loss should\n9350.88s: be going down right remember the curve\n9352.859s: we had seen before it should be going\n9354.359s: down\n9355.439s: and we have the validation loss here\n9357.6s: right so uh that's also one thing that\n9361.02s: should also go down Okay so\n9363.6s: we could track that\n9366.06s: okay so that's still uh I think that's\n9368.88s: stopped okay so that's right it stopped\n9371.16s: after 25 epochs I don't know in your\n9373.319s: case that could be random anyone got a\n9376.439s: different number than 25\n9379.979s: try try and run it please yeah just to\n9381.96s: make sure\n9386.46s: I don't think so\n9394.7s: 24. okay great\n9397.14s: 27 okay so no not the same seat so\n9399.66s: that's right\n9402.359s: make sense\n9403.92s: works for everyone\n9406.02s: success thumbs up okay right so you\n9410.399s: actually uh train your first neural\n9412.5s: network or maybe some people have done\n9414.24s: that before\n9415.62s: okay\n9417.0s: so one thing we want to pay attention to\n9419.46s: is let's look at the loss here right so\n9422.58s: the number is going down and you can see\n9424.8s: here right the number 135 96 we are\n9428.819s: plateauing right so makes sense that you\n9431.7s: know we would want typically to stop and\n9434.1s: you could actually look even here the\n9436.56s: number we went from 127 to 128 75 and\n9441.72s: 126 okay so in fact if you look at the\n9445.5s: number at the top we had 120.27 already\n9448.439s: and we are kind of wiggling around right\n9451.08s: we are very very close to 127 all the\n9453.3s: time so it means there's really no\n9455.34s: improvement whatsoever okay so we should\n9457.56s: stop and that's the early stopping that\n9459.359s: we had before and that's why we are\n9462.12s: stopping at 25 right there was no\n9463.8s: improvement the validation loss is\n9466.14s: telling us like no please wait we are\n9468.72s: trying to fit the noise in the data we\n9471.18s: are overdoing it so let's stop now okay\n9473.7s: and we can visualize that that might be\n9476.399s: even better and you can see\n9479.04s: that's the training loss in the\n9480.84s: validation loss they happen to be I mean\n9482.88s: typically the training loss is below I\n9484.56s: mean no need to get too much into that\n9486.0s: but the main point being that the\n9487.8s: validation loss\n9489.359s: is actually going up here and it's\n9492.96s: pretty flat right so that we would want\n9494.76s: to stop right there's no need to\n9496.02s: continue right and but you can see that\n9497.939s: the training loss you could actually\n9499.439s: zoom in is actually getting down a\n9501.18s: little right so we are starting to\n9502.68s: overfit right and we would want to\n9504.18s: actually avoid the overfitting typically\n9506.52s: we want to stop around here right so\n9508.859s: that's why we had this early stop it\n9511.08s: make sense\n9512.52s: to everyone\n9513.72s: so as you see it's surprisingly simple\n9516.479s: right I mean it's just a few lines of\n9518.88s: code uh we really harvested two things\n9522.359s: right we could get the climate data from\n9526.02s: pangeo no straight you know so it was\n9528.359s: really just a few lines of code to\n9530.28s: actually get some pretty complex climate\n9532.02s: data\n9532.92s: at the annual time scale different\n9535.2s: scenarios Etc and we leverage the fact\n9537.84s: that this architecture especially chaos\n9539.399s: is really really simple like adding a\n9541.14s: few layers uh works well okay\n9544.02s: so that's fine you can save the model\n9545.88s: doesn't really matter I like doing that\n9547.859s: because if you want to reuse that and\n9550.26s: now we can evaluate the model on some\n9552.72s: something else so the the one test here\n9555.6s: is that\n9557.399s: we would want to actually test the model\n9559.5s: on the other scenario we have not used\n9561.3s: remember we took off one of the\n9563.46s: scenarios\n9564.62s: so that was SSP 245 and we want to test\n9568.92s: the model on the scenario so we are\n9570.72s: again no need to actually get too much\n9572.22s: into that but we are loading the model\n9574.38s: that we just had so that's a way to save\n9576.3s: your model you can save it somewhere and\n9578.22s: load it later so that's uh you save the\n9581.399s: model here we call it NN underscore\n9584.399s: model.h5\n9586.14s: somewhere and then you're loading that\n9588.24s: later you could load that because you\n9589.979s: want to pass it over to someone else I\n9591.6s: have this great model let me give it to\n9593.28s: you you have a publication great put\n9596.52s: that model somewhere you know and just\n9599.04s: give the link to someone they can load\n9600.96s: the mother replicate your data so it's\n9603.0s: very very useful right and what the\n9605.04s: model is is actually very simple it's a\n9606.72s: bunch of weights right just a bunch of\n9608.7s: weights and biases so it's just a matrix\n9611.22s: right so it's really all tensor so\n9613.02s: really really simple\n9615.42s: okay and then we can do the same right\n9619.56s: we can so I don't know where I was here\n9621.72s: yeah so\n9623.22s: we can test that on the on the on some\n9627.0s: some other data set here so SSP 2.4 and\n9630.3s: we are going to plot that okay so no\n9631.92s: need to get too much into the weeds but\n9634.5s: we are using exactly what we've been\n9636.78s: using yesterday with Ryan right just the\n9638.64s: plotting exercise okay\n9640.56s: so let's look at that\n9643.319s: on the right hand side was this SSP 245\n9647.52s: so that's a climate model here\n9650.28s: and that's the prediction we just made\n9652.14s: with our neural net right pretty good\n9654.359s: right\n9655.439s: and you can see it's actually quite nice\n9657.78s: I mean you can see the continents quite\n9659.46s: well like Australia South America North\n9661.56s: America you know Africa are great uh and\n9664.8s: you can also see a lot of the gradients\n9666.66s: that we see in terms of latitudes as\n9668.88s: well right\n9670.56s: so quite nice right so that's in 2030\n9672.899s: why 2030 so it's 20 30 but remember it's\n9676.14s: actually not really a year that we have\n9679.08s: as an input it's actually the\n9681.0s: corresponding CO2 and methane\n9683.34s: concentration for that particular year\n9685.319s: in that particular scenario that's how\n9687.06s: it's defined okay we we we use year here\n9690.18s: but that's year within that scenario\n9691.68s: just for you to know okay\n9693.6s: and then we can do that uh 2050 here so\n9696.96s: see that's again uh doing quite well we\n9700.2s: remember we never saw that particular\n9702.359s: scenario right we never saw those\n9703.979s: particular concentration of methane in\n9705.84s: our training data or not that particular\n9707.399s: climate realization but we are doing a\n9709.859s: great job right\n9711.24s: and we can go all the way to 2100 notice\n9714.18s: that we capture even all of the\n9715.7s: structure here you know at another\n9718.56s: latitude so what we call the Arctic\n9720.12s: amplification the fact that it's much\n9721.8s: warmer at the normal latitudes than the\n9724.26s: rest okay in fact we are we're going to\n9726.96s: expand\n9730.439s: right so uh and that's going to be yeah\n9733.5s: exactly so if you could run that you\n9735.12s: know um\n9736.74s: everyone is going to be getting\n9738.18s: something slightly different right and\n9740.58s: that's okay yeah\n9749.88s: right\n9753.6s: yeah and that's basically signal to\n9755.939s: noise ratio right\n9757.92s: um we are going to see that in a minute\n9759.72s: uh so here\n9762.06s: the signal we are trying to predict is\n9764.04s: climate change right uh and so we expect\n9767.58s: that to be very very strong by 2100\n9770.34s: right by definition especially when you\n9772.2s: are in a high uh greenhouse gas\n9774.54s: concentration uh scenario right so\n9778.2s: for that particular scenario right but\n9780.18s: you could even be going further and you\n9782.16s: could say I could also look across\n9783.6s: scenarios and in the low emission\n9785.819s: scenarios I do expect to be doing a poor\n9787.92s: job than in the higher scenarios you're\n9789.96s: right right it's just signal to noise\n9792.3s: ratio right\n9793.56s: we can go one step further and say you\n9796.439s: know what\n9797.58s: uh in your network let's remember that\n9799.92s: it's a deterministic component right so\n9802.74s: the Machinery is deterministic so this\n9805.56s: map if I were to regenerate another one\n9809.1s: for the same CO2 and methane would be\n9810.899s: exactly the same one right now if I'm\n9813.78s: re-running a climate model we slightly\n9815.64s: perturb the climate model so every\n9817.2s: climate model is going to be slightly\n9819.18s: different and that's what you use yes I\n9820.92s: refer to as the Ensemble members right\n9823.2s: there's going to be slight variations uh\n9826.56s: between different models that are just\n9828.54s: inherent to The Climate system right we\n9831.06s: have some internal availability there\n9833.399s: are some there are some internal\n9834.899s: stochasticity in the climate system so\n9836.46s: we cannot be perfectly replicating that\n9839.34s: we are going to see that in a minute and\n9841.74s: that's also why we might be missing some\n9843.78s: mode availability right so for instance\n9845.939s: you should not expect to get a linear\n9848.16s: with that model right because that's not\n9851.46s: something that can be explained directly\n9853.08s: by as a yearly value as a function of\n9855.66s: CO2 and methane right so we should not\n9857.34s: have 7 and you if you have one that's a\n9859.56s: mistake okay there's an issue\n9862.02s: does that make sense\n9863.46s: right we are not capturing internal\n9865.68s: availability right so in another way to\n9868.319s: say that is that if we look back\n9871.5s: at the time series that we have\n9873.72s: remember that we had a lot of\n9875.34s: variability here that was the internal\n9877.62s: stochasticity in the climate system\n9879.18s: right internal viability such as El Nino\n9882.0s: and so on and so forth we are not\n9883.859s: capturing that the neural network is\n9885.96s: trying to do a smoothing of all of that\n9888.359s: right it's trying to fit a deterministic\n9890.7s: line a deterministic curve through all\n9892.92s: of them\n9894.96s: makes sense\n9902.939s: yeah that's what I\n9904.74s: I meant that we we say year but it's\n9907.02s: really uh for each year here especially\n9909.899s: in the future you will have different\n9911.22s: CO2 concentration depending on the type\n9913.38s: of emissions you assume\n9919.439s: they are based on co2 and methane yeah\n9921.6s: so\n9922.8s: um\n9925.08s: basically you need to have what we call\n9926.58s: an integrated assessment model so you\n9928.26s: need to have a couple system so you can\n9931.02s: actually\n9931.92s: Define for a given amount of emissions\n9934.38s: that people put in you need to know how\n9936.3s: much the land is going to take up how\n9937.859s: much the ocean is going to take up and\n9939.84s: then you need to make a basically it's a\n9941.58s: mass balance to tell you how much CO2\n9943.14s: methane you will have in the atmosphere\n9944.7s: and that's what we use as fasting for\n9946.56s: those climate models so we don't\n9948.3s: directly use years they they\n9951.18s: never see here anywhere but they see CO2\n9955.319s: and matting as input you know it's just\n9957.54s: for the plotting here because\n9959.22s: I have no I mean most people have no\n9961.14s: sense about like CO2 if I were to plot\n9962.88s: CO2 on that plot no one will know what I\n9965.1s: mean but years you you do know years\n9966.84s: right\n9967.859s: but that's uh but it's uh yeah just to\n9970.56s: give a sense of that\n9973.14s: does that does that make sense\n9975.3s: any questions yeah\n10005.74s: uh that's a great Point\n10008.18s: um so let me maybe go back to this\n10011.479s: I would say you're right I could\n10013.76s: actually use your favorite regression\n10016.16s: through your random forest or gradient\n10018.56s: boosting or whatnot right in fact for\n10020.72s: that I would say doesn't matter\n10023.6s: um as just give me the best model right\n10025.58s: and you can test that sometimes it's\n10027.08s: unclear which one is going to do to be\n10029.12s: giving you the best result\n10031.22s: typically what happens is that when you\n10033.68s: have a lot of data the neural Nets tend\n10035.54s: to be superior uh they tend to be doing\n10038.359s: a better job but you need a lot more\n10040.04s: data when your data set is a bit small\n10042.58s: xgboost random Forest Etc tends to be\n10045.319s: doing a better job you know just kind of\n10048.14s: uh for for very Simply Now what we are\n10053.06s: going to cover later is that\n10055.52s: it's true in this case because we\n10057.38s: assumed again that every pixel was\n10059.12s: independent basically from from the\n10060.859s: neighbor in terms of how we compute the\n10062.359s: loss so you're right you could actually\n10063.979s: use a regression tree but what we are\n10066.2s: going to do next is actually capturing\n10067.58s: or using the spatial features and for\n10069.74s: that you cannot do that with the random\n10071.359s: forest or an XG or gradient boosting\n10073.399s: right\n10074.42s: so that will be a huge advantage of\n10076.64s: neural networks is embedding those Auto\n10079.46s: correlation in space and type okay and\n10081.68s: that's something we cannot do with\n10082.7s: regression trees\n10085.04s: does that make sense so I would say\n10086.66s: you're right at this stage you know you\n10088.58s: could actually use a random voice fine\n10092.6s: and yeah\n10101.24s: throughout time but those with those\n10103.1s: slices\n10103.939s: if you make like a random\n10106.399s: like increasing and decreasing CO2 level\n10108.8s: and you run that and predict it's not\n10110.84s: going to predict correctly it's going to\n10113.479s: predict correctly because we also assume\n10117.439s: when we do that is that and that's\n10118.76s: actually a great question is that\n10120.8s: we assume that every year is actually\n10122.66s: independent you know we we are not using\n10125.18s: any type of so\n10127.28s: we assume that pixels were independent\n10129.68s: in space but we also assumed that years\n10132.5s: were also independent in time right so\n10135.38s: I'm using CO2 methane assuming I can\n10138.859s: predict temperature right now\n10140.899s: just based on that I don't need any\n10143.359s: memory in the climate system as part of\n10145.58s: that so what it means is that I can\n10147.319s: suffer the years right in fact we are\n10149.72s: doing that within the mini batch\n10151.1s: strategy we are shuffling the the images\n10153.38s: that we are getting\n10155.479s: um but we um\n10157.76s: but you don't see that right but we are\n10159.68s: shifting them yeah\n10161.72s: if we wanted to include a memory uh and\n10164.54s: we are going to do that at the end you\n10166.52s: cannot Shuffle randomly because you're\n10168.08s: gonna break some of those Auto\n10169.64s: correlations in time right so that's\n10171.74s: going to be a slightly more subtle\n10173.359s: aspect similar to the spatial\n10175.22s: autocorrelation right in that case we\n10177.439s: cannot just Shuffle the pixels right we\n10179.66s: need to preserve the spatial context as\n10182.42s: well\n10183.62s: does that does that make sense\n10195.2s: in real life but the model cannot do\n10198.08s: that the mother cannot do that because\n10200.5s: it only sees yeah and that's completely\n10205.16s: right I mean\n10208.06s: the climate model could yeah exactly if\n10211.22s: you had a ramp or if you had a sharp\n10212.84s: decrease in CO2 if you could assume\n10214.52s: actually we played that game with a with\n10216.2s: an Intel bag this summer\n10218.24s: um we used actually machine learning for\n10219.859s: that but anyways you can drop emissions\n10222.28s: but in your right I mean you could have\n10224.6s: some memory like the ocean for instance\n10226.16s: you know uh but this model could not\n10229.22s: capture that right because we are saying\n10231.02s: that we take a high CO2 and that will be\n10234.5s: similar to having a low CO2 when the\n10237.38s: temperature was lower but I know that my\n10238.939s: temperature will be higher for quite\n10240.5s: some time right we cannot capture that\n10242.66s: here what you could do though is you\n10244.52s: could say I could include a memory\n10246.56s: process so that my temperature now is\n10249.319s: actually dependent on the past\n10250.88s: temperature as well you could think of\n10252.8s: that basically what we are trying to do\n10254.42s: it's a dynamical system right so in that\n10256.76s: case that could make sense you could say\n10258.2s: I could look at the change in CO2 and I\n10260.899s: could see how my system is behaving\n10263.479s: yeah that's a good thing yeah\n10266.6s: does that answer you all yeah but that's\n10268.7s: a great point and that's also why I mean\n10270.92s: to me that's exactly why uh physical\n10273.979s: intuition should always be like the\n10277.22s: winning uh components here right brute\n10279.8s: forcing machine learning is wrong right\n10281.96s: I mean when people say okay I can do\n10284.0s: whatever no that's not true you can do\n10286.16s: whatever on the training data that you\n10288.14s: have but you're right that's exactly one\n10289.52s: example where uh it was not working\n10291.8s: because you were doing something that\n10293.3s: you had not seen in your training data\n10295.399s: right so in that case it would be the\n10297.859s: wrong thing to do to say I'm gonna\n10299.0s: predict what's going to happen that's\n10300.62s: wrong you're going to get the wrong\n10301.7s: prediction okay another example that to\n10304.28s: me is very useful is population and CO2\n10307.16s: highly correlated right so why don't I\n10309.74s: actually put population density or\n10311.479s: population here on the left hand side\n10313.16s: and predict the temperature because\n10315.38s: population is going to be flattening\n10317.359s: yeah that's right and plattering but CO2\n10319.76s: will keep on keep on going up right so\n10322.16s: that's the time when there will be a\n10323.72s: decoration between the two if I were to\n10325.88s: use population it would be the wrong\n10327.439s: thing to do in the future right so\n10329.3s: that's the case again where correlation\n10330.8s: and causation of physical drivers are\n10332.84s: really important always try to use\n10335.06s: physical intuition when building those\n10337.279s: tools okay\n10339.56s: yeah\n10340.52s: well it was just a comment please\n10347.319s: say I mean you have to know something\n10349.46s: about the prior to getting your\n10350.779s: posterior right\n10352.16s: if you have a bad fire then you won't\n10354.02s: make applications\n10356.3s: yep that's true it's kind of like you\n10358.279s: already know something you can put in it\n10361.04s: yeah exactly I mean prior or we talked\n10364.46s: about inductive bias I mean that's the\n10365.96s: same thing in that case we are using our\n10368.12s: physical prior right our physical\n10370.16s: inductive bias right I mean to me I love\n10373.04s: this one so I will never give it away\n10376.819s: okay\n10377.84s: good any questions so far everyone\n10379.88s: managed to run that fine did you get\n10382.46s: your maps are they very similar to to\n10385.399s: mine everyone should have a slightly\n10386.779s: different map you know\n10388.46s: okay you got that looks good and again\n10391.88s: we are not capturing everything exactly\n10394.58s: the same but that's okay you know again\n10396.62s: there might be some internal variability\n10398.18s: when not capturing\n10401.18s: oh yeah the truth should be the same\n10402.68s: yeah of course otherwise it's one class\n10405.14s: or wrong about camera\n10407.54s: okay uh so let's have fun\n10410.24s: um\n10410.84s: now so if you can run that uh if you\n10414.14s: know where you were born so uh uh so\n10418.1s: actually I put Paris here\n10420.26s: um\n10421.1s: so\n10422.54s: what you can do is now let's look at\n10424.88s: some time series right so we have pixels\n10426.92s: here\n10427.76s: and now we can look at those same series\n10430.1s: and compare that to the climate model\n10431.84s: right and we can do that in the past and\n10434.12s: we can do that in the future okay so for\n10435.859s: fun here\n10437.359s: uh cell 23 we started by doing the the\n10442.34s: um oh sorry I forgot that\n10445.64s: um we are starting by the putting the\n10448.58s: latitude and longitude of New York and\n10450.74s: you can actually now plot the time\n10452.42s: series the same way we've done that you\n10454.04s: say dot cell right remember we've done\n10455.899s: that yesterday\n10456.979s: so we can actually plot that and we can\n10459.62s: compare the truth to the prediction\n10461.66s: right so that's going to be what we are\n10463.76s: going to do so just run that\n10466.819s: okay so that's again slightly different\n10468.979s: from what I had before because I have a\n10470.54s: slightly different neural net\n10472.34s: so\n10473.66s: the truth here please run that so that's\n10476.12s: just here in New York you know from 2015\n10478.34s: on what's going to be the prediction\n10480.859s: here in terms of uh warming compared to\n10483.92s: pre-industrial first of all note that we\n10486.319s: are already above one right a degree so\n10489.8s: that's what you should expect uh and\n10492.439s: then in that particular scenario we are\n10494.12s: going to through about about 3.5 right\n10496.34s: Which is higher than what I told you\n10498.02s: before the global average is 2.6 because\n10500.84s: we Overland you know so it tends to warm\n10502.64s: up a little bit more you know as we're\n10504.5s: on on the coast so it's not sometimes it\n10506.899s: can be double but roughly right so it's\n10508.76s: more than 2.6 and the main point here is\n10512.42s: that this is the climate model OKAY the\n10515.3s: blue\n10516.5s: importantly and that goes back to your\n10518.24s: point you know you have some variability\n10520.04s: right and that's the natural\n10521.72s: availability in the system right so you\n10523.88s: could look at longer time scales if you\n10525.74s: wanted to drop say the emissions but\n10527.359s: this is the natural viability sometimes\n10529.1s: a couple of years right so you have some\n10531.14s: modes of ABC that are important some at\n10533.66s: the yearly time scale some at the\n10535.34s: sub-seasonal time scales some at the\n10537.38s: multi-year time scales but that\n10539.38s: generates some diability here that we\n10542.479s: are not capturing in the neon net okay\n10544.399s: that's very important the neural net is\n10546.92s: actually deterministic it only depends\n10548.54s: on co2 right and in that case\n10551.42s: and methane sorry thanks and so we made\n10554.42s: it increasing because CO2 and methane\n10556.46s: are increasing as a function of time\n10557.72s: there's no decrease in that particular\n10559.7s: scenario it could be actually decreasing\n10561.14s: in that case if we had a reduction but\n10563.96s: what we are showing is that there's it's\n10565.76s: really smooth right\n10567.5s: so and that you would expect it's a\n10570.14s: deterministic model right\n10572.6s: if it were already erratic it would mean\n10574.46s: there's some sign of overfitting\n10576.319s: something is not right right there's\n10577.46s: something going on it's kind of smooth\n10579.38s: so the behavior seems nice that sounds\n10581.96s: like a pretty reasonable model fits the\n10584.42s: data very well so seems to work quite\n10587.12s: well so just for fun you can change that\n10589.279s: to your particular so wherever you are\n10592.04s: born so I I just put that to Paris you\n10595.04s: can look up on Google Map change that\n10597.319s: and and try the where you were born and\n10599.0s: you can plot that and that will be the\n10600.56s: result of the climate model and you can\n10602.779s: compare that to the neural net so please\n10604.399s: do that just for fun\n10612.5s: foreign\n10615.45s: [Music]\n10616.779s: a bit biased\n10619.58s: slightly biased potentially at that\n10621.26s: pixel but remember because we are using\n10623.0s: the model that was fitting the entire\n10624.74s: Globe right it doesn't mean that we are\n10626.96s: not biased at a particular at a\n10629.12s: particular Point yeah you're right yeah\n10630.38s: that's a very good point yeah we can be\n10632.6s: biased at some particular location\n10635.84s: okay so please try and enter so I just\n10637.939s: very suggest for fun uh so we can try it\n10641.24s: again\n10642.68s: and that's how it looks like maybe less\n10644.479s: biased to your points at that particular\n10647.3s: location so it's going to be warming\n10648.92s: less you know so maybe better place to\n10650.899s: retire you know so just for me I'll keep\n10653.96s: that in my mind\n10655.46s: so try just to see if it works\n10661.7s: uh yeah maybe good yeah Canada maybe\n10664.34s: yeah Montreal maybe a better place yeah\n10667.04s: but that's a global average yeah don't\n10668.6s: forget about winter yeah\n10675.14s: does it work for everyone\n10676.939s: and you should all be getting kind of a\n10679.88s: similar care which is a very smooth\n10681.38s: curve for the neural net as opposed to\n10683.42s: The Climate model I think that's the\n10685.04s: main take home here is that we are we\n10687.439s: have this very smooth Behavior\n10689.54s: make sense\n10691.399s: good\n10692.66s: okay so we got that we managed to\n10695.06s: provide maps and we have some nice time\n10697.819s: series so we managed to basically do\n10699.74s: everything we almost wanted to do with\n10702.08s: the with the neural net okay\n10704.3s: now we are going to revisit that and be\n10707.84s: slightly more flexible than what we had\n10709.76s: before okay\n10711.08s: so we are going to go back to the\n10714.02s: structure of the neon net so remember we\n10716.359s: started here so I was just replicate\n10719.0s: replicating the structure I had above so\n10721.58s: I had as a structure this guy here\n10725.0s: and what we are going to do is we are\n10727.1s: going to make it slightly more flexible\n10728.779s: so uh we entered here\n10731.899s: uh\n10733.22s: a model that's slightly more flexible\n10735.68s: right and that's the one you're going to\n10737.66s: tune now for the competition so we are\n10740.06s: going to have a model so it's the same\n10742.399s: right nothing super complicated but it's\n10744.74s: the same it's a model that has a first\n10747.08s: input layer\n10748.46s: and then a bunch of hidden layers so we\n10751.819s: call that n underscore layer so that's\n10754.04s: the one hyper parameter you will tune\n10756.439s: and we're going to stack a bunch of\n10758.42s: layers that have a shape of n number of\n10761.899s: neurons\n10762.859s: with a given activation function right\n10764.96s: value okay and then we use the same\n10768.7s: Keras Optimizer so we can actually use\n10771.2s: that\n10772.58s: okay we can actually use this guy\n10775.76s: we can summarize that\n10778.1s: make sure it works and then we can\n10780.68s: actually train that as well\n10783.38s: okay should work similarly\n10789.02s: okay so for instance in that case I\n10791.6s: didn't go over there I had to go to more\n10793.7s: epochs right\n10795.319s: okay and I can compare the loss\n10799.34s: and plot that as well\n10802.819s: okay so C slightly more erratic here but\n10805.76s: you know it tends to work quite well I\n10808.46s: don't remember yeah I'm slightly higher\n10810.5s: than what I had before by additions Okay\n10812.779s: so what we are going to do now is we are\n10815.84s: going to report\n10817.58s: um\n10820.04s: so we are going\n10821.72s: to uh get back to the competition here\n10825.68s: so I put like a Pong video game at the\n10828.26s: top please enter your email here you can\n10830.779s: have a nickname like arcade game you\n10832.46s: know you can choose whatever you prefer\n10835.7s: yeah okay so now we know it does uh and\n10839.359s: those are the hyper parameters you are\n10840.8s: going to to to use right number of\n10842.84s: hidden layers here\n10844.34s: number of neurons per hidden layer we\n10846.859s: are going to use the same across rate\n10848.18s: that's going to be too complicated\n10849.74s: otherwise\n10852.16s: activation function I let you choose I\n10855.26s: gave you another Choice here\n10858.319s: uh uh where is that here you can change\n10861.979s: that so remember the activation is going\n10864.5s: to be here you can change that\n10867.08s: and to change that you will need to look\n10869.359s: at the hyper parameters so you can\n10871.04s: actually comment that now we don't need\n10873.02s: that anymore\n10875.479s: uh so the things you're going to change\n10877.46s: is this number of neurons\n10879.8s: activation here\n10881.66s: I gave you another one that I would\n10883.399s: suggest which is this leaky value\n10886.1s: what is the key value it's the same as\n10888.74s: rectified linear unit except to the left\n10891.8s: of zero we have a slight slope with with\n10894.439s: a given with a given slope right of 0.2\n10896.96s: so it's almost like this one to one line\n10898.76s: except we make it with a slope of 0.2\n10901.16s: right why because we don't want to get\n10903.979s: stuck on the left hand side right\n10905.6s: because otherwise remember the gradient\n10907.399s: is zero on the left hand side and we\n10908.72s: don't want that right so people\n10910.76s: typically use that very strong abrupt uh\n10914.42s: gradient to the to the right and we\n10916.7s: gradient to the left okay you can use\n10918.5s: that\n10919.88s: uh\n10921.8s: and then uh the learning rate right very\n10924.859s: important the learning rate how quickly\n10926.359s: are we going to descend that's the\n10927.68s: initial learning rate and then we use\n10929.12s: Adam right so those are the ones you can\n10931.34s: change so the learning rate here and\n10933.74s: please don't touch the other ones right\n10935.18s: number of epochs mini batch sites we are\n10938.06s: not going to touch today if you're\n10939.979s: interested you can change just to make\n10942.08s: sure we we have time okay so activation\n10945.14s: function oh sorry number of epochs we\n10947.899s: can we can change sorry uh we change\n10949.52s: that activation function You Can Change\n10951.8s: Report whatever is working best for you\n10954.26s: learning rates you can change and then\n10956.84s: number of epoch so for instance 50 was a\n10958.939s: bit potentially small in that particular\n10960.859s: case especially as you get deeper and\n10962.66s: deeper you might want to get an add more\n10964.939s: and then report your last\n10967.46s: training lust and your last validation\n10969.92s: loss okay and we'll try and compete so\n10972.5s: that we get the best validation loss\n10974.72s: across the group to get a sense okay and\n10976.819s: we'll get a sense also of the diversity\n10978.38s: we can get across the group okay so I\n10980.84s: will give you\n10982.88s: let's say 20 minutes\n10985.88s: okay should be fine uh to do the best uh\n10989.6s: the best you can do in terms of changing\n10991.819s: those and the link should be I will\n10994.279s: should be in slack okay if you don't\n10996.5s: have the link please let me know\n10998.6s: so we're gonna fix number of hidden\n11001.0s: layers yeah so\n11003.64s: you you can sorry let me repeat so\n11006.819s: you're free to change the number of\n11008.8s: hidden layers change the number of\n11010.96s: neurons change the activation function\n11012.939s: change the learning rate and the number\n11014.859s: of epochs\n11016.18s: in that particular jupyter Hub so here\n11019.779s: and do that multiple times we write\n11023.26s: somewhere maybe in the Excel file what\n11025.479s: is your best uh set you know what is\n11028.18s: your best solution and only report the\n11030.64s: best solution that you have at the end\n11032.02s: you know in 20 minutes don't repot all\n11033.819s: of them just the best solution okay but\n11036.399s: try a bunch of them so I don't know a\n11039.22s: priority what is the answer if you work\n11040.779s: pretty big\n11041.859s: it will fit quite well the the training\n11044.38s: loss maybe not so the validation loss\n11046.24s: right because you will be overfitting if\n11047.56s: it's too small the converse right will\n11049.3s: not be training so well okay uh number\n11052.12s: of epochs can work nicely but we are\n11054.58s: limited in terms of time right same as\n11056.2s: compute power so you might want to be\n11058.479s: small right or not too big because\n11060.34s: otherwise you're wasting your time for\n11061.96s: the competition right uh and then the\n11064.6s: activation loss you don't have too much\n11066.46s: flexibility so just two I would say\n11069.16s: um\n11070.479s: does that answer\n11073.12s: any questions\n11075.58s: people are getting stressed already\n11080.38s: what we care about is validation laws\n11082.3s: the competition will be on validation\n11083.68s: loss yeah\n11089.64s: typical climate data are organized in\n11092.319s: space so we talked about convolutions\n11094.359s: right so one way to actually account for\n11096.76s: spatial structure especially over long\n11099.34s: uh spatial ranges as well\n11102.279s: and there's of course the obvious thing\n11104.92s: and we talked about that before I mean\n11106.66s: you had this great comment about the\n11108.7s: fact that there's memory in the climate\n11110.14s: system right and that's something we\n11111.46s: would want to pick up in everything\n11113.38s: we've been doing when we had the neural\n11116.14s: Nets we are the convolutions we are\n11118.24s: using snapshots right so we could\n11120.279s: actually Shuffle in time right that was\n11121.899s: no problem right we could use future\n11123.88s: time past time different CO2 different\n11126.399s: scenarios we put all of that together\n11128.74s: right\n11129.88s: uh what we'd like to do now is saying\n11132.34s: you know there might be some memory\n11134.08s: right in the climate system so how can\n11136.359s: we actually include that right so we\n11138.399s: won't get too much into the weeds you\n11140.14s: know uh but just to give you a sense\n11141.76s: that there are ways to actually do that\n11143.8s: we call that using recurrence using a\n11147.46s: recurrent neural network and what we\n11149.5s: want to do here is actually using some\n11151.6s: sample features right we want to say\n11154.24s: that uh basically there are some Auto\n11157.12s: regressive autocorrelation in the time\n11159.52s: series that we have and we want to use\n11161.26s: that using that temporal context to\n11163.479s: refine the prediction that we are making\n11164.979s: if you've been dealing with the\n11167.52s: dynamical systems uh we want to\n11170.26s: basically Define some sort of ode right\n11172.06s: or you know differential equations right\n11173.8s: we want to say DX DT equals stuff right\n11176.92s: that's really what we are after here\n11180.819s: okay so where is that coming from uh\n11183.819s: from a couple of things so some of the\n11186.34s: earlier\n11187.66s: um uh exploitation of that started in a\n11190.96s: natural language processing right so\n11193.0s: phones are great now or if you go to\n11195.52s: Google uh translate for instance you can\n11197.859s: translate sentences or even like\n11199.5s: paragraphs or even chapters really\n11201.7s: really efficiently right so a lot of\n11203.859s: that starting from from those\n11205.479s: developments of recurrent neural\n11207.04s: networks right\n11208.38s: uh dnas and genes you know so those are\n11211.6s: also pretty long sequences you know so\n11213.34s: it's a sequence right so that's what we\n11215.26s: we're looking at here every time you\n11217.6s: have a sequence so things come come and\n11219.939s: are actually being ordered in time or in\n11222.1s: some sort of uh sequence that's when you\n11225.1s: will typically want to use one of those\n11226.6s: recurrent neural network right so time\n11228.819s: series words or even or letters in a\n11232.899s: world words in a paragraph paragraphs in\n11235.479s: the document etc etc right\n11239.319s: um or frames in the video people have\n11241.6s: been using that actually we have\n11242.92s: colleagues here trying to do next frame\n11245.56s: prediction it's kind of fun you know you\n11247.12s: have a car you know driving you know\n11248.5s: like uh actually one of the members of\n11250.84s: leap Calvin Rick like looking at cars\n11252.819s: and you want to predict what's going to\n11253.96s: happen next you know it's kind of fun\n11255.22s: you're trying to predict the future\n11256.66s: right so how can you do that right you\n11258.34s: want to have some temporal context right\n11260.56s: it cannot just be random\n11262.42s: okay so there's actually a lot of\n11264.279s: implications here and that's actually\n11266.8s: very similar to what we had discussed\n11268.359s: before when you have pixels right they\n11271.24s: are specially organized right so there's\n11273.64s: actually some spatial convariation right\n11277.12s: in time it means that there are some\n11279.279s: autocorrelation right so one time point\n11282.7s: is going to be dependent on the previous\n11284.439s: time point and potentially there's also\n11286.42s: a relationship with the next time step\n11288.399s: right and really what it means is that\n11291.52s: data points in time are not again\n11294.88s: independent identically distributed so\n11297.819s: basically if you want to look at the\n11299.8s: next time step you cannot just say it's\n11302.2s: random right and you Shuffle from some\n11305.14s: randomized distribution is going to be\n11307.42s: highly dependent on the previous\n11308.68s: timestamp okay that makes a lot of sense\n11311.08s: uh same goes again the example of the\n11313.84s: stock market right people use what they\n11315.819s: call martingals right so the best\n11317.859s: prediction of the future is right now\n11319.42s: right so uh you know that there are some\n11322.06s: dependence on now right I mean that's at\n11323.92s: least one way to think about that okay\n11326.38s: and that's really what one thing we want\n11328.66s: to account for right we want to say that\n11330.52s: we want don't want to assume that things\n11332.62s: are independent in time we want to say\n11335.14s: there's going to be this Auto\n11336.279s: correlation so how can I use that to my\n11338.08s: advantage right so to have a model\n11339.399s: that's actually uh not trying to overfit\n11341.8s: too much right so similar as sentences\n11344.92s: here right so you could have structure\n11347.26s: in a sequence here like I know that you\n11350.2s: know etc etc and you want to actually\n11351.939s: extract some pieces here and we want to\n11354.76s: use that on short time steps but\n11357.34s: potentially also on longer time steps\n11359.38s: right if you think for instance of a\n11362.02s: typical time series you could have a lot\n11364.3s: of variations at the daily time scale we\n11366.34s: talked about seasonal time Scalia so you\n11368.26s: could have El Nino as well right so you\n11370.06s: could have multiple time skills that\n11371.92s: could be important right so you could\n11373.18s: have a short term but also long-term\n11375.04s: type of memories right typically you\n11376.84s: would want to capture those right so\n11378.46s: that's going to be one thing we'll be\n11379.899s: focusing on\n11381.58s: so\n11382.899s: uh so that's maybe a linear regression\n11386.08s: one not 101 102 let's say second class\n11389.8s: uh is when you have a Time series the\n11395.2s: equivalent of a linear regression is\n11396.88s: what we call a notoricgressive model who\n11399.279s: has seen that was not seen that before\n11401.8s: raise your hand if you've never seen\n11403.24s: another regressive model don't be shy\n11406.96s: fine so maybe a few of you so basically\n11410.38s: the idea pretty simple is that we want\n11412.72s: to predict a Time series point so y of t\n11415.66s: and that's going to be same as what\n11417.58s: we've seen before right a bias here plus\n11420.279s: some regression so some weights times\n11422.859s: the previous time step plus two steps\n11426.279s: ahead right etc etc you can take as many\n11428.8s: step steps as you want we call that a\n11431.68s: Noto regressive model of order P other p\n11434.859s: means we stop at P time steps ahead of\n11438.58s: us right so if you've done any uh\n11441.58s: dynamical system if it's order one it's\n11444.52s: a first other differential equation\n11446.62s: order two second order differential\n11448.42s: equation etc etc so how many orders do\n11450.88s: you have in your equation okay it's the\n11452.74s: simplest model you could have it's\n11454.3s: basically a linear regression and you\n11456.76s: hope that the residuals here are going\n11459.16s: to be IID in that case and there's going\n11461.979s: to be no structure here and the only\n11464.38s: structure in time is coming from the\n11466.06s: dependence on the previous time steps of\n11468.279s: the process itself okay so that's the\n11471.04s: simplest you could have and remember\n11473.8s: what we've seen for neural networks it\n11475.42s: was actually not too different from a\n11477.22s: linear regression right it was kind of\n11479.68s: like kind of like a regression except\n11482.38s: that we added an activation function\n11483.88s: right a nonlinear one so we should be\n11486.939s: inspired by that looking at this model\n11488.74s: say in fact we would want to take that\n11490.54s: and just add some activation function\n11492.52s: right it's almost the same right I mean\n11495.04s: that's always what we do with the neural\n11496.96s: network you take something that's people\n11498.939s: have done saying statistics add some\n11500.68s: activation function and you get a\n11502.479s: miracle right that's basically what's\n11504.04s: what you do\n11505.42s: okay\n11506.859s: second approach you could do is you\n11508.84s: could say that would be kind of the flip\n11510.76s: side of that\n11512.62s: uh you could say you know what I can\n11514.96s: predict\n11516.279s: the next time step as a function of a\n11519.16s: bunch of time steps and I can do it in a\n11521.62s: nonlinear fashion I know how to do that\n11523.42s: I can use a neural net right so I can\n11526.42s: just connect every single time step\n11528.399s: ahead to uh the time step later all\n11532.899s: right so that would be okay right\n11536.62s: you could do it directly here so you\n11538.899s: could have a bunch of weights right fine\n11541.24s: or you could be more solo so typically\n11543.58s: people have uh what they call Hidden\n11547.0s: layers right so you could say I can do\n11549.1s: some sort of manipulation in between I\n11551.14s: have what we call a hidden State you\n11553.06s: know if you've done uh markovian type of\n11556.359s: model so you can have this hidden State\n11557.979s: you know that can do things in between\n11559.42s: right uh and so think of that for\n11563.08s: instance\n11563.979s: you want to predict say evaporation you\n11566.74s: could take as input precipitation over a\n11568.899s: couple of days uh and then you have as a\n11572.2s: hidden variable you have soil moisture\n11573.819s: right so that's how much regulation you\n11575.92s: have of evaporation by cell moisture so\n11577.84s: that's a hidden variable that you don't\n11579.52s: directly observe but something that's\n11581.68s: going to be modifying evaporation right\n11583.779s: so that would be your hidden variable\n11585.22s: right so that would be another option\n11586.66s: here\n11587.56s: can make things with the latent space or\n11590.319s: not you can make things non-linear but\n11592.359s: that's kind of those are kind of the two\n11594.16s: perspectives right a linear approach\n11596.439s: kind of nicely framed as an auto\n11598.96s: regressive model and then the other one\n11601.0s: is directly encoding and again similar\n11603.7s: to the fit for one unit we are\n11605.5s: connecting everything to everything\n11606.7s: right we are totally over doing the job\n11608.68s: yeah right\n11611.439s: and you you so that's kind of similar\n11613.72s: you could have dynamical systems right\n11616.0s: you can write equations right DX DT\n11618.88s: equals stuff right and you can solve\n11620.74s: that\n11621.58s: and you could have what we call Hidden\n11623.5s: Markov model so that's what I mentioned\n11624.88s: before you could have some driving\n11627.0s: variables here you can have a hidden\n11629.14s: State and you can have outputs here and\n11631.54s: you can do it in a probability\n11632.819s: probabilistic setup as well uh what's\n11635.979s: nice is you can carry memory across in\n11639.58s: the hidden state so that's the idea of\n11641.14s: the markup state is your carrying memory\n11643.54s: across the hidden state so for instance\n11645.58s: your feeding precipitation here\n11647.859s: you want a predictive operation and the\n11650.38s: hidden state is going to be soil\n11651.7s: moisture so the memory is coming in and\n11654.399s: basically you're adding the inputs here\n11656.74s: but all of the memory is kind of in the\n11659.38s: middle here right so the idea of the\n11663.46s: regular neural network is that we want\n11665.319s: to combine all of those things together\n11666.819s: right we want to say we want things to\n11669.34s: be non-linear\n11670.72s: we ideally oh\n11674.26s: sorry\n11675.64s: it's tight here\n11679.84s: uh\n11681.88s: so we want to combine those things so a\n11684.58s: hidden State because that's kind of nice\n11686.38s: we can do so manipulation and we don't\n11688.899s: need to basically keep track of all of\n11691.3s: the input data right that can be\n11692.74s: annoying you don't want to preserve all\n11695.26s: of the precipitation data from the last\n11697.06s: month to predict some moisture now right\n11698.92s: you just want to have some sort of\n11700.359s: carryover effect\n11702.1s: uh and we want things to be stochastic\n11704.38s: right that would be ideal as well not\n11706.84s: deterministic neither right so we want\n11708.88s: to have this labor and we want to do the\n11711.279s: same as the auto regressive model we\n11713.319s: want the residuals to be typically IID\n11715.899s: and not the process itself right the\n11717.58s: process has some memory as a function of\n11719.74s: the different type steps so we are\n11721.42s: trying to combine all of those different\n11723.1s: flavors together right and that's the\n11725.8s: idea of recurrent neural network\n11729.16s: Okay so\n11731.26s: it's going to be very similar to what\n11732.88s: we've done before so we are going to\n11734.319s: have a bunch of inputs here we are going\n11737.319s: to predict the outputs here the only\n11739.54s: change compared to what we had before is\n11741.7s: we are going to have a bunch of hidden\n11743.8s: layers here that are going to carry\n11746.56s: memory forward in time so what this\n11749.979s: means is that before that\n11752.439s: when we just look across like in the\n11754.6s: column here that's similar to what we\n11756.58s: are right input to Output right that's a\n11758.92s: neural network right fit forward that's\n11760.84s: fine the only change is this Arrow here\n11764.74s: right we're going from time step one to\n11766.6s: time step two times step three etc etc\n11770.2s: and what we are doing here is that we\n11772.54s: have a bunch of neural networks here A\n11774.16s: bunch of sorry a bunch of neurons here\n11776.38s: they are taking as input of course the\n11779.02s: input here but also the previous memory\n11781.96s: that they had in the hidden State okay\n11783.939s: so what it means is not now in the\n11787.359s: hidden layer we are capturing the input\n11789.46s: plus the past time step okay so that's\n11792.279s: the new thing right we're adding the\n11793.899s: past memory the Past Times\n11796.06s: and we can do that over and over again\n11798.22s: right we can go to the next time step so\n11800.74s: you can think of that those are\n11802.18s: different days so pretty we got some\n11804.64s: precipitation that day gonna feed that\n11807.16s: into the hidden state that day we didn't\n11809.5s: get any precipitation so no precip here\n11811.66s: but we fit fit field zero here it\n11815.319s: doesn't mean that it becomes zero\n11816.88s: because we got some memory of some\n11818.92s: moisture or some precipitation from the\n11820.96s: previous day right and then we're going\n11823.18s: to predict something such as evaporation\n11824.8s: right\n11825.819s: and then we can we keep on moving\n11828.88s: further uh further and further intent\n11831.52s: right so that's day one two three four\n11833.979s: five always the input from at a given\n11836.859s: time when we carry forward the memory\n11839.26s: here\n11840.76s: makes sense so the only change that we\n11843.399s: really got here is that we added some\n11845.979s: memory here by adding those arrows here\n11848.859s: okay we are taking the time steps and we\n11851.859s: are saying one current time step is\n11853.96s: dependent on the previous time step\n11855.399s: right and if it's dependent on the\n11858.22s: previous time step you could say it's\n11859.479s: also dependent on the next time step or\n11861.64s: the previous step two steps ahead three\n11863.74s: four etc etc etcetera so you could think\n11867.04s: of that it's dependent on an infinite\n11868.779s: number of time steps right because you\n11870.16s: can go you know further back in time as\n11872.56s: much as you want right ok so\n11876.399s: how do you then train that right so\n11879.16s: that's the the question right so that's\n11880.84s: the regular neural network so you're\n11882.58s: going to pass that over right\n11884.56s: same as the perceptron here we have a\n11886.6s: bunch of hidden layers a bunch of\n11888.46s: neurons feed that into a bunch of feed\n11890.979s: and layers typically one here uh and\n11894.76s: then that hidden layer at that\n11896.319s: particular time step is going to be\n11897.58s: feeding that into the future as well ok\n11901.06s: and now what we need to do right we have\n11904.3s: a bunch of data so we will have some\n11906.88s: label data at the top\n11908.56s: the label data is going to be eight\n11910.479s: times series could be multivariate\n11912.34s: doesn't matter\n11913.42s: we have a bunch of input data here as\n11916.359s: well multivariate as well\n11918.399s: and we are going to try and feed that\n11920.439s: right so that's going to be the the\n11922.06s: process here and you can think of that\n11924.22s: it's kind of a black box here where we\n11926.08s: have some input data here you have the\n11928.6s: memory there and you're trying to\n11929.92s: predict the the output at a given time\n11932.2s: okay and you pass that through some\n11934.479s: nonlinear functions such as a hyperbolic\n11937.0s: tangent or value or whatever you\n11940.3s: so one way to think about that so people\n11943.84s: like writing it this way\n11945.939s: it's what that's why they call it\n11947.56s: recurrent neural network because this\n11949.84s: time is going into the next time so it's\n11951.52s: like rolling that you know so you we\n11953.68s: could sometimes call that unrolling the\n11955.899s: neural net right because the one time\n11957.939s: step is going to fit that into the feed\n11960.04s: itself into the next time step because\n11961.84s: it's the same structure right we\n11963.64s: preserve the same structure those are\n11965.02s: the same weights right that you provide\n11967.24s: further and further back in time right\n11970.0s: so we just had the same weights so it's\n11973.0s: the same structure over and over again\n11975.04s: the only thing that's changing here is\n11977.2s: the input here and because that input\n11980.319s: state is changing that's going to change\n11982.12s: also that right because of the memory\n11983.8s: and whatever whatever you saw in the\n11985.779s: past\n11986.859s: so\n11988.3s: basically it's as simple as that right\n11990.52s: and then what do we need to do\n11995.56s: train that right so you define the loss\n11999.399s: output here typically mean square error\n12001.68s: you would want to do a regression and\n12003.66s: you need to fit a bunch of weights here\n12006.779s: and a bunch of Weights here right and\n12009.42s: they are the same right so they repeat\n12010.62s: themselves\n12012.54s: okay what's the issue\n12017.1s: that's going to be the main issue here\n12020.399s: those who know please don't\n12026.819s: yeah\n12028.56s: gradients yeah and why\n12031.8s: yes they will tend to export so the\n12034.56s: issue is that everything depends on\n12036.06s: everything right because we have a Time\n12038.04s: series right\n12039.479s: we want to minimize the gradient so I\n12041.7s: will start looking at okay what's the\n12043.5s: influence of my weight here on this\n12046.14s: output here pretty obvious that's fine\n12049.439s: influence of the previous time step on\n12052.319s: this one that's fine I can look at the\n12054.24s: weights but now we have some weights\n12056.399s: here but the same weights are coming\n12058.14s: here right and they are coming here as\n12060.359s: well right\n12061.56s: so if you remember your linear algebra\n12064.26s: right you have basically a matrix\n12065.819s: multiplication right and you will have\n12068.22s: if it were if it were to be linear those\n12071.22s: will be eigenvalues right and the\n12073.38s: eigenvalues you know depending on the\n12075.06s: coefficient can either explode or Shrink\n12077.34s: to zero right so when you multiply those\n12080.7s: matrices over and over again they either\n12083.76s: shrink to zero or they explode okay and\n12086.64s: so it doesn't work okay so practically\n12089.34s: those don't work okay so even though in\n12091.92s: principle they are great they actually\n12094.14s: don't work right so that's basically the\n12095.76s: issue is that uh the back propagation\n12098.16s: which we wouldn't want to do we are\n12099.899s: trying to do the exact same back\n12101.64s: propagation but eventually the back\n12103.5s: propagation will go further and further\n12105.359s: and further in time and we'll either\n12107.399s: explode or vanish so\n12110.1s: it's very very difficult in practice to\n12112.319s: actually vanish so you could use some\n12113.58s: tricks you could say I restrict myself\n12115.5s: to just a few time steps you know but\n12118.08s: typically especially if you have\n12120.479s: say a seasonal cycle or you have a\n12123.06s: sentence I mean you want to have like\n12124.38s: pretty long time steps or pretty long\n12126.54s: sequences right so they don't really\n12128.279s: work so well okay so they they are\n12130.38s: pretty much in Practical okay so\n12132.72s: basically they explode\n12134.399s: okay and the main point is because you\n12136.68s: multiply the same metrics again and\n12138.42s: again and that will lead to Vanishing\n12140.16s: and exploding radiance\n12143.34s: okay so uh how do we get around that so\n12147.66s: that was a trick that people used\n12149.939s: they said in fact we are over doing the\n12152.1s: job right we are trying to use all of\n12154.14s: the all of the information all the time\n12156.06s: so the trick here was to say we're going\n12159.899s: to use some of the information sometimes\n12162.42s: okay so we will have what people call\n12164.16s: forget Gates\n12165.6s: we will use some of the inputs sometimes\n12167.64s: we will use some of the paths sometimes\n12169.56s: but not all the time okay and that's\n12172.08s: going to be we would just have Gates\n12173.58s: zero ones binaries right uh and again we\n12177.12s: can train all of that and that will\n12179.939s: actually tell you whether\n12181.92s: you should write and read like if it's\n12184.319s: an input or if you should or I mean even\n12186.66s: reset the entire state right so it's\n12189.06s: like you could think of that that's\n12190.08s: really very much inspired by transistors\n12191.819s: and things like that okay so you will\n12193.979s: have what we will call input output and\n12196.62s: forget Gates so into the structure that\n12199.62s: we had before we are going to add a\n12201.72s: bunch of those Gates\n12203.279s: uh so we will actually allow to actually\n12208.02s: use or not the input use are not the\n12211.979s: memory and either discard the the same\n12215.399s: for the output so we will have those\n12216.72s: just Gates okay so one way to frame that\n12220.5s: is just to frame it this way okay you\n12222.72s: have the input here you have an input\n12225.42s: gate that will tell you whether you're\n12227.1s: using that or not\n12228.66s: furthering memory same thing are using\n12231.12s: the memory or not to make the prediction\n12233.1s: right and there might be times when you\n12234.899s: don't need that right so for instance a\n12237.84s: good example is you want to look at\n12239.34s: runoff right\n12240.72s: you have some precipitation data and\n12243.779s: maybe you have some memory in some\n12245.22s: moisture but if it rains so bad you know\n12247.2s: it's gonna I mean run off eventually\n12248.88s: right so you maybe you want to forget\n12250.8s: about the the state about soil moisture\n12252.66s: and you want to focus on that right so\n12254.04s: you're just trying to put some focus on\n12255.779s: different things right and that's\n12257.7s: basically the idea is that forget gate\n12260.1s: is going to be helping you focus on\n12262.62s: things that are important for that\n12264.3s: particular time\n12265.859s: and the same goes for the output as well\n12268.08s: right as you would expect\n12270.18s: okay so that's basically this idea and\n12273.479s: we call that lstm long short term memory\n12276.84s: and that's a practical way to make\n12278.76s: regular neural network work uh so it's\n12281.399s: basically the same as a record on neural\n12283.02s: net but with Gates yeah\n12286.38s: again the same structure and every yeah\n12289.58s: it's the same structure except that it's\n12291.899s: within the structure itself so it's\n12293.64s: within uh the one that we're replicating\n12296.76s: we have those Gates within those uh\n12298.979s: replicating structures as well\n12303.479s: yes\n12305.1s: not yeah that's a good point the forget\n12307.5s: happens sometimes so at some\n12311.52s: so you have a sequence right so maybe at\n12314.04s: time two you're not going to use the\n12315.54s: input maybe a time five and depending on\n12317.64s: the state right you're not going to use\n12319.739s: the input you know so that's that's\n12322.02s: actually State varying which is the\n12323.88s: important thing is depending on the\n12325.8s: state\n12326.64s: okay and that's a way to avoid those\n12329.22s: exploding gradients because eventually\n12330.96s: you're not using all of those metrics\n12333.18s: multiplications so you keep the focus in\n12335.46s: a sense\n12338.1s: but you're replicating the same\n12339.6s: structure so the structure is again the\n12340.92s: same right it's always the same for\n12342.239s: those neural networks because we want to\n12344.939s: train them so the structure has to\n12346.739s: remain the same right and it's just that\n12349.02s: they are going to be State dependent\n12351.06s: right so sometimes we're going to use\n12352.38s: them sometimes we are not\n12356.399s: okay so uh so that's kind of the idea\n12360.0s: you have this gating that modulates\n12362.04s: information so either we are either\n12363.96s: using that or not and it's just a\n12366.18s: sigmoid function right so uh it's really\n12368.7s: like similar to what we had for synapses\n12370.979s: before zero one right I mean you are\n12372.96s: using the information or not so it's a\n12375.06s: range in between\n12377.16s: and then sometimes you're forgetting as\n12379.08s: well you know the previous state you\n12380.58s: know so that you can actually really\n12382.26s: encode the information uh from the past\n12385.02s: or not right so how much of the\n12386.58s: information are you using and so in the\n12388.92s: end it makes it a much more practical\n12390.54s: way of actually using this information\n12392.939s: and the advantage being that in that\n12395.16s: case you can actually use memory that's\n12397.439s: actually much longer in time because you\n12399.42s: don't have those exploding gradients so\n12401.52s: if you have a valence uh sentence you\n12403.979s: can actually use that if you have a very\n12406.08s: long time series you can actually use\n12407.76s: that pretty efficient okay so they tend\n12409.92s: to work quite well they are pretty\n12411.72s: practical and they can be trained much\n12414.42s: better than a typical break around your\n12417.12s: network\n12419.16s: maybe one thing is that they typically\n12421.56s: they don't have a value function they\n12423.54s: tend to have a hyperbaric tangent just\n12425.279s: to get into the weeds here but that\n12427.14s: because they were basically developed\n12429.42s: typically a little bit before the the\n12431.279s: revolution in neural networks\n12435.359s: uh yeah so so how does it look like so\n12439.319s: this is the typical breaker on neural\n12442.38s: network right so we pass the information\n12444.319s: across and that's going to be the dlstm\n12448.859s: right so sometimes you're actually\n12450.479s: blocking so sometimes you can actually\n12452.16s: block or not so when there's an o That's\n12455.1s: the standard annotation I'm not a big\n12456.72s: fan of that because it sounds as if it\n12458.399s: were blocked but it means that the flow\n12460.2s: of information is passing through and\n12462.359s: here it's blocked right the gate is\n12464.46s: being blocked and here the information\n12466.319s: so it means that this output is going to\n12468.72s: be mostly dependent on the input here\n12470.76s: right and here you're using all of the\n12473.52s: information across that prediction is\n12475.38s: going to be using mostly the memory not\n12477.66s: the input here and same for this one\n12480.239s: right so for precipitation that would be\n12482.819s: again a good example sometimes it rains\n12484.62s: sometimes it doesn't so why would you\n12486.18s: want to use that information across\n12488.04s: right and you're only using that\n12489.899s: whenever it matters right\n12491.88s: but sometimes you want to carry memory\n12494.16s: forward right and then that's how you're\n12495.779s: going to make the prediction\n12498.18s: and that makes it much more efficient\n12499.859s: you can see that basically your\n12502.02s: cutting the the recurrence in chunks\n12504.479s: right so it makes it much more uh\n12506.7s: tailored to actually uh to the memory\n12509.04s: process itself okay so that's what\n12511.26s: people use in practice this lstm long\n12513.72s: shot uh long short term memory STM is\n12516.96s: really the practical way of doing\n12518.46s: recurrence\n12520.2s: and I put actually the sliding I don't\n12522.72s: know why it ended up here\n12524.88s: there's one thing you need to know is\n12526.62s: that this is one way to do it forward\n12528.779s: but there's also a way to do it\n12530.399s: bi-directional right you can use the\n12532.56s: pass to predict the future but you could\n12534.06s: also use future to predict the past so\n12536.7s: we we call that a bi-directional uh\n12539.58s: recurrence right there's no reason why I\n12542.1s: mean depends if you want to do a\n12543.72s: forecast yes you would want to do an\n12546.06s: lstm but sometimes you want to do the\n12548.46s: best type of product using the past and\n12551.279s: the future so\n12553.14s: you can think of that this is similar to\n12555.72s: your weather forecast right you have\n12557.939s: observations in the past want to predict\n12560.1s: the future\n12560.939s: this is similar if you're familiar with\n12563.1s: that with real analysis right a real\n12565.439s: analysis product you use future and past\n12567.42s: to get your best estimate those are\n12568.92s: exactly the same and you can show that\n12570.72s: this one is always going to be better\n12572.16s: than this one right because you have a\n12574.2s: hidden State carrying the information\n12576.8s: forward and then you have another hidden\n12579.42s: State here carrying the information\n12581.16s: backward right so by definition this one\n12583.56s: you can show will always be better if if\n12585.66s: trained correct right\n12587.52s: because you're using information from\n12589.439s: the future to inform the past as well\n12593.939s: make sense\n12596.819s: okay any questions\n12598.859s: yeah\n12601.14s: can't use the bi-directional uh if\n12604.2s: you're trying to predict the future and\n12606.359s: you only have a fast data right uh if\n12608.76s: you have the future and you want to\n12610.02s: predict the pass so you could actually\n12611.52s: use lstm backward you know so there's no\n12613.739s: need to actually use this one right\n12616.319s: if you want to predict so I think it\n12619.14s: depends on the test you know if you want\n12620.939s: to predict the best estimate\n12623.939s: of something in the past and you have\n12626.819s: access to data before and after you know\n12628.859s: you should use that bi-directional right\n12630.84s: if you want to do a project a prediction\n12633.899s: ahead of time so whether streamflow data\n12637.08s: in uh in the future then you should use\n12639.6s: that right because you will not have\n12641.1s: access to the Future right but it\n12642.899s: depends on the type of problems you\n12644.399s: could have you know if it's pure\n12646.56s: language language\n12648.08s: translation for instance we have the\n12650.34s: future in the past right so you can\n12652.2s: actually use that right nothing I mean\n12654.54s: there's no but while you're typing you\n12656.58s: know you don't know the future yet right\n12658.62s: so when you're typing you know Auto\n12660.18s: completion should use that right\n12662.76s: so it depends on the type of problems\n12665.34s: you're looking at\n12668.279s: any questions\n12670.68s: we have a little bit of time we can have\n12672.54s: a\n12673.62s: another\n12675.06s: 15 minute break so we are on time for\n12677.04s: Studio three and then we'll go quickly\n12679.26s: it's not that long and then we can have\n12680.52s: a break we can have a drink and maybe uh\n12683.22s: we'll have some data points to make sure\n12685.56s: we are progressing\n12688.32s: [Music]\n12689.58s: are we ready for that now actually we\n12692.1s: are done yeah so we then we'll get\n12694.14s: quickly into the studio three just\n12695.88s: through the notebook so we can do that\n12697.38s: at the end if that's okay\n12698.939s: perfect\n12700.439s: yeah and if people have any questions\n12702.6s: you want to learn more but climate data\n12705.6s: Etc happy to take questions\n12708.239s: okay let's have a little break then\n12710.52s: so we are recombining 15 minutes"
    },
    {
        "class": "YouTubeVideo",
        "title": "Physics to Machine Learning and Machine Learning Back to Physics with Pierre Gentine",
        "videoId": "gdCC6BP7rU0",
        "url": "https://www.youtube.com/watch?v=gdCC6BP7rU0",
        "publishedAt": "2023-02-06T19:22:44Z",
        "transcript": "5.22s: I think it's time yeah right okay good\n9.24s: afternoon everyone uh thank you for\n11.7s: joining us for our uh first spring\n14.4s: seminar led by our director Pierre\n17.039s: giantine I'm Courtney cochburn faculty\n19.56s: here at Columbia and also Lee Dei and\n22.38s: knowledge transfer for leap and I'm\n24.6s: going to read your bio even though\n25.92s: everyone knows you the year 13 is the\n28.68s: Maurice Ewing and Jay Lamar Warzone\n31.5s: professor of geophysics in the\n33.0s: department of Earth and environmental\n34.44s: engineering and Earth and environmental\n36.42s: Sciences at Columbia University he\n38.88s: studied the terrestrial water and carbon\n41.1s: cycles and their changes with climate\n43.14s: change Pierre is the recipient of the\n45.78s: NSF NASA and Department of energy early\n48.239s: career Awards as well as the American\n50.399s: geophysical Union Global Environmental\n52.8s: changes early career\n54.96s: mace Wayne Sorry metal and American\n58.199s: Meteorological Society messenger award\n60.6s: he is the director of our center\n62.399s: learning the Earth with artificial\n64.44s: intelligence and physics the largest\n66.36s: funding mechanism of the NSF and today\n69.06s: and today he'll be presenting on physics\n71.159s: to machine learning and machine machine\n72.84s: learning back to physics over to you\n75.299s: here thanks and congrats to you to be\n78.299s: officially 10 years\n82.74s: it's a bit of a sad day because uh our\n85.38s: managing director and Murray is going to\n87.299s: be living so that's uh tomorrow will be\n90.299s: our last day today with us so thanks for\n92.46s: being with us it was wonderful to have\n94.2s: you\n95.04s: great so uh so I wanted to talk about\n98.1s: some work we've been doing potentially\n100.259s: in my group also very connected to what\n102.18s: we are doing actually in the center\n103.259s: itself and\n105.299s: um I call that basically a rollercoaster\n107.1s: Journey to the Youth of machine learning\n108.78s: in climate science and trying mostly to\n110.88s: share my experience of the experience\n112.5s: that we had actually with many\n114.06s: collaborators now uh and trying to share\n116.939s: a little bit the excitement we had at\n118.979s: Perth and how we actually moved on and\n120.72s: how uh things actually fell through and\n122.579s: then how we we're hoping to actually get\n124.86s: back on track you know at least uh\n126.36s: that's the feeling we have uh there's a\n128.7s: lot of people involved so I would like\n130.08s: to mention people from the group so SARS\n132.0s: Jamaica land and you want\n134.099s: um and collaborators uh across the world\n136.14s: from Germany Veronica Irene uh\n138.54s: Switzerland burglar Mike Pritchard also\n140.819s: collaborator as part of leap I choose\n143.22s: Irvine and Nando Iglesias and Jacob also\n146.099s: in Germany\n149.58s: oh and sorry I need to move that here\n153.06s: yeah okay so just a little bit of\n155.52s: background to explain why uh I really\n157.739s: started to get really interested in\n159.06s: machine learning and how I believe that\n160.68s: or we believe that this could\n161.94s: potentially provide some Edge in terms\n163.8s: of using that for for climate modeling\n166.44s: and in particular climate understanding\n168.78s: a lot of that started with starting to\n170.94s: look at climate models and basically\n172.98s: when we look at climate models there are\n175.14s: still a tremendous amount of spread of\n177.3s: variance if you start looking at the\n179.4s: projections of those different models\n181.08s: and one metric of that is to look at\n183.48s: climate sensitivity which is basically\n185.28s: the response of the global air\n187.379s: temperature to a doubling of of uh of\n190.08s: carbon dioxide\n191.94s: and the main points of this picture is\n194.159s: actually showing you basically the\n195.36s: spread that you have across different\n196.62s: modes so every Circle here is showing\n199.08s: the response of a climate model to\n202.44s: basically uh\n204.78s: um to to uh to climate sensitivity and\n207.18s: therefore to uh to greenhouse gases\n209.58s: and the main point here is to show when\n212.34s: uh models will actually pass the two\n214.26s: degrees of global warming so the\n216.36s: threshold that we use for the Paris\n217.739s: agreement so that's one thing we use for\n219.48s: policy making and the main point being\n221.819s: here that many models actually all\n223.92s: models are very very different results\n225.48s: so when are we going to pass those two\n227.519s: degree of warming compared to\n228.78s: pre-industrial some models are saying\n231.06s: that's going to be in 2035 and some\n233.099s: models are saying it's going to be in\n234.36s: 2016. so we have very substantial range\n236.94s: in terms of when we believe we will\n238.799s: achieve those two degrees of warming and\n241.26s: of course what it means is that that\n242.64s: spread is so tremendous that it becomes\n244.5s: very difficult in the back end to start\n246.36s: and adapt so we don't know if that's\n247.739s: going to be tomorrow so 20 35 is almost\n249.599s: tomorrow as opposed to 2060 you have\n252.0s: planned for policy making or for\n253.799s: planning and infrastructure in\n255.36s: particular\n256.979s: now the question is where why do we have\n259.44s: so much uh viability and so much\n261.419s: variance across those different models\n263.52s: and that's just a scatter plot here\n265.56s: showing basically that it's very\n267.0s: strongly correlated with clouds uh and\n269.46s: you could kind of think of that in a\n271.199s: pretty easy way that clouds are very\n273.06s: reflective right so if you have more\n275.1s: clouds in your models and they tend to\n276.84s: be brighter they will actually reflect\n278.639s: more energy back to space so they will\n280.139s: cool off a little bit uh some of global\n282.36s: warming right so basically what it means\n284.699s: is that you have models here that that\n286.8s: are darker right they have what we call\n289.02s: an amplifying feedback they have fewer\n291.78s: clouds and the clouds are darker and\n293.82s: then you have models that tend to have\n295.32s: more clouds and clouds that operator and\n297.36s: they tend to be actually more optimistic\n299.22s: in a sense so they will actually buy us\n301.259s: time and so basically for those models\n303.6s: here we expect that we will reach a two\n306.9s: degrees of warming compared to\n308.699s: pre-inducing way later like in 2016. so\n312.06s: long quick summary of that it means that\n315.0s: clouds are really important they are at\n317.82s: the at the very heart of what we call\n319.44s: climate sensitivity and basically the\n321.72s: response of the planet to uh to bring us\n324.36s: gases okay even though they are really\n325.919s: small\n327.78s: and feel free to ask if you have any\n329.22s: questions\n331.02s: and it's not just a global issue so what\n333.539s: I showed you before was just the\n335.22s: response of global temperature but it's\n337.32s: more than that you can start thinking\n338.759s: about Regional scale which is much more\n340.86s: related to what we experience on a\n342.84s: day-to-day basis right typically we\n344.52s: think about how the world is going to\n346.44s: change around us uh and one example of\n349.5s: which is to start looking at the\n350.699s: regional precipitation so this is just\n352.62s: an example here of precipitation\n354.84s: distribution across the U.S here in you\n357.6s: know in in the summer June July August\n359.4s: here and you can compare the results\n362.28s: basically from a model so that's\n363.72s: actually our collaborators as part of\n365.4s: leap so that's the cam so the community\n367.86s: atmospheric model kamenka\n370.32s: pretty good model but not a particularly\n372.24s: bad model pretty good one actually\n373.94s: compared to Observation so that's the\n376.259s: green line here is showing you the model\n377.699s: compared to the observations here uh uh\n380.94s: from some satellite observations and the\n383.52s: main point being here that we are\n384.72s: basically missing out a lot of the\n385.979s: extremes okay so that's very important\n388.86s: because again for uh for for planning\n391.979s: purposes you want to know how the\n393.3s: extremes are going to change but if we\n395.039s: cannot even get the extremes correct\n397.02s: historically how can you actually expect\n398.639s: that we'll be able to do a good job\n400.44s: moving forward right so there's really a\n402.72s: big discrepancy here so we are really\n404.46s: not getting very extreme events and we\n407.759s: call that typical typically the\n409.62s: drizzling issue of climate models they\n411.66s: tend to precipitate too frequently and\n413.94s: in the form of drizzle as opposed to\n415.74s: very intense specification okay so\n417.78s: that's a major issue in the models again\n419.819s: at the original scale I would like to\n422.28s: point out we get back to this here that\n424.08s: if you have a model like this is\n426.0s: basically a climate model as well with\n427.5s: that much finer resolution it's much\n429.24s: much closer to the truth right so that's\n430.86s: good news it means that resolution\n432.3s: actually matters we can do potentially a\n434.52s: better job in that case\n438.0s: and you could start thinking about some\n440.16s: basic metrics right like droughts right\n442.02s: routes are really important you want to\n443.88s: know if the future in the future you\n445.68s: will have more of your routes right that\n447.84s: sounds very important for water\n449.58s: management for agricultural purposes and\n452.46s: that's a very nice summary from the ipcc\n454.86s: here summarizing basically the results\n456.84s: again coming from those climate models\n458.819s: and I'll explain you the details but\n460.86s: those are the different continents here\n462.12s: like North America South America Europe\n464.4s: and Africa and the main point being here\n467.16s: that there's only two places where we\n469.259s: believe that the changes are significant\n471.539s: in the past and in the future that's the\n473.94s: western North America so we've heard a\n476.16s: lot about the the U.S Southwest trying\n478.979s: and the Mediterranean right so places\n481.74s: where we're witnessing a lot of\n483.36s: wildfires over the last couple of years\n486.24s: but for the rest of the world we\n488.4s: actually don't know we know there's very\n490.38s: low agreement in terms of even the type\n492.12s: of change right we don't even know if\n493.56s: that's going to be we are going to see\n495.3s: more droughts or more flooding events\n497.52s: right so it means that pretty much\n499.44s: anywhere in the globe we are in the\n501.12s: unknown right we don't know what we are\n503.58s: planning for okay so how can you think\n505.919s: about like Reservoir planning water\n507.539s: management and agriculture when you\n509.16s: don't know what the future will look\n510.36s: like that's a major major issue\n514.86s: okay so at the end of the day those\n518.64s: uncertainties from the global scale\n520.14s: Regional scale sophistication event\n521.88s: routes you can actually relate that back\n524.219s: to actually very small processes right\n526.62s: at the end of the day the reason why we\n529.019s: have so many uncertainties across\n530.459s: different models is related to the fact\n532.56s: that we don't represent everything\n533.94s: because you know the Earth is a very\n535.92s: complex systems you know we have many\n537.48s: degrees of freedom and we have many\n540.0s: processes such as clothes that are\n541.68s: really really tiny compared to the\n543.3s: typical resolution that we have in a\n545.1s: climate model so you could think of a\n547.019s: climate model like the old video games\n548.88s: right they have a pixelated pixels the\n551.94s: pixels are working on the order of 100\n553.98s: kilometers or 100 miles roughly and many\n556.86s: of the processes at play such as clothes\n558.899s: or oceanaries or photosynthesis here\n561.779s: need to be what we call parameterize\n564.24s: right they need to be represented in an\n566.04s: empirical way and we basically have some\n568.5s: sort of adult core empirical\n570.24s: representation of those\n572.22s: but they are the processes that actually\n574.62s: lead to a lot of those this diabetes\n576.54s: whether that's for Global temperature or\n578.519s: precipitation as I showed you before a\n580.92s: lot of the work of laws uh group here\n583.2s: about ocean heat content as well or the\n586.019s: global carbon cycle you know the fact\n588.12s: that photosynthesis is so and only leads\n590.1s: to widespread uncertainties into the\n592.14s: future of the for instance of the land\n594.24s: carbon cycle we don't know if the land\n596.1s: is going to be a major sink or major\n597.72s: source moving forward into the future so\n600.42s: that is a very important role for\n602.04s: climate mitigation okay at the end of\n604.74s: the day the main point is that those\n605.94s: processes are parametrate so we need to\n608.279s: actually represent them in a relatively\n610.38s: empirical way and the question is can we\n612.3s: actually do better okay okay then\n614.04s: because we know that they are really\n615.36s: important\n617.76s: so that's kind of the whole strategy so\n619.92s: we need to climatize things because\n621.48s: things uh those processes tend to be\n623.94s: much smaller so again this is the\n625.44s: example of clothes they are much tinier\n627.18s: much smaller than the typical grid size\n629.64s: and therefore we need to actually\n631.26s: represent them in a either physical way\n634.5s: or statistical way right you could\n636.36s: choose your approach historically people\n639.18s: have used a so-called physically based\n641.339s: approach where they believe they\n643.08s: understand the equations and they they\n644.82s: have kind of an end sets of the real\n646.38s: world but of course the real world is\n648.3s: very complex right so it's only an\n649.98s: NSAIDs right oh it's a Thai version of\n651.959s: the real world\n653.22s: or you could actually approach that so\n655.26s: that's basically kind of been a lot of\n657.12s: the work that's been going on here in\n659.399s: the center is you could approach that\n660.66s: from a statistical perspective you could\n662.339s: say maybe what I could do is I could\n664.26s: actually mimic uh this particular\n666.779s: process using a statistical approach\n668.7s: such as machine learning and neural\n670.44s: networks\n671.88s: and again those processes are already at\n675.06s: the heart of the the the uncertainty and\n677.22s: what we call the inter model spread that\n679.38s: we are witnessing at the global scale\n681.0s: all the way down to the regional scale\n682.8s: and that's why basically we cannot give\n685.079s: you very precise uh uh estimates as to\n688.5s: how the future will look like\n692.04s: so with couple of colleagues we got\n694.26s: quite excited by the use of machine\n695.76s: learning and kind of the framework for\n697.8s: that is pretty simple right you take uh\n700.2s: so that's what we call supervised\n701.519s: learning and some sort of regression\n702.66s: problem you take some ground truth so\n705.12s: here actually it's a bit pixelated here\n707.399s: but you should have a high resolution\n709.44s: model here that you can use as the\n712.019s: truths right you can co-screen that to a\n714.72s: scale that's actually similar to a\n716.22s: climate model so that's basically that\n717.72s: step so you take the high resolution\n719.1s: field you should see a lot of clouds\n720.839s: here you cause rain that to basically\n723.12s: 100 kilometer scale and that that scale\n725.7s: you would actually learn the\n726.959s: relationship you know you will learn the\n728.64s: processes that you want to represent\n730.26s: right so for instance you want to learn\n732.12s: how\n733.56s: clouds are going to be represented so\n735.48s: you can actually do that at this\n736.62s: particular call scale and basically we\n738.779s: learn what we typically call the\n740.279s: Tendencies right the rate of change of a\n742.98s: particular variables what's the rate of\n744.6s: change of temperature moisture wind etc\n747.42s: etc so that's really at the uh the the\n750.36s: out of parametrization\n752.82s: okay so I'm going to show you a couple\n754.68s: of examples where we believe that was\n756.899s: relatively successful and then I'll move\n758.76s: on to some other issues and show you\n760.8s: that there were some potential uh issues\n763.62s: related to that\n765.72s: so the first example we had was to look\n768.54s: at uh basically what we call convection\n770.579s: so that's basically deep clouds if you\n772.74s: will also precipitating clouds and we\n775.2s: wanted to show that we could actually\n776.639s: mimic that with the with the neural\n778.56s: network so the approach was pretty\n780.6s: simple we took this high resolution\n782.16s: field again caused grain to the cost\n784.5s: resolution of our climate model\n786.6s: and then we are trying to actually map\n788.639s: do this mapping between what we wanted\n791.16s: to predict so the rate of change of\n793.019s: temperature in the atmosphere of\n795.12s: moisture as well as a function of the\n797.339s: core scale variable so temperature or\n799.62s: moisture wind and some surface flexes as\n803.04s: well so that's basically kind of the the\n805.079s: game here and we use a neural network to\n807.36s: actually mimic that again informed by\n809.459s: the high resolution model so we use this\n811.74s: high resolution Global simulation cause\n814.38s: grain that and then learn all of those\n816.36s: relationships so that's exactly that\n817.86s: step we have a neural network trying to\n819.839s: represent those Tendencies as a function\n821.88s: of the cost sales State okay so that's\n824.88s: very simple it's basically a regression\n826.86s: problem and you can just try to adjust\n829.079s: your neural networks you better\n830.579s: represent that\n832.32s: and that's just showing you the results\n834.12s: here so this is the result from the high\n836.579s: resolution called grain simulation so we\n838.38s: call that the super parameter Trace cam\n840.3s: for made from my pritchell's group\n842.72s: that's the difference between the neural\n845.1s: network replicator of that and this uh\n847.98s: particular simulation and that's the\n850.26s: difference between the regular climate\n852.24s: model so the regular cam model that I\n854.339s: mentioned before the committee has\n855.54s: atmospheric model compared to this high\n857.399s: resolution model\n858.66s: and the main point being that here with\n860.82s: the neural net we can very well\n862.139s: represent that and reproduce the\n863.88s: original high resolution field so the\n866.279s: fact that we had this high resolution\n868.82s: climate model so it means that the\n871.2s: neural net is really able to do that\n872.7s: even just at the cost scale right we can\n874.86s: actually basically reproduce the quality\n877.079s: of the high resolution simulation but at\n880.199s: a fraction of the cost right just using\n882.3s: the cost resolutions\n883.86s: so that's great news\n885.48s: and we are doing a much better job than\n887.579s: the regular so-called physically based\n889.8s: parametrization here when we replace the\n892.38s: physically based parametization of\n894.18s: convection of deep clouds by the neural\n896.22s: net that's what we have here which is\n897.72s: very much an agreement with that\n899.339s: compared to the physically based\n901.079s: volumization here we are doing a much\n902.519s: much better job you have a lot of biases\n904.32s: here in terms of temperature this is the\n906.18s: heart itself here so but you have a lot\n908.279s: of biases okay don't want to get too\n911.22s: much into that but the main point being\n912.6s: that we believe that we had achieved\n915.48s: success right you could actually emulate\n917.279s: complex you know very small I mean\n919.32s: relatively small scale physics at a\n921.54s: kilometer scale you could actually do\n923.1s: that at a scale of 100 kilometer and you\n925.5s: wouldn't need to resolve all of that\n926.88s: just simulating that with the neural\n928.92s: network so that seemed to be doing a\n930.36s: great job\n932.82s: okay another way to look at that is this\n935.399s: is uh just a map so that's a video here\n937.68s: you have the high resolution uh\n939.899s: simulation here cause brain and that's\n942.12s: to replicate here from the neural\n943.8s: network and you can see that we are\n945.66s: actually doing a pretty good job in\n946.92s: terms of replicating the field and you\n949.079s: can see even the the animation is\n950.699s: actually very very similar right so\n952.68s: there's very good agreement yes it's\n954.54s: this is the moistening here and this is\n956.76s: the heating uh over the entire column of\n959.1s: the of the atmosphere and you could see\n960.899s: that there's actually very good\n962.399s: agreement between what we have at the\n963.839s: top and what we are getting at the\n965.1s: bottom including realistic uh geography\n967.74s: so that was the work from Griffin most\n969.24s: uh was actually with my picture that you\n971.339s: see robot okay so again that means that\n974.1s: we can actually emulate very complex and\n976.38s: and small scale physics with a machine\n979.079s: learning approach so that seems to work\n980.699s: quite well and we were quite satisfied\n982.8s: by that so we thought that was quite\n984.3s: nice\n985.079s: one point I would like to make is that\n987.24s: if you compare that field compared to\n989.579s: that one you can see overall we are\n991.68s: getting quite a bit of uh of of accuracy\n995.22s: we can nicely replicate that but you can\n997.32s: see that there's a lot more\n998.22s: stochasticity here right the rainfall is\n1000.139s: a bit more patchy than what we are\n1001.699s: seeing here at the bottom which is way\n1003.199s: smoother okay so I'll return back to\n1004.94s: this in a minute\n1008.24s: you could also look at\n1010.279s: um whether or not we can actually\n1011.86s: extrapolate well so that's when we\n1013.82s: started having a couple of issues right\n1015.44s: so we were really Satisfied by that we\n1017.959s: said okay the simulation seems to work\n1020.0s: really well we can even represent the\n1021.699s: continents and convection and\n1023.54s: precipitation about the continents\n1025.28s: really well but then we started to think\n1027.799s: about how will we be doing with climate\n1029.959s: change right how will we do in terms of\n1031.64s: extrapolating to a different climate so\n1034.16s: we ran a bunch of experiments where we\n1036.439s: basically took the same simulation and\n1038.36s: we increased the temperature globally\n1039.919s: uniformly by one degree Carbon 2 degrees\n1042.38s: all the way to four Kelvin here and we\n1045.38s: were looking at this is just a zonal\n1048.02s: average here looking at basically the\n1049.94s: change in circulation so this is just a\n1051.919s: temperature change and that's the high\n1054.26s: resolution simulation at the top and we\n1056.24s: wanted to see if a neural network\n1058.24s: learned on the historical period so this\n1061.1s: period here uh could whether could\n1063.5s: actually replicate the future so that\n1065.059s: was kind of the game we were trying to\n1066.679s: make so basically we trained the neural\n1069.2s: network just on that particular\n1070.88s: temperature and we wanted to see can we\n1072.44s: actually extrapolate to temperatures we\n1074.419s: have never seen like all the way to\n1075.799s: photorita\n1078.26s: and the main response was it was\n1080.72s: completely paid so uh the the point\n1084.02s: being that a neural network that's\n1085.7s: trained on historical climate cannot\n1087.62s: predict the future right so basically\n1089.12s: it's completely trying to extrapolate to\n1091.46s: a regime that it's never seen and\n1093.32s: therefore this generalization is a major\n1095.0s: issue and it means that we are really\n1097.039s: disappointed by seeing that with that in\n1099.08s: your network can do a climate change\n1100.96s: simulation and it's unable to extract\n1103.64s: extrapolate beyond the training data so\n1105.86s: that was really bad news and first was a\n1107.96s: red flag because it meant that we cannot\n1110.059s: use the neural network for the intent\n1111.86s: that we had right which was to simulate\n1113.539s: climate change\n1116.72s: there are some other issues uh I can\n1119.48s: quickly mention some of them so I\n1121.52s: mentioned the fact that we are limited\n1123.38s: in terms of uh out of sample another\n1125.419s: distribution we can also have what we\n1128.179s: call spiritual correlations uh the fact\n1130.46s: that at the end of the day a neural\n1132.559s: network is just building correlations\n1133.94s: and because we have a lot of\n1135.799s: correlations in space and time and we're\n1137.6s: using all of the space and time samples\n1139.58s: all together we can actually generate\n1141.919s: some serious correlations and that's why\n1143.78s: when you look at the top of the\n1145.46s: atmosphere here we have very high\n1148.48s: biases here at the top and we believe\n1151.4s: that's due to like some spatial and and\n1153.34s: spatial artificial correlations between\n1155.72s: the bottom here so the what we call the\n1157.88s: boundary layer and the top here because\n1160.46s: of just the spatial structure of that\n1162.98s: and then the the last issue that we\n1164.9s: found is that there were a lot of\n1166.34s: instabilities so numerical instabilities\n1168.08s: when we were to plug in your network\n1170.179s: directly into a into a model so a\n1173.6s: climate model and we had like\n1175.28s: temperatures reaching for instance 600\n1177.14s: Kelvin right which is completely\n1178.76s: unrealistic and the reason for that was\n1181.28s: just numerical issues right you would\n1182.9s: actually uh plug that neural network\n1184.34s: directly into the model and it could\n1186.02s: actually blow up so that was one of the\n1187.94s: major issues\n1191.179s: there were other issues such as not\n1194.179s: conserving energy uh so we actually\n1196.28s: started to look in each column whether\n1198.14s: energy was conserved or not and\n1200.419s: basically the neural network here so\n1201.98s: that's the neural network energy\n1203.12s: prediction and that's the true energy\n1205.7s: here in the column and you could see\n1207.679s: that we were close to one-to-one lines\n1209.36s: that was close to an energy\n1211.24s: conservation but not quite there right\n1213.799s: so there was a mismatch here which means\n1216.26s: that in each individual column we're\n1217.88s: actually losing or gaining energy and\n1219.919s: that's an issue because climate change\n1221.36s: is all about a small energy imbalance at\n1223.46s: the top of the atmosphere so you want to\n1225.38s: exactly conserve energy that's a street\n1227.419s: requirement right so you cannot allow to\n1230.6s: be just to be close to the one to one\n1232.82s: line you need to be exactly onto onto\n1234.679s: that one to one line you cannot have any\n1236.299s: type of uh Missing energy\n1238.58s: hahaha\n1240.2s: so we found a fix for that so if you\n1242.72s: just very quickly to to mention that but\n1244.7s: what you can do is you can actually\n1246.14s: impose directly this uh energy and mass\n1249.08s: conservation directly into a neural\n1250.82s: network structure so what 3D block is\n1252.44s: basically a neural network where you add\n1254.9s: some additional layers which which are\n1256.7s: what we call constraining layers and\n1259.039s: basically what you allow is that you\n1260.539s: leave some of the degrees of freedom\n1262.1s: open here and each of the individual\n1264.62s: constraining layer will actually\n1265.94s: constrain those so that you impose\n1267.62s: energy and mass conservation based\n1269.84s: strictly into each of those at the same\n1272.059s: time okay so we call that a constraining\n1274.22s: layer it's actually just something you\n1276.14s: add to your typical neural network you\n1277.94s: leave some of the degrees of freedom\n1279.559s: open here some of the weights open and\n1281.96s: basically you can still train all of\n1283.64s: that what we call end-to-end in terms of\n1285.74s: a machine learning algorithm so so\n1287.419s: that's something we can solve so that\n1288.799s: issue we believe is not an issue anymore\n1290.419s: so that's something you can solve\n1292.76s: okay\n1294.2s: so basically quick summary of what we've\n1296.96s: learned or at least uh my perspective on\n1299.659s: that in terms of uh how we can use\n1301.82s: machine learning at least for convection\n1303.44s: is that at first we got really excited\n1305.539s: we thought that I mean the initial work\n1307.159s: was really exciting we could actually\n1308.539s: correct a lot of the issues with\n1310.28s: convection which is which has been a\n1312.08s: long-standing issues and we thought that\n1313.88s: was really a great uh great success\n1317.36s: but then we started getting into the\n1318.86s: weeds and we we saw that the models\n1321.44s: could not generalize so cannot do any\n1323.24s: type of climate change simulation which\n1324.799s: was the intense it lacks numerical\n1327.26s: stability so you can't actually plug\n1329.059s: that directly into a model and hope that\n1331.1s: it would actually work so there's a lot\n1332.539s: of issues there uh and that's related to\n1335.059s: Alex's work here it misses some physical\n1337.46s: invariants so there could be some mass\n1339.14s: and energy conservation you could have\n1341.179s: also some other like more sophisticated\n1343.039s: invariances so typically they don't have\n1345.08s: that\n1346.52s: but the question and that's kind of the\n1348.26s: rest of the talk so that's why I didn't\n1349.52s: want to spend too much time on that is\n1351.14s: really the question is what did we learn\n1353.0s: except for just curve feeding right we\n1355.039s: were able to replicate something but\n1356.9s: what did we really truly learned right\n1358.64s: we can replicate convection but it will\n1360.74s: learn convection better I mean that's\n1362.48s: really the question at the end\n1365.0s: and so that's why a lot of the work uh\n1367.4s: at least micro recently has been\n1369.32s: dedicated to looking at physical and\n1371.12s: variances to improve basically uh model\n1374.419s: stability generalization and also\n1376.34s: interpretation as well\n1378.26s: and also trying to think about lower\n1380.72s: dimensional representation of processes\n1382.88s: so we can start more uh getting more\n1384.62s: understanding and predictability at the\n1386.48s: same time right so trying to get into\n1388.46s: the weeds of those uh algorithms so we\n1390.86s: can understand them better\n1392.84s: so I'll show you just a couple of\n1395.0s: examples looking at this what we call\n1397.039s: lower dimensional representation and\n1399.08s: trying to see how we can use those\n1400.46s: tricks as a way to better understand\n1401.9s: physics uh at least that's the way we we\n1404.539s: are approaching that\n1407.36s: so I start with the first example which\n1409.1s: is related to Cloud organization and so\n1411.38s: we know that clouds are highly organized\n1413.78s: you know so they are they can be patchy\n1416.24s: or they can have different shapes so for\n1417.86s: instance here you have more of a flowery\n1419.72s: shape what you have as gravel here\n1421.88s: sometimes of sort of fish fish bone\n1423.919s: structure here or sometimes what is\n1425.9s: referred to as sugar you know but they\n1427.52s: tend to be organized in specific\n1429.26s: specific patterns and that was actually\n1430.88s: a competition that people created to\n1433.1s: actually uh classify them and uh with\n1435.559s: human human supervision\n1438.38s: and that's true in observation so this\n1440.78s: is just uh some satellite observations\n1442.76s: here but it's also true in models right\n1444.919s: so if we run one of the high resolution\n1447.26s: simulations I I was talking about before\n1449.96s: like a roughly at the kilometer scale\n1452.0s: you have some simulations that will\n1454.1s: basically create what we call Patch C\n1456.08s: compact uh patchy convection so popcorn\n1458.12s: type convection where basically\n1459.98s: precipitation happens pretty much\n1461.48s: anywhere and it could be pretty random\n1463.64s: and sometimes you would have what we\n1465.44s: call self-aggregation right all of the\n1467.72s: the precipitation and convection is\n1470.059s: highly organized in space and time over\n1472.4s: a particular cluster right and what you\n1475.82s: could think is that maybe it doesn't\n1477.62s: matter if you just look at the average\n1479.0s: but of course it would matter in terms\n1480.5s: of how you experience extremes right I\n1482.6s: mean you would expect for instance\n1483.62s: specification to be much more intense\n1486.02s: over that particular regime than\n1487.94s: compared to here right so that\n1489.98s: particular extreme might be different\n1491.2s: and there's also a pretty strong impact\n1493.52s: in terms of the environment in fact if\n1495.44s: we were to take a and have a look at the\n1497.72s: environment here and just the slab\n1499.34s: average here you would see that this\n1501.559s: regime here is actually much more humid\n1503.539s: so it's a much more humid environment\n1504.98s: because the clouds are pretty much\n1506.78s: anywhere but this uh region here is\n1509.96s: actually much drier so on average you\n1511.76s: actually have a much higher\n1513.44s: and that happens to be actually very\n1515.96s: important because this has an impact in\n1517.7s: terms of relative cooling back to space\n1519.38s: so that has an impact on climate\n1520.82s: sensitivity so whether clouds are\n1523.4s: organized this way or that way actually\n1525.2s: matters for climate as a whole so that's\n1527.179s: actually an important uh area of\n1529.76s: research and people have been focusing a\n1531.38s: lot on that we call that basically Cloud\n1533.6s: aggregation and Cloud organization so\n1535.46s: that's very important\n1539.179s: so how do we typically parametrize\n1541.46s: precipitation so we typically do what we\n1544.46s: what I mentioned before you say that\n1546.08s: precipitation is a function of things\n1548.24s: you can resolve in your climate model\n1550.039s: right so you have your call scale\n1551.72s: resolution and you say precipitation is\n1554.0s: just going to be a function of things\n1555.679s: that can resolve such as humidity and\n1557.96s: temperature in particular\n1560.0s: and you have different examples as to\n1561.74s: how you could approach that so that's\n1563.0s: one example one of the earlier\n1564.58s: climatization of precipitation so you\n1567.08s: have here a heavy site function so you\n1568.88s: have a threshold in terms of some\n1570.86s: moisture so once moisture passes some\n1572.9s: threshold that's temperature dependent\n1574.46s: you can have precipitation so it's like\n1577.22s: zero one and then it actually also\n1579.679s: depends on the strengths and the how\n1581.48s: much moisture you have in the atmosphere\n1582.799s: so the more moisture you have the more\n1584.779s: precipitation you have so that makes\n1586.279s: sense you need to have a threshold if\n1588.26s: there's not enough moisture there's no\n1589.7s: precip and once you pass the threshold\n1591.679s: the more moisture you add in the\n1592.94s: atmosphere the more precipitation you\n1594.5s: will have so that that makes a lot of\n1596.179s: sense\n1597.44s: you have some more sophisticated\n1599.36s: approaches that are based on some sort\n1601.34s: of some sort of Statistics they assume\n1603.32s: some sort of distribution of moisture\n1605.0s: and then there's again a threshold and\n1606.679s: everything above the threshold can\n1608.059s: actually precipitate so you have\n1609.5s: different flavors of that that can\n1611.059s: actually lead to uh basically generating\n1613.039s: precipitation based again on just the\n1616.1s: cost scale variables that you have here\n1618.2s: typically those lab average temperature\n1619.94s: or doesn't have average moisture okay\n1621.98s: but that's basically the main point and\n1624.2s: really at the end of the day the main\n1625.46s: assumption is that we believe that\n1626.779s: precipitation can be predicted as a\n1628.58s: function of just the things that we can\n1630.02s: resolve at the very last\n1633.2s: okay but the question is and I showed\n1635.779s: you before it seems that organization\n1637.7s: might be important right the how uh uh\n1640.76s: clouds and and convection is actually\n1643.52s: organized might be playing a role so the\n1645.679s: question is really what do we need to\n1647.539s: include in terms of information about\n1649.1s: that touchiness or organization and does\n1651.559s: that matter or do we can can we just\n1654.2s: discard that right maybe it doesn't\n1655.64s: matter at the other big scale so that's\n1658.34s: really the question for the rest of the\n1659.84s: of the talk\n1661.58s: and you can again see the same type of\n1664.4s: pattern that I just mentioned in\n1666.32s: observations as well so if we look at\n1668.36s: precipitation being across some column\n1671.12s: water Vapors so that's the total amount\n1672.74s: of water that we have in a column you\n1674.36s: can look at as a function of temperature\n1676.4s: what is the typical shapes that's in the\n1678.44s: Eastern Pacific here whereby David\n1680.48s: needin and colleagues and the main point\n1682.64s: being again you can see that increase so\n1684.26s: you have a threshold here once you pass\n1686.36s: this threshold you can see that\n1687.5s: precipitation increases as you increase\n1689.36s: moisture in the air right so that makes\n1691.4s: sense you need a sufficient amount of\n1693.799s: moisture and then as you add moisture in\n1695.9s: the air you will actually increase\n1697.1s: specification so and that's also\n1699.08s: temperature dependent right the\n1700.4s: threshold is actually dependent on\n1701.84s: temperature increases with temperature\n1704.24s: so that's in observations meaning many\n1706.46s: many observations and giving that's just\n1708.74s: an average here\n1710.0s: and you could also look at simulations\n1711.86s: and they have overall the same patterns\n1713.9s: so those curves are showing the same\n1715.4s: pattern here for different temperatures\n1716.84s: so you can see they have a similar type\n1718.94s: of pattern with different thresholds for\n1720.86s: different temperatures\n1722.419s: but the main point here is that if you\n1724.58s: look at individual sampling so if you\n1726.38s: take one column at a time you can see\n1728.0s: that there's a lot of spread around that\n1729.679s: curve right so there's a lot of\n1731.779s: variability around one particular curve\n1733.58s: so the curves I'm showing you here are\n1735.799s: just on average across many many samples\n1738.559s: but there's a lot of spread across that\n1740.9s: so it means that precipitation we think\n1743.0s: of that as being very stochastic you\n1744.86s: even if you knew the amount of moisture\n1747.32s: in the color you cannot predict exactly\n1748.94s: how much qcp will have you know it's\n1750.559s: going to be very difficult and people\n1753.02s: just think of that as being stochastic\n1754.76s: and say you have to represent that in a\n1757.279s: stochastic way there's no way you can\n1759.32s: precisely find the amount of precipation\n1763.76s: okay so kind of the objectives that we\n1767.24s: had where we are to say you know can you\n1770.0s: actually represent precipitation by\n1771.86s: having basically the results available\n1773.539s: so moisture and temperature at the like\n1775.94s: the slab average overcome but maybe also\n1778.76s: including some of the subred scale stuff\n1780.74s: you know we will Define what stuff is in\n1783.14s: a second and the question is if we could\n1785.48s: have some separate scale information\n1786.74s: could we better predict precipitation\n1788.6s: right could we predict even all of the\n1790.82s: variability that we had all of that\n1792.44s: presumably stochasticity could we\n1794.72s: predict precipitation really well in\n1796.46s: space and time\n1797.84s: and kind of a related question is can\n1801.14s: that subgrade scale viability explain a\n1803.24s: lot of the stochasticity or the\n1805.159s: stochastic nature of precipitation that\n1806.96s: we are seeing so typically people assume\n1809.72s: that this is completely random that\n1811.52s: there's nothing we can do about that and\n1813.08s: we cannot predict that but maybe we can\n1814.88s: relate that to the patchiness of\n1817.399s: precipitation the patchiness of clouds\n1819.32s: right and if you could do that that\n1820.82s: would be great because if we mean that\n1822.2s: precipitation would not really be\n1823.88s: stochastic it's just we don't have all\n1825.44s: of the information needed to actually\n1827.659s: get precipation okay so that's kind of\n1830.24s: the goal and a lot of people have worked\n1832.46s: on developing stochastic conversation\n1834.38s: actually including law as well uh so\n1837.02s: that's been a very hot topic as well\n1838.76s: like can we actually represent those\n1840.14s: things and and that's actually an\n1841.399s: important topic it's actually very\n1842.6s: important for weather and time\n1845.72s: okay so uh so what we did is we took\n1848.659s: those uh Global Cloud resolving\n1850.64s: simulations I mean actually mostly the\n1851.96s: work of uh Sarah shemek and Kara and and\n1855.14s: you Wong in in my group and basically\n1858.62s: you take those simulations here and you\n1860.24s: do the same trick right you take the\n1861.799s: high resolution simulation you can cause\n1863.779s: grain them to resolution that's similar\n1865.94s: to a climate model so you go from\n1867.44s: basically a few kilometers so two to\n1869.84s: four kilometer typically and you go to a\n1872.12s: 100 kilometer here so you cause grain\n1874.46s: the high resolution field make that very\n1877.279s: cost and then you want to learn at this\n1879.26s: very cost resolution again at 100\n1880.88s: kilometer scale\n1882.32s: you want to see that based on the Lost\n1884.179s: scale data can you actually predict\n1886.22s: precipitation and the large scale\n1888.559s: data that we use is CCO phase\n1891.32s: temperature so temperature of the at the\n1893.299s: surface\n1894.52s: a specific table water so the total\n1897.08s: amount of moisture in column and then\n1898.82s: some additional variables so moisture at\n1901.159s: the very bottom and temperature at the\n1903.2s: very bottom so just to have some\n1904.94s: information about the surface and the\n1906.5s: boundary layer\n1907.7s: to know because that's important for\n1909.32s: triggering authentication we know so\n1911.059s: basically those are variables again at\n1913.82s: 100 kilometer scale so we take the\n1915.919s: average value across of all of those\n1917.96s: fields and we just plug that into a\n1919.94s: neural network and we want to predict\n1921.32s: precipitation\n1923.96s: okay and when we do that so again we\n1927.2s: only have those four variables to put in\n1928.88s: precipitation we do that across space\n1930.32s: and time and when we do that we can\n1932.539s: actually get that curve that I showed\n1933.919s: you before right that increase that we\n1935.72s: see where as we increase uh the amount\n1938.299s: of moisture in the air so this specific\n1940.22s: table water we can actually see the\n1941.96s: increase of precipitation so we are\n1943.88s: capturing kind of the mean Behavior\n1945.5s: right\n1946.34s: but a lot of a lot of the spread that\n1948.919s: you see here is kind of the viability\n1950.419s: within each individual column right and\n1952.279s: you can see that there's a lot of\n1953.419s: variability that we cannot capture based\n1955.88s: on that single neural network right so\n1958.22s: what this means is that we are unable to\n1960.44s: capture this stochastic nature of\n1962.24s: precipitation and if you look at the R\n1964.1s: square the R square is actually very\n1965.539s: poor we are about 0.2 in term in terms\n1967.94s: of the R square even if you were in that\n1970.159s: case we're adding information about the\n1972.44s: boundary layer and moisture and\n1973.64s: temperature at the lower levels and you\n1975.559s: can see again the variance which is\n1976.94s: predicted here is much much lower than\n1979.22s: the veins that we have across different\n1980.6s: pixels\n1981.919s: another way to look at that is to look\n1984.02s: at the precipitation distribution that\n1985.58s: we have so this is the truth here in\n1987.559s: blue and predicted by just using C\n1990.98s: surface temperature and column water\n1992.96s: vapor we are getting this precipitation\n1995.12s: distribution if you add temperature and\n1998.059s: moisture at the very first level and to\n1999.919s: meter you're getting that so basically\n2002.14s: the same issue we had before this\n2003.519s: drizzle issue where you have two too\n2006.519s: many low frequency\n2009.12s: low intensity precipitation events and\n2012.279s: you cannot get the extremes right so the\n2014.919s: main point being here is that we cannot\n2016.899s: get the stochasticity of stochasticity\n2018.58s: of rainfall and we cannot get the\n2021.94s: extremes of rainfall right so based on\n2023.919s: this deterministic approach we cannot\n2025.779s: get the most extreme events right so\n2027.82s: that's why people think that you\n2029.26s: actually need to use a stochastic\n2030.64s: approach to actually get those extremes\n2032.44s: right and and that seems to be a really\n2034.12s: critical so the real question is can we\n2037.179s: correct that is there a way to learn and\n2039.1s: correct that so we can actually get the\n2041.08s: extremes correct and we can actually get\n2042.76s: the right precipitation distribution\n2046.12s: so the main point we wanted to actually\n2048.76s: start thinking about uh separate scale\n2051.099s: processes so again what we want to test\n2052.839s: is what if we were to add to that some\n2055.899s: submit scale information right and you\n2057.879s: could say the obvious thing is to think\n2059.379s: about some Metric of organization right\n2061.78s: so the metric of like clustering in a\n2063.94s: sense so can we can we measure the\n2065.74s: clustering that we have here is there\n2067.179s: some sort of measure we can use to say\n2068.919s: this is very cluster or very organized\n2072.82s: so we looked at the literature and every\n2075.52s: single one of them don't need to look\n2077.139s: into that but every single one of them\n2078.639s: is a definition of organization or some\n2081.52s: Metric of organization so there's a zoo\n2083.26s: of them uh and so the question is which\n2085.839s: one we choose right and we could\n2087.159s: actually choose any of those and try to\n2089.5s: predict precipitation but we said maybe\n2091.839s: there's a better way of doing that maybe\n2093.46s: we can also learn the right uh the right\n2096.099s: metric at the same time okay so instead\n2098.859s: of plugging one of those organization\n2100.359s: metrics that are made up we want to say\n2102.52s: can we actually learn the organization\n2104.56s: itself so that's kind of the trick\n2107.26s: so\n2108.46s: the idea is relatively simple you say I\n2111.52s: take the high resolution field which is\n2113.859s: this specific table water here which is\n2115.96s: basically of size 32 by 32 so that's the\n2118.3s: cost resolution pixel here\n2120.579s: you encode the information to what we\n2122.859s: call a latent space so just a few\n2124.42s: Dimension here\n2125.8s: and you want to expand that back so you\n2127.72s: want to basically reproduce that with\n2129.52s: what we call a a Noto encoder which is\n2131.8s: basically encoding that and then\n2133.72s: decoding that you could think of that\n2135.4s: it's like image compression right you're\n2136.9s: compressing the information to just a\n2138.88s: few Dimensions here\n2140.32s: and you want to represent that and using\n2142.78s: that as a way to actually improve your\n2145.42s: your prediction of precipitation right\n2147.579s: so what you want to do is you want to\n2149.38s: learn what is going to be important in\n2151.359s: that field that I can actually use to\n2152.859s: include in my precipitation forecast or\n2155.14s: my precipitation prediction and that\n2157.72s: latent space here we uh we looked quite\n2160.72s: a bit into that you can actually get\n2162.52s: just a dimensional phone that's going to\n2164.14s: be sufficient to actually better predict\n2165.64s: precipitation I'm going to show you that\n2166.9s: in a minute okay but the main trick is\n2169.06s: can we directly learn as some sort of\n2171.579s: embedding what is the dimension of what\n2173.26s: is the information content that's\n2174.579s: actually in that image that I can\n2176.2s: actually use to actually better\n2177.339s: represent or produce precipitation and\n2180.04s: just want to mention that we went from a\n2182.32s: dimension of 32 by 32 which is 2 to the\n2185.14s: 10 two dimension of 2 to the two right\n2187.3s: so only four right so huge dimensional\n2189.76s: reduction so we don't need that whole\n2191.5s: field we just need very few Dimensions\n2193.839s: to actually understand the process okay\n2195.52s: so there's and there were a couple of\n2197.619s: Tricks including a rotational and\n2199.42s: translation eBay\n2202.48s: okay so how does it work in practice is\n2204.46s: we have this Baseline neural net so we\n2207.099s: have the cost rate field you want to\n2208.9s: predict precipitation we use almost the\n2210.76s: same except that we add this kind of\n2213.22s: organization metric that we want to\n2214.9s: learn and we Define that as the latent\n2217.24s: space I just showed you before so you\n2219.04s: say I want to add some information about\n2221.619s: the separate scale so things about the\n2224.26s: field that I didn't have at the cost\n2226.119s: scale and I want to learn that at the\n2228.7s: same time right and the way we learned\n2230.32s: that is we say I want to have this\n2232.359s: latent space of very small dimensional\n2234.16s: space that's able to actually\n2235.839s: reconstruct the field and at the same\n2238.359s: time is able to better predict\n2240.16s: precipitation right so we are trying to\n2241.78s: achieve two things we are trying to say\n2244.0s: we're encoding the information in that\n2246.4s: image here and at the same time we want\n2248.68s: to use that to better predict the\n2250.24s: precipitation at the same time right and\n2252.04s: we learned that as we call it tens one\n2253.599s: so we are trying to learn that all\n2254.98s: together so we are producing the images\n2257.14s: and at the same time we are reproducing\n2259.06s: the precipitation altogether uh so that\n2261.76s: we can do that together so basically as\n2264.52s: a result we are trying to optimize the\n2266.56s: rich people of precipitation and we are\n2268.42s: trying to better and to naturally find\n2271.24s: what is the right organization metric\n2272.98s: right can we learn that directly from\n2274.599s: that latency okay so that's kind of the\n2277.359s: trick\n2279.52s: so when you include these additional\n2281.38s: organizational metric that we we\n2283.06s: actually learned all of a sudden you ask\n2285.76s: where you actually is increased\n2287.5s: dramatically so now they are square\n2288.88s: across all of the samples is really high\n2290.56s: at 43.8 the variance now the predicted\n2294.04s: by this model is almost exactly overlaid\n2296.619s: onto the onto the the one that we had\n2299.02s: from the original sample so that's\n2300.46s: that's great and you can look at the\n2302.44s: precipitation distribution here and now\n2304.24s: you can see that we can pick up the\n2305.619s: extremes really really well right so now\n2307.839s: by including some information about the\n2310.3s: subred scale and the fact that things\n2312.4s: are organized in some way we can\n2314.92s: actually start thinking about basically\n2317.079s: the fact that we can actually get the\n2318.46s: extremes right so it seems that this\n2319.96s: organization is really critical to get\n2321.76s: the extremes and it seems that there's\n2324.22s: no stochasticity of a little outside of\n2327.28s: just that organization so quick summary\n2329.859s: of that is by including some information\n2331.96s: about how clouds are clustered together\n2334.24s: we can predict extremes really well and\n2337.18s: we can predict basically most of the\n2338.8s: stochasticity of liability in\n2340.96s: precipitation\n2342.16s: so that's great\n2344.8s: another way to look at that is if you\n2346.66s: look at the Baseline neural network at\n2348.7s: the top here so that's the one that\n2350.56s: didn't have any information about Cloud\n2352.3s: aggregation and Cloud clustering you can\n2355.24s: see the Dr squares so the ability power\n2357.22s: that we have on the base and neuron that\n2358.9s: is almost zero across right so this is\n2360.94s: in space here so this is mostly the the\n2363.76s: tropics here\n2364.96s: uh and if you were to look at the one\n2367.359s: that includes the organization all of a\n2369.64s: sudden the the R square is much much\n2371.68s: higher close to one right so it means\n2373.42s: that we can actually do a great job at\n2375.28s: capturing that in space and time so we\n2377.619s: can really predict precipitation with\n2379.119s: great accuracy even though we are not\n2381.04s: resolving the entire small scale\n2383.14s: processes so that's great so it means\n2385.3s: it's very approachable to actually plug\n2387.099s: that in a climate model you don't need\n2388.599s: to resolve the Pain Scale structure you\n2390.64s: can directly get precipitation over\n2394.0s: now the question is that when we return\n2396.76s: back to this like we created some sort\n2398.92s: of embedding of the these these uh High\n2402.099s: dimensional space into very few\n2403.54s: Dimensions here but the question is how\n2405.94s: can we actually Define that in a climate\n2408.28s: model right we don't know that a priori\n2410.2s: and we don't have access to that right\n2411.46s: we used in that case the high resolution\n2413.32s: field we encoded the information to a\n2415.9s: latent space but in a climate model you\n2417.94s: don't have that latent space a priority\n2419.619s: right so you need to find a way to\n2421.0s: actually get that\n2422.98s: so you could say\n2424.72s: the first approach would be to say maybe\n2427.24s: the latent space depends on the column\n2429.64s: average temperature and moisture feels\n2431.56s: right so you could directly try and\n2433.0s: predict that as a function of the COS\n2435.579s: scale variable and that's what we tried\n2436.96s: at first so can we predict the latent\n2439.06s: space just based on the cost scale\n2441.099s: variables and that seems to work for the\n2443.619s: first mode of ability but not for the\n2445.839s: rest right so across those four\n2448.06s: dimensions only the first one seems to\n2450.16s: be due to the large scale moisture and\n2452.2s: temperature but not the other one so it\n2454.06s: seems that there are some additional\n2455.26s: information that we don't have and that\n2457.3s: we cannot retrieve just based on the\n2459.28s: information we have you know in a\n2460.96s: typical climate model that's 100\n2462.76s: kilometers\n2464.8s: so what we thought is that maybe your\n2467.26s: trick is would be to think about this\n2468.88s: latent space as a memory process right\n2470.859s: so if you think about that we know that\n2472.54s: clouds are organized but they don't\n2473.859s: organize in a snapshot right they\n2476.2s: organize over like some time steps right\n2478.119s: and when clouds are organized they carry\n2480.28s: over some memory so what we thought is\n2482.2s: that maybe a way around that is to say\n2484.48s: uh what we could do is that we could\n2486.339s: potentially represent this latent space\n2488.02s: as a memory process right in that case\n2490.78s: you just need to initialize that in your\n2492.94s: climate model and then you can carry\n2494.8s: that forward in time and space and\n2496.9s: that's something you can basically move\n2498.4s: around with the climate model\n2500.38s: and that's what happens if you do so so\n2503.619s: that's using four time steps here so 60\n2506.38s: Minutes in that particular case and we\n2509.02s: could show that basically this latent\n2511.0s: space is is a memory processor that can\n2513.16s: be highly that can be predicted really\n2515.619s: really well and with great accuracy just\n2517.72s: by including a few time steps before\n2519.4s: right so what this means is that we can\n2522.7s: predict organization just based on the\n2524.56s: past you know and the organization is\n2526.06s: going to change over time based on the\n2528.28s: history and things and how things are\n2529.9s: changing but that's something that's\n2531.46s: very practical in the past you know in a\n2533.56s: climate model you just need to carry\n2534.94s: over that memory across in space and\n2537.46s: time okay and that's something we again\n2539.38s: just learned based on on the data\n2543.579s: now kind of the last question is what is\n2546.22s: that latent space here right so we we\n2548.02s: said that we have a some sort of\n2549.7s: organization metric so we have a latent\n2551.5s: space here but what is that latent space\n2553.24s: right so that's kind of the interesting\n2554.98s: part of that you could say maybe we can\n2557.26s: start thinking about what is really that\n2558.7s: latency\n2561.64s: so typically when we have this those\n2564.4s: Auto encoders what happens is you can\n2566.32s: start looking at different dimensions of\n2568.18s: the latent space so one dimension here\n2569.98s: will be potentially like uh you go from\n2572.74s: an angry face to a sniding phase so that\n2575.38s: first mode here is basically smile and\n2578.38s: that second uh Direction here is\n2580.839s: basically the pose going from the uh\n2582.76s: from the right to the left right but you\n2584.92s: can interpret that latent space right\n2586.42s: one dimension here another dimension\n2588.4s: here and so we thought maybe we can do\n2590.74s: the same in that particular latent space\n2592.66s: start understanding each Dimension and\n2594.88s: what they are actually doing and what\n2596.319s: they are actually showing us\n2598.359s: okay so that's basically two\n2602.079s: um Dimensions here of the organization\n2603.64s: actually that's a no picture the new one\n2605.619s: is actually better but whatever uh but\n2608.319s: the main point being that we have one uh\n2611.14s: Direction here which is showing you that\n2613.119s: things becomes more humid so more uh\n2615.88s: basically you have more clouds and then\n2617.92s: that direction here so they are not\n2619.42s: exactly aligned along the First\n2620.92s: Dimension second dimension they are\n2622.359s: orthogonal to that but this one is\n2623.859s: actually showing you the degree of\n2625.06s: organization so things are becoming more\n2627.28s: and more clustered here as you get here\n2629.079s: and now things are getting less and less\n2630.94s: cluster they're more diffuse no it's\n2632.98s: actually slightly better actually we\n2634.54s: have this uh it's actually more centered\n2637.72s: but the main point being that you can\n2639.339s: start interpreting these latent space is\n2641.38s: actually very doable that's something\n2642.64s: you can query right it's only four\n2644.92s: dimensions so you can visualize that and\n2647.02s: you can understand how that's actually\n2648.339s: contributing to your physical intuition\n2650.619s: and physical understanding and kind of\n2653.079s: the great thing is that we didn't impose\n2655.0s: any physics here we just learned the\n2656.68s: physics by itself right we learn the\n2658.42s: physics by trying to actually replicate\n2660.46s: 3C right and by trying to replicate\n2662.8s: precipitation we could show we could\n2664.66s: actually do a great job at actually\n2665.98s: learning new things and also improving\n2667.72s: the predictive power as well\n2671.2s: so that's great uh in terms of using a\n2674.26s: lower dimensional representations to\n2676.0s: actually improve the understanding of\n2677.74s: physical processes\n2680.26s: the last thing I wanted to talk about\n2681.88s: was to start thinking about more than\n2684.76s: correlation so typically when you have\n2686.74s: uh a bunch of neural networks you're\n2689.14s: just building collisions you know and I\n2690.7s: mentioned that they are sometimes\n2691.9s: previous correlations that could come up\n2693.64s: from like different spaces and times you\n2695.98s: know that you're aggregating together\n2697.2s: and everyone knows that cause and effect\n2699.819s: is different from correlation right so\n2701.319s: the question is can we build a system in\n2704.44s: which we could build more than\n2705.88s: collisions but we could actually have\n2707.26s: causes and effect\n2710.44s: so what we did is we looked back at the\n2713.14s: same system that we had before so again\n2714.819s: this high resolution Cloud resulting\n2716.74s: model we take again the call scale field\n2718.96s: and we want again build those uh what we\n2721.66s: call physics Tendencies so the rate of\n2723.28s: change of temperature and moisture uh at\n2725.98s: different levels in the atmosphere and\n2727.359s: that's something we would want to have\n2728.56s: in a particular climate model\n2731.8s: so we started uh thinking about that and\n2735.04s: thinking in terms of can we Define\n2736.66s: instead of building a regular neural\n2738.579s: network can we build a so-called\n2740.079s: causally informed neural network right\n2741.88s: so when you look at the neural network\n2743.98s: you're connecting many many nodes to\n2745.839s: some other nodes and what you want would\n2747.88s: want to do here is you would want to say\n2749.68s: I just want to have the nodes that are\n2752.619s: closely connected right so for instance\n2754.599s: one part of the atmosphere is only going\n2756.7s: to causally impact oh sorry the other\n2759.579s: part of the atmosphere but I don't want\n2761.26s: to add things that are correlated right\n2762.819s: I don't want to have correlations I just\n2764.44s: want to have like the causally informed\n2766.24s: uh processes so what you can do is you\n2769.78s: can use this so-called pcmci algorithm\n2772.9s: which is\n2776.02s: eventually why\n2779.2s: oh\n2788.319s: okay sorry so that's which is an\n2791.8s: algorithm that's trying to do what we\n2793.48s: call causal Discovery so it's basically\n2795.4s: a graph and you want to know and learn\n2797.8s: the causal connections between different\n2799.78s: parts of the graph right oh and the\n2802.839s: different nodes and basically the idea\n2804.7s: is that each point here is like a Time\n2806.74s: series right and you investigate the\n2808.54s: time series to try to think about cause\n2810.52s: and effect in that particular graph\n2812.619s: right and you can look at your entire\n2814.599s: time series and then try to dissect that\n2817.0s: and then basically defining and removing\n2819.16s: experience links right so if some of the\n2821.44s: links are serious you can actually drop\n2822.94s: them and then it would mean that in that\n2825.099s: particular example oh sorry those two\n2828.579s: variables are causing the one at the\n2830.02s: bottom right so but the other ones we\n2831.64s: have previous correlation so that's kind\n2833.98s: of the trick you investigate the time\n2835.96s: series\n2837.579s: to where that is\n2840.52s: oh sorry about that\n2846.52s: sure always\n2851.26s: yeah and so in the end you will just be\n2854.079s: left with what with what we call a\n2855.88s: causal graph a directed graph where this\n2859.42s: edge here is going to impact this one\n2861.04s: this node is going to impact that one\n2862.48s: and this one is going to impact that one\n2864.04s: but the other ones we are curious they\n2865.66s: didn't pass a significance test right so\n2867.94s: we can drop a lot of those nodes and we\n2869.68s: can basically remove various\n2871.24s: correlations across different variables\n2873.579s: and that's convenient because it means\n2875.74s: that in the end compared to that\n2877.24s: particular version\n2878.8s: the new graph that we will have will be\n2880.839s: much faster than what we had originally\n2882.819s: right we don't have all of those\n2884.14s: connections and therefore if you have a\n2886.119s: neural network you can actually drop a\n2887.74s: lot of the connections that we have if\n2889.839s: you're familiar with dropouts that's\n2891.28s: kind of similar to Dropout but causally\n2893.02s: inform right you can drop connections\n2894.7s: but based on the causally relevantly\n2897.94s: okay so that's kind of the approach we\n2900.819s: take as a reference the neural network\n2903.339s: model fully connected where everything\n2905.56s: is fully connected\n2907.119s: and then another one which we call a\n2908.92s: causally uh basically a cause cause on\n2912.7s: your network where only the links here\n2915.099s: that are causally relevant based on this\n2917.02s: causal Discovery algorithm are left so\n2919.96s: basically it looks like a similar neural\n2922.06s: network but many of those links are\n2923.38s: dropped in fact there's just a fraction\n2925.54s: of the original links in fact we have\n2927.579s: one tenth of the original connections\n2929.38s: right so we are much much faster in\n2931.06s: terms of the connections and we have way\n2933.52s: fewer uh uh correlations and therefore\n2936.64s: we are trying to assess really cause and\n2938.56s: effect in that particular case\n2940.78s: and we have another yeah let's try the\n2943.06s: details here\n2945.22s: up here we have the high resolution\n2946.72s: simulation again uh that's basically a\n2949.359s: Time average here and here is the\n2952.18s: prediction from the from the neural\n2954.64s: network the standard approach that I\n2956.14s: showed you earlier so very similar you\n2958.359s: can see they they look very much alike\n2959.98s: and that's the causaline formula Network\n2962.2s: here where you can see we are actually\n2963.7s: doing very similar jobs compared to the\n2965.98s: to the full neural network but again at\n2968.079s: a fraction of the number of links right\n2969.88s: so we use cause and effects here so we\n2972.52s: can actually have correct uh I mean we\n2974.68s: hope correct cause an effect\n2976.9s: and that's a Time average but you can\n2979.119s: even look at snapshots so you can even\n2980.619s: look at some particular events where you\n2983.079s: have some precipitation events and you\n2984.64s: can see again the prediction of the\n2986.319s: funeral net is pretty similar but even\n2989.2s: the causal neural network is doing very\n2990.94s: similar job to the to the to the fully\n2993.16s: connected much much higher dimension in\n2994.839s: your network so that's very convenient\n2996.22s: it means that at a fraction of the of\n2998.74s: the compute cost you can actually do a\n3000.66s: good job plus you hope that you also\n3002.819s: have the cause or relationship and not\n3004.44s: just those curious correlations\n3007.44s: why is that important is that what we\n3010.079s: found is that with the causal inform\n3011.76s: your network which is the red line here\n3013.38s: we're actually much closer to the truth\n3015.54s: in fact the R square across the entire\n3017.76s: profile so that's a an average profile\n3019.68s: in the atmosphere the course on your\n3021.66s: network does a better job than the Deep\n3023.4s: neural network that we had originally\n3025.319s: because we're really getting the cause\n3027.06s: and effects so on data that we haven't\n3029.16s: seen in the training Set uh in a new\n3032.339s: test set we can actually do a much\n3033.72s: better job by using this causally inform\n3036.0s: your network so it means in in a\n3038.04s: nutshell that this your network can\n3039.78s: extrapolate better so when it hasn't\n3041.7s: seen the conditions uh in the original\n3043.68s: training data it can do a better job\n3045.839s: because the links are cause and effect\n3047.52s: as opposed to being pure correlations\n3049.02s: right so you can you're actually much\n3051.059s: closer to the real physics and we\n3053.76s: believe that's kind of nice because it\n3054.9s: delegates many of the issues such as\n3056.52s: previous correlations that we had\n3058.079s: originally uh there's also way fewer\n3060.72s: instabilities because now you have real\n3062.579s: cause and effects right so as opposed to\n3064.559s: Serious correlations that could\n3065.88s: sometimes blow up uh and that were kind\n3068.28s: of uh uh not really under control and\n3071.52s: then same as what I was just mentioning\n3073.619s: before we are limiting kind of this out\n3075.359s: of sample uh prediction issues right\n3077.94s: because we're really building codes and\n3079.5s: effect so you don't have a lot of true\n3081.24s: escalation that could actually act funny\n3082.859s: you know in in in a data set or in a\n3085.319s: training in some some data that you\n3087.48s: haven't seen right or in some conditions\n3088.92s: you have nerves so that's We Believe\n3090.66s: kind of nice so that provide really a\n3092.579s: framework to actually have a much more\n3094.559s: like physically informed uh neural\n3097.2s: network and you can then also start\n3099.72s: looking at some interpretive or\n3101.64s: expendable AI tools so that you can\n3103.619s: start looking at what particular\n3105.78s: variable is actually causing one\n3109.14s: okay so quick conclusions uh before I\n3112.14s: just uh have a few slides to explain a\n3114.24s: couple of things uh so machine learning\n3116.4s: can do much more than emulating we\n3117.9s: believe these days now especially in in\n3119.76s: the climate science uh uh so we believe\n3122.22s: that we can actually learn new things uh\n3124.859s: we can actually discover new processes\n3126.48s: that were very difficult to actually get\n3128.52s: before so I showed you the example of\n3130.619s: aggregation that's something that was\n3132.54s: really\n3133.92s: um difficult to get and now we can show\n3135.78s: that we can optimally try to actually\n3137.7s: learn uh this process and the process of\n3140.52s: organization\n3141.599s: there's a lot of things to be learned\n3143.4s: from lower dimensional representation\n3144.839s: right because that's how you can start\n3146.579s: interpreting uh processes in particular\n3149.339s: so especially in tandem with physical\n3151.5s: constraints right so there's a lot that\n3153.3s: can be done there and I just wanted to\n3155.339s: raise a few what I believe interesting\n3157.2s: challenges uh just have a few slides\n3159.119s: here but I believe are interesting for\n3160.92s: the field\n3162.3s: so\n3163.619s: especially for the machine learning\n3165.0s: community so the type of work we are\n3167.22s: doing is actually quite interesting\n3168.42s: because and I showed you that couple of\n3170.16s: times we are struggling with\n3171.359s: extrapolation and generalization right\n3173.16s: we typically have some sampling data so\n3175.74s: some example would be climate change via\n3177.78s: data all the way up to today right but\n3180.3s: we are trying to extrapolate into the\n3181.98s: future right so that's definitely an\n3183.66s: extrapolation issue very unusual for a\n3186.78s: typical machine learning uh algorithm so\n3190.14s: we are dealing with net very\n3191.339s: non-stationary processes right so that\n3193.02s: can be an issue uh to use that\n3195.96s: we also have typically class\n3197.64s: observations right we want to know\n3199.079s: what's going on across the globe but we\n3201.18s: only have limited and we have a lot of\n3202.619s: data imbalance right in fact you could\n3205.079s: see a lot of the data is like in North\n3206.52s: America Europe and Southeast Asia\n3208.619s: there's a huge imbalance in many\n3210.24s: continents as well so the data imbalance\n3212.16s: and you could think about inequity as\n3214.079s: well there's a huge uh lens to that\n3216.24s: which is really lead to where funding is\n3218.339s: in terms of where we are acquiring data\n3220.619s: and the issue is that this is also\n3222.9s: biasing the way we approach things right\n3224.76s: it's biasing the way we are actually\n3226.2s: retrieving things because we always\n3227.579s: observe at the same places right so\n3229.38s: that's an issue in terms of our capacity\n3231.9s: to actually generalize our findings to\n3234.42s: the to the globe in terms of time and\n3236.339s: space as well\n3238.619s: the other issue that's a little bit uh\n3241.74s: unusual to some extent in the machine\n3244.079s: Learning Community is that we typically\n3245.88s: have very very noisy observations right\n3247.98s: so when we think of a satellite sensor\n3250.319s: this is an example of some sort of\n3251.579s: photosynthesis product here uh actually\n3253.8s: Rosine will know uh that's what we call\n3255.78s: solar induced fluorescence it's\n3257.4s: extremely nice even at a very very core\n3259.26s: scale okay and that's also pretty\n3261.359s: unusual in the machine learning\n3262.8s: community in the sense that the level of\n3264.359s: noise we're dealing with is very very\n3265.8s: high and the question is how can we\n3267.66s: actually use that at scale and typically\n3270.359s: we are not directly observing the\n3271.98s: process in fact I said photosynthesis\n3273.599s: but it's not directly photosynthesis\n3275.22s: it's a byproduct of photosynthesis\n3276.96s: observed from space so typically we only\n3279.599s: have indirect observation and not\n3281.22s: directly what we want right so we have\n3283.02s: what we call an observable in between so\n3284.76s: what we want is typically available say\n3286.859s: why and we observe something indirectly\n3288.96s: connected to that so it's not like in a\n3291.059s: typical computer vision exercise\n3292.38s: wherever you directly absorb the image\n3294.18s: in that case You observe something\n3295.44s: that's fairly related to an image and\n3297.72s: that happens to be very noisy and\n3299.819s: oftentimes bass paths as well we don't\n3301.98s: observe all the time uh everywhere all\n3304.319s: the time we just observe Sometimes some\n3306.72s: some locations right so we have a lot of\n3309.18s: viscosity as well in the data\n3313.02s: and that's very similar or connected to\n3315.599s: what we call data simulation in weather\n3317.16s: forecasting where people actually have\n3319.319s: different model simulations here and\n3321.42s: they do what they they do they they\n3323.52s: actually have um what they call it\n3325.859s: nonsense forecast so they run multiple\n3327.78s: on some member multiple simulations here\n3330.48s: and then they nudge them so during the\n3332.88s: data assimilation uh uh time when they\n3336.0s: have observation they nudge that to the\n3337.68s: observations to actually correct the\n3339.18s: trajectory right and they keep on doing\n3340.68s: that so that the weather forecast are\n3342.42s: actually so good and it's not not just\n3344.4s: because of the model it's because the\n3345.66s: model is corrected by the observations\n3347.64s: we can do that for climate right because\n3350.04s: we're always trying to predict the\n3351.24s: future ahead of time right so we don't\n3352.68s: have that luxury that they're having\n3353.819s: with our forecasting where they keep on\n3355.74s: nudging every time the the the\n3357.66s: trajectories and therefore they can\n3359.46s: actually do a pretty good a great job\n3362.04s: basically at predicting weather on a on\n3364.26s: a narrowly and daily time scale so we\n3366.78s: don't have that luxury and basically\n3368.22s: there's an opening there in terms of\n3370.079s: defining how we should actually do that\n3372.24s: at scale for climate because again we\n3374.579s: are trying to predict something we\n3376.079s: haven't seen so we are trying to predict\n3377.52s: the future so there's it's a it's a real\n3380.04s: open Avenue\n3382.88s: the third point is also about\n3385.079s: interoperability and physical intuition\n3386.819s: so there are some of that in the\n3388.44s: literature as well uh in fact that\n3390.42s: ourselves and we are really struggling\n3391.619s: with that what is the right approach to\n3393.0s: that and so that's something that's very\n3395.16s: important for the physicists here we\n3397.68s: really want to understand why we are\n3399.24s: making a particular choice what we\n3400.92s: really understood and they are still uh\n3403.2s: we are still at the early stage\n3404.46s: especially in machine learning in terms\n3405.72s: of interpretability especially when we\n3407.819s: start getting really really high\n3409.079s: dimension right but that's something\n3410.339s: that's really fundamental for the\n3412.319s: physicists in the room also to build\n3413.76s: trust in the algorithm because they will\n3416.28s: choose an algorithm if they trust it and\n3418.02s: they will trust it if they understand it\n3419.88s: so that's actually very important\n3422.64s: and another Point that's also very\n3424.98s: important that we typically uh occult\n3427.98s: when we use machine learning is we want\n3430.079s: to have uncertainty quantification right\n3431.76s: and the reason is that we want to know\n3434.46s: what is for instance I showed you the\n3435.96s: precipitation we want to know what is\n3437.22s: the stock at 60 what is random you know\n3439.14s: when I talk about specification or some\n3440.88s: other film and that uncertainty can come\n3444.72s: from many different things it can be\n3446.16s: just Randomness you know there can be\n3447.66s: some stochasticity in the process itself\n3450.24s: but it could also be that we have some\n3452.46s: observational errors right your sensor\n3454.44s: could have some observation error or\n3455.76s: you're observing from a satellite and\n3457.26s: therefore it's not exactly precise right\n3459.3s: and you could also have errors in the\n3461.52s: model structure what we call epistemic\n3463.2s: error so for instance the\n3464.28s: parametrization is just again an NSAIDs\n3466.619s: of the world right so it's not exactly\n3468.18s: perfect and so therefore we really need\n3470.64s: to have precise uncertain quantification\n3472.5s: we want to predict ahead of time but\n3474.48s: also we want to be sure I mean we want\n3476.819s: to really know what are the\n3478.079s: uncertainties in terms of the prediction\n3479.46s: we are giving and that's typically\n3481.2s: something we we don't we don't do so\n3482.94s: much in machine learning much more in\n3484.319s: statistics but that's something really\n3486.24s: really important in in climate science\n3490.02s: and kind of the last thing and that's\n3491.64s: kind of related to that is eventually\n3493.8s: what we would want is we would want to\n3495.359s: actually merge physics with ML I mean\n3496.98s: that's kind of the I hope the long-term\n3499.02s: objective especially for leap is that\n3500.76s: ideally what you would have is you would\n3502.74s: have some variable here that will evolve\n3505.14s: over time could be temperature or\n3506.819s: moisture and some part of that will be\n3509.28s: will be resolved by something where you\n3510.9s: know the physics quite well so it could\n3512.46s: be what we call attraction you know like\n3513.96s: how you're moving things around there\n3515.94s: may be some parameters here that are\n3517.5s: physically based but there may be some\n3519.48s: parts where we will say you know we are\n3520.859s: struggling with that so let's use some\n3522.48s: machine learning algorithm on your nets\n3524.4s: right and this machine learning\n3525.839s: algorithm will also have some parameters\n3527.52s: here right so let's go\n3529.76s: and eventually what we'll do is we'll\n3532.079s: have to actually merge that together and\n3534.299s: we basically have to learn in tandem the\n3536.28s: parameters of the physics and the\n3537.839s: partner of the machine learning\n3538.98s: algorithm right so there's a lot of\n3540.78s: things that can be done so there's this\n3542.339s: tool called automatic differentiation\n3544.079s: you can take the gradient of your codes\n3546.359s: and you can actually start thinking of\n3548.46s: physical parameters and machine learning\n3550.44s: panels the same way and that could be a\n3552.54s: way to a potentially Miracle Fields\n3553.98s: there's a lot of issues I spell you the\n3555.9s: details some people in microbiology\n3558.0s: struggling with that but there's a lot\n3559.98s: of issues related to how you can\n3561.18s: actually do that at scale but this is\n3562.98s: actually very important how can we\n3564.18s: actually merge physics and machine\n3565.44s: learning it seems that the two can\n3567.54s: actually be seen they can be approached\n3570.18s: the same way basically if we frame them\n3571.859s: the right way\n3574.2s: so I think that's also yeah and maybe\n3576.78s: there are some people from stats or\n3578.339s: machine learning please reach out you\n3579.78s: know uh happy to have you involved in\n3581.52s: leap and happy to take any questions\n3591.02s: are there any questions for Pierre\n3600.839s: I'm curious uh when you were doing the\n3604.68s: uh dropping the spurtis connections the\n3607.98s: causal did you ever see how well it\n3611.46s: extrapolated into the future using that\n3613.68s: kind of network yeah we did we did and\n3615.96s: it does a better job it's not quite\n3617.579s: there yet neither because the\n3618.9s: extrapolation is too big of a test so we\n3620.819s: can extrapolate\n3622.02s: for like a couple of degrees but not all\n3624.359s: the way because we were we had a an\n3627.119s: increase of four degree Kelvin so that\n3628.68s: was a lot but to some extent we are\n3631.26s: doing a better job up to some point and\n3632.94s: then you know it falls apart\n3635.4s: the second question I had you talked\n3637.799s: about supervised learning and\n3640.079s: um you also examine on supervised\n3641.819s: methods such as common filters yeah\n3646.859s: um so cabin filter so yeah we cannot\n3650.16s: talk about that here\n3651.96s: um\n3653.7s: so we are\n3655.819s: what will be the right answer for that\n3658.02s: uh\n3660.42s: so why can't we actually trying to think\n3662.4s: about that slightly in a slightly\n3664.319s: different way so common filtering is\n3665.76s: typically for initial condition but you\n3667.26s: could also have parameters as well what\n3669.66s: we are trying to do is uh and that's\n3671.46s: actually related to what I showed here\n3673.44s: is that we are trying to correct model\n3675.299s: structural errors as well so we are\n3676.98s: trying to see if there's a way to\n3678.24s: combine basically approaches that we\n3680.28s: have from data assimilation such as\n3681.96s: Kalman filter with maybe more uh machine\n3685.38s: learning based approaches so basically\n3687.119s: you could actually Target the initial\n3689.339s: condition issue the parameter uh from\n3691.799s: your physics so basically this here and\n3694.799s: also some of the the structural errors\n3696.96s: here on the right hand side so we are\n3698.04s: trying to see if we can bridge that\n3699.059s: actually is actually doing some of that\n3701.22s: work actually with colleagues that are\n3702.96s: very involved in the development of data\n3705.0s: simulation algorithms back in Europe but\n3707.88s: that's I think that's an open area\n3709.319s: that's actually very important like how\n3711.18s: can we actually do that and it's very\n3712.98s: different from what we typically do for\n3715.98s: typical gamma filtering which is for\n3717.599s: control theory because you have\n3718.799s: observations that come in and you really\n3720.72s: want to Target the initial conditions\n3722.22s: typically here and I don't think people\n3724.859s: really appreciate that but we don't know\n3726.48s: the initial condition so well so it's\n3728.16s: much more about correcting model\n3729.839s: structural errors you know so so I think\n3731.819s: that's why we need to reframe that a\n3733.38s: little bit\n3735.839s: what's how for me is to understand that\n3738.359s: like common filtering is a continuous\n3740.28s: version of hidden markup models right so\n3743.16s: you know when you think of a space of\n3745.38s: solutions you know to toggle between the\n3748.38s: continuous\n3749.819s: algorithm versus the street algorithm\n3752.04s: that helps kind of frame the space right\n3755.94s: here\n3758.46s: I agree\n3763.319s: hi um I was wondering when you were\n3765.599s: talking about predicting the\n3768.0s: organization based um latent space via\n3771.359s: memory have you guys thought at all\n3773.28s: about how you would adapt that memory I\n3775.98s: think you said that you carried over the\n3778.26s: Korean space yeah so\n3780.9s: um so what we what we can show is that\n3783.24s: this\n3784.38s: um in fact it's very simple it's just uh\n3786.42s: at first we had the most sophisticated\n3788.46s: so we started very complex so we said oh\n3790.2s: let's try with the netstm and then I had\n3792.42s: quite a bit of pushback on that because\n3793.799s: the netstm buys like a long memory and\n3796.38s: that's kind of annoying to have\n3797.46s: Entertainment also we just included a\n3799.2s: few time steps in a non-linear fashion\n3801.42s: so that basically a non it was a neural\n3803.4s: network of the previous time steps plus\n3805.619s: the large scale and now what we have is\n3808.26s: just not a regressive model so it's just\n3810.18s: a linear model that depends on the large\n3812.16s: scale and the previous time steps of the\n3814.38s: organization and you can carry that\n3816.599s: thought in Space by just carrying\n3818.7s: forward the through the advection of the\n3820.68s: love scale so that's the advantage the\n3822.599s: advantage right the last scale\n3823.92s: temperature and moisture is moving\n3825.96s: across through the adduction and then\n3827.64s: you can carry that forward in time right\n3830.64s: so it's actually actually surprisingly\n3832.799s: simple\n3834.839s: in fact it's not too far people do some\n3836.88s: of that for Gravity waves they also have\n3839.04s: this sort of regressive model they so\n3840.839s: that's something that's been done\n3841.92s: actually\n3843.54s: and very practical\n3854.72s: thanks Brianna was worked as always\n3858.119s: um good question on Sarah's work\n3860.099s: um also as well kind of following up on\n3861.599s: the latent space so you showed that the\n3863.76s: first right so the First Dimension seems\n3865.859s: to collapse onto kind of you know\n3868.079s: average quantity when you're able to\n3870.0s: maybe like you know do it as a residual\n3872.28s: we remove the first and then you try to\n3874.98s: yeah so yeah that's a great point so\n3877.38s: that's actually what we have now so\n3879.24s: that's why I said this is the old\n3880.26s: version so that's what we did now and\n3881.76s: it's much cleaner actually so we removed\n3884.4s: the love scale component we should\n3886.44s: remove all of that and then we're only\n3887.819s: working on the residual which is really\n3889.38s: which really truly the separate scale\n3891.059s: exactly yeah so that's why it's an\n3892.619s: update version I should have updated\n3893.88s: that yeah you're right and then you can\n3895.44s: actually see it's much nicer you can see\n3896.94s: like a really nice disc in the middle\n3898.98s: and then you can see the disc expanding\n3901.2s: and then diffusing out and taking those\n3903.18s: basically it's actually much cleaner I\n3904.559s: should have taken that sorry about that\n3913.5s: foreign\n3919.099s: I from a non-scientific perspective you\n3923.099s: talk about how this\n3925.38s: um machine learning and climate modeling\n3927.9s: will be better will be more helpful for\n3931.38s: policy makers and how policy\n3933.44s: implications can you share a little bit\n3935.88s: more how you are or how you will plan to\n3938.94s: get this information into the hands of\n3940.859s: the policy makers and when you think\n3943.26s: you'll be able to do that well that's uh\n3946.319s: the ultimate question\n3948.18s: um I would say that's a file I mean\n3950.579s: that's going to be a long-term goal\n3951.9s: right I mean it's not going to happen\n3952.98s: overnight but what we hope is that\n3955.5s: machine learning is going to improve\n3957.24s: just to get back to the to the initial\n3959.099s: uh motivation is that a lot of the\n3962.04s: issues we have are related to those\n3963.839s: small small-scale processes right so\n3965.94s: that's why we hope that machine learning\n3967.319s: could actually help with is actually\n3968.76s: representing those things better so for\n3970.559s: instance law and our group have been\n3972.24s: working a lot on Ocean Edis they can\n3973.619s: show quite a bit of success here it\n3975.599s: seems we can do a decent job here for\n3977.4s: cloud so maybe and actually in my group\n3979.68s: we are working also quite a bit on\n3980.94s: photosynthesis we think we can actually\n3982.44s: do a much better job at several of those\n3984.66s: things\n3985.619s: now getting all the way to policy makers\n3988.14s: you know it will take some times you\n3989.46s: know it will uh\n3990.98s: if 10 years would be a great great uh\n3995.339s: Advance you know but I think it will\n3997.14s: take a long time you know when one thing\n3999.299s: we are discussing is that the other\n4001.339s: thing is how machine learning can help\n4002.72s: like also digesting information you know\n4005.0s: so taking the information from climate\n4008.26s: climate models like digesting that\n4010.7s: processing that to the to give that to\n4012.74s: the to the public or to the private\n4014.66s: sector as well I think for quite some\n4017.48s: time that's where the edge is going to\n4019.22s: be right with the data processing and\n4021.5s: data tools uh there's a lot to be done\n4023.96s: there like we have a lot of climate data\n4025.64s: we and that's a lot of what we are\n4027.38s: trying to do in the center as well is\n4028.76s: how do we provide that data at scale to\n4030.74s: the public right so that they can\n4032.0s: actually use that even if it's still\n4033.38s: uncertain at least they have that right\n4035.119s: and we can actually provide some\n4036.92s: uncertainty quantification like right\n4038.66s: what what we have and the different at\n4041.059s: least the range of the different models\n4042.5s: so I think I think for the next couple\n4044.66s: of years most of the impact will be\n4046.579s: there I'm pretty confident you know and\n4048.26s: then we hope that we will improve the\n4049.819s: climate models in the meantime but it's\n4052.52s: not happening often in fact I had that\n4054.92s: here I mean it's already been more than\n4056.96s: 40 years that we've been struggling with\n4058.579s: that actually back here early 80s right\n4060.859s: so yeah it's uh it's difficult\n4065.2s: yeah all right so there's a good\n4067.28s: question about the cost of discoveries\n4069.619s: um what was a little bit uncluded was\n4071.78s: that what are the variables that are\n4073.7s: being input to the causal Discovery\n4075.92s: algorithm because it seems like you were\n4077.299s: saying that you could use that too yeah\n4079.599s: Network or make it sparse yeah so we use\n4083.119s: the same as here so we use a temperature\n4085.46s: at different levels moisture at\n4087.619s: different levels so we uh uh velocity at\n4091.819s: different levels and then flux is at the\n4094.46s: bottom so evaporation and then sensible\n4096.38s: in fact which is the heating at the\n4098.0s: bottom and then what we do is we try to\n4099.98s: predict the rate of change of\n4101.96s: temperature that uh at those levels but\n4104.6s: it can actually be also impacted by\n4106.16s: lower levels or higher levels same\n4108.14s: formulation it could be impacting by\n4109.64s: lower levels or higher levels and that's\n4112.1s: radiation at the top and precipitation\n4113.779s: so those are the things we want to\n4115.1s: predict and instead of connecting\n4117.08s: everything to everything so basically\n4118.46s: every level here of the atmosphere is\n4121.819s: trying to predict that right he's trying\n4123.739s: to predict one particular level called\n4125.299s: one moisture moistening or heating rate\n4128.179s: at a particular level we are saying in\n4130.219s: fact it doesn't depend on everything it\n4131.6s: depends just on specific levels or it\n4134.48s: just depends on specific variables maybe\n4136.699s: moisture is really important to explain\n4138.62s: temperature which is actually the case\n4140.199s: oh temperature is actually only\n4142.58s: important for temperature but not for\n4144.08s: moisture so that's something we can\n4145.699s: actually and that varies uh in the\n4148.279s: vertical as well so basically what we\n4150.319s: have at the end is we have a map that\n4152.66s: shows you you could think of that like a\n4154.279s: heat map that says okay those variables\n4156.38s: we can use those we don't use uh those\n4159.02s: levels we can use those we should not\n4160.88s: use you know and then we use that as a\n4162.799s: way to\n4163.759s: but when you construct a neural network\n4165.38s: after that it's like made up of sub\n4167.66s: networks basically that yes exactly yeah\n4170.719s: exactly so we have then that's a great\n4173.06s: one so that's why I call that single\n4174.56s: neural network in the Middle where we\n4175.94s: are connecting one particular levels\n4177.5s: based on this causal graph to that\n4179.719s: particular prediction so each prediction\n4181.46s: here\n4182.6s: as a particular neural network so they\n4185.839s: are you could say they are independent I\n4187.819s: mean they are just causally builds yeah\n4189.199s: that's a great point\n4191.719s: you know back to the question about\n4193.58s: policy makers and I imagine that your\n4196.46s: answer to this might change depending on\n4198.08s: the the process that you're examining on\n4199.82s: the technique that you're using but what\n4201.14s: is the the threshold for we think this\n4204.14s: is good enough to start communicating to\n4207.46s: policy makers\n4209.84s: um\n4210.56s: and I'm thinking in particular about\n4212.48s: situations of you know data poor\n4214.88s: conditions sparse data where it feels\n4216.98s: like anything you find will be more\n4219.8s: given the techniques that you're using\n4221.48s: will be better than what they have right\n4223.94s: now right or what we understand given\n4225.62s: those uh those data poor conditions\n4227.84s: right now so right do you have a\n4229.46s: threshold in mind in terms of does it\n4231.8s: have to be yeah what's good enough to\n4234.44s: start communicating to policy makers and\n4236.96s: perhaps it's an ongoing\n4239.06s: we're giving you this information now\n4241.1s: with the understanding that there's\n4243.26s: still a lot of uncertainty and we'd like\n4245.9s: to keep communicating with you as we\n4247.64s: start to learn more and I'm wondering\n4249.62s: how you from the scientific perspective\n4251.42s: think about that so the way um that's a\n4254.0s: great question you know uh the way I'm\n4255.739s: approaching that is more\n4257.84s: from a what is the question uh\n4261.14s: perspective you know uh and typically\n4263.9s: talking to various uh people you know\n4266.179s: like for instance actually we are\n4268.1s: talking yesterday with the the the\n4269.659s: potential future Olympic Games right you\n4272.719s: want to know it's not covers say in the\n4274.699s: in the western U.S right so that's\n4276.98s: that's the goal right so what do you\n4278.9s: need to know right you need to know\n4279.98s: what's going to be climate variability\n4281.719s: like in the future you need to know\n4283.1s: snowpack in the future so those are the\n4285.32s: different processes that you need to get\n4286.82s: right right\n4288.56s: um is that but I don't think there's a\n4290.12s: one feet tall type perspective you know\n4291.739s: another example is here we are\n4293.719s: developing uh as part of a community\n4295.4s: effort we are trying to develop uh uh\n4298.52s: basically a carbon emission map so\n4301.28s: there's like emission from people of\n4302.9s: course but there's also like carbon\n4304.699s: uptake from Land carbon uptake from the\n4306.38s: ocean and you need to have a mapping of\n4307.699s: that that's evolving all the time we we\n4310.88s: feel comfortable once we believe we have\n4313.34s: achieved some level of success at\n4315.38s: actually being able to reproduce pretty\n4317.42s: much data anywhere even when wherever\n4320.36s: it's passed you know so that we can\n4321.679s: actually provide that but that's also\n4323.42s: where it's important to have decent\n4324.8s: scientific qualifications that people\n4326.0s: can say we can take that information but\n4328.52s: we know how important that is yeah so\n4330.38s: but I would say to me it's very tailored\n4333.44s: to the question or the the other one\n4335.0s: would be you want to look at\n4336.62s: precipitation do you want to look at\n4338.06s: Extremes in precipitation you know so if\n4340.34s: you want to look at Extremes in\n4341.6s: precipitation you want to get that part\n4343.4s: of the distribution correct you know and\n4345.08s: so if you have a model that's like that\n4347.12s: I mean it does just cannot answer the\n4349.04s: question\n4350.48s: foreign\n4353.96s: participants\n4360.86s: uh yeah hi\n4362.54s: um I was just curious about this\n4364.219s: organization neural network\n4366.32s: um I was wondering how the latent\n4367.88s: variables and obtained when the\n4370.58s: parameterization is like embedded in a\n4372.26s: climate model\n4373.46s: so it seems to like embed some high\n4375.62s: resolution field but what do you do in\n4377.9s: the climate model when you don't have\n4379.34s: the high resolution field\n4381.38s: yeah uh great question so that's what I\n4384.02s: meant here that uh you could say we are\n4386.42s: cheating right because we have the\n4387.62s: higher resolution field to Define that\n4389.36s: organization but that's what I try to\n4391.4s: explain here so is that the first option\n4394.64s: that we had was trying to explain the\n4396.199s: latent space just unavailable called\n4398.06s: scale variables right and it didn't work\n4400.179s: uh and then the second option that we\n4402.98s: had was we said maybe that latent space\n4405.08s: is a memory process so what we can do is\n4407.239s: just representing that memory and that's\n4409.46s: how we Define that so basically the\n4410.9s: array there's a a Time rate of change of\n4413.659s: that latent space and then we can carry\n4415.46s: that forward in time by including so\n4417.679s: basically if you if you will the\n4420.02s: organization depends on the previous\n4421.34s: time steps or four different times\n4423.26s: previous time steps and the large scale\n4425.6s: and we can actually build a model for\n4427.28s: that and that's something that's totally\n4428.98s: implementable in our climate model if\n4431.12s: that makes sense\n4432.739s: yep that makes sense thank you thanks"
    },
    {
        "class": "YouTubeVideo",
        "title": "Adventures in Physics-AI Climate Modeling and Full AI Weather Prediction with Mike Pritchard",
        "videoId": "VMM1adoxFOU",
        "url": "https://www.youtube.com/watch?v=VMM1adoxFOU",
        "publishedAt": "2023-05-19T15:08:05Z",
        "transcript": "4.04s: let's get started everyone so we have a\n6.6s: good crowd I'm surprised at the end of\n8.7s: the semester I was uh thinking that\n10.679s: people would be uh Vanishing and\n12.24s: disappearing uh so it's a great pleasure\n14.639s: to have our way on my picture this is\n17.16s: actually part of the leap Center\n19.38s: uh long story short so you guys industry\n21.72s: professor at you sir van actually only\n23.699s: part of the time and became last year\n26.039s: actually we are discussing that last\n27.9s: June actually he moved to Nvidia as well\n30.779s: so 80 of the time right now where is\n33.6s: director of Planet simulation research\n35.399s: and he's been going to be talking about\n37.739s: that uh so Mike studied at UCSD and he\n42.42s: told me the funny story that uh at the\n44.34s: time he was about to start his PhD in\n46.379s: Toronto and then someone told me told\n48.18s: him you know what you can actually learn\n49.5s: the exact same equations with just by\n51.42s: the beach in San Diego so that's how\n54.42s: everything started uh and then we met\n57.66s: like randomly at the doe meeting uh\n60.6s: previewing some proposals starting to\n62.34s: talk about clothes and things and uh I\n65.28s: remember at Christmas time I was getting\n66.78s: really frustrated with the convective\n68.7s: pronunciation I said and I called Max\n70.56s: said you know what maybe we can do\n72.119s: better you know using machine learning\n73.799s: and that's how we we can kind of\n75.78s: partners in crime uh uh on in that area\n78.36s: and since then he's been doing it\n83.64s: I don't know\n88.86s: oh really no no not this one either\n94.68s: okay\n98.54s: I'll be quick anyways so yeah so it's a\n101.939s: great pleasure to have Mike today and\n103.38s: he's going to be telling us about the\n104.939s: all of the exciting uh things going on\n107.04s: in his group and also in Nvidia there's\n108.659s: a lot going on right there so great to\n110.52s: have you here thank you\n115.259s: thanks Vera that was super sweet\n117.24s: um yeah that was a life-changing email\n120.119s: um\n121.079s: yeah so thanks so much thanks so much\n122.7s: for coming um\n124.2s: I'm going to let's see\n128.039s: learn how to advance my slides uh\n130.58s: there's this work\n136.8s: hey there we go okay yeah so um I want\n139.56s: to acknowledge my conflict of interest\n140.64s: kind of wearing two hats right now um\n142.68s: we'll divide it up cleanly um despite\n144.9s: the Nvidia slides first part is going to\n147.18s: be all about leap and UCI\n150.48s: um and then I'll spend maybe 10 minutes\n152.16s: at the end talking about Nvidia stuff\n153.72s: but I especially want to talk about the\n155.819s: work that we're doing because of leap\n157.319s: that's been enabled by leap here\n160.62s: um so so let's jump right in there so a\n163.68s: bit about me\n165.3s: um I've been interested in two things I\n167.099s: kind of have attention here throughout\n168.48s: my academic career I think Global\n170.34s: Climate Dynamics are beautiful\n172.26s: um the for their own sake planetary\n174.239s: fluid dynamics you know these questions\n175.5s: about how will Cloud patterns reorganize\n178.56s: as the planet warms over the remote\n180.18s: Ocean or beautiful on the one hand but\n182.58s: they're also really important to us as\n183.959s: people half of me is just as concerned\n185.879s: with that but what's going to happen for\n187.739s: my kids how the water cycle is going to\n189.599s: change in the future you know the\n192.18s: multiple geographic regions that may be\n194.28s: stressed with water hazard and\n195.659s: geopolitical migrations Etc\n198.06s: um so yeah I found both of those\n200.04s: interests tend to coincide around these\n202.44s: computational issues of confronting\n203.879s: turbulence with computers people live in\n205.62s: a turbulent boundary layer the water\n207.599s: cycle Dynamics are highly turbulent\n209.4s: turbulence is under resolving climate\n211.2s: models\n212.28s: um and and yeah I guess this um\n215.22s: yeah this this lack of explicit\n217.26s: subclimator physics and climate models\n219.3s: today is something that should keep us\n221.4s: up at night or at least as worried me\n223.44s: for a long time and because of that I I\n226.14s: really like to explore big super\n227.819s: computers we live in such I'm from\n229.5s: Canada originally and I came down here\n231.06s: and discovered the scale of U.S cyber\n233.159s: infrastructure and it's just amazing but\n235.56s: it still is not enough climate\n237.9s: scientists bring super computers to\n239.4s: their knees and because the phenomena is\n241.56s: an audacious task the phenomena's been\n243.54s: eight to ten orders of magnitude and\n245.459s: time that matter and you're just not\n246.54s: going to simulate at all all the stuff\n248.459s: that matters\n249.54s: um\n251.04s: okay so oh sorry that didn't come\n253.56s: through\n254.22s: um yeah in Academia I've mostly tried to\n256.979s: cope with a particular algorithm that I\n258.72s: want to tell you a bit about because\n259.68s: it's going to inform most of the first\n261.06s: half of this talk which is called MMF\n263.22s: the multi-scale modeling framework it's\n265.74s: one of many ways to cope with not enough\n267.66s: resolution in climate models some people\n270.06s: embed high resolution over their country\n272.34s: as a coping mechanism that's nice\n274.56s: because it's got lots of geographic\n276.0s: detail about your mountains Etc but it's\n278.16s: not Global\n279.78s: um super parametrization which is also\n281.699s: called multi-scale modeling framework\n283.759s: decides to embed small samples of\n286.86s: explicit convection within each grid\n289.44s: cell of a conventional planetary model\n291.36s: so imagine like 10 000 micro models Each\n295.32s: of which is subcycling with a really\n297.0s: fast time step and making explicit\n298.919s: clouds and convection living within a\n301.32s: predictor corrector relationship with a\n303.78s: large-scale model that knows nothing\n305.1s: about convection\n306.54s: and the way the system works is that the\n308.759s: planetary model chugs along in time\n310.5s: updates its state Vector so you get a\n312.9s: new temperature profile a new moisture\n315.06s: profile but it didn't know about\n316.56s: convection the micro model feels that\n319.02s: tendency but convex in response to it it\n321.06s: goes somewhere different\n322.32s: and because the convection is all\n325.32s: localized and periodic it turns out that\n327.72s: this approach has allowed for really\n329.699s: convenient arteries for machine learning\n331.919s: because there's very clean scale\n334.259s: separation in the way this strange\n336.539s: coping mechanism has been designed\n339.3s: um so\n340.919s: um so yeah that's the MMF and and that's\n344.759s: been my playground for 10 or 15 years my\n347.82s: area of expertise and it's also what\n350.22s: okay can I remove this thing somehow\n352.639s: okay let's see uh\n357.72s: uh so it's also been my journey to\n359.1s: artificial intelligence\n360.9s: um it's learning the arteries of that\n363.0s: scale interaction\n365.16s: so that's using deep learning you know\n366.84s: which is just\n368.4s: you know better than human software that\n370.199s: can learn from many examples of data\n373.08s: um to produce remarkable mappings\n376.4s: that is powered by gpus it's like\n379.62s: regression multi-dimensional High\n381.6s: dimensional regression so deep learning\n383.28s: is just you know uh find F given X and Y\n385.979s: so the the X the inputs can be very high\n388.02s: dimensional in my case those inputs are\n390.18s: going to be that large-scale model that\n392.46s: didn't know about convection at some\n394.259s: location in space what's the temperature\n396.18s: vertical structure what's the moisture\n397.86s: vertical structure what's the incoming\n399.539s: sunlight what are the incoming Heat\n401.039s: fluxes and the outputs will be what did\n404.039s: convection do in response how did the\n406.44s: moisture change how did the temperature\n407.639s: change how did convection vertically\n409.5s: distribute redistribute mass and\n411.419s: moisture and uh and how did radiation\n413.759s: interact with that to result in a new\n415.86s: temperature profile okay so do we get\n417.479s: the ideas one dimensional\n419.34s: temperature and moisture in heating out\n422.28s: moistening out\n423.68s: that's the mapping I'll be concerned\n425.819s: with\n427.08s: um so of course you know we're all\n428.699s: blessed with the fact like Manna From\n430.259s: Heaven that we have GPU accelerated\n432.36s: beautifully engineered software Stacks\n435.24s: now to do to do this sort of mapping um\n438.0s: it's all powered by gpus so it's fun to\n440.52s: work at a company that makes gpus now\n442.919s: um\n444.44s: I remember just anecdotally my student\n448.02s: Griffin Moore is five years ago bought\n449.759s: him a brand new Macbook and he started\n451.199s: to do one of these problems and he\n452.699s: started consuming power faster than the\n454.68s: supply could deliver it when he hit dot\n456.66s: train because it was trying to explore\n458.16s: all the available hardware and then we\n460.08s: plugged into GPU and things got better\n462.539s: um okay but yeah this gets back to\n463.86s: Pierre's comment about this email that\n465.599s: kind of changed my life um you know when\n468.18s: in 2017 it was like I think we can do\n470.22s: better with convection parameterization\n472.259s: with machine learning and um and we\n475.02s: realized that we could use this\n476.819s: multi-scale modeling approach\n479.039s: um to to try to test this idea we could\n481.319s: take a simple test bed remove some\n483.419s: complexity no continents no Seasons keep\n485.819s: it kind of simple but keep a lot of\n487.68s: complexity really stochastic physics\n489.96s: convection radiation microphysics fluxes\n493.139s: and create a beautiful training data set\n495.539s: hundreds of millions of double Precision\n497.34s: samples input output Pairs and then ask\n500.4s: ourselves could these you know crude\n501.84s: sheets of dumb digital neurons learn\n503.699s: that essential physics of the pdes\n506.22s: inside these micro models\n508.44s: um that was the exercise and at first\n510.84s: very skeptical writing you should be\n512.099s: skeptical because it's just curve\n513.539s: fitting on steroids and anyone that's\n514.979s: tried to fit a curve you know should\n517.74s: know that oh that animation doesn't work\n519.599s: darn it you know extrapolation's a\n521.52s: problem pure fitting is imperfect\n523.5s: um but this was the first result offline\n525.48s: so from that training data set that that\n528.06s: shook me a bit\n529.92s: um this paper that Pierre LED in 2018\n531.779s: and what you're looking at here is as we\n533.76s: go up in the atmosphere from the South\n535.14s: Pole to the North Pole these blue\n536.94s: regions are where that fit was good\n539.399s: enough that it was explaining more than\n540.72s: 80 percent of the variance of the actual\n543.0s: data and and those are not uh those are\n545.459s: important regions because this is the\n547.14s: middle of the troposphere in the\n548.519s: intertropical Convergence Zone where\n550.38s: convection couples to the planetary\n552.0s: circulation and in the middle of the\n553.5s: storm tracks in the mid-latitudes where\n555.54s: that skill is important as well so\n557.04s: there's clearly regions where it's not\n558.18s: working but but it was starting to work\n559.98s: in those regions and that that got me\n561.54s: interested\n564.12s: and then this amazing guy stepping Ross\n566.82s: came to UCI for a summer and Karen and I\n568.8s: co-advised him on this and it was um we\n571.2s: worked for a long time and he uh you\n573.779s: know he he went deep and aggressive on\n576.3s: the Deep learning and eventually we got\n578.1s: this result this is more important\n579.42s: because this is taking that that fit\n582.6s: that was achieved with data and then\n584.82s: taking the learn machine learning model\n586.5s: and actually implanting it inside the\n589.2s: climate model so ripping out the the\n592.14s: actual micro models and replacing them\n594.36s: with 10 000 instances of the machine\n596.1s: learned model and then asking the sys\n598.44s: the coupled system to chug along and so\n600.779s: despite the imperfections of the fit can\n603.18s: the skill interactions this time with\n604.92s: the the microscale being handled by pure\n606.899s: AI hang together a simulation and so so\n610.2s: to to ask ourselves if it works we look\n612.0s: at pictures like this this is a 2d\n613.92s: space-time Fourier transform that\n615.6s: summarizes the variability of the\n617.16s: tropical atmosphere and there's patterns\n619.26s: here that we look for called dispersion\n620.82s: relationships like this that represent\n622.92s: the aggregate effect of a particular\n624.48s: type of motion that's coupled to\n625.98s: convection called equatorial Kelvin\n627.899s: waves and this is something called the\n629.519s: Madden Julian oscillation it's just a\n630.899s: nice rich summary figure of how they\n633.24s: convectively coupled atmosphere is\n634.56s: supposed to behave if convection is is\n636.839s: realistic and this is non-super\n639.3s: climatized models that look unrealistic\n640.68s: and so anyway this the maps between\n642.42s: these two figures was the thing that\n643.74s: really struck me was like wow this can\n645.18s: work to the point that we can hang\n646.32s: together a multi-year simulation and get\n649.079s: reasonable Dynamics and now I'm really\n650.7s: interested\n653.579s: um there are still existential questions\n655.079s: like can you conserve mass and energy to\n657.18s: meticulous Precision you must if you're\n658.8s: going to be a climate scientist and then\n660.6s: this other brilliant Guy Tom be clear\n662.64s: that Tom and or that pier and I\n664.44s: co-advised them\n666.36s: um came up with a way to just make it\n668.279s: make it so that the Deep learning could\n669.779s: never hallucinate a scenario that that\n671.7s: didn't conserve mass and energy just by\n673.5s: mucking with the architecture to make it\n675.12s: so\n676.38s: um there's quite a general method but um\n678.6s: yeah it had remarkably little effect on\n680.82s: the optimization skill which surprised\n682.56s: me I thought maybe it would help but in\n683.76s: hindsight there's not very many degrees\n685.38s: of freedom of constraints maybe four\n687.779s: despite the brothers of a large degree\n689.64s: of Freedom maybe 100 scalers in the in\n691.68s: the input and output space\n693.779s: um\n695.519s: and now this brings me to the main\n697.62s: purpose of today which is uh the current\n699.899s: Frontier that we're working on with leap\n701.64s: which is controlling the prognostic\n703.68s: error so I told you a nice story but\n705.6s: it's been a very difficult to reproduce\n707.22s: story\n708.48s: um and so we got lucky I think in rasp\n711.12s: it out and you know even minor\n714.48s: variations on the theme like making the\n716.459s: embedded Cloud resolving models a little\n718.019s: bit bigger\n718.98s: we can never get it to work and\n722.22s: um\n722.82s: and we're adding geography you could\n724.86s: never get it to work more often than not\n726.54s: what we see is this is that for\n728.64s: inexplicable reasons and inexplicable\n730.56s: places our simulations blow up\n732.12s: spectacularly when we rely on these\n734.459s: emulated physics in the subgrid so\n736.56s: hybrid AI physics climate simulation is\n739.92s: really challenging\n743.279s: okay so that brings me to the thing I\n745.26s: was most excited to work about on you\n748.019s: know when when leap started and so I\n751.38s: want to tell you a story about Jerry and\n752.7s: sunduck's work\n755.22s: um\n755.88s: so the the big question is\n758.459s: how do the decisions we make in the\n760.86s: formulation of our inputs and outputs\n762.54s: and in the formulation of our machine\n764.22s: learning architectures effect is\n766.86s: Downstream signal that we ultimately\n768.54s: care about the coupled hybrid error\n771.42s: um and the problem I think right now is\n773.639s: that that signal is not well sampled at\n776.399s: all in the literature so there's a lot\n778.2s: of people saying what they think matters\n779.7s: very little sampling to convince you\n783.06s: um\n784.74s: and it's just a logistics problem\n787.079s: um it's a technical problem you think\n789.06s: about what it takes to run a climate\n790.8s: model it's a lot of work and it's\n792.899s: unglamorous work of the sort that\n794.519s: doesn't normally get you the line items\n795.959s: on your CV that Academia rewards and so\n798.3s: I think it's logical there's not a lot\n799.62s: of it logging into HPC systems dealing\n802.68s: with cues doing hyper parameter tuning\n805.079s: on a GPU cluster it's sufficient scale\n806.76s: to get a large set of architectures\n808.26s: linking all those architectures that are\n810.36s: in Python world to your Fortran climate\n812.16s: model doing the Integrations on the CPU\n814.68s: partition of the cluster managing all\n816.72s: the output deriving the statistics all\n819.12s: this context switching between different\n820.56s: types of workflows you add it up and\n822.959s: then you've got to rinse and repeat\n823.8s: every time you want to try a new design\n825.3s: decision or a new mlr architecture\n828.0s: decision and and of course there's not\n830.04s: going to be much of this type of work\n831.3s: it's really janky um\n834.3s: you know\n837.0s: so that was the problem we wanted to\n839.22s: lean into\n840.42s: um with a bit of sustained funding that\n842.519s: could enable it um and yeah so I want to\n845.82s: tell you about a new end-to-end pipeline\n847.38s: enabled by by this this leap project so\n850.62s: industrial scale auto training to Auto\n852.54s: testing and yeah this is fully the work\n854.88s: of Jerry Lynn Lead fund and PhD student\n857.16s: and sun.view project scientist who's\n859.74s: co-mentoring him\n861.42s: um\n862.92s: and the work tries to combine five tools\n865.86s: that have emerged from Pair in mind\n867.72s: others work on this this problem\n870.36s: um over the past three years I'll tell\n871.86s: you about each of the elements the first\n873.899s: is that test bed I mentioned in the\n875.639s: beginning that's intentionally kind of\n877.44s: simple no continents no seasons on the\n880.5s: on the physical side and kind of simple\n882.18s: on the ml side intentionally just MLP\n884.94s: models simple ones 2018 machine learning\n887.88s: no Transformers nothing else\n890.699s: um\n892.74s: the second is a a prototype Auto tuning\n896.04s: Paradigm from a paper in 2021 by Jordan\n898.139s: Knox computer science student at UCI\n900.199s: with Pierre Baldi who worked with us for\n902.699s: some time\n903.86s: and this summarizes some some work he\n906.36s: did beginning in this direction where he\n907.86s: was at least making you know 50 to 100\n910.139s: prognostic tests involving 50 to 100\n912.959s: separate candidate neural networks and\n914.94s: so each of these lines tells you the\n917.1s: error worse is up of a prognostic test\n920.399s: that um and some of them are terrible\n922.68s: it's a log scale it's you know 100\n924.24s: Kelvin mean tropospheric temperature\n925.8s: error is stable it can hang together a\n928.86s: very bizarre state for a year but\n930.899s: stability is not the metric uh error is\n933.139s: so you know reassuringly your offline\n936.42s: fits the better you get in the bluest\n938.1s: colors maybe it's not a coincidence that\n940.26s: the best prognostic errors or the\n942.18s: deepest blue\n943.62s: um so uh but but yeah but clearly\n945.779s: there's a lot of spread here there's a\n947.1s: lot of variability there's a lot of\n948.36s: stuff worth sampling\n951.24s: but but these I think these error\n953.1s: metrics that we converged on in this\n954.42s: paper were a helpful tool\n956.94s: um\n957.66s: the other thing is then an extension of\n959.76s: that auto tuning Paradigm that emerged\n961.56s: in the last uh uh couple years and here\n964.139s: I want to emphasize that U.S cyber\n966.24s: infrastructure again so hopefully you\n967.68s: all know that through the NSF especially\n970.079s: as part of an NSF funded Science and\n971.76s: Technology Center you can apply to get\n975.0s: access to a dozen or so supercomputers\n977.699s: around the country with no Grant and\n979.74s: very little overhead\n981.48s: um including like lots of gpus on this\n983.88s: Pittsburgh super computer center and you\n985.5s: can also apply if you need it for\n987.3s: in-kind software engineering support if\n988.86s: you have a task you don't know how to\n990.06s: solve and so we did that because we\n991.92s: didn't know how to get this Auto tuning\n993.6s: to play nice and really scale on the on\n996.24s: the nation's computers but we got a\n998.399s: quarter of this guy's time for a year\n999.839s: and he helped us figure out how to do it\n1001.22s: and and sunduck wrote a paper that you\n1003.56s: can read about where he's trying to he\n1005.3s: explains how to do it if you're\n1006.38s: interested in and applied it to a\n1008.0s: microphysics aerosol emulation problem\n1010.16s: but um but that's another tool we can\n1012.259s: take advantage of\n1013.699s: and then the other one was another\n1015.32s: really simple crude tool to deal with\n1017.3s: the python to Fortran interface um it's\n1020.0s: got limitations it can only work with\n1021.5s: simple MLP models but it's easy enough\n1023.66s: and lightweight enough that it's uh you\n1025.699s: know a good way to to solve the coupling\n1027.679s: problem called the Fortran Karis Bridge\n1031.459s: yeah and then finally a lot of elbow\n1033.74s: grease and hard work by Jerry who's been\n1035.78s: very patient and willing to engage in uh\n1038.72s: slow high performance Computing training\n1040.88s: and building all the kinds of bashing\n1042.559s: unit scripts you need to actually\n1043.88s: automate and pipeline these tools and\n1045.86s: Link them together\n1047.099s: [Music]\n1047.48s: um\n1049.82s: so I want to acknowledge that work but\n1051.44s: put together I'm really excited about\n1052.88s: what we have now so it's like a push\n1054.32s: button tool that will launch hundreds of\n1056.24s: trainings and testings and you can\n1058.039s: actually test ml design hypotheses at\n1060.5s: some statistical depth so the way it\n1062.78s: works is you have a first phase of\n1064.52s: automated hyper parameter tuning that\n1065.9s: you launch on the GPU partition it works\n1067.7s: its way through the queue you get\n1069.14s: hundreds of machine learning model\n1070.82s: candidates and then there's a little\n1072.86s: script to automatically link each of\n1074.419s: those to hundreds of separate prognostic\n1076.28s: runs that are handled on a CPU partition\n1078.02s: and auto Harvest all the resulting\n1079.88s: statistics and and Jerry's gradually\n1082.94s: honed and automated this to the point\n1084.32s: where he can now turn around and\n1085.82s: experiment in about four days including\n1087.32s: the Q latency which is which is great\n1091.4s: so all right let's get to some results\n1095.66s: so let me spend a bit of time on this\n1097.28s: slide so there's four ideas worth\n1100.34s: testing\n1101.6s: um this is where we started\n1104.419s: so I mentioned the raspedal problem has\n1107.0s: been kind of unstable hard to reproduce\n1108.94s: it used uh one decision that was made is\n1112.34s: that the way the moisture variable was\n1113.96s: formulated is in terms of specific\n1115.76s: humidity specific humidity is a wiggly\n1118.34s: Target you have the option of instead\n1119.96s: formulating your moisture variable on\n1121.52s: the input in relative humidity the\n1123.679s: advantage there is that relative\n1124.76s: humidity is bounded in any climate and\n1127.039s: so it's less prone to out-of-sample\n1128.78s: drift if the coupled system starts to go\n1131.059s: somewhere outside the training set\n1132.559s: that's you're going to be less exposed\n1134.179s: to those problems if you're using\n1135.32s: relative humidity on your input Vector\n1137.0s: so there's a few papers that have been\n1138.86s: making that point in the past couple\n1140.0s: years and so that's one choice that we\n1142.22s: can examine the consequences of the\n1144.44s: other one is to expand the input Vector\n1147.2s: climate models are really complicated\n1149.12s: the million lines of code it's easy\n1151.039s: you're going to miss a causatively\n1152.419s: relevant ingredient when you try an\n1154.34s: exercise like this and we did we\n1155.78s: realized in rasp it off and some others\n1157.64s: we missed ozone ozone obviously matters\n1160.16s: for rated of transfer it should be in\n1161.84s: the input Vector I don't know what else\n1163.22s: we missed but ozone was definitely one\n1165.14s: of them\n1167.12s: um convective memory super\n1168.679s: parametrization multi-skill modeling is\n1170.6s: interesting because that interior micro\n1171.98s: model remembers what it where it was\n1173.78s: last time step there's an inertia and a\n1175.82s: memory that's carried at the micro scale\n1177.26s: it's not purely local in time unlike\n1179.299s: conventional parameterization so you can\n1181.4s: you can begin to incorporate that by\n1183.799s: also expanding the input Vector to\n1185.48s: include the outputs of the neural\n1187.4s: network one time step ago\n1189.559s: and the fourth family is to try\n1191.9s: something that learns Heating and\n1193.64s: moistening separately rather than\n1194.9s: learning eating and moistening in the\n1196.52s: same output Vector they have kind of\n1198.799s: just different distributions it may be\n1200.66s: worth training separate MLP models on\n1202.82s: the separate output variables\n1205.34s: okay so that's into the weeds a little\n1206.66s: bit but those are the the first test\n1208.28s: that Rose to the top of our mind when we\n1209.78s: decided what we wanted to investigate\n1211.4s: with this new machinery\n1213.38s: people have been claiming these things\n1214.7s: matter in the literature it has not been\n1216.74s: sampled enough to really know\n1222.679s: okay so let's look at the offline\n1224.539s: results first so what you're looking at\n1225.98s: here are the results of 400 member hyper\n1229.16s: parameter scans in in each of these four\n1232.4s: families so the Baseline is in dark blue\n1234.98s: uh what we call specific that'll be the\n1237.08s: Baseline the rasp it all kind of result\n1238.52s: and so lower is better here you want to\n1240.98s: have less offline error and you can see\n1243.44s: uh here in the in the tail the\n1245.539s: stabilized tail of the performance\n1247.039s: models\n1248.36s: um you've got you know maybe a little\n1249.799s: bit more skill offline when you switch\n1251.419s: to relative humidity maybe a little bit\n1253.1s: more even than when you expand the input\n1254.96s: Vector that's encouraging a lot more\n1256.7s: when you get to the previous tenancies\n1258.2s: which is interesting as well\n1259.94s: um you see that not just for the heating\n1261.2s: error but for the moistening error\n1262.88s: offline\n1263.78s: but of course the ultimate test that\n1265.88s: matters is online that's we did why we\n1268.28s: did all this pipelining work so let's\n1269.96s: see how things change\n1271.58s: um does it still go Baseline relative\n1274.22s: previous Tendencies when we go to the\n1276.679s: online metric let's have a look\n1279.86s: okay okay that's hard to tell that's\n1281.72s: that's\n1282.919s: a few thousand prognostic hybrid climate\n1285.98s: model tests I think um\n1287.78s: same colors apply here I don't know if I\n1289.52s: just look better on my laptop can you\n1291.02s: see anything\n1300.34s: so how about that one that looked the\n1302.539s: best offline the purple previous\n1304.039s: Tendencies is it looking the best online\n1311.24s: maybe maybe purple's hovering down here\n1313.52s: at the bottom of the air graph on the\n1314.9s: moisture\n1316.22s: definitely not over here though you\n1317.84s: squint your eyes this is hard to look at\n1319.34s: right let's summarize it with some PDFs\n1323.0s: okay so here\n1325.7s: higher is worse this is a log scale blue\n1328.22s: is the Baseline a lot of error\n1331.64s: um this is heating this is moistening\n1332.96s: error okay as we incorporate relative\n1335.72s: humidity\n1337.4s: good things are happening prognostic air\n1340.1s: is going down a lot log scale\n1342.679s: there's a tight mode here not just\n1345.2s: repeating but also for moistening that's\n1346.7s: encouraging\n1347.78s: as we expand the inputs to include the\n1349.7s: ozone\n1351.919s: and the Mode's kind of similar\n1354.14s: but the left tail that kind of really\n1355.76s: matters to me the best fits is looking a\n1358.46s: bit better maybe especially for\n1360.38s: moistening\n1362.059s: as we further include the previous\n1363.44s: Tendencies yeah maybe that's the best\n1365.059s: tale yet\n1366.2s: to the moistening but not for the\n1368.24s: heating\n1369.5s: remember that drift\n1371.419s: So This is complicated\n1373.88s: um a key point is there's a lot of\n1375.26s: dispersion in these PDFs there's a lot\n1377.84s: of empirical uncertainty here\n1382.88s: so\n1385.46s: the implications of that you can kind of\n1387.86s: take this exercise in morphine and say\n1389.299s: hey what would it take let me say I've\n1390.919s: got a I've got a threshold that I care\n1393.14s: about that's like a threshold of\n1394.4s: operational viability let's say it's two\n1396.679s: Kelvin rmsd in the troposphere mean\n1398.96s: State climate temperature one gram per K\n1401.72s: per kilogram moisture you know what's\n1404.12s: the chance that I will find\n1406.34s: one fit that meets those skill targets\n1410.0s: based on these distributions\n1413.539s: and and it's really different for the\n1415.76s: different architectures so for the\n1417.919s: relative humidity you're basically never\n1419.6s: going to find one but for this test that\n1422.539s: included expanded inputs and previous\n1424.28s: Tendencies yeah we can find one but you\n1426.799s: know you've got to chain at least 100\n1428.179s: MLPs to have an 80 of chance\n1432.02s: um so I think this just speaks to the\n1433.76s: point\n1435.08s: that sampling is really important\n1437.78s: um do we need to lean into Auto like\n1439.52s: hyper parameter scans\n1441.62s: um at least with these simple MLP\n1443.0s: architectures to find a decent fit\n1447.02s: okay the other thing that we're looking\n1448.58s: at and this is kind of hot off the press\n1450.08s: so I haven't fully processed it I wanted\n1451.58s: to show you some some Research In Motion\n1454.28s: um we can look at the bias structures in\n1458.059s: the top models okay so each of the\n1459.799s: columns here is a Top Model the top five\n1461.6s: models in these three families the first\n1463.7s: family relative humidity second family\n1465.86s: expanded inputs third family previous\n1468.44s: tenancies\n1469.94s: and you can see right away screaming off\n1471.86s: the plot we've got a big Stratosphere\n1473.48s: problem\n1474.38s: way too cold stratospheric drift it's\n1477.799s: inescapable none of the architectures\n1479.48s: have solved it\n1481.039s: um so something's missing still\n1484.1s: um but then I'm reassured that there's\n1486.14s: some reproducibility in these bias\n1487.94s: attractors after all this sampling that\n1490.52s: maybe we've got a shot at actually\n1493.46s: having a stable enough statistical\n1495.38s: ground now to understand what's what's\n1497.299s: missing and what's what the the causes\n1499.64s: yeah because you've replaced in the in\n1501.799s: the in the real GCM have you replaced\n1503.72s: radiator transfer yeah sorry I should\n1505.82s: have mentioned yeah so the emulator is\n1508.159s: replacing rated of transfer and all of\n1510.799s: super parametrization which itself it\n1512.659s: seems boundary layer turbulence and\n1514.46s: convection uh all the common things\n1516.799s: essentially at most of the vast majority\n1518.9s: of the diabetic physics yes yeah\n1523.64s: you don't have to formulate it that way\n1525.32s: but that that limit of most complexity\n1527.96s: is of most interest to me\n1529.76s: um\n1530.6s: yeah\n1532.7s: I think when you're there's a subtle\n1534.559s: Point here when you're not poor\n1537.14s: screening in time\n1538.7s: you have the ability to split processes\n1541.7s: as soon as you coarse grain and time\n1543.74s: processes are mixed and you can't split\n1545.539s: them and then you leave a bunch of\n1547.34s: compute acceleration potential on the\n1549.14s: table\n1550.279s: um so I'm I'm really interested in the\n1552.86s: the challenging problem of course\n1555.559s: creating in time and space because\n1557.48s: that's where the biggest potential\n1559.12s: sidestepping of Moore's law that we all\n1561.08s: need can happen\n1563.12s: yeah thank you\n1567.799s: how am I doing for time I lost track\n1570.86s: yeah that's what I mean it's been 20\n1572.72s: more minutes 30 30 more yeah till the\n1575.539s: end of 20 you'll swim I'm going fast\n1577.76s: good all right\n1580.159s: maybe I'll pause there in case any of\n1581.72s: that was unclear yeah there was already\n1583.34s: one question\n1584.6s: yeah\n1585.799s: in those spreads that you were showing\n1587.9s: the difference\n1590.779s: in the just the initialization of the\n1592.4s: way it's not hyper parameters or was the\n1593.96s: test data samples also at randomly\n1595.58s: inside\n1596.779s: I didn't explain the search I'm sorry\n1598.94s: yeah the the things we search over\n1601.22s: randomly are you know generic aspects of\n1604.279s: the architecture the depth the width of\n1606.679s: every node\n1608.059s: um of every layer uh what else did we\n1610.52s: sample I think we've yeah the optimizer\n1612.799s: to some extent the learning rate\n1615.62s: but we had to choose a dimension of the\n1617.6s: hyper parameter space to sample it\n1619.159s: there's some intuition here building off\n1621.02s: auded outward that you know some some\n1623.059s: had been rolled out as less important\n1626.059s: mm-hmm sorry yeah\n1628.82s: oh sorry one more point on that there\n1630.679s: was an intentionally a random not a\n1631.94s: business in church because it only then\n1633.38s: could be really rapidly make use of a\n1635.72s: lot of GPU Hardware to just get a quick\n1637.34s: answer and beat down the latency I'm an\n1640.279s: ml person\n1641.419s: this into my language\n1644.36s: how different the trading data and\n1646.22s: online test data that these models have\n1648.679s: been offer how they look like and how\n1650.48s: important\n1652.159s: urgency\n1653.179s: yeah what a great question yeah well so\n1655.1s: I think you can get a taste for that\n1658.88s: in this plot which shows the bias of the\n1661.7s: online runs compared to the Baseline run\n1663.74s: and so these are significant biases that\n1666.799s: this the couple simulation encounters\n1668.419s: that were definitely out of sample to\n1669.799s: its inputs and you could imagine them\n1672.919s: intelligent things to do to expand the\n1675.679s: training data set with four knowledge of\n1677.9s: this Halo I don't think we could have\n1679.52s: done that earlier because this Halo was\n1681.08s: so Wiggly that we didn't know what it\n1682.94s: was but that's an opportunity that's\n1684.5s: emerging\n1686.38s: yeah I was going to ask a similar\n1688.279s: question kind of how much does this sort\n1690.32s: of sensitivity of the setup of the uh of\n1694.159s: the algorithm make you worry about its\n1697.34s: potential generalizability to do\n1698.84s: climates new environments right\n1702.08s: yeah and I guess the idea is to expand\n1705.02s: the training set try to make it work\n1706.88s: yeah I generally am more attracted to\n1708.86s: the interpolation limit to try to find a\n1710.779s: more diverse training set that spans\n1712.279s: climates\n1713.24s: um you know I've thought about doing\n1714.919s: janky things like maybe we should be our\n1717.14s: training simulations should constantly\n1718.46s: have bombs going off in them just to\n1719.9s: seat a bunch of diversity that's we\n1722.059s: don't expect to encounter but to provide\n1723.559s: some guardrails to learn the corrective\n1725.24s: response and that would be fun to try at\n1726.86s: some point um but um yeah\n1730.88s: I think there's there's a nice paper by\n1732.919s: Tom that's in on archive as well that\n1734.96s: looks at um at adding physical con\n1738.26s: physical renormalizations that are\n1739.94s: strategic to the input Vector that try\n1741.5s: to turn the extrapolation into\n1743.0s: interpolation across climates as you can\n1744.679s: do to a degree and and precedent that\n1746.9s: things like the relative humidity input\n1749.179s: definitely expose you less to out of\n1751.039s: sample error and do provide a bit more\n1753.679s: generalizability but I think we have to\n1755.539s: demand an extreme amount of\n1757.64s: generalizability to thwart the many\n1759.799s: degrees of freedom with which coupled\n1761.6s: errors could manifest I mean\n1763.58s: yeah\n1764.899s: another comment on that is that these\n1767.36s: statistically steady aquaplanets may not\n1769.46s: be diverse enough maybe that their their\n1772.059s: idealization's attractive by virtue of\n1774.74s: less complexity but their lack of\n1776.0s: variability may be unattractive by\n1777.62s: virtue of less opportunity to learn\n1779.2s: diverse situations yeah\n1781.7s: um\n1782.419s: yeah\n1786.74s: okay so okay let me resurface a little\n1789.62s: bit with some outlook here we've talked\n1791.299s: about some of it but yeah one headline\n1793.1s: is yeah this is an old problem now\n1794.72s: that's getting a bit mature and it's\n1796.52s: still a tough nut to crack at least to\n1798.26s: have reliable reproducible skillful\n1800.559s: emulation of even this very simplified\n1802.94s: nesting of convection so you know let\n1805.159s: alone trying to machine learn and\n1806.6s: actually spatially explicit region of\n1808.52s: nasty convection we need to solve this\n1810.2s: before we can move there\n1812.48s: um\n1815.899s: right now if you ask me my opinions\n1818.299s: changed over time but right now I feel\n1819.98s: like we're missing something in the\n1821.24s: design of the problem maybe something in\n1823.76s: the data that we should have saved that\n1825.679s: we didn't\n1827.24s: um I know we forgot ozone what else did\n1829.279s: I forget in full complexity climate\n1831.919s: models it's really hard to rule out that\n1833.779s: some causatively relevant input Vector\n1835.76s: you know I've I've been with this\n1837.5s: climate model for a decade I thought I\n1839.539s: knew it well but I still surprised\n1841.039s: myself\n1842.299s: um\n1844.58s: I think it's hard enough that it's\n1846.08s: worthy of a benchmark data set to scale\n1848.0s: it to our machine learning colleagues\n1850.22s: um in the sense that imagenet has had a\n1852.2s: huge influence on rate of progress and\n1854.6s: image recognition so it's time\n1857.6s: we're so we're trying to do that now\n1860.179s: um so sung duck led the charge to team\n1862.58s: up with these two guys who are\n1865.159s: um the lead developers of the world's\n1867.2s: best multi-scale modeling framework now\n1868.82s: the only one that an actual private\n1870.559s: modeling agency is invested in the\n1871.94s: department of Energy's e3sm MMF it's got\n1874.94s: lots of bells and whistles but most\n1876.26s: importantly they know how to go through\n1878.419s: this code with a fine-tooth comb because\n1879.86s: they wrote a ton of it they had to\n1881.779s: refactor all the data structures to get\n1883.34s: this thing to run on GPU and so they're\n1885.559s: in a good position to make sure that all\n1887.299s: the data flows across the code regions\n1888.98s: that we're trying to emulate um can be\n1891.5s: can be saved in a refined attempt okay\n1894.44s: so it's time to make a new Benchmark\n1896.48s: that that we know is positively complete\n1898.58s: and we've been working hard on this as\n1900.2s: part of leaf I'm excited we've got it\n1902.0s: now it's about 50 terabytes it's going\n1904.7s: to be the focus of the Summer's leap Ru\n1906.5s: students\n1907.82s: um it's got a hierarchy of complexity so\n1909.919s: there's a of course resolution option\n1911.659s: that's not too discontentive maybe a\n1913.46s: terabyte you could some sample it more\n1915.14s: or a higher resolution one it's a bit\n1917.12s: more ambitious there's an aquaplanet\n1918.799s: version that doesn't have much\n1920.12s: variability or continents and there's a\n1921.98s: real geography one that does and it's\n1923.539s: got Seasons there's about 10 years of\n1925.52s: output for each time step level output\n1927.399s: there's the opportunities to close\n1929.659s: budgets and draw lots of physical\n1930.86s: constraints really rich data set it's\n1932.96s: got for the first time all the inputs\n1934.94s: and outputs that are needed to both\n1936.14s: couple from and to the land model so we\n1938.36s: found the packages and the containers\n1939.799s: that explicitly send information to and\n1941.72s: from the components in the model and\n1943.1s: made sure we got all of them\n1944.96s: um and um yeah so we're we're planning\n1947.84s: we're hoping we're working right now to\n1949.039s: try to to train Baseline models on this\n1951.44s: new data set and and the goal is to\n1953.539s: submit a data publication and uh you\n1955.82s: know this is a big team effort and if\n1957.32s: anyone wants to get involved in stand-up\n1959.299s: Baseline models you're part of leap let\n1961.1s: me know\n1962.12s: um uh yeah this is going on right now\n1963.74s: but um but there'll be more hackathons I\n1966.5s: think we can announce around it soon\n1970.1s: yeah and yeah I guess I want to conclude\n1972.08s: this segment\n1973.159s: but my obsession with multi-scale\n1974.899s: emulation by saying it's it's\n1978.679s: it might seem uninteresting because the\n1980.84s: convection is obviously not realistic or\n1983.12s: important to people convection who cares\n1984.98s: about 2D convection hiding in a locally\n1986.899s: periodic array right\n1989.6s: um sure people care about high\n1990.919s: resolution and impacts on the skills\n1993.2s: that matter to them but that's not real\n1995.12s: convection right but but it's a it's A\n1998.659s: Fine Place to stop feeling\n2000.7s: um because it includes enough of the\n2002.14s: complexity of the problem the\n2003.1s: stochasticity the microphysics the\n2005.98s: radiation the convection that it's hard\n2008.44s: enough but it excludes some other things\n2010.48s: that are even harder so like another\n2012.279s: thing you can do is coarse grain\n2013.72s: uniformly resolve high resolution models\n2015.7s: but there you've got a non-locality\n2017.14s: problem to worry about you don't know\n2019.059s: where to draw the spatial filter here we\n2022.179s: know because it's engineered in the host\n2023.62s: model itself and so the the coupled test\n2026.32s: is much more readily approachable in in\n2029.38s: a super parametrized model so I feel\n2030.94s: like if we can stop failing on this then\n2032.679s: we'll open the door as image net did to\n2034.48s: a bunch of richer applications we\n2035.86s: actually care about because there are\n2037.84s: assistance of nested complexity in the\n2039.82s: climate that we can't afford to revolve\n2041.799s: that resolve that are climate critical\n2043.299s: like low clouds but also like\n2045.72s: phytoplankton communities that interact\n2047.679s: with plumes of turbulence and you know\n2049.48s: the the details of the turbulence matter\n2051.52s: in terms of how the nutrient pulls that\n2053.5s: limit the ecosystems and their\n2055.0s: competitive Dynamics interact that's\n2057.04s: nested complexity there's um ice sheet\n2059.8s: having zones\n2061.54s: um you know where you know the details\n2063.76s: of the coastal topography really matter\n2065.5s: so they're constraints on on\n2067.74s: outflow and melting rate of their\n2070.179s: Antarctic and Greenland ice sheets and\n2071.859s: their consequent contributions to sea\n2073.659s: level rise those are locally invested\n2075.58s: physics um\n2077.08s: you know the details of water management\n2079.119s: and estuaries that happen and you know\n2081.58s: the spatial details here really matter\n2083.56s: so if we can stop failing on this\n2085.0s: problem as a community then maybe we can\n2087.22s: start doing things that will really\n2088.659s: matter like machine learning the\n2089.859s: perimeter of a region of actually\n2091.72s: geographically explicit uh\n2094.0s: high-resolution physics um and maybe\n2096.7s: even sparsely sparsely super resolved\n2099.4s: diagnostically a subset of the Interior\n2101.98s: resolution where the infrastructure and\n2104.08s: the vulnerability lives\n2105.94s: um so yeah so that's that's why I'm\n2107.2s: still interested in this problem and I\n2108.58s: hope we can compete on it\n2110.92s: okay so I'll pause there one more time\n2113.26s: because we have 10 minutes here or\n2116.099s: a team let's say there's no I'm not\n2118.78s: going to pause that all right because\n2119.92s: this might take longer than I think okay\n2121.359s: so I'm going to switch hops now we're\n2122.74s: going to talk about Nvidia\n2124.96s: um I've been having an unexpected year\n2127.359s: working with an amazing tech company and\n2129.88s: what I mostly want to tell you about is\n2131.44s: the revolution in AI weather prediction\n2133.0s: because they built this thing that I\n2134.92s: think is kind of amazing\n2137.4s: uh here we go okay so context here now\n2141.579s: switching from climate to weather\n2142.839s: weather also takes a lot of computing\n2144.94s: because you've got to do two things\n2146.68s: initialize and we don't really know the\n2148.72s: initial conditions so you need a lot of\n2150.339s: uncertainty to sample here and then you\n2152.32s: need to do a probabilistic prediction\n2154.599s: where you do many simulations of the\n2156.46s: next several days to get some Halo of\n2159.579s: forecast uncertainty and a probabilistic\n2161.5s: outcome to plan around and if these\n2163.42s: things have always been intention\n2164.4s: computationally you'd like to have more\n2166.3s: Ensemble members because you'd like to\n2167.859s: have the Tails of that PDF better\n2169.599s: resolved for hazard but you'd also like\n2172.06s: your forecast to be high resolution to\n2173.619s: resolve the hazards themselves like\n2175.0s: tropical Cyclones which take a lot of\n2176.44s: grid resolution so There's a\n2178.18s: computational constraint here just like\n2179.8s: there is for future climate stimulation\n2185.619s: now I'm not going to talk about hybrid\n2187.66s: AI simulation now where you've got a\n2189.4s: nested AI model that has to interact\n2191.5s: with\n2192.339s: explicit physics and all the problems\n2194.38s: that can happen there this is just pure\n2195.94s: machine learning so AI weather\n2197.98s: prediction is like\n2200.14s: video prediction is treating the weather\n2202.48s: data as an image and trying to predict\n2204.099s: the next six hours image except instead\n2206.32s: of the image of having three channels\n2207.64s: RGB it's got lots of channels\n2209.56s: temperature wind at different altitudes\n2211.72s: but it's the same game and it's an auto\n2214.119s: regressive game so you have one model\n2216.099s: that just learns the mapping from time\n2218.14s: step one to time step two we're gonna\n2219.88s: use six hours as the spacing here and\n2222.04s: then the outputs and form its inputs and\n2224.14s: it auto regressively rolls out until at\n2226.78s: some point the imperfections of the fit\n2228.64s: pile up and Fort you and it goes off the\n2230.68s: rails as you should expect\n2233.32s: um\n2234.099s: yeah and then so um unlike video\n2237.22s: prediction we don't have the whole\n2238.3s: internet to train off but we do have 15\n2240.52s: 000 days of satellite observations which\n2243.099s: is pretty good\n2244.66s: um\n2245.38s: and and it's turned out and there's\n2247.42s: evidence in the last six months that\n2248.98s: small even small teams of deep learning\n2250.72s: engineers at tech companies that know\n2252.28s: how to scale big enough models to big\n2254.56s: enough volumes of data can stand up\n2256.18s: these sorts of weather prediction models\n2258.22s: and there's they're uh they're producing\n2259.839s: skill gains rapidly so at Nvidia I was\n2263.26s: one of the first to do this with\n2264.339s: forecast net and ambitious resolution so\n2266.32s: using the full 25 kilometer resolution\n2268.359s: of the era five reanalysis that's the\n2270.339s: training data\n2271.599s: um this is JD Pathak who I'm totally\n2274.0s: honored to have on my team\n2275.98s: um who who wrote a great paper or on\n2278.44s: archive where you can read about the\n2279.7s: model it's got a thousand pixels so you\n2282.76s: can't use Transformers like in large\n2284.44s: language models where the the sequence\n2286.42s: length is more like 4 000 that's kind of\n2288.16s: a hard limit to get past this is like a\n2289.9s: million\n2291.04s: um and so instead\n2293.619s: what we use is a Fourier neural operator\n2295.839s: which gets around the quadratic scaling\n2297.88s: of Transformers by using Fourier modes\n2300.82s: to do the spatial convolution but it\n2302.859s: looks like this inputs come in the model\n2305.2s: predicts the the same inputs the same\n2307.3s: state Vector uh some time step in the\n2309.82s: future and then um yeah we train it and\n2312.46s: then we do it we do a first stage of\n2314.079s: training and then a second stage of\n2315.28s: training that expands the time Horizon\n2317.38s: of the of the discretization uh doubles\n2320.14s: it and you can get still games by\n2322.06s: increasing that time Horizon\n2324.94s: um yeah it's about tens of terabytes of\n2326.619s: data a fraction of what's available we\n2329.74s: use just a few variables on a few\n2331.9s: pressure levels spanning the atmosphere\n2333.4s: winds and temperatures at a few pressure\n2335.26s: levels\n2336.7s: um yeah that's all I'll say about that\n2339.82s: this is what the architecture looks like\n2341.5s: it's like a Transformer model that uses\n2343.9s: uh Fourier modes inside of it to do we\n2346.18s: can we don't have to talk about this but\n2347.56s: let's move on to the results\n2349.3s: um yeah so this is the key point though\n2351.4s: is it's a global weather prediction\n2353.38s: model that's fully AI\n2356.26s: um it's got 25 kilometer resolution you\n2358.839s: can initialize it with even with\n2360.339s: real-time GFS conditions and um and this\n2363.16s: is the key point it runs you can run a a\n2366.579s: two-week forecast in a quarter of a\n2368.74s: second which is ten thousand times\n2370.9s: faster than classical weather\n2372.099s: predictions like a totally new limit of\n2375.16s: computing for the atmosphere fascinating\n2377.74s: fascinating only if it produced skill\n2379.96s: that you believe\n2381.88s: um skill is easy to measure we've got\n2383.32s: good metrics\n2384.82s: um so this is the anomaly correlation\n2386.56s: coefficient you expect it to decrease as\n2388.54s: the memory of your initial conditions is\n2390.28s: lost in the chaotic system at a\n2391.78s: particular time scale yellow is the gold\n2393.94s: standard Benchmark from the the European\n2396.04s: Center for medium range weather\n2397.06s: forecasting which has some of the best\n2398.859s: medium range forecasts in the world and\n2400.78s: the goal of whether prediction is to try\n2402.22s: to push these curves as far to the right\n2403.72s: as you humanly can\n2405.64s: um and and so this is where forecast net\n2407.619s: was a year ago or a year and a half ago\n2409.42s: and in just a few months of deep\n2411.099s: learning Engineers twiddling knobs and\n2412.54s: doing other things you know getting\n2413.859s: skill games like this and it's moving\n2416.14s: very quickly I can tell you and and\n2418.66s: other teams at Huawei and uh and\n2421.48s: deepmind have produced preprints in the\n2423.7s: last six months they claim that they're\n2424.9s: beating classical deterministic\n2426.76s: forecasts now it seems like this is the\n2428.14s: year that AI weather prediction is\n2430.359s: surpassing the skill of classical\n2432.16s: weather prediction yeah all right we've\n2434.619s: trained it on a weather prediction of\n2437.079s: training animals so how can you tell\n2439.359s: whether it's better than the training\n2441.64s: data oh thanks yeah thanks we're\n2443.32s: printing it not on a weather prediction\n2444.82s: but on an assimilated state which is a\n2447.28s: fusion of a weather prediction system\n2449.079s: and an observing system that creates the\n2451.54s: best state of the observed state of the\n2453.22s: ionosphere and it's an uncertain state\n2455.859s: but it yeah it's not it's um yeah so\n2459.339s: what we're holding it accountable to in\n2460.9s: this picture are retroactive hindcasts\n2463.42s: against that same observed say\n2466.599s: did I answer your question\n2469.78s: so it's the analysis it's not it's the\n2472.359s: analysis it's not trained on the\n2473.859s: forecast it's trained on a estimate of\n2476.56s: the state and and you and you're doing\n2478.66s: an individual uh tuning to the six hour\n2482.619s: the two day the five day the seven day\n2484.78s: forecast no we're choosing an individual\n2486.76s: time scale yeah we're choosing a time\n2489.22s: scale a discretization time scale six\n2491.02s: hour in this case we've tried three and\n2492.46s: two you can pick your number\n2494.14s: um you expect some trade-offs there you\n2495.579s: expect the noise to pile up faster if\n2497.02s: it's a shorter time scale\n2498.94s: um yeah\n2501.88s: okay so your five-day forecasts are\n2504.88s: are 20\n2506.38s: 26 hour forecast strung together\n2508.72s: our five-day forecasts are the same\n2511.359s: machine learning model the same mapping\n2513.4s: doing Time Zero to time T six hours 12\n2516.52s: hours 18 rolling out its inputs are\n2519.46s: becoming its outputs it's ruling out\n2529.06s: and and yeah I want to make the point\n2530.68s: that it's the speed change that that is\n2532.839s: the significant thing here because it's\n2534.82s: it's just a completely different it's\n2536.14s: four words of magnitude it's ten\n2537.4s: thousand times faster one's Trend so\n2539.68s: that tension I mentioned between\n2540.64s: resolution and combo sites is gone one's\n2543.4s: trained an AI model has fixed resolution\n2545.38s: but it's trivial to infants\n2547.839s: um and so you can think of things like\n2549.46s: massive ensembles ten thousand member\n2551.2s: ensembles as long as you can deal with\n2552.52s: the output but the stuff lives in memory\n2554.859s: and you can pipe whatever subset of\n2556.48s: output stakeholders only ever care about\n2558.04s: a subset\n2559.359s: um out the Machinery in intelligent ways\n2561.52s: yeah\n2562.3s: sorry to be the only person asking\n2564.04s: questions please yeah\n2565.359s: um I how do you generate\n2568.18s: an ensemble\n2569.92s: um let me talk to you offline I'm not\n2571.599s: going to talk about Ensemble results\n2572.98s: here but I'd love to talk to you about\n2574.54s: that yeah exactly because the Ensemble\n2577.18s: and\n2579.4s: forecast system comes because it's it\n2582.46s: has a chaotic yes right is is the\n2586.18s: machine learned yeah is it a chaotic\n2588.94s: dynamical system chaotic yes itself yes\n2591.22s: it is yes it's remarkable\n2593.319s: um you know so so I should mention that\n2594.819s: Nvidia Earth 2 project is closely\n2597.22s: advised by Peter Bauer Peter Dubin some\n2599.44s: of the top weather forecasting centers\n2601.3s: leaders in in Europe and you know of\n2603.099s: course the first question they asked is\n2604.3s: similar what's your CRPS do you get can\n2607.06s: you get a reasonable spread skill ratio\n2608.74s: from an ensemble forecast you know\n2610.24s: Mission critical questions to answer and\n2611.8s: weather prediction\n2613.24s: um you know spread should increase at\n2614.56s: the same rate as error and and it's\n2616.72s: interesting to note in operational\n2617.859s: weather forecasting because they're\n2619.359s: computationally limited you have to go\n2620.74s: to Great Lengths to achieve these sorts\n2623.26s: of goals you have to find your singular\n2624.819s: modes to to spend your 50 Ensemble\n2626.8s: members most strategically on the\n2629.319s: singular vectors that that will grow\n2631.48s: fast enough to counteract the under\n2632.98s: dispersive nature of typical classical\n2635.76s: deterministic forecasts in machine\n2638.68s: learning you may have across those modes\n2640.42s: in a massive Ensemble but we're just at\n2642.579s: the dawn of ensembling AI machine\n2644.38s: learning weather prediction yeah\n2648.52s: this one is\n2651.22s: always 25 yeah and that means that we\n2653.8s: don't have any self-eating scale right\n2655.48s: yeah there's no so good scale yeah\n2663.66s: like reproduced\n2665.92s: you have to miss some sort of\n2669.46s: the feature space it's the model I've\n2672.64s: described is never going to simulate uh\n2674.44s: mesoscale convective system or a severe\n2676.42s: convective event that has a life cycle\n2678.099s: less than six hours and a spatial scale\n2680.2s: less than 25 kilometers because the data\n2682.66s: doesn't exist\n2683.98s: I don't think it needs a subject scale\n2685.839s: scheme to correct it because it's\n2687.22s: trained on assimilated observations that\n2689.56s: include the unresolved subgrid physics\n2691.66s: that normally are a challenge to\n2693.04s: represent deterministically in climate\n2694.72s: models\n2695.98s: um\n2696.76s: but yeah that's sort of the limit now\n2699.7s: could be then cited it's\n2707.26s: apply that to predict the future\n2712.48s: you could think of it that way I guess\n2714.64s: if you wanted to say that your typical\n2716.2s: mapping in a deterministic forecast has\n2718.78s: to have a divide between Dynamics and\n2720.64s: physics and the representation of the\n2722.2s: subgrid scale that's part of the overall\n2724.06s: mapping there's no such separation in a\n2726.819s: data-driven model because the it's just\n2728.619s: the outcome of all the physics that\n2730.18s: informs the best estimate of The\n2731.8s: observed State that's ultimately the\n2733.54s: information source for the dynamical\n2735.64s: mapping\n2737.26s: um\n2737.92s: since I'm not fully yeah can we talk\n2741.04s: offline okay I just realized I'm running\n2743.26s: late uh and I love these questions just\n2745.54s: like the best\n2747.04s: um this is Bill Collins world famous\n2748.599s: climate modeler helped write the ncar\n2750.339s: CSM or like its first open source\n2752.68s: version he's recording he's been working\n2754.54s: for like a decade just to try to\n2755.74s: characterize extreme events in the\n2757.96s: current climate to better understand\n2759.099s: them to understand their climate drivers\n2760.9s: and he's recognized this this is a great\n2763.0s: way to bootstrap The observed record to\n2765.22s: create you know 10 000 counterfactuals\n2767.26s: of extreme events if you believe it's\n2768.64s: internal variability so that's what\n2770.02s: we're exploring together\n2771.7s: um and and his hope is that we may\n2774.28s: understand the probabilistic mapping\n2776.38s: between climate drivers and extreme\n2777.94s: events in The observed record without\n2779.74s: going to Future climate to help us\n2781.78s: better build a better framework for\n2783.64s: understanding future climate extremes\n2785.68s: and I'm really excited about that\n2787.48s: um\n2790.54s: yeah and then I want to conclude with\n2792.28s: just some hot off the press recent\n2793.48s: developments that I think are really\n2794.68s: exciting\n2795.94s: um that you'll be hearing more about\n2796.9s: soon so I mentioned the fact that\n2798.76s: machine learning models will blow up\n2800.26s: inevitably right\n2801.88s: um and because of imperfections um and\n2804.819s: and I just want you to take this in this\n2806.319s: is the pythagadel model and you'll see\n2809.14s: it blow up and this is our new model\n2810.88s: that has uh actual spherical geometry in\n2813.76s: it\n2816.22s: and there's your blow up it's after\n2817.42s: about two weeks\n2821.02s: two months\n2822.52s: we're we're into two two months here it\n2824.859s: hasn't blown up\n2826.54s: um really did not expect this really\n2829.48s: interested in it\n2830.859s: um and so a tool to share open source\n2833.68s: tool that's driving this is a nice small\n2836.14s: gosh what is going on\n2839.8s: there's a nice pytorch Library that's\n2841.359s: open source with MIT license that has uh\n2843.88s: uh good uh good GPU optimized really\n2846.819s: fast uh spherical transforms that\n2849.099s: underlie this so you can check that out\n2851.079s: if you need such a thing it's fully\n2852.64s: differentiable\n2856.48s: and our new model uses spherical\n2859.3s: geometry and relies on these spherical\n2861.52s: mappings in the interior rather than a\n2863.2s: 2d fft that makes in inappropriate\n2866.44s: assumptions about creativeity across the\n2868.06s: poles and is probably a better way to\n2870.4s: think of doing your Global convolutions\n2871.9s: and it's just that step of respecting\n2873.94s: spherical geometry and the Machine\n2875.319s: learning that's led to this new\n2877.06s: capability to roll out\n2879.28s: um months and months and months so far\n2881.92s: um and so I'm just kind of frankly\n2883.54s: amazed that this is possible you'll see\n2886.24s: secondary tropical Cyclone Genesis\n2888.099s: months into the simulation which I think\n2890.5s: you ought to be spooked exist in a model\n2892.18s: with a six hour time discretization\n2894.42s: these are different fluid dynamics these\n2896.8s: are sparsely learned hidden dynamics\n2898.42s: that are unfamiliar and fascinating and\n2900.819s: therefore there's many many questions we\n2902.74s: ought to be thinking about including the\n2903.94s: great ones about ensembles and to what\n2906.4s: extent they represent chaotic dynamical\n2908.14s: systems that we think are appropriate\n2909.64s: caloric dynamical systems and that's\n2911.14s: work I hope we can do together if you're\n2913.359s: interested too it's all open source you\n2915.88s: can check out their original afno model\n2917.859s: it's downloaded from GitHub\n2919.68s: ecmwf's inferencing it knows inferencing\n2922.359s: it they're looking at real-time\n2924.04s: forecasts right now and hot off the\n2925.9s: press a week ago the spherical version\n2927.4s: just went open source open to keep open\n2929.8s: sourcing these things need to be working\n2931.66s: closely with the community of\n2934.06s: atmospheric science domain experts to to\n2936.22s: be scrutinizing this technology there's\n2938.2s: a few climate people inside Nvidia and I\n2940.24s: if you're interested in using these\n2941.92s: together let me know I'd love to to talk\n2944.14s: and you can also tune into a White House\n2946.66s: residential Council of advisors briefing\n2948.579s: this is anima Anand Kumar our\n2950.92s: unbelievable director of machine\n2952.24s: learning research we'll be sharing some\n2954.22s: some of these updates in a few more at\n2956.5s: uh 12 15 Eastern tomorrow so yeah I'll\n2959.079s: stop there and thanks so much for your\n2960.28s: time and yeah\n2969.24s: you are training your model\n2972.339s: using a data set\n2976.9s: and\n2978.88s: so development here\n2982.48s: so you are using your mother using a\n2987.64s: you are training your mother or you are\n2989.859s: teaching the mothers\n2991.96s: using our an existing data set\n2995.44s: a real time but that depends on how how\n3000.599s: it was uh\n3003.24s: accomplished right where the points of\n3008.46s: measurements were made\n3011.099s: plus you have a\n3013.26s: some equations right demonstrations\n3019.319s: but you you there are\n3022.38s: equations in in Duality right\n3026.4s: yeah the model I described does not use\n3028.8s: equations to produce its forecast\n3030.18s: although the data that it was trained on\n3032.7s: involves an assimilation between a\n3035.04s: numerical model with equations and a\n3037.14s: observing system yeah because you plug\n3039.839s: in\n3040.619s: the real time\n3042.78s: initial conditions in those equations\n3048.0s: yes since it's a machine learning model\n3050.099s: instead of plugging them into equations\n3051.66s: we we feed them into the input of a\n3053.819s: giant Transformer model but otherwise\n3056.099s: yes\n3060.5s: this transformation yes correct the the\n3063.48s: the\n3064.28s: uh extent of things that can be learned\n3066.54s: by the machine learning model like any\n3067.92s: machine learning model is limited by the\n3069.96s: data set it's trainable yeah\n3071.94s: I see yes yes that's correct yeah\n3075.119s: and there are many many forms of data\n3077.16s: one could imagine training these sorts\n3078.599s: of models on I've mentioned weather but\n3081.24s: I didn't mention what we want to do also\n3082.98s: which is to teach them to learn climate\n3085.859s: projections of the future\n3087.96s: um which have similar data formats and\n3090.599s: if successful could also provide very\n3092.64s: low latency ways to inference and\n3094.5s: reproduce the essential characteristics\n3096.72s: of climate simulations that maybe help\n3098.339s: us analyze them more easily may also be\n3100.92s: able to generate more realizations of\n3102.42s: internal variability than are available\n3105.0s: in in Planet predictions there's a lot\n3108.54s: of things we'll need to work out for\n3109.68s: that to happen but we're exploring it\n3113.339s: any other questions maybe from uh early\n3115.559s: careers and suspicion\n3121.2s: one question regarding climate Tech in\n3123.48s: general so like is it safe to make an\n3125.64s: assumption that this field will be\n3127.2s: growing continuously in the future and\n3129.24s: like you showed some applications of AI\n3131.16s: so we'll have more coming up with the\n3133.74s: coming years especially with carbon\n3135.72s: emissions increasing and the rise of EV\n3137.52s: Vehicles especially in those type of\n3139.559s: areas\n3140.579s: I feel less qualified to answer your\n3142.5s: question than at least two people in the\n3144.54s: room I'm thinking Pierre you sent a\n3146.22s: slide about this Ryan is in the back I\n3148.14s: know he's investigated for climate tech\n3150.059s: industry so\n3151.38s: is it safe to assume the climate Tech\n3153.24s: will be industry will be growing in the\n3154.92s: future\n3160.02s: yeah\n3161.22s: I feel yeah I'm not a business person\n3163.26s: I've been wrenched out of an academic\n3165.599s: live into an interesting tech company I\n3167.28s: don't know the answer to your question\n3169.14s: but it seems like a lot of things are\n3170.94s: pointing that way Mr Maria it was uh it\n3174.18s: was the number two um in terms of growth\n3177.0s: you know after AI so Clement take a\n3179.16s: second number two yeah in the industry\n3185.88s: I don't think so it's interesting um you\n3188.099s: showed a little of the work you're doing\n3189.48s: with Bill Collins I was wondering if\n3191.099s: there's any results from that yet and\n3192.839s: you're able to see\n3194.88s: like doing some hind tests on things\n3196.619s: like the Northwest Heatwave and some of\n3199.079s: these crazy events we've been having\n3200.16s: that are also certainly dynamically\n3201.9s: driven how the the AI is doing with that\n3204.18s: yeah we're on the same wavelength yeah\n3205.859s: we're spinning up on that right now yeah\n3207.78s: but this is a new new collaboration just\n3210.0s: been resourced and uh yeah yeah I could\n3213.18s: talk to you are we recording\n3215.04s: thanks\n3221.16s: let me just check with the early careers\n3225.119s: and so a great time so one question so\n3228.059s: most uh pure data driven uh where the\n3231.48s: forecasting model they do pretty good\n3233.22s: job but the uh like a very short range\n3235.8s: of weather forecasting so do you have\n3237.54s: any idea on how to improve the low range\n3240.9s: of predictability in the future\n3243.78s: so I've showed you that that\n3245.819s: reformatting the AI to the equivalent\n3248.16s: under spherical Transformations has made\n3250.14s: a big deal for us anecdotally Dale\n3252.599s: Duran's reported the same at UW I know\n3255.54s: he's very enamored with the heel picks\n3257.4s: Grid in astronomy right now because it\n3259.38s: happens to be uh amenable to\n3262.4s: convolutions that obey spherical\n3264.5s: variants so that's a sample size of two\n3267.42s: but I would say uh not\n3270.3s: in incurring inductive bias that due to\n3273.48s: having a machine learning algorithm the\n3275.76s: inconsistent with spherical geometry\n3277.7s: seems to set you up to fail on short\n3280.98s: time scales but\n3282.72s: um yeah and I guess I should say I think\n3284.76s: Dale's work is very interesting if\n3286.14s: you're interested in this check out\n3287.22s: leanadal 2021 they have a fourth\n3289.98s: resolution version of something like\n3291.18s: this that has a seasonal cycle in it\n3293.64s: that doesn't look terrible alongside\n3296.819s: um medium range weather predictability\n3298.26s: and some S2s that's not far from ecmwf's\n3302.359s: S2s ensemble\n3305.64s: so um have you tried this out with a\n3308.76s: different climate State plot from a\n3311.4s: climate projection and does it kind of\n3313.68s: revert to the mean or does it stay in\n3317.46s: that same climate\n3319.92s: uh\n3322.859s: I don't know much how much I can say\n3324.66s: about that but um yeah I'm definitely\n3326.4s: interested in that question I to me in\n3329.16s: as much as I feel like in my super\n3330.359s: parameterization work I want my training\n3332.22s: data set to span all climates I'm\n3333.839s: interested in inferencing I also view\n3335.94s: this technology as being most\n3337.319s: appropriately trained in that way and so\n3339.42s: for future I do think there's an\n3341.04s: extrapolation boundary to the extent it\n3342.839s: has learned some Physics it's worth\n3344.52s: defining and it and uh don't expect it\n3347.099s: to be very large and so my main goal in\n3351.3s: using Tech like this for climate\n3352.559s: prediction is just to use it as an\n3354.66s: interpolator and memorizer of um\n3356.88s: existing climate projections and Bjorn\n3358.68s: Stevens who's one of our advisors is\n3360.54s: very passionate about that as a way to\n3362.88s: just reduce the clunky barriers to\n3365.52s: getting all the rich spatial temporal\n3367.319s: detail out of time with data archives\n3369.68s: yeah the active compression can seem\n3372.839s: like a boring engineering exercise but I\n3374.4s: think it's actually it's remarkably\n3376.2s: enabling\n3377.88s: yeah\n3379.559s: yeah I have lots of questions but one of\n3382.02s: the ones was um like how much is\n3383.819s: explainable AI coming into this and like\n3385.8s: how much can we learn right are we just\n3388.8s: going to learn the same things\n3391.14s: are we fundamentally gonna learn more\n3392.579s: because we have an ensemble of 10 000 is\n3394.98s: that's the idea just the better\n3396.24s: distribution versus uh are we gonna just\n3399.42s: uncover all the uncertainties in our the\n3402.42s: fundamental model in which this is\n3403.8s: trained right like so do we have an\n3405.66s: opportunity to learn something about the\n3406.74s: real climate system here\n3409.2s: um yeah what's your perspective on that\n3410.94s: I guess yeah\n3412.92s: yeah I'm leaning into both fixed sort of\n3414.9s: Applied applications here that aren't\n3416.46s: about fundamental understanding right\n3417.839s: like reducing latency of climate\n3419.76s: prediction access achieving better skill\n3421.92s: and weather prediction not trying to\n3423.18s: understand the sources of skill I do\n3425.46s: think you could think about the fact\n3426.9s: that um these are differentiables and\n3429.48s: that one of the ways that people have\n3430.859s: tried to understand sources of S2s skill\n3433.26s: is by spending a lot of human effort to\n3435.78s: build an adjoint and to use the adjoin\n3438.54s: to understand once you've gained a skill\n3440.579s: anomaly where it came from so I could\n3442.74s: see if we pass a important S2s Milestone\n3446.099s: that being a little easier to approach\n3448.14s: and maybe\n3449.46s: resonating with your interest\n3456.66s: there was a question online\n3458.52s: um could you comment on how we could\n3459.839s: improve numerical weather prediction\n3461.52s: using ml\n3463.079s: which\n3466.7s: Well yeah if you believe that what we\n3469.559s: showed is a few might be the future of\n3471.3s: weather prediction then if you know\n3474.24s: maybe the the role of weather centers\n3476.099s: should be to to your point enrich the\n3478.68s: available data record\n3480.72s: um and to yeah\n3483.9s: I think I don't I don't know I mean\n3487.38s: far be it for me to say what at a\n3489.18s: numerical weather prediction center\n3490.26s: should do but um I think the data that\n3492.9s: they've produced is invaluable and is a\n3494.88s: government enabled common good that has\n3497.7s: enabled all of this technology and the\n3500.22s: data is imperfect and depends on sparse\n3502.859s: sensor networks and it will only get\n3504.78s: better with better sensor networks so to\n3507.119s: the extent all of us agree that machine\n3508.68s: learning methods are limited by the data\n3510.3s: center trained on\n3511.8s: um I feel like this is a\n3513.599s: a\n3514.98s: you know maybe uh\n3517.38s: you should re-embolden us to think about\n3519.42s: how many more measurements we could be\n3520.92s: taking or how we could be making better\n3522.24s: use of uh the measurements already\n3524.04s: available I've only talked about\n3525.72s: training on error five and of course\n3527.64s: there's much more out there\n3531.599s: any more questions oh we have other than\n3533.7s: this uh yeah yeah um\n3535.859s: yeah maybe yeah following up on the team\n3538.319s: uh have you looked at I mean these are\n3541.2s: these are of course the frontier\n3542.339s: problems like these are as hard as they\n3544.319s: get and they showcase like you know\n3547.68s: the best turbo software and Hardware but\n3551.46s: like maybe I guess a different kind of\n3554.22s: problem like modeling say distribution\n3556.26s: of clouds or like something more\n3558.72s: stochastic as it evolves over time is\n3561.119s: that something that uh you are\n3563.7s: interested in as as\n3565.859s: like you Professor Richard and then you\n3570.059s: as uh Nvidia Richard yes yeah but on\n3574.2s: both fronts I would say for the\n3575.28s: hackathon they're about to stand up I\n3576.839s: think it'd be great to explore\n3578.52s: stochastic generative methods for it um\n3580.68s: Governor Barons a student that cares\n3582.599s: worked closely with uh through the use\n3584.4s: of all project has has gone a step in\n3586.799s: that direction it seems very promising\n3588.24s: the data center we've got I mean it is\n3590.4s: stochastic data it ought to be held\n3592.559s: accountable to stochastic metrics you\n3594.119s: could use you know generative methods\n3595.619s: like diffusion methods or variational\n3598.339s: encoder decoders there um and then to\n3601.2s: your question about files I wanted to\n3603.24s: share uh there's a I've got to remember\n3605.819s: his name but I'll send it to your guy at\n3607.68s: the University of Hawaii I met at a\n3609.059s: workshop at UCI a couple weeks ago that\n3610.859s: was doing lovely work with diffusion\n3612.48s: models to do exactly what you described\n3614.4s: to kind of predict the stochastic\n3617.64s: spatial details Cloud fields in a\n3619.559s: regional scene over Hawaii trained\n3621.119s: directly on satellite observations for\n3623.099s: solar energy forecasting I think that\n3624.96s: works already around us and there will\n3627.0s: be more of it and\n3628.68s: um it's one way to think about achieving\n3630.54s: the resolution humans care about despite\n3632.52s: the 25 kilometer footprint of the data I\n3634.74s: described is to tack on generative super\n3636.599s: resolving models and I do think those\n3638.64s: should be stochastic models because of\n3640.859s: course those time scales are quite\n3642.42s: stochastic\n3645.18s: thank you\n3647.76s: I was wondering about some of the work\n3649.92s: from Jerry that you showed about a hyper\n3652.859s: parameter performance online versus\n3655.14s: offline\n3656.46s: do you do you kind of see anything in\n3658.859s: the more skillful hyper parameters that\n3662.339s: um you think iteratively could lead us\n3664.619s: to select\n3666.48s: um better hyper parameters from the\n3668.04s: offline training I love that question\n3670.14s: yeah\n3671.04s: I feel so ignorant in the Dark Ages when\n3673.5s: I do hyper parameter tuning because it's\n3675.24s: just too random and I'm sure that's not\n3677.22s: how card carrying machine Learners would\n3679.079s: do this right I'm aware of such a thing\n3681.0s: called like a machine ending task with a\n3683.52s: downstream reward that's not\n3685.2s: differentiable this is an example of one\n3687.119s: and maybe there are clever MLP models\n3689.94s: that could be helping us understand the\n3692.16s: answer to your question about how to\n3693.54s: more strategically approach the hyper\n3695.22s: parameter Space by feeding off of the\n3697.799s: large samples we're starting to stand up\n3699.599s: that contain enough signal to train them\n3701.339s: on yeah\n3703.44s: that would be fun to check out yeah\n3707.4s: yeah so one question on\n3709.94s: one question online from jobs are you\n3712.859s: working on testing and probabilistics\n3714.48s: course such as CRPS\n3716.94s: yeah absolutely yeah\n3719.94s: um yeah I did I didn't mention that for\n3721.74s: super parameterization but uh yeah and\n3724.079s: certainly in the weather prediction\n3725.099s: World everything's moving in that\n3726.66s: direction there's a preprint you can\n3728.579s: check out from nerves in the fall Andre\n3730.74s: grobner at all 2022 that shows with a\n3733.92s: bit of brown noise perturbation into the\n3736.619s: initial condition we can uh get a\n3738.96s: reasonable spread skill and CRPS\n3741.24s: resolved\n3742.92s: um I think it's early days there\n3745.38s: yeah I think uh\n3748.14s: Dale Duran just exploited the 51 the\n3751.079s: existing initial perturbations from the\n3753.24s: ucmwf which has a limit of an ensemble\n3755.94s: size so if you want to perturb a 10 000\n3757.5s: member on top you're going to have to\n3758.7s: come up with your own algorithm and uh\n3761.04s: yeah but yeah CRPS is\n3764.04s: the important thing to Chase\n3767.16s: I'm aware that Peter Demon's been\n3768.72s: involved in the paper too that CRPS was\n3770.579s: directly the objective our machine\n3772.74s: learning model was trained on an L2 loss\n3774.48s: based on that mapping but you could\n3776.579s: equivalently try to train an ensemble to\n3779.22s: be optimized towards a CRPS and uh let\n3782.64s: me blur Your solution\n3784.68s: um but I think it's quite interesting\n3788.099s: maybe just before closing I'd like to\n3790.38s: ask a question so do you think we could\n3792.18s: do better than weather forecasting you\n3793.859s: know because my thinking has been that\n3796.799s: actually data assimilation is pretty\n3798.66s: great you know uh in a sense that it's\n3800.76s: pretty much like machine learning you\n3802.26s: have a loss except that you can be very\n3804.42s: objective in terms of having an\n3806.579s: observation operator right and we don't\n3808.799s: have that mindset and that framework\n3810.42s: currently within the kind of the machine\n3812.46s: learning toolbox right so\n3814.859s: I was always wondering can we even do\n3816.78s: better we can do faster for sure you\n3818.819s: know but uh which is great because then\n3820.559s: you can regenerate on some members and\n3822.96s: Etc but would love to hear your thoughts\n3825.299s: on that so deepmind claims to have done\n3827.04s: better\n3827.88s: you can look at their scorecard they're\n3829.68s: beating ecmwf on 90 of their own\n3832.14s: internal scorecard metrics\n3834.74s: across variables and Lead times so they\n3838.02s: would say we're already doing better\n3839.099s: even without when you describe uh but\n3841.319s: yeah I think there's great opportunities\n3843.24s: in binding machine learning with data\n3845.4s: assimilation I'm aware of at least one\n3847.619s: NOAA Google partnership to that effect\n3850.859s: um yeah am I speaking to your question\n3853.44s: or um yeah\n3855.02s: but it's like what a year this is\n3858.599s: yeah and maybe kind of relate to that\n3860.52s: you still need the initial condition\n3861.78s: right so you still need the model in in\n3864.0s: the n and the assimilation yeah we\n3866.46s: should all we\n3870.54s: should have produced the data sets from\n3873.299s: deterministic models and observing\n3875.04s: systems which only together produce\n3877.02s: these High Fidelity estimates of The\n3879.059s: observed atmospheric state that are\n3880.74s: worth training these machine learning\n3882.119s: models against and that are the source\n3883.799s: of their skill and that that is a\n3886.28s: republican that has produced an\n3888.9s: incredible thing I think\n3890.819s: um and how can we make that public good\n3892.44s: even better and and I don't want to\n3894.78s: compete with one of the thing I'm being\n3895.859s: wrenched out of the Ivory Tower now and\n3897.48s: realizing that in a company you can\n3899.22s: maybe make things that people use and\n3901.079s: have impact and thinking about\n3903.0s: data-driven weather prediction is so\n3904.559s: liberating because you can as a\n3907.14s: stakeholder directly engage in the loss\n3909.059s: function of a machine learning model you\n3910.98s: know I'm talking about a person worried\n3912.599s: about wildfires in California and I want\n3914.88s: to coerce a deterministic model to\n3916.799s: become better at them it's a nightmare\n3918.18s: as you probably all know of twiddling\n3920.04s: parameterizations and hunting for\n3921.54s: something that may give me a bit of\n3923.099s: anomalous skill for a sub phenomenon but\n3925.799s: you can express your preference for\n3927.299s: machine learning attention to pay\n3928.68s: attention to some phenomena I think\n3930.48s: that's liberating interesting I haven't\n3932.76s: seen a proof of content yet that shows\n3934.559s: me that it doesn't just trade off\n3936.0s: against other phenomenon ways that\n3937.38s: afford you but I you know I feel like\n3939.42s: it's likely possible and\n3941.88s: um I think there's a huge category of\n3944.339s: exploration that needs to be done today\n3947.7s: um and again a lot of exciting questions\n3950.46s: if if trying out the gizmos is a barrier\n3953.579s: to getting involved in your motivated to\n3955.079s: please let me know\n3959.0s: let's thank and Mike again thank you"
    },
    {
        "class": "YouTubeVideo",
        "title": "Retrieval of Aerosol Properties Using Invertible Neural Networks",
        "videoId": "jV-aVhk5-6w",
        "url": "https://www.youtube.com/watch?v=jV-aVhk5-6w",
        "publishedAt": "2023-06-02T18:05:23Z",
        "transcript": "5.1s: okay\n6.359s: um I think we could probably just get\n8.04s: started then um I'll just introduce you\n10.44s: guys so today we have uh Romana boyger\n13.32s: who's a tenure track scientist at PSI\n15.78s: and also Rob modini who's a senior\n18.42s: scientist um also at PSI and today\n21.42s: they're going to be talking about um\n23.279s: using invertible neural networks or\n25.26s: retrieval of aerosol properties\n27.539s: um from different measurements so\n29.939s: um without further Ado um you guys can\n33.059s: present for about 40 minutes and then at\n35.64s: the end with whatever time we have left\n37.44s: we could answer questions or have\n40.02s: whatever discussions\n41.7s: um so take it away\n45.899s: thanks a lot Joe\n47.76s: um so yeah as Joe mentioned uh we'll\n51.36s: talk about our recent paper which was on\n55.14s: invertible neural networks\n57.899s: um\n58.92s: since we're sitting in Switzerland I\n62.039s: thought briefly just to give a picture\n63.48s: of of where we are\n66.54s: um as you may not have heard of the pal\n68.4s: Sarah Institute\n70.26s: um so it's a federal Research Institute\n71.939s: we're based in the north of Switzerland\n73.799s: like really just on the border with\n76.08s: Germany\n77.76s: um the institute's mostly known for like\n80.759s: its large-scale facilities so there's a\n83.04s: synchrotron light source and a free\n85.259s: electron laser but we also have a lot of\n88.14s: computing and modeling going on and a\n91.979s: little bit of Environmental Research\n94.799s: um and that's the part that I'm involved\n96.84s: in\n97.799s: um so I come from the laboratory of\n99.299s: atmospheric chemistry\n101.28s: so this is a different part of the\n103.259s: Institute to where Ramana is coming from\n105.659s: so when we started this collaboration\n108.84s: um she was in the laboratory for\n110.159s: simulation and modeling she's now moved\n112.619s: to the laboratory of Waste Management\n114.659s: and it came about because we saw a\n117.84s: presentation from the modeling group on\n120.42s: these invertible neural networks but it\n123.479s: was applied to a different inverse\n125.34s: problem which was like the optimization\n128.22s: of\n129.239s: a particle accelerator operation or\n131.94s: something like this and we thought this\n134.94s: is an interesting solution\n137.04s: could potentially apply to this inverse\n139.44s: problem that we have in aerosol science\n141.56s: and so we started the collaboration and\n145.14s: we'll present the results today\n147.9s: um yeah romano and I are presenting but\n150.959s: there's many others involved in the\n153.3s: project and this is just one sub-project\n156.48s: um in a much broader range of research\n158.52s: activities and so uh just to highlight\n161.34s: our colleagues below who work with us\n164.819s: so yeah as I said on the previous slide\n167.819s: I'm the problem part of this\n169.86s: relationship uh then Ramona is the\n172.56s: solution\n173.42s: so I get to introduce the general topic\n177.08s: and introduce the inverse problem that\n180.3s: we hope to solve and then remind it will\n183.54s: take over and talk about uh the\n187.14s: invertible neural networks and and the\n189.3s: results that we got\n191.64s: um but yeah the focus is on atmospheric\n195.42s: aerosols that's what we're interested in\n198.54s: um and so I like to start with this\n201.18s: Global portrait of atmospheric aerosols\n204.06s: which is just a picture of them on one\n207.54s: particular day of the year in 2018\n212.04s: um and I like this picture because it\n214.8s: shows kind of the complexity of what\n217.5s: we're trying to study when it comes to\n219.239s: aerosols in the atmosphere and in\n221.879s: particular it shows like the extremely\n223.68s: strong spatial variation like for\n226.86s: example on any particular day if we look\n229.799s: at Africa for example the north of the\n233.099s: continent is is uh\n235.86s: we'll have very strong loadings of dusk\n238.44s: coming from the Sahara whereas the\n241.379s: picture in the south of the continent\n242.879s: can be completely different in this case\n245.099s: there was a lot of black carbon coming\n247.14s: from biomass burning\n249.239s: um and yeah so we have this extremely\n252.599s: strong spatial variability which makes\n255.48s: them a very challenging thing to study\n258.359s: and we need to know this spatial\n260.04s: variability\n261.359s: um because obviously if we think about\n264.66s: aerosols over the ocean versus these\n267.18s: black carbon aerosols or the Dust\n269.4s: then the environment environmental\n271.979s: impacts are going to be very different\n274.1s: for example like if we think of their\n276.78s: climate impacts this highly absorbing\n279.979s: smoke is going to be very different to\n282.66s: aerosols over the ocean so we need to be\n285.479s: able to model and understand this\n288.08s: what gets even more interesting in\n290.639s: modern day times is\n292.68s: we kind of want to do this in real time\n294.78s: now\n296.58s: um which is even trickier and a good\n299.759s: example last weekend here in Europe we\n303.12s: occasionally have these episodes where\n304.919s: dust from the Sahara comes up and\n307.56s: travels over Europe\n309.0s: and what happens when this occurs is\n312.72s: the way the models are not taking\n314.52s: account of this dust at the moment and\n317.639s: so we have large forecast errors in the\n320.52s: weather forecast because of this this\n322.74s: also affects things like\n324.78s: uh solar energy production and so on and\n328.56s: so as these things come more important\n331.139s: there's there's a push to try and get\n333.3s: this global distribution in kind of near\n336.18s: real time\n339.3s: how can we do that okay so basically we\n342.9s: need a huge infrastructure to be able to\n344.759s: provide\n345.66s: This Global picture so obviously we need\n348.9s: a model to be able to track aerosols\n352.08s: everywhere around the globe over time\n355.4s: but to make sure that that model is\n358.08s: realistic and reasonable\n360.32s: we need to assimilate observations into\n363.84s: it to make sure that the models are\n365.94s: giving us\n367.44s: um reasonable pictures of the global\n369.36s: distribution\n370.62s: and so I like this schematic which comes\n375.12s: from a very recent review from Ralph\n376.86s: Khan\n378.24s: and he talks about basically the three\n380.58s: pillars that we need\n382.62s: um so as well as the models we need two\n384.479s: types of observations uh the satellite\n387.06s: observations but also observations from\n389.639s: within the atmosphere the satellites are\n392.52s: important because they provide uh very\n396.979s: uh broad coverage in space and time but\n401.28s: the problem is the\n402.96s: the measurements are not very detailed\n404.819s: and so we need to supplement those with\n407.16s: sub-orbital measurements or measurements\n409.319s: from within the atmosphere\n411.68s: so this is the part that we're mostly\n414.66s: focused on uh in our in our research is\n418.8s: on the observation side and\n420.9s: traditionally we come from more the\n423.479s: within the atmosphere part and so in\n426.12s: particular we operate measurement\n428.28s: networks\n429.96s: um for example we we operate a\n432.539s: measurement station on the Jung fro York\n435.259s: which is a famous mountain here in\n438.24s: Switzerland and we've been taking\n440.46s: measurements there for\n442.62s: continuous aerosol measurements now for\n444.84s: the last 25 years\n447.259s: more recently we started to move into\n449.819s: this issue of how we can then combine\n452.16s: such observations with satellite\n453.78s: observations\n455.12s: and there's many details that can be\n457.8s: covered here one thing I'll point out\n459.84s: today\n460.86s: is that amongst all these different\n462.9s: types of observations\n465.3s: um aerosol light scattering is a key\n467.58s: physical process\n468.96s: all right and so that's\n470.94s: an important basis for many of these\n473.099s: observations that are feeding into this\n474.96s: system\n478.68s: okay just show that in a bit more detail\n480.66s: here so\n483.18s: we have many different types of sensors\n485.639s: that are probing our atmosphere which\n489.3s: are based on this principle of measuring\n491.34s: the light that is scattered from aerosol\n494.46s: particles\n495.66s: and the important thing to point out is\n498.24s: that that scattered light depends on the\n501.3s: properties of the underlying aerosol\n504.24s: um so for example how much of the\n506.94s: aerosol is present its size the\n509.639s: refractive indices of the particles that\n511.62s: are present in their shape\n513.839s: um so if we then take these measurements\n516.779s: of light scattering in the atmosphere uh\n519.959s: the trick is we then want to apply\n522.24s: inversion algorithms or we want to try\n525.42s: to retrieve information about the\n528.24s: underlying aerosol properties\n531.18s: foreign\n535.58s: whether it's done using a satellite\n538.44s: remote sensor or ground-based remote\n540.959s: sensing instruments or in-situ\n543.42s: measurements that are taking\n544.74s: measurements of light scattering within\n546.42s: the atmosphere so in all these cases we\n550.32s: want to use inversion algorithms to try\n553.019s: to retrieve information about the\n554.7s: aerosol\n558.86s: so what are some of the approaches that\n562.56s: are used to invert measurements of\n564.959s: scattered light\n566.7s: um\n567.959s: the first one and the one that's\n569.82s: probably used most commonly in remote\n571.98s: sensing at the moment is pre-computed\n573.839s: lookup tables\n575.279s: so here we can create tables where we\n579.24s: take different sets of aerosol\n580.92s: properties and pre-compute different\n585.24s: um\n586.08s: like properties of the light and then we\n588.779s: can try our match our measurement to\n591.06s: these tables and try to retrieve some\n593.16s: information\n594.36s: the advantage of these methods is that\n596.519s: they're very fast this is the quick\n598.26s: process\n599.519s: um so when we're talking about the very\n601.14s: large volumes of data that come from\n604.14s: satellites and different networks this\n607.62s: can be done in near real time\n610.339s: the disadvantage of it is you're\n612.839s: necessarily simplifying and discretizing\n615.899s: your solution space and so this can lead\n618.6s: to some inaccuracies\n623.16s: the next method that's been applied\n626.459s: um and which in order to improve the\n629.58s: accuracy is to do a full physics-based\n632.88s: retrieval\n633.959s: and in this case the key point is we\n636.839s: need a Ford model of the underlying\n638.519s: physics\n639.62s: so the classic example is me Theory okay\n643.32s: where we assume that we have spherical\n645.0s: particles and then we're able to\n647.339s: simulate the scattered light from these\n649.98s: particles\n651.18s: then we can use different iterative\n652.98s: solvers in order to solve this inverse\n655.98s: problem and this can be done very\n658.26s: accurately and so a current\n661.44s: state of the art example is the grasp\n663.66s: algorithm this stands for the\n665.88s: generalized retrieval of aerosol and\n667.98s: surface properties\n669.36s: it's a very versatile algorithm so you\n672.06s: can put in many different types of data\n674.519s: whether it's from remote sensing\n676.8s: instruments or in-situ instruments and\n680.1s: you can then solve this iterative\n682.079s: process and as an output have some\n685.26s: properties of the aerosol and also of\n687.72s: the underlying surface of the Earth\n690.079s: and these things work really well they\n693.3s: can be very accurate but we come up we\n696.779s: then come up with computational speed\n699.24s: problems so when we're based on me\n701.82s: Theory and we're making a simplification\n704.1s: that we have spherical particles\n706.579s: then this can be done relatively quickly\n709.62s: but if we want to simulate more\n711.6s: realistic aerosols with more complex\n713.579s: shapes than speed very quickly becomes a\n717.66s: big problem\n719.339s: so\n721.74s: more recently where a lot of researchers\n725.399s: started to develop is whether we can\n727.56s: then use machine learning based models\n729.899s: to solve this inversion process\n732.68s: and the hope with such models is that\n735.48s: once they're trained they're then going\n737.76s: to be able to be operated much more\n740.94s: quickly than full physics based\n743.04s: retrievals\n744.32s: and hopefully with similar levels of\n747.959s: accuracy\n749.399s: um this\n751.14s: but this is still a question whether\n753.48s: this is going to how successful these\n756.18s: approaches are going to be\n757.98s: um\n758.579s: and also mention it doesn't need to be\n760.5s: either or so very likely it's probably\n763.68s: going to be a combination of different\n765.06s: approaches that works that ends up being\n767.639s: the most effective way to solve these\n769.44s: inverse problems\n773.22s: coming back a bit to our towards our\n775.32s: research at PSI\n777.899s: um\n778.92s: thinking about these different inversion\n780.899s: products the question we like to ask is\n784.8s: how can we then validate the retrievals\n787.98s: and so if we're thinking in terms of a\n789.899s: remote sensing retrieval\n791.839s: what we're actually doing there is we're\n794.22s: probing a column of the atmosphere\n797.1s: so for example a satellite is is looking\n799.92s: at some\n801.68s: looking at some of the like the light\n804.3s: scattered through a column of the\n806.399s: atmosphere\n807.6s: if we then perform a retrieval on that\n810.06s: measurement what we're retrieving is\n812.459s: some kind of average aerosol properties\n814.62s: throughout that column\n816.899s: the difficulty with this is It's hard to\n819.899s: independently measure\n821.66s: such average properties and so it's hard\n825.3s: to validate such retrievals for example\n828.48s: we could take a plane and try to fly it\n831.12s: through the same column\n833.1s: um but this is going to be a very costly\n834.779s: thing to do and we're always going to\n837.6s: have a a question do the measurements\n840.779s: match up precisely so validation is kind\n843.72s: of a very tricky thing\n846.06s: one approach that we've tried to take in\n849.42s: order to validate these different\n850.74s: retrievals is to take it back to the\n853.8s: laboratory\n855.66s: and so in particular we've developed a\n858.139s: prototype laboratory based instrument\n861.86s: that allows us to perform in-situ light\n864.779s: scattering measurements so in this case\n866.7s: what we're doing is we're drawing\n868.139s: aerosol from the atmosphere into an\n871.2s: instrument which is known as a polar\n873.24s: nephilometer\n874.5s: and where shining laser light onto that\n878.1s: aerosol sample and then measuring the\n881.76s: distribution of the scattered light\n883.139s: coming off that\n885.12s: the idea behind this is that because\n887.699s: we're in a laboratory we can then use\n889.8s: very well controlled and defined\n891.779s: aerosols\n893.519s: um and we can also have co-located\n895.32s: independent measurements of the\n897.6s: properties of that aerosol so that we\n899.579s: can validate the inversion\n903.899s: um and so yeah this is a schematic and\n906.54s: and a picture of the instrument that\n908.22s: we're using at the moment and the two\n910.74s: things that we measure are what's known\n913.68s: as the\n915.18s: um the scattering phase function uh\n917.76s: which is the angular distribution of\n920.579s: scattered light coming off that aerosol\n923.339s: sample and we also measure the polarized\n926.94s: phase function\n928.38s: um and so this is a ratio of two\n930.66s: different polarizations of that\n933.0s: scattered light intensity\n935.459s: um and so this is the measurement data\n937.26s: that we're dealing with\n938.639s: if we then want to test a validation or\n941.04s: if we want to validate an inversion\n942.6s: sorry how can we do this so we can set\n946.38s: up an experiment where we have a\n948.72s: particular aerosol with well-defined\n951.24s: physical properties\n953.339s: um so a well-defined size distribution\n955.26s: shape and refractive index\n957.66s: we can put it into our polynephalometer\n960.3s: we can measure the phase function in the\n962.82s: polarized phase function\n964.44s: and then we can input those measurements\n966.6s: into an inversion algorithm and compare\n969.18s: the retrieval results\n970.76s: with independently measured values or\n974.04s: known values\n975.72s: and so these are the type of experiments\n977.76s: that we've been doing\n979.68s: um and we've just started to to get our\n982.98s: first results from this process\n985.5s: um and so just to show some examples\n988.44s: here so if we start first of all with\n992.16s: spherical testerosols so spherical\n994.98s: particles which are quite simple to\n996.66s: model\n997.519s: then we can\n999.779s: we can demonstrate that we can obtain\n1002.079s: accurate retrievals using the grasp\n1004.82s: algorithm\n1005.92s: so\n1007.459s: there's a lot of detail on this\n1009.32s: bottommost plot but the main thing to\n1011.6s: point out is that the independent\n1013.279s: measurements or the literature values\n1015.68s: are in black and gray and different\n1018.5s: types of grasp retrievals in the blue or\n1021.259s: the red\n1022.1s: and we can demonstrate that we're able\n1024.14s: to retrieve the aerosol size\n1026.299s: distribution and the refractive index\n1029.299s: both the real and the imaginary part\n1032.02s: with good accuracy\n1035.12s: this is all well and good but if we then\n1038.179s: take the same retrieval method which is\n1041.179s: based on me Theory so assuming that we\n1043.4s: have spherical aerosols\n1045.199s: and if we then apply it to more\n1048.319s: to aerosols that we know are not\n1050.36s: spherical\n1051.5s: for example these fractal shapes\n1054.32s: um we see that uh the the inversion no\n1057.98s: longer works well which is as expected\n1061.46s: um the it's relying on an assumption\n1064.1s: that we have spherical particles\n1066.32s: so what this means is that we need to\n1068.059s: move to more complex Optical models in\n1070.94s: order to be able to simulate such\n1073.34s: types of particles which again brings up\n1077.0s: the problem of computation speed\n1080.0s: because the inversion Works relatively\n1082.039s: quickly if it's based on me Theory but\n1085.1s: if we're using more complex models then\n1087.559s: the inversion starts to slow down\n1092.299s: which brings us to the research\n1093.799s: questions of this particular project and\n1096.32s: so given this problem we then thought\n1099.799s: can we develop an accurate and fast\n1103.52s: machine learning approach that's going\n1106.4s: to solve this inverse problem of aerosol\n1108.62s: light scattering it's our first research\n1111.02s: question\n1112.16s: we then want to see is there a speed\n1114.02s: benefit from using such a model and how\n1117.32s: do the results compare to physics-based\n1119.24s: retrievals like grasp and also how do\n1122.299s: the results compare to\n1124.36s: Independent real measurements\n1127.82s: so they're the research questions I now\n1131.24s: hand over to Romana and she'll talk\n1134.059s: about the paper and our results\n1145.76s: okay so thanks a lot\n1148.34s: um so to answer this research questions\n1152.72s: um let us first put this in a bit more\n1155.36s: mathematical framework our whole problem\n1158.38s: so let's say we have our input our cause\n1162.02s: our aerosol properties that we will\n1164.419s: denote by X and solving the forward\n1167.299s: problems so retrieving our measurements\n1169.64s: is then just applying some function f of\n1172.16s: x is equal to y\n1173.84s: and the inverse problem so going from\n1177.2s: the measurements back to our aerosol\n1179.539s: properties would then be applying\n1182.419s: something like the inverse function\n1185.419s: and from a mathematical point of view\n1188.66s: the inverse problem is more often harder\n1192.14s: to solve than the forward problem and\n1194.66s: the reason lies in the ill postness\n1197.419s: which is here defined according to other\n1200.179s: marks\n1202.1s: um and inverse problems are ill post\n1204.26s: because\n1205.34s: um there either exists no solution the\n1207.38s: solution is not unique or small\n1209.72s: perturbations in the data can lead to\n1211.94s: large errors in the solution and that is\n1214.4s: mainly the case if we deal with\n1216.02s: measurement data\n1219.2s: um but nevertheless we have\n1222.44s: um\n1224.0s: a ways to to solve inverse problems so\n1227.12s: there are different solution approaches\n1228.799s: so there is this classical approach\n1231.02s: using regularization methods meaning\n1233.36s: that we solve some optimization problem\n1236.799s: where we use the regularization uh term\n1240.2s: here\n1241.58s: um there is the spatial approach where\n1243.62s: we use random numbers and probability\n1245.72s: functions\n1247.1s: and the latest approach which developed\n1251.84s: quite fast over the last years was the\n1254.419s: machine learning approach like for\n1256.28s: example using neural networks that\n1258.86s: approximate either the forward\n1260.919s: function f or the inverse function\n1266.9s: and\n1268.28s: well the the big disadvantage of the\n1270.5s: first two approaches is that we need a\n1273.2s: lot of knowledge and that they can be\n1276.5s: computationally very expensive\n1279.02s: uh whereas for a machine learning\n1281.12s: approach we do not need any prior\n1282.919s: knowledge but we need of course some\n1284.78s: data but once our models are trained\n1288.02s: um\n1288.62s: we need little computational effort\n1292.94s: and so the idea here was uh also to to\n1297.2s: use machine learning\n1299.48s: um because then we get a fast and\n1301.82s: accurate solution to our aerosol\n1304.82s: property uh retrieval and in this case\n1308.78s: our goal was to not only solve the\n1311.24s: inverse problem but to also have a model\n1313.94s: for the forward problem\n1316.28s: and\n1318.08s: um there are different machine learning\n1321.919s: architectures especially in neural\n1324.14s: network architectures that can do\n1326.539s: exactly that so solving the forwards and\n1329.0s: the inverse model at the same time like\n1331.4s: for example Auto encoders and so but we\n1335.78s: decided to use those invertible neural\n1338.48s: networks that were introduced by Arizona\n1340.28s: in 2019.\n1342.919s: and so how do those invertible neural\n1346.52s: networks work\n1347.72s: so maybe let's start by um\n1351.7s: introducing again forward neural\n1354.14s: networks which you might all be familiar\n1357.14s: with so we have here our input layer we\n1360.2s: have different hidden layers uh that are\n1363.02s: densely connected meaning each neuron is\n1365.539s: connected\n1366.98s: um with each neuron of the following\n1368.72s: layer and we have some output layer and\n1372.5s: and with this kind of architecture we\n1374.84s: can in principle approximate any\n1376.96s: function due to the universal\n1379.76s: approximation theorem\n1381.799s: and we learn the rates and the biases\n1384.34s: within the network by optimizing such a\n1388.94s: cost function which compares the\n1391.76s: predicted and the true output\n1395.539s: so this is how normal feed forward\n1397.58s: neural networks work invertible neural\n1400.52s: networks work a bit different so we have\n1403.159s: again our input and for the hidden\n1406.1s: layers here we have some so-called Alpha\n1408.919s: and coupling plugs and permutation\n1410.48s: layers and those are the uh most those\n1415.52s: are fine coupling plugs are the most\n1417.32s: important parts of this invertible\n1420.2s: neural networks because they guarantee\n1422.6s: Us in the end the invertibility and this\n1425.299s: is how it looks like so we have here our\n1428.419s: input that is split up into two parts U1\n1431.36s: and U2 and they are connected via some\n1434.96s: mathematical expressions like\n1436.76s: exponential function multiplication\n1438.679s: summation but also these functions s and\n1441.26s: t and in the end we get some outputs so\n1444.02s: here you see the mathematical formula\n1446.0s: and as one and T1 and S2 and T2 those\n1450.38s: are neural networks themselves\n1453.98s: and due to this\n1455.96s: um\n1456.62s: special structure we can compute the\n1460.039s: inverse analytically so here we have the\n1463.28s: formulas\n1464.72s: and yeah so so this is basically the\n1467.96s: trick behind those invertible neural\n1470.059s: networks\n1471.28s: the permutation layers in between they\n1474.62s: guarantee us that we do not split up the\n1477.44s: input always in the same way\n1481.0s: and what we need that the invertibility\n1484.82s: really works is\n1487.039s: um we need to have\n1489.08s: input and output to be the same\n1491.539s: Dimension so we need to add some padding\n1493.82s: variables either on the input or output\n1496.159s: side\n1497.179s: and on the output side we also have such\n1500.059s: a latent space that accounts in\n1501.62s: principle for any information that is in\n1505.46s: the input but is not shown\n1508.46s: or not visible in the output\n1512.78s: and now the last function is a bit more\n1516.159s: complicated than we had before so first\n1520.1s: of all we have again the same term as\n1522.62s: here so we compare the true with the\n1524.84s: predicted output but then we also want\n1528.08s: to compare the true and the predicted\n1530.299s: input\n1531.98s: um we have here some reconstruction loss\n1534.62s: so we we give the true input compute the\n1538.58s: forward model the and then again the\n1541.82s: inverse model and compare\n1543.98s: um if we get again something similar to\n1546.62s: the true input\n1548.96s: um here this artificial last terms\n1551.0s: ensures that not much information is\n1554.9s: embedded in the in the in the padding\n1557.96s: variables and this last term makes sure\n1561.5s: that our latent space follows a\n1563.36s: pre-scribed distribution\n1569.12s: um yeah and with such a neural network\n1572.24s: architecture we are now able to solve\n1575.179s: the forward and the inverse problem at\n1577.039s: the same time by only training one\n1579.5s: neural network\n1581.86s: and this is how we did it then for our\n1585.559s: problem from our soul physics so the\n1588.26s: first step in our methodology was to\n1591.08s: compute the training data set\n1594.38s: um so we chose some aerosol properties\n1596.419s: within certain ranges we used in the\n1598.46s: physics-based model to to create our\n1600.74s: simulated measurements and we use the\n1603.62s: properties and the measurements\n1605.96s: um for for training our neural networks\n1608.6s: so in total we had 100 000 data points\n1611.24s: where we used 80 for training and\n1614.059s: validation and 20 for testing\n1617.779s: um and once our network was trained we\n1622.52s: can then use it\n1624.679s: um or prediction so we can either give\n1627.02s: the errors or properties and get some\n1629.9s: predictive measurements or we can give\n1633.02s: it some measurements and it will\n1635.0s: retrieve the aerosol properties\n1639.62s: and this is how our data set looked like\n1643.34s: so we assumed that we have\n1646.72s: mono modal spherical pure component\n1649.4s: aerosolus with a size distribution\n1651.86s: consisting of some volume radius and\n1655.279s: geometric standard deviation and a\n1657.5s: refractive index for three different\n1659.48s: wavelengths this was our input and the\n1663.38s: output were the simulated laboratory in\n1666.679s: C2 measurements so consisting of the\n1668.659s: scattering phase function and the\n1670.1s: polarized phase function where we have\n1672.32s: one data point pairing\n1676.76s: okay and yes here are the results so the\n1681.5s: first step to get good results was to do\n1684.679s: a data pre-processing\n1687.38s: um so for the polarized no for the\n1689.84s: scattering phase function we needed to\n1691.46s: apply the logarithmic function and then\n1694.46s: for both the scattering and the\n1697.159s: polarized phase function we use the\n1698.9s: standard scalar so this was really a\n1701.24s: crucial step in order to get good\n1703.279s: results with the neural network\n1707.419s: and yeah here here is the result first\n1710.24s: of all for the forward model so we get\n1712.34s: an r squared value this coefficient of\n1714.38s: determination of 0.997 where one is the\n1717.98s: best we can get so this is already quite\n1719.96s: good and the relative error of the\n1722.12s: scattering phase function is 1.5 percent\n1724.76s: and the absolute error 0.06 so both lie\n1729.2s: below the\n1730.9s: expected measurement device errors and\n1734.24s: for the inverse model we get a squared\n1736.159s: value of 0.993\n1739.1s: which is also quite close to one and\n1743.059s: here in this table you see for the\n1745.4s: aerosol properties\n1747.44s: um the absolute error in the middle and\n1749.36s: below for comparison the weighted mean\n1752.059s: absolute percentage error which is for\n1754.94s: all of them below 1.5 percent\n1759.98s: and here you see a qualitative\n1762.5s: representation so for different\n1764.799s: wavelengths you see the\n1767.5s: scattering phase function and the polar\n1769.7s: rest phase function and here is size\n1771.32s: distribution and you can hardly see that\n1774.62s: the blue line so the true\n1777.02s: um\n1777.679s: test functions behind yes just because\n1781.399s: our fit was really good Alpha One one\n1784.76s: already sees here that here for example\n1787.159s: one sees that our predictions are a bit\n1789.74s: noisy but that comes from the fact how\n1792.679s: we chose to model\n1795.799s: in the end our data set so we really\n1798.26s: took one data point per angle and not a\n1801.02s: smooth function\n1804.74s: and then we've further played around a\n1807.559s: bit with our aerosol data set so we\n1810.98s: wanted to make it more similar to real\n1812.899s: measurements\n1815.24s: um therefore we\n1817.22s: um looked at cases where one or two of\n1820.76s: the wavelengths are missing and we also\n1823.58s: considered the case where we would only\n1825.38s: have the scattering phase function\n1826.94s: available or the polarized phase\n1828.86s: function\n1830.0s: and in addition we\n1832.46s: um\n1833.059s: removed some angles at the beginning the\n1835.82s: end and in the middle because with our\n1839.0s: measurement device we cannot measure it\n1840.86s: those angles\n1844.22s: and here you see the results for this\n1847.1s: different\n1847.899s: showcases so on the y-axis we have the r\n1851.48s: squared value and on the x-axis you have\n1854.419s: the different wavelength combinations\n1857.299s: and so for one wavelength here on the\n1859.58s: left a combination of two wavelengths\n1862.1s: and here three wavelengths on the right\n1864.399s: and the colors so red are the trust the\n1870.26s: polarized phase functions blue just the\n1872.36s: scattering phase function green\n1874.159s: recombination of both and brown is where\n1878.539s: we have everything available so also all\n1882.26s: the Angles and we see here\n1885.2s: um as one would expect that for the\n1887.419s: forward model it of course doesn't make\n1889.7s: a big difference\n1891.32s: but for the inverse model the situation\n1895.039s: is different so here you see the\n1897.799s: absolute errors for the different\n1900.7s: aerosol properties and we can clearly\n1904.039s: see if we look at the red circles that\n1906.919s: we cannot predict the volume if we just\n1910.7s: have to polarized phase function which\n1912.38s: also makes sense from the definition of\n1914.36s: the polarized phase function\n1916.82s: and we also see that it is harder to\n1919.82s: detect the the radius and the real part\n1923.36s: of the refractive index if we have just\n1925.94s: given the full polar rest phase function\n1929.179s: and what we also see which might also\n1932.779s: not be very surprising is that\n1935.539s: um\n1936.08s: the best results can be achieved if we\n1939.2s: have both functions available and and\n1942.919s: the more wavelengths we have the better\n1945.44s: the results are\n1949.52s: yes so so far I'll show you the results\n1952.88s: which we had in a paper we also did it\n1955.279s: then for a bit more complicated case\n1957.679s: where we had a bimodal\n1959.72s: um aerosol distribution but there are\n1961.64s: the results looked quite similar that's\n1963.44s: why I will not show it here\n1965.899s: um instead I want to show a more recent\n1969.14s: result where we looked at the\n1972.14s: performance of such networks for real\n1974.48s: measurements\n1976.76s: um\n1977.899s: which is not yet published so here you\n1981.38s: see four different measurements so the\n1983.84s: blues dark blue solid lines are are the\n1986.72s: measurement data and here we we first we\n1991.7s: wanted to apply the network we had in a\n1993.799s: paper but this was not really possible\n1996.08s: because uh the range of the aerosol\n1999.019s: properties that we measured here was\n2000.58s: outside the training range we used for\n2003.34s: training our neural networks so we\n2004.96s: needed to train new neural networks and\n2007.899s: we we played around with different\n2011.5s: um aerosol property ranges but also with\n2014.14s: different\n2015.34s: um data set sizes\n2018.46s: and in addition to training\n2021.1s: um the invertible neural network we also\n2023.26s: chained uh neural networks that\n2026.019s: approximate only the inverse\n2028.559s: function and this is what you can see\n2031.6s: here because they give a bit of a better\n2035.14s: results and and to\n2038.32s: um be able to approximately the inverse\n2042.039s: Direction the trick was to add in\n2044.019s: addition to structure feed forward\n2045.94s: neural network add a gaussian noise\n2048.339s: layer so that was a crucial point\n2051.94s: and so what you can see here now is so\n2056.139s: that the dark blue dotted lines are then\n2058.96s: the retrievals from uh with our forward\n2062.74s: neural network\n2064.419s: and you see that for example for this\n2067.419s: case and this case they match quite well\n2070.3s: but but here for measurement six and and\n2072.879s: eight there is still some room\n2075.52s: um for improvement\n2078.94s: and and yeah yeah somehow still working\n2082.899s: on improving that\n2085.839s: so to to summarize now and and answer\n2089.02s: some of the research questions so\n2092.8s: um yes we were able to develop a machine\n2095.26s: learning model that solved the inverse\n2097.42s: and forward problem uh for Arizona light\n2100.359s: scattering we did it with invertible\n2101.92s: neural networks but we did it all the\n2103.72s: way forward neural networks and calcium\n2105.52s: knife layers\n2107.56s: um we also saw by using the machine\n2110.5s: learning models we we saw an increase in\n2113.5s: speed\n2114.7s: um it compared to grasp it was one\n2117.7s: thousand times faster\n2119.44s: and it actually showed quite similar\n2123.28s: results\n2124.599s: um like physics based retrievals and we\n2128.74s: also saw that we can if we have the\n2130.78s: right models we are able to retrieve the\n2133.54s: aerosol properties from real\n2135.94s: measurements\n2138.52s: and as mentioned uh most of the work is\n2142.119s: is published in in this publication\n2146.8s: and with that I will hand over to Rob\n2150.099s: again because he will show you\n2152.14s: um\n2152.98s: some of the currently ongoing work of\n2156.579s: his laboratory\n2170.5s: yeah so very quickly\n2172.72s: um just two slides to kind of finish off\n2175.3s: with\n2176.619s: next steps and kind of future outlook so\n2180.52s: um yeah that first part of the project\n2182.32s: worked really well and and we could kind\n2185.079s: of demonstrate successful uh proof of\n2188.14s: concept with this approach\n2190.54s: um which was really cool\n2192.4s: um and so now we think to move Beyond\n2196.06s: spherical shapes where the light\n2198.52s: scattering problem is already pretty\n2200.2s: well defined to more complex particle\n2203.38s: shapes that are more\n2206.16s: perhaps more representative of the\n2209.02s: different types of shaped aerosol\n2211.24s: particles we can find in the atmosphere\n2213.66s: and so this is this is where our current\n2216.339s: efforts are focused and this involves uh\n2221.079s: performing simulations\n2223.72s: um of of these light scattering\n2226.359s: distributions uh four different shaped\n2229.3s: aerosols we are using a multiple sphere\n2233.32s: T matrix model to perform these\n2235.72s: calculations which is takes a lot more\n2239.14s: time than the me calculations we're\n2242.079s: doing for the spherical part of the\n2243.64s: project\n2244.5s: at the same time we're measuring\n2247.24s: these aerosols like this in the\n2250.06s: laboratory and starting to build up our\n2253.18s: training data set so that we'll be able\n2255.76s: to train some new invertible neural\n2259.0s: networks using these more complex\n2261.64s: aerosol models\n2265.9s: um that's the future outlook there\n2268.78s: also very briefly mentioned some\n2271.18s: completely different\n2273.46s: um so this was kind of the first\n2275.46s: collaboration of its kind that we've\n2278.079s: done it that we did at PSI and\n2281.2s: um we think it worked pretty well\n2284.079s: um and so then we thought romano and I\n2286.3s: thought about what are some other\n2288.52s: problems that we could try to combine\n2290.859s: some of her machine learning expertise\n2294.06s: uh with some of our aerosol data sets\n2297.76s: um and one idea we came up with was\n2302.079s: using the measurements we we collected\n2304.119s: our research station at Young freyuk so\n2308.099s: here's a a picture of the research\n2311.079s: station\n2312.339s: um so this is the where we have\n2314.92s: over 25 years of continuous measurements\n2317.74s: now\n2318.94s: um and one big issue we get up there is\n2321.64s: we're conducting these measurements\n2324.52s: um and then we have these dust events\n2326.92s: that occur and you can see in the\n2330.16s: picture here in the top right corner\n2331.9s: looking down the glacier so on a clear\n2334.359s: day this is what it normally looks like\n2336.76s: quite Sunny after the passage of a\n2339.64s: Saharan dust event uh you'll see it's\n2342.579s: very yellow and kind of yellow snow and\n2345.64s: ice where the dust is deposited\n2348.52s: um and for these type of strong events\n2350.619s: it's obviously very obvious when a dust\n2352.66s: event has occurred uh but there's many\n2355.18s: weaker events which are much harder to\n2357.099s: predict using the measurements\n2359.74s: um or any other uh type of indicator\n2362.2s: actually\n2363.579s: um and so we're now going back over our\n2365.859s: old measurements\n2367.48s: um and applying uh different types of\n2370.119s: models\n2371.38s: um to try and identify these states and\n2375.7s: very interestingly using some\n2377.68s: unsupervised methods to see if we can\n2380.32s: get a model that does a better job of\n2382.9s: picking out these dust events than we've\n2386.44s: been able to do\n2388.18s: um manually as humans\n2390.76s: um and so this is something that romano\n2392.859s: and I started but Romano's moved on now\n2395.74s: to another Laboratory\n2397.96s: um but we have\n2399.839s: a master student Andrew Zia who's who's\n2403.18s: working with us now\n2405.16s: um and yeah I don't have any results to\n2408.64s: show yet but just to present it as an\n2411.7s: example of how we try to combine our\n2415.8s: in-situ measurements with some of the\n2418.359s: data science and machine learning\n2419.859s: activities uh ongoing at PSI\n2424.54s: okay so yeah thank you very much for\n2428.079s: listening and for your attention\n2430.54s: um and if you have any questions we're\n2432.76s: happy to answer them\n2437.52s: great thank you so much\n2440.26s: um see if there's any questions\n2445.72s: um yeah maybe if there's any questions\n2447.46s: from online first\n2451.0s: uh Jatan yeah go ahead\n2455.02s: thanks for the great talk\n2456.94s: um I had a question for Romana uh I\n2460.18s: think I missed your\n2462.22s: slide about like how the scaling is\n2465.099s: really important\n2467.2s: um maybe could you like uh walk us\n2469.72s: through uh like you know what was\n2472.06s: important in that in that slide or or\n2475.24s: like in general how you found that\n2477.46s: pre-processing the data affects the\n2479.56s: results\n2482.74s: and yeah\n2485.56s: here here is the slide\n2487.839s: um so I I mean here here you can already\n2490.72s: see\n2493.54s: we cannot we cannot see your slides yeah\n2495.76s: all right sorry\n2498.339s: I will\n2502.42s: No it should be tested\n2506.68s: right yeah you should see it yeah yep\n2510.28s: um so so here you see for example the\n2512.98s: the\n2514.0s: face function at a scattering phase\n2517.0s: function and you see already see here\n2518.5s: for them from the plot that the\n2521.8s: functions are not really distinguishable\n2524.56s: and and so if if I take the logarithm\n2527.619s: already from those functions\n2530.74s: um then one can distinguish all the\n2533.2s: functions much better so that that's the\n2536.26s: first point in doing the pre-processing\n2538.18s: and the other thing is if if you look\n2539.74s: now at the scale so if I take the\n2542.079s: logarithm I'm somewhere between minus 14\n2544.359s: and minus 26 for the face scattering\n2547.06s: phase functions but for the polarized\n2550.119s: phase functions I'm somewhere between -1\n2551.98s: and 1. so the ranges are quite different\n2554.5s: or not quite but but they are different\n2556.96s: and then therefore we then decided to do\n2559.599s: another scaling step in this case we\n2562.18s: took the standard scalar to just have\n2564.28s: all the functions at the same scale and\n2566.8s: that makes it in in general better for\n2568.96s: for neural networks and the easy airport\n2570.82s: chain\n2573.94s: so so we also tried it without doing all\n2576.46s: those steps but the results were much\n2578.619s: worse\n2580.0s: yeah and and no this is and I'm\n2582.52s: wondering if you did like like in some\n2584.74s: sense consistency with like the physics\n2587.319s: because you're like yeah there's a\n2589.18s: numerical reason I'm sure but like yeah\n2592.18s: the sensitivity to log of uh the\n2594.64s: polarization like does it have any\n2598.0s: um physical meaning uh or no this is\n2600.579s: just a convenient numerical tool\n2603.339s: to take in the logarithm I think it it's\n2606.94s: quite uh standard to do it for for\n2609.28s: scattering measurements\n2611.56s: yeah yeah yeah no I believe yeah I think\n2614.44s: this is great and I feel like you know\n2615.94s: this is one of those happy accidents\n2617.619s: that work but I'm just wondering like if\n2619.3s: this means anything in terms of\n2622.359s: um or maybe not maybe it doesn't have to\n2625.0s: um I don't know yeah yeah but it means\n2628.06s: in terms of physics\n2629.68s: yeah there probably would be if you I\n2633.46s: mean potentially but yeah I mean\n2636.099s: you would need to to go through\n2639.819s: the the equations of me Theory and and\n2643.599s: see if there is some physical basis\n2645.22s: behind doing something like that\n2647.56s: um we didn't do that\n2649.839s: but it worked\n2653.14s: yeah awesome this is great thank you\n2661.5s: oh yeah Romano I'm wondering if you\n2664.359s: could elaborate on the um gaussian noise\n2667.359s: layer step and like what did that help\n2670.66s: you with and why was that so critical\n2672.4s: for the observations\n2675.7s: um and in principle when you want to to\n2678.16s: solve an inverse problem you have this\n2680.619s: this uh problem of ill postness and so\n2683.44s: if if you would\n2685.3s: um\n2685.9s: use adjust the feed forward neural\n2688.599s: network\n2689.859s: um you without any any tweaking then\n2694.599s: then you would get into trouble if if\n2696.88s: you enter some noisy data because then\n2699.04s: this the results can be quite\n2701.319s: um different to what they should be and\n2703.54s: and by adding such a gaussian noise\n2705.94s: layer what what you're in principle do\n2707.92s: is you add some noise to your input\n2710.2s: already\n2711.7s: and and that makes it in general much\n2714.04s: more stable so in in the end you do some\n2716.5s: kind of regularization\n2720.16s: and then that helps a lot to make a\n2722.98s: network more stable\n2726.599s: estimate error at all if\n2729.819s: sorry or can you use that to estimate\n2732.099s: like uncertainty in your retrieval\n2737.44s: you mean if I can use the the gaussian\n2740.26s: noise layer to estimate some\n2742.54s: yeah yeah\n2744.24s: no I don't think so\n2748.66s: no no it's it's it's in principle just\n2751.54s: an additional layer in in your network\n2755.079s: for for estimating\n2757.54s: really the uncertainty one would use\n2760.66s: some uncertainty quantification method\n2762.819s: so one would need really to propagate\n2764.92s: some some noise at the beginning\n2773.2s: does anyone else have questions online\n2777.099s: uh I have one question actually so for\n2779.92s: someone who's not like really familiar\n2781.54s: with the invertible neural networks\n2783.88s: um the way you um from this presented\n2785.98s: from this presentation it kind of seems\n2787.72s: like almost like a silver bullet\n2789.22s: solution like you're able to get two\n2791.2s: from one two for one like the forward\n2793.359s: and the inverse so what potential\n2795.94s: pitfalls are there like from your\n2797.68s: experience and when would you like\n2799.18s: Resort back to using like the more\n2801.46s: classical approach or a Bayesian\n2802.839s: approach\n2806.02s: um\n2806.68s: I mean if you know all the physics\n2809.14s: behind your your problem and and\n2811.96s: um calculating with all the physics you\n2814.9s: know the the forward problem is not not\n2817.78s: really computationally expensive\n2822.22s: then\n2823.72s: I would go with your\n2826.24s: just physics-based model and use some\n2829.119s: classical approach\n2833.98s: um\n2835.079s: on the other hand if you already have a\n2838.0s: lot of measurements for example then of\n2840.22s: course it's worth trying something like\n2842.079s: an invertible neural network\n2845.02s: um but but I think the somehow a problem\n2848.2s: with the invertebral neural network is\n2850.119s: that you have a lot of of hyper\n2852.099s: parameters then you that you can choose\n2855.4s: um because it's not clear how many of\n2858.16s: those um have fun coupling plugs you you\n2861.52s: will need how many of and how many of\n2864.099s: the permutation layers and also how you\n2866.44s: choose the the neural networks in\n2869.079s: between your plugs I'm I mean we we made\n2871.96s: our problem easier because we we decided\n2874.0s: to use one neural network for all the s\n2876.94s: and t but in principle you could choose\n2879.7s: four different ones and then you get a\n2881.8s: lot of hyper parameters that makes it\n2887.56s: um yeah computationally expensive to\n2890.079s: train such neural networks or or to find\n2892.54s: the right hyper parameters to train it\n2897.94s: yeah and I can also say like we hit the\n2900.16s: limit a bit\n2901.54s: I mean this so one this was using so the\n2906.28s: range of aerosol parameters that we\n2908.02s: train this network over\n2909.94s: it initially was quite narrow\n2912.22s: and we then had a thought okay it would\n2915.099s: be great if we made this very Broad\n2917.619s: so that we wouldn't have to train\n2919.96s: different networks for for different\n2922.24s: types of situations and measurements and\n2925.24s: stuff like this\n2927.04s: um and I think at this point\n2929.44s: yeah we started to approach the limit of\n2932.859s: like what we could achieve with the\n2935.92s: invertible neural network\n2938.319s: um without doing a full optimization of\n2940.72s: all the hyper parameters and so on\n2944.14s: um and then at some point we reverted\n2946.72s: back to a standard uh Ford neural\n2952.119s: network to do this\n2954.64s: um\n2955.54s: yeah so they\n2957.819s: yeah there is there was that limit that\n2961.18s: we got to eventually\n2963.22s: I see\n2975.94s: any uh final questions\n2982.66s: um if not\n2983.92s: I have one more question if you guys\n2986.02s: have time so\n2988.48s: um\n2989.14s: do you think there's any implication for\n2991.66s: invertible neural networks for like\n2993.339s: maybe explainability\n2996.579s: um like EX in terms of the physics like\n2999.339s: if there's kind of like\n3000.72s: more unknown physics\n3002.76s: or if you're comparing different\n3004.2s: physical models like I'm thinking in the\n3006.3s: context of like microphysics\n3008.64s: um or like Cloud microphysics for\n3010.74s: example where the physics are kind of\n3012.3s: unknown or uncertain so do you think\n3014.819s: invertible neural networks have any uh\n3017.28s: kind of implication for that\n3018.92s: explainability portion or I don't know\n3021.96s: if you have any thoughts on that if not\n3023.64s: that's totally fine\n3027.0s: a good question\n3032.339s: I mean I I\n3034.98s: maybe you want to say something no no I\n3038.28s: I have not really thought about it so\n3041.04s: yeah I mean okay no\n3043.44s: I can't speak from the kind of machine\n3045.839s: learning point of view I mean one step\n3047.819s: we tried to take was like\n3050.22s: which as the next step was\n3053.46s: um to try to\n3055.859s: so for example if we like if we\n3061.079s: start with the physics based model\n3064.2s: um and we input a phase function that\n3066.359s: corresponds to like a more complex\n3067.92s: aerosol for example like a bimodal\n3070.26s: aerosol\n3071.579s: and we only try to retrieve a monomodal\n3074.099s: solution\n3075.18s: then we know that this physics-based\n3077.64s: model is going to give us some average\n3079.619s: distribution that approximates the this\n3082.68s: bimodal size distribution\n3085.14s: and so then the next set of games that\n3087.96s: we wanted to kind of play was\n3090.48s: um what does the neural network do in\n3092.16s: this case\n3093.72s: um when it when it's giving some kind of\n3095.64s: effective size distribution or effective\n3098.46s: set of refractive indices or so on\n3101.76s: um and\n3103.38s: it seemed to work pretty well actually\n3105.48s: like it gave like kind of like a\n3108.54s: physically reasonable result\n3111.54s: um\n3112.38s: whether that's something that could be\n3114.48s: explored and tweaked to try to like gain\n3117.42s: some insight into the underlying physics\n3120.48s: for a problem like Cloud microphysics\n3123.72s: where you don't have access to that\n3125.52s: maybe\n3127.559s: um\n3128.339s: but yeah we we didn't\n3131.099s: fully explore that yet\n3133.859s: cool thank you\n3138.18s: if there aren't any questions and I\n3139.859s: guess um we can conclude and thank you\n3141.9s: Romana and Rob for your time and uh yeah\n3145.319s: take care\n3146.64s: yep thanks a lot guys yeah thank you for\n3149.94s: inviting us yeah"
    },
    {
        "class": "YouTubeVideo",
        "title": "Climate KT in a Time of Crises, Transitions, and New Collaborations with Jean-No Landry",
        "videoId": "8q6P1xuH7EM",
        "url": "https://www.youtube.com/watch?v=8q6P1xuH7EM",
        "publishedAt": "2023-02-20T16:22:55Z",
        "transcript": "6.72s: all right thank you so much uh it's\n9.3s: really an honor and a pleasure to be\n10.62s: back in uh in New York City obviously\n12.78s: finding a way to come back is always a\n14.88s: good thing uh but Montreal not being too\n17.1s: far away you know it's uh there's a lot\n19.08s: of similarities between\n20.64s: um our cities\n22.02s: um so today I want to talk about climate\n23.52s: knowledge transfer and economic crises\n25.32s: Transitions and new collaborations\n28.26s: um Courtney explained kind of my my\n30.48s: background and I think you'll be able to\n32.42s: uh to know right away that I'm not a I'm\n35.1s: not a climate scientist but I've worked\n37.079s: with a lot of different\n38.88s: um you know climate scientists as well\n40.079s: as different researchers from different\n41.219s: fields as well through transdisciplinary\n44.18s: interdisciplinary approaches uh from\n46.92s: applied research\n48.42s: um you know opportunities\n50.7s: um but today\n52.26s: um I really want to hone in on you know\n53.94s: some things that I'm I'm seeing some\n56.52s: things in kind of the work that I'm\n58.02s: doing that I'm helping set up whether\n59.34s: it's within an institution like\n61.02s: Concordia University or even in the\n63.059s: climate activism space and how do those\n64.92s: two kind of connect with one another\n66.72s: gonna unpack that with you\n69.42s: um\n71.22s: I'm going to start with a little bit of\n72.9s: a kind of my own my own story I'm not\n75.0s: going to tell my whole story of self\n76.26s: although you know that's how I was\n77.52s: trained with the Obama Scholars Program\n78.96s: but I'm not going to do that today but I\n80.34s: think it's really important to share\n81.72s: kind of the perspective and the\n83.4s: background that I bring into this\n84.72s: conversation uh and I think that's part\n86.58s: of the issue too is to be able to be\n88.439s: kind of more visible to one another and\n90.659s: appreciate each other's uh you know\n92.46s: competencies and perspectives on\n94.32s: different kind of problems and how to\n95.759s: collaborative collaboratively uh resolve\n98.52s: them or address them\n100.32s: um so these are the 10 open data\n102.479s: principles\n103.56s: um that were uh that were developed uh\n107.939s: in about 2007 2008 uh Under the Umbrella\n112.02s: of the sunlight Foundation that's no\n113.7s: longer active\n116.04s: um and\n117.659s: of course when you look at this\n120.119s: um you know in a way the open data\n121.799s: principles kind of responded to a need\n123.78s: for alignment and interoperability\n126.06s: between people and technological and\n128.88s: Data Systems right so we needed to find\n131.06s: parameters by which we could be able to\n133.56s: kind of coordinate ourselves\n136.08s: um and by stating the principles people\n138.72s: were able to then align in the way that\n141.0s: they used and leverage technology and\n142.739s: shared knowledge\n144.36s: um\n145.56s: the open data principles even though\n147.3s: they were named you know by the Civic\n150.0s: Tech and open data Community uh in that\n152.879s: period\n153.959s: um obviously climate scientists were\n155.52s: already applying a lot of those\n157.02s: principles in the work that they were\n158.34s: doing it was certainly the case that\n159.9s: Northern uh you know Canada with large\n162.599s: Arctic research consortiums that needed\n165.42s: to share knowledge and so they were in\n167.34s: many ways open data wasn't named open\n169.14s: data but it wasn't named open data at\n171.599s: that time but it was already part of the\n173.519s: culture of how scientists were already\n175.319s: kind of sharing data and you know some\n177.3s: of you might have already been kind of\n179.34s: involved in some of that research over\n181.319s: several decades\n183.12s: um\n184.14s: and so for uh for me I think it's\n187.379s: important just to kind of name the how\n190.14s: the principles translated into a real\n192.84s: Global movement and one of the main kind\n195.78s: of umbrella organizations and network\n197.34s: that shared that kind of knowledge and\n199.019s: collaborativeness was the open\n200.879s: government partnership the US was very\n203.22s: involved in the early days of the\n204.599s: creation of the open government\n205.62s: partnership there's upwards of like 80\n207.78s: different governments now that are part\n209.22s: of the ogp\n210.72s: um and that was you know a way to\n212.9s: normalize these value systems right\n215.879s: according to the principles that I just\n217.68s: named\n218.58s: in in a nutshell if you want to be part\n220.799s: of the ogp you have to develop an action\n223.92s: plan that abides by the values of\n226.2s: transparency accountability and Civic\n228.18s: engagement gain consultation with uh\n230.7s: citizens locally\n232.2s: um and if you don't do that then you can\n233.76s: be part you know of the ODP so the ogp\n236.519s: created incentives for collaboration but\n239.04s: also the adoption of these principles my\n241.379s: organization open north\n243.239s: um was very much aligned with that we\n245.28s: were quite small but we needed to find a\n247.08s: home and a way to be able to connect\n248.459s: with the work that we're doing locally\n249.959s: from a Civic Tech perspective and then\n251.819s: connect that to the broader context and\n254.28s: because of the values of\n255.78s: interoperability we were able to kind of\n259.139s: benefit from you know developers and\n261.479s: work and science and research that was\n263.28s: being done in other parts of the the\n265.08s: world and learn from their own\n266.82s: experiences in applying different\n268.62s: solutions because it was open source\n271.38s: because the data was being shared and so\n273.479s: there were a lot of uh potential gains\n276.0s: by collaborating by having similar norms\n278.58s: around data so that was really important\n281.16s: for us a key publication if you're not\n283.44s: already familiar with the open data\n284.759s: movement would be from the the gov lab\n287.24s: that track kind of different waves of\n289.8s: the open data Community\n291.479s: um and I'm naming this because this is\n292.919s: really part of kind of my perspective\n294.6s: that I bring to knowledge transfer\n297.78s: um another key thing from a background\n300.0s: perspective uh\n302.16s: is also the reframing of technological\n305.1s: and Democratic systems and how do those\n307.46s: facilitate knowledge transfer on the\n310.32s: left you see a definition of an open\n313.32s: Smart City and that was really important\n316.259s: um I you know it's really important to\n318.0s: how to translate values and principles\n320.34s: into technological uh systems and we we\n324.72s: were seeing\n326.1s: um at the time a a big project uh urban\n329.34s: development project that was uh\n331.199s: operating in the city of Toronto in\n334.86s: Waterfront Toronto what a kind of high\n336.6s: value kind of uh you know Waterfront\n339.02s: that was basically the city that decided\n342.06s: we're gonna invite\n344.1s: um uh sidewalk Labs uh which is\n346.74s: affiliated with alphabet under Google\n349.22s: and basically give them you know 50\n351.84s: million dollars to develop a a proposal\n354.419s: for developing a whole swath of the city\n358.74s: um and within that Vision that Google\n360.9s: developed\n362.699s: um we were talking about things like\n364.139s: Urban data we were talking about\n366.66s: um it was like a whole kind of like a\n368.22s: system of ideas and principles around\n370.44s: data governance\n371.88s: um that it was kind of uh you know\n374.16s: Google's language it wasn't really\n375.6s: anchored in you know governance laws in\n378.24s: in Canada and so for us it was really\n380.699s: important as open data Advocates that we\n382.74s: didn't lose that interoperability that\n384.78s: we didn't lose you know what the\n386.699s: benefits and the gains that we saw from\n388.68s: an open data perspective and so we\n390.24s: developed a definition of an open uh\n392.819s: smart city with a guide as well as a\n396.12s: whole training curriculum and how to\n397.68s: train people on becoming open and smart\n400.199s: and in many ways cities were already\n402.66s: applying\n404.699s: cities were already applying uh\n409.139s: how do we fix this\n432.419s: okay\n433.759s: just Wi-Fi\n442.62s: and we're back okay great okay so I\n445.44s: don't want to talk too much about this\n446.58s: the key thing is basically the reframing\n448.68s: of technological and Democratic systems\n450.36s: it gave us power it gave us power in the\n453.12s: way that we could Define the vision of\n455.46s: the way that we wanted communities to be\n457.08s: able to connect with one another that we\n459.0s: saw actually in real terms at the at the\n462.24s: local level no problems that they were\n464.099s: addressing and we didn't want to lose\n465.84s: you know in locked in systems of\n468.0s: proprietary data the opportunities and\n470.28s: the outcomes that we saw from a shared\n471.9s: perspective in an open Smart City\n474.78s: um\n475.8s: okay and also from the open Smart City\n478.139s: definition\n480.36s: um there was a uh a smart cities\n482.4s: challenge in Canada 100 million dollars\n484.68s: by the federal government uh Montreal\n486.84s: won the top prize so 50 million dollars\n489.419s: but you had 170 cities that competed for\n492.66s: for that pot of money and so and the\n495.72s: values and the principles of the\n498.12s: challenge itself were very much inspired\n500.46s: by the open Smart City definition okay\n502.5s: we worked with the federal government to\n504.0s: kind of co-design this vision and so\n506.099s: because they saw you know the benefits\n508.02s: of interoperability adaptability\n509.759s: operating in the open and those 170\n512.58s: cities had developed these proposals but\n515.219s: they didn't win but they still had you\n517.2s: know uh convened and worked and um\n522.659s: so I'm getting like updates here okay\n526.62s: um there were the point that I want to\n528.66s: make is that you had a hundred cities\n530.339s: 170 cities that had developed these\n532.68s: proposals but even though they had not\n534.6s: won they were still uh they still had\n537.48s: that vision of how to collaborate around\n539.399s: technological systems that were more\n540.899s: open and transparent and so we pitched\n542.94s: to the federal government the\n544.019s: establishment of a capacity building\n546.12s: program uh that enabled us to reach\n549.0s: those 170 cities and more uh to train\n551.7s: them on different technological issues\n553.5s: and and problems\n556.2s: as the as\n561.92s: I think you have to share your slides\n564.42s: again I have to show my slides again\n565.74s: okay\n587.18s: require that again\n611.779s: here we go\n636.48s: step on the side\n670.98s: okay\n677.519s: okay\n679.38s: take through let's do it\n682.62s: okay\n691.26s: I'm going to speed up the background a\n692.94s: little bit\n693.959s: so the key here is that\n696.36s: you can reframe you know a set of uh\n699.54s: systems you know with values and it can\n702.899s: be adopted on a large scale and that can\n705.36s: help kind of really kind of facilitate\n706.86s: collaboration across levels of\n709.14s: government across communities and that's\n711.3s: what we did in the Canadian context\n712.74s: through this open Smart City approach\n715.14s: all these dots these are all people that\n717.42s: were connected to our program okay\n720.0s: um and as the open data Community uh\n723.0s: evolved\n724.62s: um\n725.339s: in many ways people started like they\n727.079s: were kind of uh they thought we were a\n728.88s: little bit naive because there's a lot\n730.92s: of issues that came up around\n734.1s: purity of data privacy\n737.339s: um you know these these types of issues\n739.44s: that we didn't we knew about when we're\n741.899s: advocating for the first open data\n743.459s: policies but that's not how you would\n744.959s: win an argument with an elected official\n747.0s: to adopt an open data policy right and\n749.22s: so we didn't want to kind of complicate\n750.54s: these things and the open data Community\n753.66s: then got into a space where we it wasn't\n758.16s: just about government data\n760.019s: it was also about how to share data and\n763.38s: create enabling conditions between\n765.36s: sectors and between people that you know\n767.82s: in theory had you know a lot to gain\n770.1s: from one another from a collective\n771.839s: intelligence perspective if we would be\n774.42s: able to share and collaborate under you\n776.519s: know certain types of conditions and so\n778.56s: these enabling conditions here\n781.38s: um I think are actually quite relevant\n783.3s: today when we talk about climate uh\n785.519s: collaboration uh between different types\n787.98s: of stakeholders\n789.66s: um but they don't happen you know by\n792.06s: themselves we need there's different\n793.44s: roles and there's an appreciation of you\n796.5s: know where people are coming from and\n798.06s: the Dynamics that exist within each\n800.1s: institutions and each sector in order to\n801.899s: facilitate that type of data sharing but\n804.54s: it's useful to name uh those uh those\n807.779s: enabling conditions\n809.519s: um and they they have a direct impact in\n812.88s: terms of knowledge networks as well\n815.399s: um from a coordination perspective from\n817.98s: a learning and Innovation perspective\n819.839s: how we translate what we know\n822.72s: um as well as how do we support uh\n825.12s: individual members that are part of\n826.74s: knowledge networks uh as well and so\n829.32s: those enabling conditions don't happen\n831.6s: in isolation from who contributes their\n834.12s: knowledge to this Dynamic that you want\n836.279s: to create and\n838.68s: um let's shift now to more of the uh the\n842.339s: knowledge transfer context and and\n844.26s: Dynamics and here I want to focus on the\n846.72s: complex shifts underpinning the gap\n849.24s: between climate science and climate\n851.1s: action specifically\n852.839s: um\n853.5s: so got the chance last year to uh move\n857.16s: to New York as an Obama scholar based on\n859.68s: the the work that I had done in the tech\n861.959s: and data sector as well as you know\n863.94s: about 10 years of work in democracy as\n866.519s: well\n867.48s: um when I first came to\n869.279s: um\n870.06s: uh to New York I I moved to Harlem\n873.839s: um and you know this was before I\n876.12s: actually started my classes\n878.7s: um and I I was you know I witnessed and\n882.12s: I experienced climate change you know\n883.98s: directly um I was a resident newly\n885.899s: arrived resident in in Harlem hurricane\n888.3s: struck uh some of you might remember\n890.1s: this was last summer or two summers ago\n892.74s: um and floods there were people people\n895.32s: died you're at Metro station right next\n897.54s: to my place got flooded\n899.519s: um and I it really kind of brought you\n901.139s: know a question to myself kind of going\n902.88s: like okay how come I didn't know about\n904.26s: this you know how come I wasn't prepared\n906.12s: what information would I have needed in\n908.699s: order to you know plan ahead and what\n911.1s: was I supposed to do during the\n913.019s: hurricane and how could I then you know\n915.3s: participate or even know where to go to\n917.399s: after the hurricane had had struck so\n920.279s: those are all knowledge and data types\n922.38s: of issues I was like okay well there's\n923.82s: there's something there you know and I'm\n926.1s: obviously you know not the most\n928.44s: vulnerable kind of population in uh you\n931.019s: know in New York and so I was very kind\n933.12s: of mindful of that\n934.62s: um so I brought this kind of like\n935.76s: question with with me when I went to uh\n938.339s: to Colombia basically kind of asking\n941.639s: um you know how do we know that the\n945.12s: climate science is translating into you\n948.0s: know climate action\n949.26s: and those very very basic question and\n951.24s: so as I met with uh academics and I\n953.94s: probably met around like 20 25. I always\n956.279s: ask them that question because I wanted\n957.779s: to know what was their strategies um in\n960.24s: the way that they kind of facilitated\n962.04s: the sharing of their knowledge because\n963.899s: we knew that the hurricane was coming\n966.36s: the models were there we knew which part\n969.18s: of the neighborhood would be impacted\n970.62s: the models were you know quite quite\n972.959s: accurate but the accuracy of the science\n975.24s: didn't translate into Readiness of the\n977.699s: people who were most susceptible to\n979.5s: being vulnerable you know in in that\n981.839s: type of situation\n983.519s: um\n984.12s: so\n985.56s: you know further further to that\n988.139s: um I was also seeing how well you know\n992.1s: the ipcc report had just come out\n995.1s: so again the authority of Science and\n998.1s: knowledge was there\n999.48s: Mass mobilization was was happening uh\n1002.24s: big uh kind of Earth Day or certainly in\n1004.339s: Montreal and elsewhere uh really kind of\n1006.44s: picking up and communities were\n1008.6s: organizing locally because they were\n1010.459s: directly impacted\n1012.259s: um but that the bridge between the two\n1015.8s: um again I wasn't really necessarily\n1017.48s: kind of seeing it and this was not a\n1019.399s: scientific kind of research that I had\n1020.899s: done this was mainly from a lived\n1022.88s: experience\n1024.26s: so you know that's kind of like a high\n1026.6s: level\n1027.559s: um kind of issue that you know I\n1029.059s: struggled with\n1030.559s: um\n1031.339s: but I think underneath\n1033.559s: um that that kind of high level question\n1035.9s: around knowledge transfer from a climate\n1038.72s: science to uh local communities there\n1041.839s: were a lot of different shifts and\n1043.28s: Transformations that were also occurring\n1045.74s: and so I think it was important for and\n1048.98s: something that I you know I I connected\n1051.02s: with and through different different\n1052.64s: communities one of which through the the\n1054.919s: Wolf Willow uh Institute of systems\n1057.5s: learning uh in in Canada uh very much\n1060.14s: informed by indigenous and in knowledge\n1062.36s: and perspectives and really kind of\n1064.52s: challenging some of the assumptions\n1065.84s: about the moments that we were living we\n1068.12s: were living in now\n1069.679s: um from five different dimensions and\n1072.38s: this isn't just attributable to Wolf\n1074.36s: Willow and kind of other collaborators\n1076.16s: uh you know that I've been involved with\n1079.039s: um but maybe looking at you know what\n1081.14s: are the the relationships in past\n1082.88s: failures or tensions that weigh you know\n1085.64s: more than the successes that are\n1087.08s: impacting us uh today\n1089.72s: um the alignment of actors the\n1091.28s: objectives and incentives specific to\n1093.32s: each\n1094.6s: that don't tend to uh you know to lend\n1098.66s: themselves to modes of implementations\n1100.16s: that are difficult to reconcile uh Power\n1103.4s: is symmetries the Dynamics of power and\n1106.76s: you know Capital uh accumulation that\n1109.16s: aren't necessarily discussed clearly or\n1111.44s: are leaving room for latent tensions uh\n1114.74s: theories and practice that are kind of\n1116.48s: disjunctive that don't necessarily you\n1118.64s: know the theory is initially translated\n1120.2s: into the way that we Implement what we\n1122.179s: know you know based on on the science\n1123.98s: and the uncertainty of of Divisions and\n1126.919s: I think that's something that we've kind\n1128.539s: of felt over the last several years\n1131.419s: um and the kind of antagonistic kind of\n1134.539s: like postures that are kind of like\n1135.799s: emerging in society right now\n1138.26s: so those those types of Reflections are\n1141.08s: are quite important\n1142.82s: um for knowledge transfer because that's\n1145.28s: the context of uh this kind of complex\n1148.34s: sets of shifts and transitions that are\n1150.26s: also occurring that we need to kind of\n1152.059s: delve into\n1153.5s: one way to think about it is what could\n1156.14s: be called the uh or What's called the\n1157.82s: the two Loop Loops model from The\n1160.34s: burkana Institute and basically what uh\n1163.4s: the true Loop model\n1164.84s: uh you know explains is that we're in\n1168.08s: the moment where you have uh\n1170.78s: institutions that are are shifting that\n1173.419s: are facing a lot of pressures that are\n1175.1s: transitioning to something new you have\n1176.96s: a lot of people that are still holding\n1178.4s: on to the way that they've been doing\n1179.66s: things for a long time right and so\n1181.7s: that's something that's in government in\n1184.22s: Academia pretty much you know in in any\n1187.16s: sector people kind of hold on to the\n1188.6s: things that they don't it's just like a\n1189.919s: basic assumption about you know the way\n1191.539s: that kind of human institutions work\n1194.66s: um at the same time you also have people\n1196.7s: that are\n1197.78s: um you know wanting to shift and\n1200.36s: innovate and kind of transition those\n1202.4s: institutions into something new\n1204.62s: um and they will Prototype uh different\n1207.32s: approaches but the bridge between the\n1210.08s: old and the new doesn't happen often by\n1213.26s: itself and how to deal with or how to\n1216.38s: support people that are you know\n1218.48s: transitioning kind of out of the the\n1220.82s: mode the current modes of the modes of\n1222.86s: thinking and working that they've been\n1225.5s: used to without kind of totally for uh\n1229.58s: um uh totally putting them aside but\n1232.94s: actually helping them contribute to this\n1234.679s: new kind of transition in a way that is\n1236.72s: nourishing and kind of illuminates the\n1238.4s: way that we think in terms of future\n1239.96s: opportunities and future institution uh\n1242.419s: building so it's a there's a there's a\n1244.82s: moment in time right now that I think\n1246.38s: we're we're kind of positioning\n1247.76s: ourselves in that kind of innovation\n1249.2s: kind of space and I'll give a couple of\n1251.059s: examples a little bit later\n1253.34s: another way of thinking about kind of\n1255.08s: the underpinning transitions that are\n1256.46s: happening right now I'm naming this the\n1258.44s: nods diagram because it's from a friend\n1260.0s: of mine who uh runs the future of good\n1261.98s: in uh in Canada with also a broad\n1264.2s: publication internationally is that\n1266.48s: oftentimes we there's a kind of a\n1269.36s: division this is a simplistic model but\n1272.24s: I think it's a helpful one where you've\n1274.64s: got a tendency for kind of design kind\n1277.22s: of thinking that looks to the Future and\n1279.62s: uh another kind of like kind of uh SWAT\n1282.559s: of uh people that who are thinking about\n1285.08s: kind of the moment but are more geared\n1287.12s: towards a justice-based uh kind of\n1290.12s: mindset that's focused on kind of\n1292.039s: historical kind of Grievances and how to\n1293.659s: bring that into the present and better\n1295.52s: understand that and it's it's often\n1297.98s: difficult to think about the future as\n1300.14s: you think about the past and so there's\n1301.76s: a division there that also exists uh\n1304.1s: that we need to again reconcile with I'm\n1306.5s: not giving you solutions to this I'm\n1308.72s: just kind of naming the shifts and the\n1310.82s: transitions that are informing the way\n1312.86s: that knowledge transfer is impacted\n1314.6s: today\n1316.94s: another I think a key element of these\n1319.94s: shifts and transitions is that we're you\n1322.7s: know we're seeing a lot of opportunities\n1324.02s: around intersectoral\n1326.12s: um kind of collaboration you know and\n1327.799s: I'm not including the private sector\n1329.179s: into this although I know that the\n1330.44s: private sector can contribute to it\n1332.659s: um but I'm focusing more on community\n1334.4s: Academia and government\n1337.039s: and anybody who's worked you know in an\n1339.98s: intersectoral kind of uh system or\n1343.039s: approach or partnership we'll see very\n1345.62s: clearly that there's\n1347.36s: um a lot of differences right with\n1348.98s: people who work in government and we\n1350.48s: kind of tend to make fun of that right\n1352.4s: I'm like oh Academia is so slow\n1354.38s: government is so slow and then well\n1356.179s: actually we're all kind of slow but\n1357.26s: we're trying to innovate we're trying to\n1358.4s: move things uh forward but the\n1360.679s: characteristics of each of these\n1363.08s: different sectors it's really important\n1365.24s: to exercise more mindfulness around that\n1367.88s: and that includes time scales objectives\n1370.419s: uh resources access to expertise\n1374.36s: um even the way that the leadership kind\n1377.179s: of operates decision making so having a\n1380.24s: clearer understanding of how each of the\n1383.36s: sectors has built up these cultures\n1385.52s: internally in the way that it makes\n1387.26s: decisions manages data manages knowledge\n1390.02s: right it's really important in order to\n1392.539s: establish connectivity you know from an\n1394.58s: intersectorial perspective and the key\n1397.039s: here is going to be who's going to be or\n1399.74s: how to how does this interdependency\n1402.26s: gets facilitated and what is the role of\n1405.2s: an intermediary to facilitate that\n1407.059s: brokering between these different\n1408.5s: sectors\n1411.5s: a key uh a last one here in terms of\n1415.159s: underpinning shifts and transitions\n1418.34s: um is that we have to reconcile with\n1419.78s: different types of governance\n1422.24s: um and this is something that comes up\n1424.4s: quite a lot now when we see uh different\n1427.34s: alliances that are you know where we see\n1429.74s: government and Civil Society for example\n1432.14s: kind of collaborate uh on a common\n1434.9s: Vision on climate\n1437.36s: um that we need to be able to understand\n1439.059s: hierarchical concentric and polycentric\n1441.799s: modes of governance that's important\n1444.26s: because that's how decisions are\n1445.82s: actually made Within These systems and\n1448.52s: the way that communities organize\n1449.78s: themselves inside and outside\n1451.34s: institutions\n1452.9s: um it's going to have a really big\n1454.76s: impact in the way that you can actually\n1456.98s: align your kind of research objectives\n1459.26s: or engage you know people into your\n1461.6s: project you know if you don't understand\n1463.76s: or you're not Mindful and you don't plan\n1466.28s: and include a sensitivity to the way\n1468.98s: that you know they're operating within\n1471.02s: their own organization and institution\n1472.82s: as well and oftentimes we don't get to\n1476.179s: when we do a lot of collaboration\n1477.5s: intersectorially\n1479.419s: um we don't get to you know only say\n1481.58s: well I'm from civil society and this is\n1483.679s: the way that we do things you have to be\n1485.6s: able to kind of negotiate and kind of\n1487.64s: change some of your own behavior in\n1489.799s: order to facilitate that knowledge\n1491.299s: exchange as well and that's a key kind\n1493.64s: of governance type of issue\n1497.72s: okay now I'm going to turn to emergent\n1499.94s: shifts in knowledge transfer\n1501.38s: collaboration situations\n1503.659s: um and I'll start with leveling not\n1507.2s: leveraging but leveling networks to\n1509.72s: exchange expertise\n1512.0s: and you'll see that I'm naming uh and\n1514.82s: I'm using literature from knowledge\n1516.919s: networks and kind of naming a few kind\n1519.86s: of situations that I'm I've been a part\n1522.44s: of as examples to help kind of\n1524.72s: characterize that so again when I was at\n1527.72s: Columbia\n1528.98s: um you know I was uh like I said I had\n1531.26s: that question around climate science and\n1533.059s: climate action and I went to uh the the\n1536.24s: head of the climate School uh professor\n1538.4s: defreeze and I asked her it would be\n1540.86s: interesting\n1541.779s: maybe convene a group of Obama scholar\n1544.82s: climate Leaders with\n1547.4s: um you know researchers from the climate\n1548.9s: school and have a dialogue about\n1550.82s: intersectoral collaboration on climate\n1553.22s: science\n1554.36s: um and the key question that we wanted\n1556.34s: to ask is how can Academia engage with\n1558.62s: other sectors and work that addresses\n1560.179s: climate change\n1561.44s: well that's a really a Decor of the\n1563.36s: fourth purpose of of Columbia University\n1565.22s: and many uh academic institutions and\n1568.64s: you can see here some of the questions\n1570.559s: that we asked so and I won't kind of\n1573.08s: read them all uh all at once here but\n1575.179s: how do we direct knowledge and resources\n1577.52s: with civil society leaders\n1579.62s: um how can we you know what stage of a\n1582.44s: climate research process is best to kind\n1584.9s: of engage\n1586.279s: um uh you know Civil Society leaders\n1590.059s: um how can we be how can the climate\n1591.98s: school be aware and address uh the power\n1594.559s: kind of asymmetry uh as well in those\n1596.96s: types of relationships what climate\n1599.299s: climate research topics and types of\n1601.159s: collaboration opportunities are emerging\n1603.26s: from non-academic sectors that could\n1605.419s: benefit from greater collaboration with\n1607.039s: uh with Academia\n1608.72s: we didn't solve all those issues in that\n1610.94s: conversation but it was good to name\n1612.5s: them and I think that's that's a\n1613.94s: learning for for anybody who's trying or\n1616.4s: has an aspiration to knowledge transfer\n1618.38s: across sectors is to be able to name\n1620.659s: questions that open up a space or\n1622.46s: dialogue to be able to address them\n1624.2s: otherwise we're kind of ignoring that\n1626.36s: you know we have to compromise a little\n1628.22s: bit that we have to see each other and\n1629.9s: kind of respect each other\n1631.76s: um so this is what I'm calling leveling\n1633.919s: networks to exchange expertise so as a\n1636.799s: situation that's emerging\n1639.98s: um defining emerging uh intersections of\n1642.62s: movements objectives and outcomes uh as\n1645.38s: well that's another kind of key feature\n1647.419s: of knowledge networks the one that I'm\n1649.76s: I'm pinpointing here is the intersection\n1652.64s: of the digital rights movement and the\n1655.88s: climate Justice movement\n1657.74s: um so in many ways\n1659.539s: um as you know climate will cause more\n1662.12s: impact and more harm specifically\n1664.179s: especially for vulnerable communities\n1667.12s: we're going to need and we're collecting\n1669.86s: more data and we need to be able to\n1672.86s: protect and Safeguard and address\n1674.9s: digital rights of the people that were\n1677.72s: designing new services and new analyzes\n1680.419s: I'm you know about\n1682.1s: um and so that intersectorality or\n1684.919s: intersectionality\n1686.779s: um with a report by the uh the engine\n1689.0s: room kind of like puts a stake in the\n1691.58s: ground like this is a conversation that\n1694.1s: um we should be having that we're not\n1695.72s: really having as much in the\n1697.46s: environmental justice space at the\n1699.26s: moment and as a fairly like I've done a\n1702.08s: lot of work on different issues that are\n1703.46s: now impacted by by the climate but I\n1706.039s: haven't been a climate activist for for\n1707.96s: that long\n1709.22s: um I've worked on housing issues I've\n1710.72s: worked on homelessness issues Food\n1711.919s: Systems all of which are impacted by the\n1714.02s: climate right now but when you talk to\n1715.88s: climate Justice activists for example\n1718.039s: you're not necessarily thinking about\n1719.779s: habitual rights but it is an issue that\n1722.12s: that will uh come up as we look at the\n1724.88s: transition from uh environmental justice\n1728.0s: perspective as well as from a digital\n1730.58s: you know transformation as well so again\n1733.179s: defining emergency emerging\n1735.44s: intersections is kind of naming a space\n1737.72s: that knowledge transfer across sectors\n1740.12s: needs to reconcile\n1744.32s: um then well there's emerging new kind\n1746.96s: of convening structures uh and uh and\n1749.659s: infrastructure\n1751.34s: um obviously I'm speaking more from an\n1753.08s: open data perspective but we can also\n1755.0s: kind of broaden that to kind of more of\n1756.679s: open science as well\n1758.659s: um and we're seeing kind of new new\n1760.46s: networks kind of call to actions to\n1762.38s: create new communities of practices\n1765.26s: um but the the question around knowledge\n1767.6s: transfer is really at the core of like\n1769.7s: how do we establish you know an identity\n1772.159s: that is common around kind of shared\n1774.919s: leadership understandings that we can\n1777.44s: translate uh climate science into\n1780.43s: [Music]\n1780.799s: um\n1785.539s: um\n1786.88s: let's do this again\n1817.1s: thank you\n1823.0s: I'm getting good at this oh yeah that's\n1825.679s: good\n1827.419s: um\n1828.32s: okay so four four examples of how\n1831.919s: um\n1833.24s: new convening structures and new uh kind\n1835.58s: of infrastructures are being set up\n1836.899s: right because I think you know as\n1838.76s: there's a sentiment of like urgency\n1840.5s: right around the climate there's also a\n1843.559s: bigger imperative to collaborate in for\n1846.02s: alignment with people who don't normally\n1848.12s: talk to one another\n1849.44s: that's kind of like the theory that I've\n1851.059s: had and that's kind of what I've noticed\n1852.5s: in these new spaces where people that\n1854.84s: don't usually talk to each other are not\n1856.7s: now starting to talk to each other and\n1858.559s: because of the underpinning kind of\n1859.82s: ethos around and the principles around\n1861.2s: open data you know that lends itself to\n1863.299s: share and collaboration but that's not\n1865.7s: sufficient right how do we share what do\n1868.22s: we share what do we know what we know\n1870.08s: how do we kind of translate the context\n1872.12s: from which research and applications of\n1874.64s: technology and data are able to be\n1876.919s: communicated meaningfully in group\n1879.14s: settings in communities of practices\n1881.059s: there's a lot of new spaces where you\n1883.7s: know people are trying to kind of\n1884.899s: untangle and wrestle with those types of\n1886.52s: issues and I'm naming a few here and you\n1889.52s: know\n1890.6s: you know if I take the example on on the\n1892.82s: right\n1893.6s: um with the head of the center for open\n1895.159s: data Enterprise with an article in\n1897.38s: apolitical which I invite you to to read\n1900.38s: um you know it's there's also kind of um\n1903.74s: sometimes like we think that people are\n1906.02s: already connecting with one another when\n1908.12s: they're not and we have to kind of like\n1910.34s: have that vision and kind of put it put\n1912.74s: out kind of a an opportunity or a name\n1914.899s: an opportunity that people may or may\n1917.179s: not be thinking about and sometimes\n1918.919s: naming something is also an invitation\n1920.899s: you know to participate and to be in a\n1923.059s: room and to share what you know right so\n1924.98s: I'm saying that because\n1926.779s: um it kind of goes without saying but\n1928.58s: there's like obviously the uh\n1931.82s: connectivity that it happens right now\n1934.039s: internationally where I think there's a\n1936.62s: lot of impetus to be able to kind of\n1938.0s: create and hold those spaces and who\n1939.74s: holds that space and who makes a claim\n1942.2s: to have the legitimacy to holding that\n1944.899s: space is a very important kind of type\n1946.88s: of issue around creating governance\n1949.22s: mechanisms and spaces that are inclusive\n1952.159s: um and equitable\n1955.88s: okay another another trend\n1958.159s: to continue on that line of thinking is\n1960.44s: that we're moving past kind of classic\n1962.179s: more classic models of participation and\n1964.7s: getting into areas that are a little bit\n1967.159s: Messier around co-construction and the\n1969.74s: example that I have and on well on the\n1972.26s: on the left\n1973.399s: basic kind of like a ladder of\n1975.62s: Engagement from the iap2 international\n1978.2s: body around public participation and\n1980.12s: consultation\n1981.679s: um that kind of shorts it stops a little\n1983.659s: bit short of like getting into\n1984.86s: co-creation and co-construction on the\n1987.62s: right this is the launch of a new Civic\n1989.84s: Alliance in Montreal called\n1992.08s: and what tech does\n1994.94s: um it's in theory it's it's simple it's\n1997.82s: to develop a common Vision around the\n1999.559s: social ecological transition\n2001.539s: but how you do that in practice requires\n2004.899s: you to you know align with each other's\n2007.48s: timelines align around each other's ways\n2010.48s: of of thinking and doing but then also\n2014.2s: um being able to kind of go into the\n2015.7s: weeds of how government works and name\n2018.46s: what are the blockages perhaps from a\n2020.74s: regulatory perspective that stand in the\n2023.14s: way of local uh you know activists at\n2026.44s: the neighborhood level that are already\n2028.12s: mobilizing to kind of Leverage what they\n2030.58s: know in collaboration you know with uh\n2033.46s: with experts\n2034.96s: um to kind of shift\n2036.64s: um you know their responses locally to\n2038.44s: address the social ecological transition\n2040.779s: but the co-construction angle is one\n2044.44s: that is uh you know challenging to to do\n2048.22s: um and then defining new purposes and\n2050.679s: norms and so you know I've named here\n2053.08s: you know I've included Colombia's\n2055.179s: Columbia University's fourth purpose the\n2057.52s: three kind of main pillars around\n2058.599s: connecting empowering and accelerating\n2060.22s: and some and I've been asked like in the\n2062.56s: past you know you know how how could we\n2065.56s: do that you know how can we kind of\n2068.02s: achieve those those objectives you know\n2070.0s: that Colombia has set out for for itself\n2073.24s: um I think the answer to that relies on\n2075.94s: you know asking the people who could\n2077.379s: benefit from uh you know the support and\n2080.679s: the translation of knowledge into action\n2082.659s: uh themselves what's important I think\n2085.599s: in the\n2086.56s: um when we think about kind of new\n2088.48s: purposes and it's not obviously not just\n2090.46s: not Columbia not only Columbia\n2092.139s: University a lot of universities are\n2094.119s: doing this but also governments are\n2095.8s: doing this by creating different\n2098.14s: um you know mechanisms like Innovation\n2100.24s: labs for example that are a bit kind of\n2102.339s: hybrid within kind of government sit\n2105.04s: outside of government kind of be more\n2106.96s: tapped in into kind of the reality of\n2109.3s: like civil society as well but\n2111.4s: negotiating how to do that and a lot of\n2114.28s: these Labs not a lot but I know of a few\n2116.56s: that have had to kind of shut down\n2118.3s: because when they made the case to\n2121.18s: maintain that functionality of having a\n2123.16s: foot in community to internal kind of\n2126.76s: stakeholders that wasn't necessarily\n2128.859s: valued as much as it should be right so\n2131.44s: the hybridity of kind of innovation Labs\n2134.44s: uh in government you know it's difficult\n2137.02s: you have to kind of continually kind of\n2138.94s: like make the case that there's value\n2140.26s: and being able to kind of straddle uh\n2142.24s: different communities as well uh because\n2144.22s: it's not part it's not all work it's the\n2146.02s: the culture within government hasn't\n2147.52s: shifted kind of sufficiently in order to\n2149.44s: kind of appreciate a new kind of\n2151.42s: situational kind of branch of government\n2153.339s: that does that kind of bridge building\n2156.099s: um I've included kind of two examples\n2158.74s: around policies around research data uh\n2162.579s: sharing when in the US One in Canada and\n2167.02s: I guess the point that I'm trying to\n2168.52s: make with uh uh kind of highlighting\n2170.98s: those is that even though there's a\n2173.2s: policy you know that sets out you know\n2175.72s: very clearly objectives around uh\n2178.18s: knowledge uh sharing amongst uh research\n2180.7s: communities doing that in practice uh\n2183.82s: within a university setting even if you\n2186.099s: have the digital infrastructure to kind\n2187.9s: of facilitate sharing of data and\n2189.7s: knowledge\n2191.2s: um doesn't often happen you know\n2193.0s: certainly in the case of you know\n2194.56s: Concordia University I have great\n2196.42s: conversations with Librarians you know\n2198.4s: at Concordia University have explained\n2200.079s: to me oh yeah we have we have digital\n2202.18s: infrastructure to share knowledge across\n2204.339s: different departments\n2205.9s: but people aren't coming to talk to us\n2208.119s: to do that why is that you know so you\n2211.3s: have the purpose you've got the\n2212.8s: infrastructure but why is that not\n2214.599s: happening\n2215.74s: right it's that's okay\n2217.42s: um kind of another step afterwards\n2220.96s: and then we're seeing\n2222.579s: um you know as the last slide for this\n2224.38s: section you know active\n2228.22s: almost almost\n2230.5s: do it again\n2231.88s: maybe there's another computer\n2236.56s: all right we can just keep doing that\n2240.339s: foreign\n2288.3s: that's okay uh what should we do\n2292.78s: cushion in terms of the God conversation\n2295.72s: itself\n2298.24s: okay\n2306.3s: okay it's there\n2312.099s: foreign\n2318.579s: trying to keep my train of thought here\n2321.339s: um okay so this is another example\n2323.98s: um and we're still\n2326.26s: we're still in um identifying kind of\n2328.78s: shifts right in knowledge transfer all\n2330.579s: right so last example for this\n2333.4s: um based on activism that I did as a\n2335.56s: volunteer with react here in Harlem\n2338.5s: um which was a uh a project pretty neat\n2342.16s: um and the goal was really to consult\n2344.079s: citizens well you know local residents\n2346.54s: to understand what are your\n2348.28s: informational needs\n2350.26s: before during and after an extreme\n2353.56s: weather event what do you need to know\n2356.619s: um this is actually a picture of a map a\n2359.74s: physical kind of like you know\n2361.3s: communication product that was generated\n2363.22s: based on that consultation with local\n2365.32s: residents and what's neat about it\n2368.44s: um isn't necessarily the you know the\n2371.32s: accuracy of you know\n2373.54s: which area is going to be the worst hit\n2376.119s: although that's important that's like a\n2377.619s: scientific uh something that can be kind\n2379.599s: of Quantified and demonstrated through\n2381.22s: different modeling\n2382.72s: the social interactivity that happened\n2385.119s: you know in the back end of developing\n2387.52s: that map people talk to one another and\n2390.579s: they saw that actually you know we need\n2393.099s: to better communicate with one another\n2394.66s: and to kind of share our own experience\n2397.119s: and context in order to better prepare\n2399.52s: and to build that Community kind of\n2401.68s: resilience ourselves and so when there\n2404.14s: is a notification that there's going to\n2405.7s: be an extreme weather event that that\n2407.079s: occurs knowing your neighbor in advance\n2409.24s: and actually preparing and kind of maybe\n2412.0s: cleaning up uh those sewer kind of uh\n2415.3s: you know uh the subdetermined English\n2418.359s: but you know what I'm talking about\n2419.68s: being able to do that uh being able to\n2422.44s: know who has a generator you know like\n2424.78s: things like that really kind of concrete\n2426.339s: things\n2427.42s: um and the process by which this map was\n2431.2s: was developed and it was a printed kind\n2433.599s: of product that was kind of handed out\n2434.98s: help help frame uh a conversation at the\n2439.599s: different kind of Block Level so people\n2441.579s: convene and they're like What's our plan\n2443.38s: as residents how do we kind of you know\n2446.2s: support each other you know when uh\n2448.72s: there's going to be the next uh you know\n2450.82s: hurricane or flooding situation or\n2453.28s: extreme uh heat\n2455.44s: um this is a model that can be adaptable\n2459.4s: and scalable it's also one that can be\n2461.98s: aligned and\n2463.8s: can supplement the you know different\n2466.78s: kind of emergency preparedness Protocols\n2468.7s: of government it's also one that can be\n2471.04s: informed by uh and should be informed by\n2473.74s: climate science and when I showed this\n2476.2s: map to a climate scientist uh here at\n2479.14s: Columbia you know the first thing that\n2480.7s: he did was to really kind of hone in on\n2482.44s: this hearing was like oh yeah this\n2484.599s: changed here\n2485.74s: like the the flooding it goes up a\n2487.839s: couple of more blocks now like okay\n2490.119s: that's true but it's the soul that's\n2492.76s: that's really important actually but\n2494.68s: it's a social interaction of how to\n2496.42s: develop that kind of like social uh you\n2498.94s: know connectivity behind it that's also\n2500.5s: very important\n2502.119s: um\n2502.96s: and it wasn't a conversation that was\n2504.7s: led by data or but talking about data\n2507.46s: and access to data or access to\n2509.32s: knowledge it was one that really relies\n2510.88s: on the wisdom of the community itself\n2515.14s: okay now I want to name a few\n2517.78s: um\n2518.74s: if you can uh knowledge transfer\n2520.96s: practices in a period of transition and\n2524.68s: I'll focus on five\n2527.98s: the first one is on adopting a\n2530.5s: stewardship mindset\n2533.26s: so uh climate scientists\n2536.98s: um you know people that are in a\n2538.359s: position that you know they have access\n2539.98s: to uh research budgets uh have the\n2543.64s: ability to collect\n2545.2s: um a lot of data uh whether it's in an\n2548.02s: institution like an academic institution\n2549.64s: or whether it's in government\n2551.68s: um you know tend to have incentives to\n2553.48s: kind of protect and guard you know their\n2555.22s: data because you know there's incentives\n2557.079s: for for that uh you know in terms of\n2559.3s: your own kind of prestige and career\n2560.859s: there's also a lot of incentives to\n2562.54s: share that data and what we're seeing is\n2564.94s: a shift from a more custodian kind of\n2567.4s: relationship towards knowledge the one\n2569.32s: that's more based around the notion of\n2570.88s: stewardship and it's two word\n2573.7s: um kind of and it enables you to kind of\n2576.46s: think through\n2577.66s: how to navigate that kind of interaction\n2580.42s: that I named for a little bit earlier\n2582.099s: from that intersectoral kind of\n2583.72s: collaboratives as a steward yes you have\n2587.26s: uh access and you're collecting a lot of\n2589.839s: data that could be useful to others but\n2592.06s: if you started adopting a stewardship\n2593.68s: mindset then you also kind of view the\n2596.26s: data that you're collecting as\n2598.96s: um you have the responsibility to ensure\n2601.18s: that that data is accurate and in good\n2603.76s: quality in order to share it potentially\n2606.099s: with other types of users\n2608.14s: from the data that you've collected\n2609.819s: yourself which you see what I mean and\n2611.319s: so that stewardship mindset kind of\n2613.42s: changes the positionality of climate\n2615.819s: scientists in ways that you know might\n2618.16s: fall a little bit outside of kind of you\n2620.2s: know current kind of uh Norms\n2622.359s: um\n2623.74s: related to that\n2625.72s: um and I'm just highlighting Peter uh\n2627.64s: Coleman here at uh at Columbia\n2629.56s: University\n2631.24s: um because I think because of the the\n2634.119s: the collaborativeness you know that is\n2636.94s: more and more required across sectors\n2638.859s: and between different types of\n2640.42s: organizations and institutions we're\n2642.76s: also seeing potential tension kind of\n2644.98s: come up\n2646.3s: um you know I'm not talking about\n2647.579s: conflict in terms of War but I'm talking\n2650.26s: about conflict in terms of interests and\n2652.9s: incentives and potentially values as\n2655.0s: well and so once you start thinking\n2657.099s: about kind of conflict in that way and\n2660.16s: you think about negotiation kind of\n2662.319s: techniques there's a lot that can lend\n2665.02s: itself to a data stewardship or a\n2667.66s: knowledge Steward in order to navigate\n2669.76s: that kind of intermediary role between\n2672.16s: different organizations and institutions\n2674.2s: to facilitate that fourth purpose agenda\n2677.38s: um I found that to be quite helpful and\n2680.14s: it's something that I took on with me\n2683.5s: um in a training of public servants in\n2687.46s: Canada as well as with the the gov lab\n2689.859s: Academia Academia Academy\n2693.06s: for uh for data stewards as well\n2696.76s: um so thinking about self-knowledge and\n2698.44s: regulation constructive conflict\n2700.3s: resolution uh you know the Adaptive\n2703.24s: adaptability this these are not part of\n2706.0s: regular training for\n2708.16s: um you know Engineers it's not part of\n2710.2s: kind of the normal kind of training uh\n2712.18s: for uh you know necessarily for for\n2714.4s: climate scientists but the more that we\n2716.56s: need to collaborate the more we need to\n2718.18s: be able to compromise and the more we\n2720.099s: need to negotiate okay that's the kind\n2721.9s: of key underlining issue there\n2728.14s: okay another\n2729.88s: um\n2731.859s: kind of example of of uh kind of new\n2734.38s: techniques and methods here that I'm\n2736.48s: seeing is um collaborative and intuitive\n2739.96s: engagement and monitoring and here I'm\n2743.68s: um\n2744.339s: you know too often we were thinking of\n2746.68s: like theories of change in ways that\n2748.599s: were like okay a linear kind of like\n2750.22s: process you know cause and effect if we\n2752.8s: do this then we think that it will do\n2755.319s: this and then we'll measure after we've\n2757.24s: completed our research and kind of look\n2759.099s: back and decide okay did we achieve the\n2761.619s: desired outcomes that we had set for\n2763.359s: ourselves roughly speaking right\n2766.24s: um the uh an emerging kind of like new\n2769.48s: theory that I've uh kind of picked up\n2771.46s: and this is from Merlin Chapman from uh\n2774.04s: currently at open doors\n2775.78s: um is there on the notion like\n2776.859s: contribution analysis and to how to how\n2779.56s: to build in to your not just your design\n2782.319s: process but the actual implementation of\n2784.96s: your research and your work\n2786.76s: how to build in a consultative way\n2788.8s: assumptions that you're testing along\n2791.14s: the way so that you're refining and you\n2793.48s: have these cycles of engagements that\n2795.16s: are built in through your methodology as\n2797.319s: you're deploying your research method as\n2799.72s: well as how you're using your research\n2801.4s: kind of outputs as well\n2804.04s: um so it's a theory of change that\n2805.9s: combines results results chain with\n2808.599s: assumptions about the necessary\n2809.98s: conditions for the results to be\n2811.42s: achieved it's more nuanced it takes a\n2813.52s: little bit more work but you're actually\n2815.02s: collecting kind of data about your work\n2817.359s: as you're doing it as well and I'll\n2819.4s: share you know there's a good kind of\n2821.44s: citation there for for you if you're\n2823.0s: interested\n2828.099s: you might have seen this uh this article\n2830.079s: that kind of circulated a lot I think\n2831.76s: over the last a few weeks from MIT uh\n2834.76s: technology review and a challenging you\n2837.16s: know design thinking\n2838.9s: um\n2839.68s: and uh\n2842.2s: you know design thinking you know has\n2844.3s: according to the article uh limitations\n2847.06s: around you know problem framing that\n2849.22s: sometimes lacks context\n2851.68s: um emphasis on on empathy but sometimes\n2854.02s: at the expense of expertise we want to\n2856.48s: listen we want to kind of pay attention\n2857.92s: but who holds the the knowledge you know\n2861.88s: of what the problem that we're actually\n2863.5s: talking about and how do we respect that\n2865.24s: knowledge not just from a scientific\n2866.98s: perspective but also from different\n2868.72s: World Views and from different contexts\n2870.76s: themselves\n2872.14s: um sometimes it kind of sets maybe\n2873.52s: unrealistic or ungrounded uh\n2875.859s: recommendations that lack the dimensions\n2878.079s: of power right so we we you know anybody\n2881.319s: who's participated in these like Post-It\n2883.18s: note type of like settings or like okay\n2885.099s: great and then we're gonna do this but\n2887.44s: we don't necessarily have an\n2888.339s: implementation plan that really aligns\n2890.859s: with like the power mapping of how we're\n2892.9s: going to do the thing that we've all\n2894.579s: decided was a good thing to do\n2897.76s: um you know it sometimes also kind of\n2900.4s: reinforces\n2902.14s: um you know according to the article\n2903.7s: kind of inequity and exclusion as well\n2906.099s: which is obviously very important\n2908.26s: um\n2910.0s: the other kind of uh image that you see\n2912.76s: there is from a pan Canadian meeting of\n2915.16s: social Innovation lab uh uh across\n2917.5s: across Canada so there's about 50 of us\n2919.96s: who uh who met\n2922.24s: um obviously not exhaustive but actually\n2923.8s: quite quite interesting because we had a\n2925.54s: diversity of views there and I mentioned\n2927.52s: Different World Views uh indigenous\n2929.44s: worldviews were quite present and it's\n2930.88s: something that's kind of mainstreamed in\n2932.56s: the Canadian context as well\n2935.079s: um and we kind of like came up with you\n2937.18s: know we didn't want to talk about design\n2938.319s: thinking we wanted to talk more about a\n2940.72s: humility centered uh design approach\n2944.44s: um one that is\n2945.94s: um maybe based on on different sets of\n2947.859s: principles around kind of listening to\n2949.66s: dissonance or kind of a greater kind of\n2952.78s: a self-awareness\n2954.76s: um one that's focused more on like\n2956.2s: curiosity and patience and time and\n2958.3s: vulnerability uh one that also speaks to\n2961.78s: um you know uh\n2963.88s: you know compassion and reciprocity kind\n2966.819s: of New Dimensions that are not\n2968.319s: necessarily kind of embedded into like a\n2970.24s: design thinking approach and so I\n2972.22s: mentioned that because in the context of\n2974.14s: knowledge transfer\n2976.24s: we looked at the different kind of\n2977.68s: incentives and kind of mindsets that\n2979.599s: play into the relationships of who is\n2982.3s: transferring what to whom right there's\n2985.3s: a relationship that needs to be\n2987.099s: established there and the humility\n2988.9s: Center design approach can lend itself\n2991.24s: to maybe more\n2993.4s: um kind of fruitful type of like\n2995.44s: interactions as well but it's not\n2997.359s: something that's that's necessarily\n2998.68s: embedded into a design kind of\n3000.319s: problem-oriented and solutions kind of\n3003.18s: focused approach like design thinking\n3006.119s: again emerging I'm not saying that\n3008.339s: there's a lot of literature on this I'm\n3009.78s: just kind of naming kind of different\n3011.579s: kind of ways of thinking about knowledge\n3013.26s: transfer and different pieces that\n3014.579s: connect to it\n3018.66s: um and then lastly and I'll go into a\n3020.64s: couple of examples of work that I'm\n3022.26s: currently working on\n3023.76s: um social infrastructure as Community\n3025.2s: kind of knowledge hubs this is an\n3027.359s: academic research that that came out uh\n3030.3s: looking at uh Japan and the the tsunami\n3033.3s: and they were able to quantify and look\n3035.28s: at okay like the importance of community\n3038.16s: centers and libraries and kind of social\n3040.5s: infrastructure\n3042.0s: um as ways that climate scientists were\n3045.359s: able to connect to community Through you\n3047.88s: know that social infrastructure\n3049.2s: themselves so that's that's something\n3051.0s: that\n3052.2s: um\n3052.92s: uh obviously is important and I don't\n3055.26s: think that this is necessarily kind of\n3056.7s: you know groundbreaking but it talks to\n3059.22s: it speaks to like the balance around\n3061.2s: these approaches and what type of\n3062.7s: infrastructure we want to uh to Value\n3064.8s: from social infrastructure and digital\n3066.54s: infrastructure and also uh great\n3068.52s: infrastructure\n3069.96s: um there's also a set of issues around\n3073.02s: um\n3073.619s: you know systemic\n3075.359s: um Equity uh that needs to be kind of uh\n3078.359s: simultaneous and effective in the way\n3080.28s: that we built on in those relationships\n3082.2s: with uh social infrastructure approach\n3086.28s: here I just want to turn to uh for the\n3089.16s: last uh last section uh a few slides\n3091.859s: about current work that kind of\n3093.78s: translates some of what I've been\n3095.04s: thinking into uh actions so the things\n3097.8s: that I've been working on in the\n3099.119s: Canadian context\n3102.359s: um\n3103.68s: so breaking it down into uh four\n3106.44s: different layers in terms of how to how\n3108.72s: we've been kind of prototyping different\n3110.16s: kind of knowledge transfer approaches\n3111.66s: and kind of multi-layered and scaled\n3113.7s: collaborations\n3115.38s: um intro institution\n3117.14s: inter-institution or organization\n3119.119s: intersectoral and intersectional\n3122.46s: um and you know I thought\n3126.18s: from a non-profit perspective\n3128.76s: um\n3129.359s: you know\n3130.74s: I mean maybe I was a little bit uh not\n3133.68s: naive but when I when I first started\n3135.54s: working at Concordia I was like okay\n3137.28s: cool I'm going to work within Academia\n3139.26s: and I'm going to try this maybe build a\n3141.119s: a data collaborative I want to because\n3143.579s: that digital infrastructure existed I\n3145.38s: was coming in with like open data\n3146.52s: principles like\n3147.66s: we should try to like facilitate data\n3149.819s: sharing within uh within government uh\n3151.859s: within uh Academia\n3154.14s: um\n3154.8s: it's proven easier to collaborate across\n3157.319s: academic institutions than it has been\n3160.14s: with him okay\n3162.72s: um and I see that that's not necessarily\n3165.24s: kind of a surprise but it's not\n3167.7s: necessarily a given to anybody who wants\n3170.28s: to be brought in to kind of you know\n3172.68s: bring in their skills and expertise\n3174.839s: within an academic context so the\n3177.3s: preparedness of how to kind of recruit\n3181.2s: and hold on to talents that isn't\n3184.38s: strictly academic within an academic or\n3187.44s: science kind of based institution I\n3189.78s: think there's like a preparedness and\n3191.819s: also kind of a way of kind of navigating\n3193.619s: those Waters that\n3195.24s: um kind of requires more more thinking\n3197.64s: around that\n3199.02s: um\n3199.92s: the work that uh that I'm doing at\n3201.9s: Concordia\n3203.46s: um it's a really kind of underpinning or\n3205.619s: you know uh connected through a\n3208.319s: collaborative uh lens\n3210.66s: three key values that inform our\n3212.76s: inter-university collaboration work on\n3215.46s: action equity and uh and Trust\n3218.88s: um it's a uh you know there's a a few\n3222.9s: initiatives that that we're doing\n3225.24s: um that you know go right into the heart\n3227.339s: of knowledge transfer\n3229.559s: um one is repurposing climate uh data\n3233.339s: Frameworks mapping as well as portals\n3236.099s: and dashboards\n3237.78s: um so Montreal climate partnership at\n3240.9s: the at the bottom there you see that\n3243.0s: um\n3243.599s: so you know we've got uh yeah a public\n3246.96s: philanthropic uh you know private\n3249.66s: partnership that has the responsibility\n3251.579s: of monitoring the implementation of\n3253.8s: Montreal's uh climate action plan\n3257.04s: um and I like I like to be able to\n3259.98s: connect with Partnerships because\n3261.359s: they're there they already have you know\n3263.28s: the the systems and the networks they\n3265.38s: have the ability to convene so I reached\n3267.839s: out to them and I said you know we're\n3269.04s: setting up an interim University data\n3271.44s: studio and the ecological transition how\n3273.599s: could we be helpful or would it be\n3275.16s: helpful\n3276.059s: uh you know if we um helped map out the\n3280.859s: availability of data on different themes\n3283.26s: that they had prioritized within you\n3285.359s: know the partnership\n3287.04s: um said okay yeah that would be that\n3289.02s: would be interesting\n3290.64s: um you know and I was like well this is\n3292.14s: kind of a method that we've used in\n3293.4s: other contexts uh um you know it's\n3295.38s: called like a data mapping kind of\n3297.0s: framework we did we could do that making\n3298.98s: visible what data already exists but\n3300.96s: also naming different gaps and different\n3303.18s: kind of blockages around kind of data\n3304.74s: sharing you know so that if a researcher\n3307.079s: is involved in one of the streams of\n3308.76s: programming they're able to know who's\n3310.619s: working on what and what data is\n3312.059s: available and then you take and name the\n3314.819s: barriers to accessibility and kind of\n3317.04s: translate that back to you know\n3318.66s: governments to kind of make the case\n3320.04s: that those those data could be uh\n3323.04s: valuable and there's a need for for that\n3325.079s: but if you don't document that\n3327.359s: um you know you're not going to be able\n3328.559s: to make that case\n3330.54s: um and so they said yeah we're\n3332.28s: interested in in the mapping uh the data\n3334.619s: flow like that\n3336.0s: um and maybe you could help us kind of\n3337.619s: build a or take the initiatives to lead\n3339.42s: the establishment of a dashboard you\n3341.22s: know on emissions data so okay you know\n3343.619s: dashboard is basically a kind of a more\n3346.5s: complex kind of like iteration of a data\n3348.54s: inventory with like different kind of\n3350.04s: analytics kind of like features and\n3351.54s: whatnot\n3353.04s: um so we're going to be kind of a\n3354.48s: engaging with the with that\n3357.059s: um but we could go further than that\n3359.819s: because the dashboard only takes you uh\n3362.46s: so far and if we look at\n3365.28s: um\n3365.94s: you know different approaches like the\n3368.46s: Twin Cities for example that really\n3370.5s: integrate social physical and digital\n3373.68s: kind of reality into one then you see\n3376.52s: ways of being able to engage citizens\n3379.14s: kind of locally and part of the citizens\n3380.88s: more broadly but you know talking about\n3382.079s: kind of\n3383.16s: um the advantages of uh you know digital\n3387.18s: twin uh Concepts\n3389.579s: um from an open Urban platform where it\n3392.04s: is not just the data flow but you\n3393.9s: actually have the complementarity of the\n3396.359s: lived experience of people that are you\n3398.579s: know uh you know experiencing the uh\n3401.52s: climate\n3403.14s: um and through kind of scenario-based uh\n3405.66s: modeling then you're able to kind of\n3408.24s: supplement the the missing data that\n3410.4s: you're not necessarily able to access as\n3412.5s: well and so we want to start kind of\n3414.72s: build that in building we want to build\n3416.88s: that into\n3418.5s: um you know an iteration of a dashboard\n3421.92s: the dashboard is only a dashboard we're\n3423.9s: only going to be able to go so far with\n3426.059s: that it's still important but there's a\n3428.16s: lot of other kind of ways that we can\n3429.48s: leverage technology\n3432.9s: um last couple of examples\n3435.0s: um so hard to read but I think you get\n3436.8s: the the gist of kind of a pathway type\n3439.619s: of like approach here\n3441.359s: um this was done by another University\n3442.74s: in Montreal called investing\n3445.559s: um and the map tell transition Pathways\n3447.3s: from an ecological transition\n3448.8s: perspective as well as a digital\n3450.9s: transition perspective\n3452.28s: but they haven't merged the two\n3454.26s: and so this to me and so they're naming\n3456.54s: things like okay like uh uh at different\n3459.96s: state a different set of timing over the\n3462.839s: next like 30 or 40 years we want you\n3465.9s: know free internet access for for all uh\n3468.96s: Innovation sharing kind of policies Tech\n3470.88s: procurement transparency sustainable\n3472.8s: kind of tech infrastructure so these are\n3474.66s: all kind of things that you can measure\n3475.92s: you know potentially\n3477.78s: um the data that gets collected\n3479.88s: you know through the engagement and\n3482.099s: setting up that type of like digital\n3483.72s: kind of infrastructure in a transition\n3485.94s: pathway from in how you kind of align\n3490.2s: that with a social ecological transition\n3493.5s: will bring up the types of issues that\n3495.839s: you know I mentioned earlier from the\n3497.339s: engine room around digital rights okay\n3499.619s: and so we're now kind of looking at how\n3501.839s: do we convene and hold the space where\n3503.579s: we can talk about\n3505.2s: um developing Community data agreements\n3508.26s: because we're going to need more data\n3510.359s: for more people and because we know that\n3512.64s: the climate is going to be impacting\n3514.02s: people that are more in situations of\n3516.599s: vulnerability so we want to be able to\n3518.22s: talk about uh protecting uh you know the\n3521.04s: right to privacy and inclusion and\n3522.66s: consent and digital kind of sobriety and\n3524.819s: these types of issues as we move and\n3526.859s: emerge these different types of uh\n3528.9s: pathways\n3530.94s: and lastly\n3533.52s: um the type of like practice that we're\n3536.16s: seeing here combining this role of an\n3539.579s: intermediary and a broker kind of\n3541.74s: situating yourself between\n3544.2s: um you know sectors and different types\n3547.2s: of organizations lend itself to kind of\n3550.2s: a systemic intermediation practice\n3552.78s: uh which you know really kind of\n3555.42s: comprises of uh being able to not just\n3558.72s: convene intervening actors involved in\n3560.88s: multi-actor transformational approaches\n3563.579s: um but being able to uh to nudge and to\n3566.76s: bring in you know folks that aren't\n3568.68s: necessarily participating in the design\n3570.48s: of programs on bigger scales for example\n3574.14s: um being able to facilitate and\n3577.26s: negotiate the recognition of common and\n3580.319s: specific objectives and prioritizing\n3582.96s: them and anchoring them in relationships\n3584.579s: of trusts with each other\n3587.4s: um\n3588.119s: it's a\n3590.52s: it's a response and it's a way to be\n3593.16s: able to\n3594.599s: um bring a certain type of value that\n3597.72s: doesn't necessarily fit into current\n3600.059s: institutions that as they're currently\n3601.92s: designed but in ways that in a way that\n3605.819s: institutions all kind of need that type\n3607.799s: of functionality\n3609.059s: in order for themselves to be able to\n3610.98s: collaborate better internally across uh\n3614.339s: sectors as well as you know within their\n3617.099s: own organizations as well and so just\n3619.079s: kind of naming the systemic\n3620.22s: intermediation practice as an emerging\n3622.26s: field from a transformative perspective\n3625.02s: so I'll stop there thank you\n3627.96s: thank you\n3632.94s: so we'll open it up for questions and um\n3635.52s: I think talking with John away about how\n3637.859s: to approach uh you know engagement with\n3640.14s: you all and we and you have a preference\n3642.24s: I think for a conversation as opposed to\n3644.04s: you standing against the firm speaking\n3646.02s: and so if you'd like to I think help uh\n3649.799s: support our conversation around what\n3651.9s: does this mean for your work as\n3654.299s: scientists in this space how do you\n3656.339s: integrate this knowledge and\n3657.839s: understanding about knowledge transfer\n3659.7s: into what you do\n3661.02s: um so I'll kick us off and then happy to\n3663.0s: take other thoughts questions points of\n3665.28s: reflection but what's coming up for me\n3667.74s: is who's responsible for this who's\n3669.599s: responsible for figuring out how to take\n3672.72s: what we're learning on the the climate\n3675.48s: science side or on in the case of leap\n3678.059s: and translate that in ways that can be\n3680.76s: used by the public is one and then two\n3683.4s: what\n3685.02s: um barriers or ways of uh facilitating\n3689.64s: engagement from scientists in in this\n3692.4s: kind of work I could see particularly\n3694.98s: depending on the type of science that\n3696.839s: you're engaging how it can be difficult\n3698.28s: to LEAP from my study of say cloud\n3701.4s: systems to knowledge transfer and\n3703.68s: engagement in this way and I think it's\n3704.88s: it's a particularly uh poignant well a\n3708.54s: particularly relevant issue related to\n3710.4s: LEAP science it's more distal from\n3712.68s: climate adaptation translation and\n3714.78s: Community engagement so I'm wondering\n3717.0s: one uh who's responsible for a knowledge\n3719.94s: transfer into what is your experience\n3722.52s: working with climate scientists in terms\n3724.44s: of how they\n3725.72s: perceive barriers and getting in the way\n3727.859s: of their engagement in these ways or\n3730.44s: what has helped facilitate that kind of\n3732.0s: Engagement yeah I mean I think who is\n3734.28s: responsible is that we're all\n3735.359s: responsible I think that's the key kind\n3737.64s: of to that is that we all need to shift\n3739.74s: you know the context is Shifting there's\n3742.079s: a requirement there's an impetus there's\n3743.52s: an imperative for us to be able to\n3745.079s: collaborate and it can't just be one\n3747.299s: person who's going to have you know the\n3749.7s: key to succeeding in facilitating all of\n3752.46s: that so I think that's the kind of\n3753.839s: pressure that we're kind of facing right\n3755.579s: now\n3756.299s: um and it comes you know from within\n3757.92s: organizations outside organizations\n3760.38s: um and I think it's you know for for\n3762.18s: Humanity's sake that we need to kind of\n3763.799s: train ourselves differently but also\n3765.78s: maybe the competencies that we're\n3767.099s: learning in order to do that so from an\n3769.5s: academic perspective or from a place of\n3771.839s: you know of knowledge and education you\n3774.78s: know part of the training could also be\n3776.88s: how do we equip ourselves with different\n3778.92s: kind of skills right in order for us to\n3781.92s: be able to go uh and uh and test those\n3785.88s: skills\n3787.079s: um you know in in the world\n3788.819s: um and so you know for you know I'm a\n3791.819s: strong believer and like you know as\n3793.68s: you're as you're doing research also you\n3796.079s: know sit on different boards or a\n3798.18s: volunteer or do things that aren't only\n3800.64s: only for yourself and I'm and I don't\n3802.799s: mean to say that academics are all kind\n3804.599s: of self-interested I just know that\n3806.339s: there's a you know I know that\n3809.28s: um but the way that you know rewards\n3811.92s: come from you know the type of research\n3813.839s: that you do\n3815.52s: um you know sometimes the incentives\n3817.02s: don't necessarily lend themselves to\n3818.52s: being able to justify taking time to do\n3821.819s: things that aren't necessarily kind of\n3823.38s: rewarded kind of like institutionally\n3824.94s: and I think we need to kind of think of\n3826.68s: what are those outcomes that eventually\n3829.14s: help build better relationships you know\n3831.599s: with stakeholders and local\n3832.92s: organizations for example that are on\n3834.66s: the front line that know a lot you know\n3837.059s: that are very very interested and to\n3838.92s: treat that with curiosity but not\n3841.079s: necessarily in a way that's going to be\n3842.339s: extractive or like what can you do for\n3844.44s: me you know so there's that kind of\n3845.819s: reciprocity there that I think is\n3847.26s: important but the responsibility I think\n3849.72s: falls on all of us you know\n3852.119s: um and that's why I mentioned the uh the\n3854.52s: public service uh schools because they\n3856.619s: are training themselves to be to think\n3858.72s: differently about their own careers and\n3860.819s: their positionality as like you know\n3863.46s: um uh in the public interest and I think\n3865.98s: that's also something that can lend\n3867.18s: itself here\n3868.68s: um experience working with the climate\n3870.24s: scientists\n3871.799s: um yeah I mean it's like different\n3873.839s: settings where I've experienced that\n3876.54s: um and like I said you know this is uh I\n3879.66s: didn't necessarily work with climate\n3880.98s: scientists before you know coming back\n3882.839s: to Canada and so this is kind of\n3884.579s: relatively new to me so I'm also kind of\n3886.68s: hoping that people can answer that\n3888.42s: question for for uh their own experience\n3890.88s: of how they've navigated relationships\n3892.799s: and Partnerships and you know things\n3894.599s: that maybe didn't work out when they\n3896.28s: kind of approached a non-profit locally\n3898.74s: and they're like okay you know how do we\n3900.54s: work together\n3901.92s: um I mean I think it's going to be\n3904.619s: um\n3905.88s: yeah it's the kind of configuration of\n3907.98s: the you know the\n3910.14s: you know the the language and the\n3912.359s: objectives of each researcher you know\n3914.64s: and kind of really kind of spending time\n3916.2s: understanding where they're coming from\n3918.059s: and what were the assumptions that were\n3919.559s: built into the work that you know\n3921.18s: they're driving and their commitment to\n3923.52s: uh knowledge development uh and uh so I\n3928.319s: think there's like a certain kind of uh\n3930.54s: obligation if I can say that is that in\n3933.18s: order to engage with climate scientists\n3934.68s: you got to respect the work that they've\n3936.72s: done and kind of you know put yourself\n3938.64s: in their shoes to understand like what\n3941.22s: drove them to be able to you know kind\n3943.02s: of dedicate so much of their time to do\n3945.0s: that\n3946.079s: um\n3946.68s: that's about respect essentially you\n3949.44s: know I kind of bring that back to kind\n3950.88s: of very kind of basic values because I\n3952.859s: think values and principles can really\n3954.96s: kind of set a tone in interactions\n3958.26s: um and the the collaborativeness and\n3960.0s: work that I've done I always lead the\n3962.339s: principles\n3963.54s: you know I never start talking about you\n3965.88s: know the great things that we can do\n3967.44s: together I always want to make sure that\n3969.42s: I know who's in the room and I\n3971.16s: understand you know their context and\n3973.74s: the challenges that they've faced and\n3975.72s: things that are maybe under the surface\n3977.099s: and kind of naming you know challenges\n3979.619s: related to power or difference or fear\n3981.96s: or loss you know like I want to hear the\n3984.42s: stories from which they're coming from\n3985.98s: not just the data the data is a means to\n3988.799s: understanding the world in a\n3990.24s: quantitative way you know that's highly\n3992.28s: powerful you know potentially but it's\n3994.619s: the people and how they talk to each\n3996.299s: other that develop human kind of\n3998.039s: interoperability that will make the data\n4000.38s: and knowledge interoperability kind of\n4002.359s: succeed so I think just having that\n4004.339s: saying that kind of opens up and lends\n4006.68s: itself to kind of a different\n4007.52s: conversation that from my experience has\n4009.74s: been a little bit new in the way that\n4011.18s: I've interacted with climate scientists\n4012.559s: but let's see where it goes you know\n4014.96s: that's kind of like a theory\n4017.24s: and just quickly the you know one one\n4020.42s: part of this that we're talking about is\n4022.16s: how we take the science that we're\n4024.2s: developing here and share it out and how\n4026.78s: do we build Partnerships and\n4028.52s: relationships and human Connections In\n4031.16s: your experience how do those types of\n4033.2s: Partnerships and connections potentially\n4035.18s: change the science as well so we think\n4037.88s: about this as being bi-directional we\n4039.92s: talk about this\n4041.359s: um in some ways it's a principle right\n4043.4s: that there are other people who hold\n4045.98s: knowledge that could be useful to us I\n4048.26s: think sometimes it's it's uh difficult\n4050.18s: to see how that how that works can you\n4052.7s: speak to your experiences around the\n4055.339s: other way of trans the other direction\n4057.26s: of transferring or knowledge and how\n4059.72s: those types of Partnerships and\n4061.339s: relationships might enhance or change\n4063.14s: the science itself\n4065.059s: yeah I think it's maybe kind of stepping\n4067.339s: outside of a more kind of kind of a\n4069.68s: research kind of like frame and kind of\n4072.319s: establishing a middle ground where you\n4074.839s: can kind of meet kind of like halfway\n4076.52s: and that's why I mentioned the\n4077.66s: Constitutional can learn that Civic\n4079.039s: Alliance because you have climate\n4080.72s: scientists that are in those committees\n4082.64s: and they come and they're there and you\n4084.98s: bring a lot of uh knowledge and\n4087.559s: expertise\n4089.059s: um you know on so many different ways\n4090.98s: but the\n4093.26s: yeah I think it's the\n4095.66s: kind of building that that trust and\n4097.94s: Equity you know and that kind of wanting\n4100.759s: to be able to understand\n4103.1s: um yeah I put a lot of emphasis on like\n4105.38s: the relationship building to be honest\n4107.239s: like that that to me is so critical uh\n4109.58s: in in how to achieve that\n4112.04s: um but the nature of Partnerships\n4114.799s: um I think uh maybe not necessarily a\n4117.679s: mistake but I think something that you\n4119.54s: know might have been more common\n4121.279s: or could be quite common is that you\n4123.98s: know in these uh these types of like uh\n4125.96s: you know Partnerships\n4127.52s: the partnership is a vehicle through\n4129.92s: which you're able to kind of Advance\n4131.359s: kind of viewer interests and then you\n4133.58s: kind of take a piece of that partnership\n4135.319s: and you're like okay I'm gonna dedicate\n4137.359s: some time and resources in order to\n4139.46s: drive you know research on that question\n4141.679s: and we're going to bring people in to\n4143.66s: kind of like explore that together\n4146.12s: um I think being able to\n4148.64s: um you know at the design stage\n4150.98s: you know be being open to maybe kind of\n4153.5s: looking at uh questions differently you\n4156.739s: know outside of you know questions that\n4158.719s: have been driving kind of a research\n4160.1s: agenda I think is important\n4162.38s: um just like understanding the source\n4164.12s: and the context from which data was was\n4165.739s: being collected in the first place and\n4167.42s: being able to kind of name the\n4169.04s: parameters and the setting of uh of that\n4171.92s: um\n4172.819s: yeah but it goes back to the the slide\n4175.16s: around the the incentives and kind of\n4177.14s: being able to be much more explicit\n4179.66s: um sometimes Partnerships you know get\n4181.759s: established\n4183.62s: um not necessarily quickly but not\n4186.38s: necessarily with everybody who could\n4187.88s: benefit from the partnership and it\n4190.64s: starts with a smaller group of people\n4192.02s: and then it kind of expands and you kind\n4194.719s: of as you're expanding and adding more\n4196.94s: kind of participants and beneficiaries\n4198.679s: in the partnership model\n4200.239s: it's sometimes difficult to kind of lose\n4202.16s: the kind of the original Identity or to\n4204.44s: be able to kind of have that identity of\n4206.42s: the partnership and what it is that\n4208.28s: you're trying to do you know to get that\n4210.26s: coherence you know so that people that\n4212.3s: are contributing to it at different\n4214.46s: layers you know have you know the same\n4217.04s: sense of you know why you're there\n4220.699s: are there any questions\n4226.36s: any questions\n4230.48s: okay join me in thanking generally for\n4234.5s: continuing"
    },
    {
        "class": "YouTubeVideo",
        "title": "LEAP ML Journal Club: Aurelien Ribes",
        "videoId": "s77I3yLnvR0",
        "url": "https://www.youtube.com/watch?v=s77I3yLnvR0",
        "publishedAt": "2023-02-02T15:45:38Z",
        "transcript": "4.02s: foreign\n6.42s: welcome\n9.42s: um today we're going to have aurelian\n10.74s: Reeb um he's from\n13.139s: um he's leading the research team\n14.219s: cleanstat at uh cnrm\n17.16s: um in Toulouse and he's kind enough to\n20.039s: uh talk to us I guess the evening his\n22.439s: time\n23.52s: um so he's yeah\n25.199s: um it would be great to hear\n27.359s: um what you have to say so thank you\n30.539s: okay good morning to everyone\n33.84s: um so I'm I'm working in the same group\n35.94s: as Blanca I think you you had Blanca\n38.1s: again\n39.239s: uh two weeks ago for another talk maybe\n41.879s: more related to machine learning than\n44.1s: than the one I will I will present today\n46.82s: and in fact the the idea of\n50.46s: giving this seminar was uh came from\n52.98s: discussion I had with Pierre\n55.739s: um and uh and uh he was interested in\n59.399s: the way we we can use part of the part\n62.879s: of the framework statistical framework\n64.799s: behind data simulation so Kalman\n67.619s: filtering to learn things about climate\n70.979s: change and and the mixing of of\n72.9s: observations and climate models and so\n74.7s: this is talk of the subject of today\n76.74s: talks\n78.0s: um\n79.02s: okay so um most of this work was done\n83.4s: with uh close colleague said kathmi and\n86.4s: and there is a series of paper I will I\n88.86s: will present\n90.78s: okay so let's go\n92.7s: um\n93.42s: a bit of context and motivation first\n96.18s: um\n97.02s: in fact the context has been evolving\n99.18s: quite quite quickly on this topic\n102.299s: there is when we start working on on\n105.54s: that questions\n107.159s: it was before the ipcc air six and and\n110.46s: the context was a bit different what\n112.439s: what people were were facing at that\n114.42s: moment is a new Ensemble of climate\n117.06s: models Global couple model semit six and\n120.84s: in this Ensemble one remarkable feature\n123.6s: was that there was a a number of very\n126.899s: high sensitivity models\n129.599s: um finally higher than what was found in\n132.18s: Team 5 and so people were struggling\n134.099s: whether whether they should believe\n136.08s: trust these models or not\n139.02s: um\n139.86s: at the same time uh there was new\n142.8s: observations because you know between\n144.3s: semi different semi exercises there are\n147.12s: a few typically like six eight years so\n150.54s: you we have we had a bit more of\n152.28s: observations and observation was was\n154.8s: still not warming that much\n157.68s: um making high sensitivity models\n160.08s: questionable in terms of again of\n162.54s: accuracy Maybe and and also there was a\n165.84s: general uh wish I would say to update\n168.959s: all results uh typical ipcc report can\n172.379s: provide about attribution uh the amount\n175.68s: of roaming that can be found in today's\n178.58s: temperature or climate and and many\n181.56s: other things about projections\n183.9s: and so there was that that key question\n185.94s: what what\n187.62s: I mean can we reconcile High sensitivity\n189.9s: models with observations and can we find\n192.239s: a way to combine uh observations and\n195.239s: models to provide the best assessment of\n197.94s: both past and future warming and this is\n201.18s: a key topic today\n204.12s: now\n205.76s: 2023 we are two years after the ipcc R6\n210.599s: was\n211.44s: was made public\n213.3s: um and um and and published\n216.12s: um\n216.9s: and now the context is a bit different\n218.58s: so finally the IPC I I will come back to\n221.28s: that in the talk but finally now the\n223.56s: ipcc has decided to to use observational\n226.92s: constraints so to use this kind of\n228.48s: combination of observations and models\n230.34s: to provide an assessment of of\n232.44s: projections for the 21st century in\n234.959s: terms of government temperature but in\n237.18s: fact this given given available\n239.4s: literature this was possible only for\n241.5s: Global immune interpreter and and so\n243.12s: Regional projections are typically those\n246.18s: providing the report I mean are\n247.92s: typically unconstrained and so are not\n250.5s: based on the same kind of calculation\n252.959s: and of course there was a key question\n254.76s: whether we can do better on that point\n256.859s: and maybe have uh Regional versions\n260.519s: um of uh observational constraints and\n263.4s: this is Again part of the topic today uh\n266.22s: so the overall question to me is how to\n268.139s: combine uh model simulations or\n271.68s: Productions and available historical\n274.86s: observations to deliver an accurate and\n278.52s: consistent assessment of past and future\n280.199s: retirement this is really the question\n281.58s: I'm going to discuss and so we we have\n284.34s: been working on that for uh about three\n286.86s: years now and and I will discuss\n289.56s: um and and maybe both\n292.08s: um our statistical method\n294.66s: um Global application Regional\n296.34s: application and and discuss a bit\n299.16s: um implications and also Avenues\n302.52s: um of that work\n304.5s: okay so I start with a few a quick\n307.139s: presentation of the method\n308.88s: in fact\n310.32s: um this is an illustrative example\n313.8s: um just to understand how this work\n316.5s: um this is a collection of of force and\n320.4s: responses uh simulated by um six models\n324.72s: in response to historical for things and\n328.02s: and SSP 2 4.5 scenario so it's an\n331.919s: intermediate queen of gas emission\n334.86s: scenario for the 21st century okay and\n338.28s: and so this is I I will not explain in\n341.4s: detail how how\n343.919s: what filtering is applied to obtain\n346.74s: these curves but it represents an\n348.84s: estimate of the faucet component of of\n350.94s: the government temperature and so there\n353.039s: are quick quick uh cooling sometimes\n355.58s: corresponding to large volcanic\n357.84s: eruptions which are uh uh simulated by\n360.9s: by the models in in historical\n362.52s: simulations and there is of course no\n364.56s: volcanoes in the future so uh the the\n367.32s: over history\n369.199s: historical period until 2014 you have\n372.84s: you have the historical for things so\n374.52s: what really happened in the real world\n377.22s: and and after that date you have a\n380.0s: dynastic emissions scenario\n383.28s: and in fact there is a a pretty strong\n387.199s: range of values in terms of the amount\n390.18s: of roaming in in the 21st century uh a\n393.66s: bit more than a factor of two between\n395.94s: the the the the the\n397.819s: models which warm the less and those\n402.3s: which are in the in the upper bound\n405.12s: and of course you can take this sample\n408.3s: it's a very relatively small sample but\n410.88s: you can still consider this as a sample\n412.919s: uh assume for instance that temperature\n415.199s: the temperature response is a more or\n417.36s: less gaussian which given the small size\n419.22s: of the sample is not is not a big big\n422.16s: issue and then you get the mean and the\n424.68s: confidence branch on that on these uh\n427.319s: the expected warming value\n429.84s: and now you can put on this graph uh\n432.66s: what are the actual observations\n434.12s: available in temperature over the same\n437.039s: period of time and I forgot to say that\n439.259s: okay I'm using a reference period here\n441.84s: which is the same as in the ipcc which\n443.759s: is the first 50 years of this period of\n446.819s: time so the second half of the of the\n449.28s: 19th century so I we we put the\n451.5s: observations uh these are yearly value\n454.56s: for the global mean temperature\n456.419s: and clearly it seems that some of the of\n460.02s: the\n461.16s: Pathways or trajectories simulated by\n463.979s: the models\n465.12s: are off the the The Cloud of points\n468.9s: given by observations for essential a\n471.36s: few a few estimations below which seem\n474.96s: to be far too cold compared to\n476.94s: observations and maybe at least one\n478.86s: above which is also very very pretty\n481.86s: much too warm uh close to plus two\n484.319s: degrees of warming in 2020 which is not\n486.9s: what we find in the observations and so\n489.3s: yeah the key idea of what what we we are\n491.52s: doing is can we\n493.38s: basically consider that is this a sample\n496.919s: of responses is in a priori in the\n499.68s: Bayesian uh framework and compute the\n502.379s: posterior of what is possible both I\n505.5s: mean especially in in the future given\n507.9s: what we have already observed and if we\n510.479s: do that and that we explain in terms of\n511.979s: equations how does this work we we\n514.14s: obtain this kind of of\n517.039s: reduced uh confidence range for the\n520.32s: future warning\n522.24s: okay but the key ID is to compute which\n525.72s: pathways are consistent in terms of\n527.82s: temperature are consistent with\n529.44s: available observations\n531.66s: now I try to put this all in into\n534.18s: equations and what what we do is in fact\n537.3s: pretty simple to summarize so we we take\n539.459s: a vector which is a Time series this is\n541.56s: the false response between the all here\n544.26s: denote the fact that this is the\n545.76s: all-forcing response and you could do\n548.16s: the same for specific subsets of all\n551.1s: things if you will\n552.959s: um I take the time series for for this\n555.36s: quantity\n556.38s: um it's a 250 a year vector\n560.519s: um and um so this is uh this is the the\n563.7s: vector I am interested in I want to\n565.44s: estimate X\n567.18s: and I I write the observations as Y and\n570.72s: I have observations available so at the\n572.58s: time we made the study uh it was it was\n574.62s: until uh 2019.\n577.98s: um then we assume that we have a prior\n581.459s: information for what is the the fossil\n584.339s: response of the system and it comes from\n586.74s: the available sample of climate models\n589.44s: and we assume this this follows the\n591.6s: quotient distribution so you have a mean\n593.339s: and a kubernetes matrix it's a big\n595.08s: Covenant Matrix because it's two 250\n597.6s: times 250 so pretty big not big for\n600.839s: people working in data assimilation\n602.519s: that's still a bit\n604.68s: um and there is an and uh\n608.1s: observation equation describing how\n610.86s: observations are made on this state\n613.32s: Vector X and you need an operator for\n616.98s: observation H which is accuracy it's\n619.56s: very very simple because everything is\n621.6s: lower mean temperature so you just what\n623.519s: you say here is just that the the the\n626.04s: observations for instance in in year\n628.44s: 2000 is exactly the X at near 2000 plus\n633.24s: plus some noise Epsilon okay so H is\n636.779s: just a way to extract the appropriate uh\n641.04s: year in X to make it correspond to what\n645.18s: is in y\n646.88s: only one and zero in this Matrix H in in\n651.06s: this very simple case\n653.88s: and then you have this equation and and\n656.82s: so you can you can uh you can so yeah so\n659.94s: there are a few uh uncertainty in y\n662.88s: there are essentially two two sources of\n665.94s: uncertainty in y the first one is of\n668.04s: course internal viability because what\n669.839s: you have in observation is not just the\n671.82s: force response X is the phosphorus only\n674.04s: so you have internal viability and\n676.32s: there'll be another source for\n677.459s: uncertainty which is a measurement in\n679.74s: certainty so basically the fact that we\n681.24s: don't know exactly the the government\n683.76s: temperature there are assumptions and\n685.98s: uncertainty related to reconstruction\n687.899s: and that it is true today and also in in\n691.32s: the over the history\n693.42s: now when you have a\n696.6s: settle these these two equations it's\n699.24s: pretty easy because everyone is quotient\n701.459s: and so you can derive a posterior of x\n704.459s: given Y and that's exactly what what we\n707.94s: are interested in in observational\n709.62s: constraints\n711.24s: um\n712.56s: so now if you if you\n715.62s: take a bit of perspective on these\n718.32s: equations in fact you can identify\n720.36s: everything that is used\n723.0s: in in two other fields of of Applied\n727.5s: Mathematics I would say the first one is\n729.899s: Trading\n731.04s: so this is exactly like rigging and the\n733.86s: other one is is a carbon filtering and\n736.5s: in fact because we are using here a set\n739.62s: I mean a sample of of models it's in\n743.399s: fact it's kind of Ensemble Ensemble\n745.2s: Calamine filtering but we focus only on\n749.16s: the on the climatic response so the\n752.399s: fossil response and everything else is\n754.92s: treated as a noise\n756.54s: which of course is a kind of application\n758.519s: that is pretty different from what is\n760.74s: done in in uh numerical weather\n763.2s: forecasting\n765.12s: and so you have the same four key inputs\n769.2s: um as in in usual Kalman filtering so\n771.24s: you have you have observations\n773.7s: you have\n775.139s: um\n775.76s: an estimate of uh so this is this will\n778.68s: be called the analysis I think by by\n781.74s: data simulation people an estimation of\n784.62s: the state of of X without any other\n787.98s: source of information and you have two\n790.26s: key uncertainties the first one is is uh\n793.74s: I mean governance Matrix is discovering\n795.72s: this uncertainty the first one is the\n797.22s: model uh model error\n800.76s: um again that's the way people in in\n802.26s: data simulation call it and um\n805.139s: observational Evo uh\n808.2s: um again described by this by this\n810.72s: Matrix so and and everything every I\n813.3s: mean the result we directly depend on\n815.7s: how you can\n817.139s: estimate these matrices so estimating\n820.019s: these matrices is in fact part of the\n822.3s: of the issue\n825.54s: okay\n826.56s: um I I forgot to say that if\n828.839s: someone has questioned about about this\n831.899s: what I am saying you can interrupt me\n833.82s: anytime\n834.899s: better to to ask\n837.72s: okay so the first thing we have done\n840.54s: with that methodology is to to to test\n843.959s: it in a perfect model framework so we\n846.3s: take basically um\n849.72s: collection of of\n852.48s: historical and scenario simulation by by\n855.06s: various uh semi-d6 models and we try to\n858.3s: apply this technique to predict the\n861.779s: amount of farming in the future uh\n865.019s: um only based on observations of\n867.66s: government temperature in the model up\n870.48s: to 20 or 2020 so pretty much the same\n873.779s: kind of configuration then what we have\n876.24s: to do in the with the real data\n880.86s: um sorry this was a question\n885.66s: no okay\n887.82s: um so the thing so for so this is a\n890.1s: collection of of run\n892.139s: um each value is run you have in pink\n895.079s: you have the uh what what is the prior\n898.019s: so the information of future warming\n899.88s: just based on the prior the priorities\n901.86s: is is made with all other models than\n905.1s: the one used uh for the test and\n909.0s: um and the the red bars indicate the\n912.66s: posterior uh confidence interval and the\n916.019s: black black dot is is a true value of of\n919.56s: the model so this is for instance I will\n921.42s: take this one there are a lot of front\n923.1s: for this one this is scanning sm5\n924.779s: because it's a bit large and Sample so\n927.54s: we have lots of a friend I take the\n929.94s: first one we have we have all these uh\n932.76s: similar Kani sm5 simulations and so they\n935.519s: gave us an estimate on what is the true\n938.16s: warming at the end of the 20 rule which\n940.38s: is the back point and it's the same for\n942.06s: all runs because they are all simulating\n943.86s: the same on average the same Frozen\n946.079s: response\n947.88s: and of course we want the Red Bar to be\n951.42s: close uh to I mean to to cover the True\n955.139s: Value which is the black one and so we\n957.24s: we use this kind of validation uh\n959.94s: methodology to to\n961.86s: um estimate the coverage probabilities\n964.5s: of the coverage probability is in fact\n966.72s: when you calculate for instance a 90\n968.399s: confidence interval which is the case\n970.74s: here you expect the True Value to fall\n973.68s: within the confidence interval about 90\n975.899s: percent of time and so you need to check\n977.88s: whether you find this 90 probability uh\n981.6s: to be correct in practice\n983.579s: and that more or less the case here\n985.38s: because\n986.459s: um depending how you you weight models\n988.62s: uh and and and runs we are about at 90\n992.76s: percent uh\n995.579s: for for the coverage probably this is\n997.8s: the kind of\n998.94s: perfect model validation of the\n1001.459s: technology\n1003.98s: um okay now I come to the to the real\n1006.38s: application to um\n1008.92s: to Global mean temperature warming\n1013.94s: um this is kind of the key figure so\n1015.86s: this was describing a paper in science\n1017.959s: advances in 2021\n1021.38s: um and this so this was made calculation\n1024.02s: prior to the to the ipcc rf6\n1027.25s: [Music]\n1027.62s: um\n1028.9s: I have highlighted three key scenarios\n1032.959s: here SSP one 2.6 SSP 2 4.5 nft5 8.5\n1039.699s: and the general uh I mean the key points\n1043.459s: here are the fact that first and it was\n1045.74s: in fact a surprise\n1047.66s: we will use uncertainty ranges\n1050.66s: uh pretty strongly in fact even in the\n1053.54s: in in 20 uh sorry at the end of the 21st\n1057.74s: century uh the red the the narrowing of\n1060.559s: uncertainty is close to 50 and this is a\n1063.74s: lot and we clearly did not expect that\n1065.9s: the high value\n1067.1s: of course uncertainty is even uh more\n1070.46s: reduced over the historical period\n1072.679s: because we the available observation\n1074.6s: provide even more accurate information\n1076.82s: over that period of time\n1079.1s: uh but still we have you have this\n1081.32s: consistent uh picture of of future of I\n1084.799s: mean past and future tense which is\n1086.66s: perfectly consistent at any time\n1090.38s: and that's a nice property of the of the\n1093.62s: method\n1095.0s: um another important result was the fact\n1097.4s: that both the upper and\n1099.58s: uh and the the\n1102.08s: um and the lower end of the range were\n1104.36s: affected by the constraint previous\n1106.46s: studies in fact mainly reported the fact\n1109.16s: that given the\n1111.4s: relatively limited or weak worrying over\n1115.16s: the last decades\n1117.02s: um essentially the only only the high\n1119.36s: sensitivity uh busways were rejected by\n1124.039s: any observational constraints and we\n1125.78s: also find in this case that there are a\n1128.12s: few models which in fact do not run\n1130.1s: enough\n1131.299s: and and they probably still do not warm\n1134.0s: enough at the end of the 21st century so\n1135.919s: we are also revising a poor the lower\n1138.98s: the lower end of of these ranges which\n1142.1s: which was new\n1143.66s: and and another Advantage here of the\n1146.059s: technique is the fact that\n1148.22s: when we do this calculation we use the\n1150.5s: entire observational record there is no\n1153.32s: uh empirical choice about how to select\n1158.12s: maybe the last 40 years\n1160.52s: for for the trend and this trendy can\n1163.039s: provide some information or another\n1164.66s: period of time or how whether we have to\n1167.179s: project the observations on the linear\n1169.46s: Trend or another another temporal shape\n1171.74s: no you just use the take the entire\n1174.74s: record and and apply the method with\n1177.86s: without having to care for other things\n1180.32s: than just estimating the Covenant\n1182.0s: matrices that I mentioned before\n1184.16s: okay and so these results were\n1187.059s: considered by the ipcc R6\n1190.58s: I will speak more about that later\n1192.98s: um\n1193.82s: now another thing you can do I did not\n1197.08s: provide detail on on how you can how you\n1201.32s: have to adapt the method the equations\n1203.6s: to make this sort of assessment but you\n1207.2s: can also use the same technique to\n1208.58s: provide revised estimates of attribution\n1211.94s: attributable warming what what the DNA\n1214.7s: Community has been called occurring\n1216.38s: attribute to performing which in fact\n1218.419s: the the warning related to each uh\n1221.539s: one into several subsets of external\n1223.76s: forcing individually so this is uh in\n1227.84s: fact this is a\n1229.82s: yeah this this type of result so again\n1232.58s: you have two bars for each subset you\n1235.1s: have one Graybar which is the and\n1237.26s: constraints with six results and the\n1240.32s: black bar which is uh the the same\n1242.539s: estimate after uh comes during\n1244.46s: observations and so this is the\n1246.32s: constraint value\n1248.78s: you can see that okay see it's in that\n1250.88s: the warming induced by the natural\n1252.679s: forcing is very very small the all of\n1255.02s: the value induced by all forcing is\n1256.58s: exactly uh consistent with what was\n1259.52s: shown here so it's about the same thing\n1261.62s: but just focused at in 2020\n1265.94s: and then you can reconstruct the the the\n1268.16s: the impact of\n1271.16s: human inference as a wall or uh you can\n1276.14s: also make the distinction between\n1277.4s: greenhouse gas and other entrepreneuric\n1279.799s: inferences\n1281.72s: um dominated by by anthropogenic\n1283.76s: aerosols and so of course you you find a\n1286.7s: result which is pretty well known since\n1289.1s: at least cr5 and maybe even before the\n1293.0s: fact that there is part of the Equinox\n1295.039s: gas warming which is offset by uh the uh\n1299.36s: cooling induced by aerosource and and\n1302.299s: all other\n1303.7s: entrepreneuric forcing taken together\n1306.62s: okay and in that way you have an\n1308.78s: estimate of the warming to date\n1311.48s: it was a bit above 1.2 degrees in 2020\n1315.679s: at the time we made this study and in\n1318.919s: fact because we have time series and you\n1320.72s: can see here you have smooth time\n1322.159s: service so it's pretty also\n1324.2s: um suitable to estimate uh warming\n1326.84s: height and you can uh specifically\n1329.9s: estimate the human induced forming rate\n1332.299s: which is uh Point 20 23 degrees Celsius\n1337.039s: by by decade over the last\n1341.14s: decade and this was again considered by\n1344.78s: iptcr assets\n1347.48s: okay so implication of this work uh\n1350.179s: where that I mean practically for for\n1353.12s: the R6 were where that there are six for\n1356.78s: the first time\n1358.1s: considered uh observational constraint\n1361.46s: to to assess the amount of warming over\n1365.419s: the 21st century and this was a kind of\n1369.62s: working point if you compare to previous\n1371.659s: assessment report because until until\n1373.46s: now this this\n1375.32s: was not the case\n1377.659s: um and so uh previously ipcc report only\n1379.76s: considered uh raw unconstrained uh semi\n1383.539s: model results\n1385.22s: and so here is a the figure 4.11 from\n1388.7s: the the R6\n1390.799s: um\n1392.36s: there were three studies doing more or\n1395.0s: the same type of calculations that I\n1396.74s: shown before so ribital is one of the\n1399.2s: three dialect\n1401.659s: and these are the the unconstrained\n1403.7s: ranges for different scenarios\n1406.299s: at the end of the 21st century and it\n1409.22s: has a constrained ranges from the same\n1411.86s: scenario\n1413.9s: um and there are things also considered\n1417.02s: uh emulators which are in fact very\n1419.78s: simple climate more only usually uh ebm\n1422.96s: so energy balance models\n1425.179s: um two boxes ebms usually uh and this uh\n1429.38s: so because these tools are very\n1432.08s: you know practical because very cheap so\n1435.74s: you can make lots of calculations with\n1437.78s: many scenarios which you can cannot run\n1441.14s: with with full complexity cement models\n1443.72s: so that's why there have been pretty\n1445.22s: much used and considered in the AR6 and\n1448.159s: in fact the result provided by the three\n1450.919s: uh observational constraint methods and\n1454.159s: you see very simple climate models where\n1457.4s: pretty much\n1458.919s: consistent and and so finally the uh the\n1462.799s: assessment of GSAT warming was was based\n1466.1s: on on the combination of all these\n1467.9s: sources\n1470.179s: um\n1472.4s: okay\n1473.9s: oops and then a little after there was\n1477.5s: this this uh this paper\n1481.48s: in nature um\n1483.919s: speaking about the the hot model problem\n1487.82s: um\n1488.84s: and so this this paper was was\n1491.36s: essentially uh\n1493.1s: explaining that okay we have we have the\n1495.62s: problem and if you if you come back here\n1498.2s: uh you look at the at the upper bound of\n1500.24s: the ranges there is one one clear\n1501.86s: problem in that there is a collection of\n1503.78s: of high sensitivity models in cm6\n1506.9s: which simulate the high amount of\n1509.179s: warming for any any scenario here uh\n1512.48s: which doesn't seem to be consistent with\n1514.52s: with uh observations and which are\n1517.1s: basically\n1518.5s: removed or yeah excluded by\n1521.96s: observational constraint here okay this\n1524.539s: is these high values are rejected and so\n1527.96s: uh this should be uh taken into account\n1530.659s: so this is a disease is developed by\n1532.94s: this by these people is that this should\n1535.4s: be accounted for in any uh climate\n1538.46s: impact study because considering the the\n1540.74s: role\n1542.059s: um 76 Ensemble there is a risk to\n1545.12s: overestimate uh warming and and all\n1548.36s: Associated impact\n1550.22s: and so they were suggesting to to to\n1553.179s: Simply remove\n1556.22s: hot models from this sample uh and of\n1560.779s: course I've been pretty much debate\n1562.34s: within the community whether this is a\n1564.26s: good idea on Art\n1565.58s: um and our response maybe is that this\n1568.1s: is not necessarily the the best practice\n1570.2s: because probably you can you can find\n1573.08s: other ways to provide a regional\n1575.84s: information\n1576.7s: including the uh\n1579.58s: observational constraints another topic\n1582.799s: of the of the YouTube now\n1585.86s: so I will I will uh for this so this is\n1588.5s: a different work uh down I mean\n1591.32s: published last year 2022\n1594.08s: um\n1594.679s: two papers describing this and to\n1597.98s: explain how we do this I will I will um\n1600.98s: uh focus on an example one of the study\n1604.34s: which was looking specifically at the\n1607.1s: temperature of the front so okay France\n1609.26s: is a small domain\n1611.38s: uh probably not not representative of\n1614.419s: what is happening in other places but\n1616.22s: it's an illustrative example here\n1618.62s: uh and in fact so in terms of equations\n1621.26s: as a method first in fact you you are\n1623.36s: just doing the same thing but you just\n1626.9s: considering a bit longer vectors so this\n1630.14s: is the time series I had before\n1632.38s: 250 years and this is a global mean\n1635.96s: temperature and in fact what you do it's\n1637.46s: very simple you just add another time\n1639.74s: series same length uh 20 200 uh 50 50\n1644.779s: years again but this is a regional\n1646.94s: temperature this regional response\n1649.52s: to external forcing\n1651.94s: and again you have two types of\n1654.2s: observations you have the global mean\n1655.7s: temperature observations and you have\n1657.14s: the regional observations and there\n1659.12s: might be some level of some some amount\n1661.88s: of dependent statistical dependencies\n1663.86s: between these two things which you need\n1665.24s: to\n1666.02s: take into account\n1668.419s: now when you do that there are at least\n1670.52s: two ways you can you can think about to\n1673.88s: implement an observational constraint\n1675.2s: the first is just to consider the\n1677.659s: regional implication\n1679.279s: of the global mean temperature\n1681.32s: constraint so basically you will\n1683.059s: constrain this large vector by just\n1685.7s: considering a global mean temperature\n1687.38s: observations\n1688.539s: and the other step is whether or not\n1692.72s: Regional observation provide useful uh\n1696.2s: additional value\n1697.84s: over the global observation and that's\n1701.48s: the topic we have been discussing the\n1703.52s: result suggests effectively uh\n1706.58s: there is some added values in during\n1708.62s: Regional observations\n1711.08s: okay so this is the example this is a\n1713.72s: this is a Time series of mean\n1716.179s: temperature over Mainland France\n1719.12s: um\n1720.38s: so you have one one point here for uh\n1723.02s: one one punch is one Euro from uh 1900\n1728.419s: to 2020\n1730.299s: 2020 was the record high ah year in\n1734.779s: France at that time and so you can you\n1737.9s: can make I mean compare these observed\n1740.179s: time series with with various ways of\n1741.98s: applying the observational constraint\n1743.419s: the first\n1744.52s: things\n1746.24s: to begin with is is uh you can run a\n1749.96s: basic smoothing and if you do that uh\n1752.48s: spline smoothing here just without\n1754.64s: considering models\n1756.32s: you get an estimate of the warming in\n1758.36s: 2020 which is close to plus two degrees\n1760.94s: so much much higher than the government\n1762.679s: temperature\n1764.24s: now if you look at the same six models\n1767.38s: multiple mean\n1769.82s: no no treatment here you have this Gray\n1772.76s: Line\n1774.32s: um and this is in fact is the mean\n1775.88s: including the hot models so even if you\n1779.96s: incorporate very high sensitivity models\n1782.6s: you still feel like over the last 3D\n1785.539s: case maybe almost all years are hotter\n1789.38s: than what they should have been on\n1791.419s: average given the fossil responses\n1793.22s: estimated by this Gray Line and so maybe\n1796.34s: there is not enough running in this Gray\n1798.44s: Line\n1799.34s: now you can you can Implement first the\n1802.22s: constraint observational constraint by\n1803.96s: by global mean temperature only this is\n1806.36s: a gray line and when you do that in fact\n1808.82s: as I have shown before you are\n1811.039s: essentially rejecting the high\n1812.419s: sensitivity models and so you are really\n1814.399s: revising uh downward uh the amount of\n1817.46s: Plumbing uh over the recent period and\n1820.159s: also in the future which is now shown\n1822.08s: here but I I can say\n1825.2s: um and in that case it's sent uh pretty\n1827.779s: attractive to consider the regional\n1829.34s: observations you can either consider\n1831.62s: only Regional observations in the\n1834.14s: constraint which is the blue line here\n1835.58s: so the fit with the black points is\n1837.62s: pretty pretty good because there is no\n1839.6s: other source of of of observations used\n1843.26s: in this calculation and if you combine\n1845.72s: the two sources of the global and the\n1847.34s: original you have this kind of\n1849.08s: red estimate which is uh in between\n1852.62s: blue and green and you have also an uh a\n1857.72s: confidence range around this value\n1859.659s: saying that basically you estimate the\n1861.98s: amount of running between between what\n1863.72s: what gives multiple mean and and the\n1866.6s: constraint with only Regional\n1868.279s: observations\n1871.399s: perfect model analysis in that case\n1873.5s: suggests that there is some alert values\n1876.2s: considering the the the two source of\n1878.72s: information and and that's what we will\n1881.48s: use in the following\n1883.58s: um\n1884.179s: and so this is the same pictures but\n1886.7s: picture but for the for the future\n1888.32s: warming and you can see that in fact it\n1890.12s: has a\n1891.14s: I mean using this applying this\n1892.88s: technique for for\n1894.38s: the future running reference was was\n1896.539s: pretty\n1897.799s: uh important because we find that\n1899.539s: finally uh despite low sensitivity\n1903.08s: at the global scale we find\n1905.059s: a pretty high sensitivity regionally and\n1908.179s: we release the amount of roaming\n1910.039s: expected in in\n1913.34s: coming decades Apple\n1916.1s: again we find a very substantial\n1918.559s: reduction\n1919.72s: of of the uncertainty up to 40 to 50\n1925.46s: percent even at the end of of the of the\n1928.58s: 20 which is again a very high amount of\n1931.58s: reduction especially because during you\n1933.559s: are at the regional scale\n1935.72s: um and so in fact there is a competing\n1938.0s: effect in this at least in this region\n1939.86s: between between the global global\n1941.84s: observations\n1942.98s: and the original observations and uh\n1946.72s: arguably accounting for for the tweets\n1950.12s: is effective\n1952.279s: so the final conclusion with respect to\n1955.7s: the hot model problem is that in that\n1957.74s: particular case\n1959.779s: um hot models are very useful and in\n1962.12s: fact that can be useful at least for\n1963.919s: some specific regions we can because\n1966.08s: observations seems to agree more with\n1969.2s: these hot models over that region\n1972.5s: um even if it is not the case globally\n1976.399s: okay so uh the global perspective was\n1979.159s: was provided by casmian ribs in in\n1981.08s: science advances again we try to\n1983.6s: replicate this kind of analysis for any\n1986.48s: any uh any single location uh on Earth\n1990.44s: so this is a just uh\n1992.96s: advertisement of of the study\n1995.96s: um what happens for a few uh\n1998.299s: well-known cities and you can see that\n2001.0s: the amount of revision revision uh\n2003.64s: downward for instance or or or upward in\n2006.88s: some case uh varies uh depending on the\n2009.76s: location and and so the the local the\n2012.7s: regional observations and another thing\n2014.98s: you do in that case is that in fact you\n2017.919s: are revising and in fact constraining\n2022.48s: based on observations the the pattern of\n2025.84s: of warming and so this is an\n2027.82s: illustration of that this is the the uh\n2030.279s: the pattern of warming at plus two\n2033.22s: degree global warming level published in\n2035.86s: the nipscr6\n2037.899s: I mean maybe maybe not exactly the same\n2040.0s: because I'm not sure we are using the\n2041.74s: same models but but doesn't matter\n2043.24s: really\n2044.62s: um and and uh we are we have shown that\n2047.62s: if you constrain by uh chlorine\n2050.74s: temperature\n2052.0s: observations you are already\n2054.82s: uh changing this pattern a bit okay of\n2058.06s: course it's a large scale the big\n2059.8s: picture Remains the Same you still have\n2061.98s: continents warming more than ocean the\n2064.899s: Arctic is is warming the most\n2067.72s: Etc but but locally there are some\n2069.7s: differences and when you incorporate a\n2072.159s: local uh observation to also release a\n2075.46s: bit so it is spatial bottom and Below\n2078.96s: how much you you change locally the\n2082.06s: values in all cases this is at plus two\n2085.659s: degrees global warming so in fact we are\n2088.0s: now at the point where probably\n2089.82s: observations can be used also to\n2092.56s: constrain uh patterns of warming\n2097.32s: quick quick slide this is the last one\n2100.06s: discussion um\n2102.76s: so our key results are in fact are I\n2106.119s: mean the first one to me is really uh\n2109.42s: um introducing this new statistical\n2111.94s: technique I think the analogy with with\n2114.88s: Karma and Philippine is very interesting\n2116.92s: because you know data assimilation and\n2119.14s: using this type of of statistics for a\n2121.9s: long time and and in fact there is\n2123.46s: probably a lot to learn with people\n2126.46s: involved in that area on how to extend\n2130.06s: application\n2131.619s: of that technique and improve the method\n2134.14s: itself\n2135.4s: um using what I've been doing in data\n2137.14s: simulation so that's the first result\n2138.94s: maybe\n2140.2s: um\n2140.8s: other key result more more focused on\n2143.859s: the application is are that uh\n2146.14s: observational constraints now seem\n2148.24s: pretty effective\n2149.74s: for constraining uh temperature changes\n2153.54s: both globally and regionally\n2156.76s: and there are in fact substantial\n2158.32s: implications for for that result in\n2161.14s: particular uh the fact that we can\n2163.54s: reduce uh uncertainty is important for\n2166.96s: impact adaptation and other policies\n2170.2s: uh there is a wide range of applications\n2172.42s: so I have shown only temperature here\n2175.54s: um but we already have started working\n2177.7s: on other variables in fact\n2180.28s: as soon as\n2182.02s: the signal to nodes ratio is is pretty\n2184.9s: good pretty high meaning that there is\n2187.42s: in the observations\n2189.4s: um an information that is that that is\n2192.04s: uh that can be used\n2194.079s: to learn things about the long-term\n2196.9s: change\n2197.56s: you can apply this technique and get\n2199.42s: interesting results so there have been a\n2202.18s: few attempts attempts already on on the\n2204.28s: water or cycle variables in particular\n2205.9s: the amount of water vapor in the\n2207.46s: atmosphere which is called precipitable\n2210.04s: water\n2211.66s: um and and\n2213.72s: the humidity of our continent and it\n2217.119s: seems that in these two cases\n2220.24s: we learned a few things in implementing\n2223.24s: this type of constraints\n2225.06s: probably we can do a similar thing for\n2227.8s: extremes not done yet but that's uh in\n2230.859s: our scalp\n2232.359s: and there is also the possibility which\n2234.76s: is maybe a bit new\n2236.92s: uh to try to monitor climate change\n2239.02s: because we can probably and that's\n2241.119s: something we're working on at the moment\n2243.76s: uh try to update this kind of analysis\n2246.88s: on a regular basis as as as soon as you\n2249.64s: have new observations coming uh uh each\n2252.94s: year you can\n2254.94s: reduce the calculation and have uh some\n2258.64s: gain in in uncertainty reduction about\n2261.16s: both the past and the future warming\n2265.359s: um\n2266.26s: this is this can be important even even\n2268.599s: you know just the fact that you can\n2270.28s: assess the amount of two days to day\n2272.8s: warming uh to just monitor uh how how uh\n2277.26s: Paris agreement targets for instance\n2280.72s: are becoming closer\n2283.599s: foreign\n2286.66s: there are a few issues too the first one\n2289.599s: is related to the Simi band symbol in\n2291.88s: fact Simi piece is a\n2294.52s: not so uh\n2296.56s: perfect it's very small\n2298.839s: models are not independent they are\n2301.24s: pretty much literature discriminates and\n2304.0s: and the design is very poor in the sense\n2306.76s: that there is no coordinated effort in\n2310.3s: Simi to explore and turn into in fact\n2313.119s: each modeling Center develops its its\n2315.579s: own model and try to make it the most\n2318.16s: accurate as possible and no one is is\n2321.339s: trying to develop a model to explore the\n2323.98s: low sensitivity or the high sensitivity\n2325.839s: so in that case considering this\n2328.72s: Ensemble as a prior is a pretty big\n2331.119s: assumption but probably the only one we\n2332.98s: can we can use at the moment but not not\n2335.74s: that good maybe\n2337.99s: [Music]\n2338.38s: um\n2339.4s: and also another source of of content\n2341.8s: comes from the all the the pattern\n2343.54s: effect literature so uh the fact that\n2346.72s: model in fact all climate models semit\n2349.54s: models\n2351.4s: are maybe missing uh important features\n2354.28s: of the of the the response to the to the\n2357.22s: green of gas forcing in particular in\n2359.56s: the Pacific region but the Pacific it's\n2361.54s: large and and uh and so if of course if\n2364.96s: we have a prior in which all\n2368.02s: all models are doing are similarly\n2371.02s: biased\n2371.98s: it's not not good\n2374.56s: for by agent statistics\n2379.359s: okay and now there is a new maybe a\n2381.88s: challenge we are trying to face as at\n2383.98s: the national scale I'll just quickly\n2386.079s: mentioning here is the fact that okay we\n2388.18s: were used to provide\n2390.28s: to a wide range of users uh information\n2393.76s: of about climate change of reference and\n2396.52s: sometimes at the local scale using a\n2399.4s: previous generation of climate balls and\n2402.28s: in fact Regional climate models of\n2403.66s: colleagues eurocodex grants typically\n2406.66s: but now we have this obstacle\n2408.16s: observational constraints coming\n2412.06s: into the game and and they are providing\n2415.3s: different estimates of the future\n2416.98s: warming and so there are uh there is a\n2419.8s: challenge how to reconcile these two\n2422.74s: sources of of data and how to use uh\n2427.42s: maybe\n2428.32s: um\n2428.859s: uh model outputs\n2431.28s: which permanently do not do not form\n2433.839s: enough\n2435.339s: and and and given given all the new\n2438.16s: results we have with observational\n2439.54s: constraints that's a typically uh\n2442.359s: Climate Services question but but still\n2444.579s: an interesting one I think\n2446.74s: and and I will stop here thank you I'm\n2450.64s: I'm happy to respond to questions\n2458.92s: I suggest to uh to stop sharing uh maybe\n2463.18s: and uh and uh and see you all\n2469.06s: okay yeah maybe maybe questions\n2471.22s: um from postdocs and PhD students first\n2473.5s: if anybody has an I'd like prop uh\n2476.8s: please raise your hand\n2490.599s: uh oh yeah can you hear me yeah\n2494.619s: okay yeah thanks for a great talk this\n2497.079s: is very informative\n2498.7s: um I have I have a couple of questions\n2501.4s: but I think I'll just stick to one in\n2503.26s: the interest of time\n2505.119s: um maybe this is something that you\n2507.52s: explained and I I wasn't following very\n2509.619s: closely uh but he's you know it's just\n2513.22s: one of those main results of the first\n2514.54s: part of your talk where you talked about\n2516.04s: how the uncertainty ranges were narrowed\n2518.92s: by say 50 percent\n2521.619s: um and and there and and I think this is\n2524.619s: one of the issues you also mentioned the\n2526.06s: end about like the whole like about\n2528.339s: using\n2529.66s: um\n2530.32s: you know correlated Ensemble members so\n2533.98s: maybe yeah so just to phrase my question\n2536.32s: would be what is this uncertainty range\n2539.02s: that is being reduced by 50 like\n2540.76s: mathematically is this the one Sigma\n2542.32s: Ensemble spread uh or is this the two\n2546.579s: Sigma whatever uh spread for\n2549.94s: um the quartile range so just just some\n2553.06s: uh just being a little bit concrete\n2555.04s: about what the uncertainty is and how\n2557.32s: does this in principle affect extremes\n2559.24s: because you're only talking about I mean\n2560.74s: this is not something that you've shown\n2561.94s: but I'm curious about like if you've\n2563.859s: played with uh you're talking about\n2565.66s: average temperatures but what happens in\n2567.88s: cases of um I don't know extremes saying\n2571.0s: like heat waves and so on\n2572.92s: yeah so uh so so the Rangers I have Sean\n2576.16s: where or\n2577.9s: always\n2579.04s: um 90 confident range assuming a\n2582.04s: gaussian distribution\n2583.96s: so it's more or less a plus minus two\n2585.94s: Sigma okay no no it's 90 now it's not\n2590.319s: 95. okay so but a bit a bit less than\n2592.78s: that uh but that that what we do\n2596.079s: um\n2597.28s: and this is true for the prior\n2600.94s: and this is true for the posterior\n2603.52s: I always use this type of calculation\n2607.5s: now the relationship to extremes that\n2610.96s: was the question\n2611.98s: yeah in fact\n2614.74s: it is very important to constrain the\n2616.48s: global mean temperature because you know\n2617.8s: almost everything in the system scales\n2620.98s: with lowering temperature\n2622.72s: if you are aware of the pattern scaling\n2625.48s: literature and it's about this applies\n2627.819s: to the pattern but it applies also to to\n2629.68s: changing in a wide range of extremes and\n2633.46s: so for instance if you look at the uh\n2635.819s: AR6 summary for policy makers you have\n2639.46s: numbers about how much heat wave will\n2643.24s: change in probability for a given global\n2646.06s: warming level\n2647.079s: so people now provide the response for a\n2649.24s: plus two two degree world for instance\n2651.16s: and uh if you constrain the government\n2653.44s: temperature of course you constrain the\n2655.96s: timing at which you will face this type\n2658.0s: of change in exchange\n2660.88s: uh right but I mean yeah no I think this\n2664.0s: is clear and I am aware of like the the\n2666.4s: fissure and uh Nutri paper and and stuff\n2670.06s: for the of you know the scaling with the\n2672.22s: extremes and around the stuff even\n2674.98s: um but but yes the question is does\n2677.38s: constraining with observations I don't\n2680.319s: know like because they they're only\n2681.819s: looking at at models right and I'm\n2683.859s: wondering if if you've like even played\n2686.38s: around with some of your experiments\n2687.94s: where including observations would\n2690.64s: so you would just say that you know like\n2692.74s: whatever scaling that they have for the\n2694.78s: mean temperature you would just put you\n2697.06s: know use your results and use their\n2699.16s: scaling relationships and and obtain the\n2701.5s: the answer for for experience yeah so\n2704.68s: okay I understand I think uh as a\n2706.72s: question uh maybe maybe your question is\n2708.579s: can we can we learn more and constrain\n2711.22s: the response of extreme better\n2713.44s: accounting for observations of extremes\n2715.96s: that's right yeah because it's a\n2717.4s: distribution at the end of the day and\n2718.66s: this is where you get both from the\n2720.819s: ensembles as well as the observations\n2722.5s: and in fact so in fact we I have another\n2725.26s: paper uh trying to do that so many\n2728.319s: people try to model\n2730.18s: from a statistical point of view the\n2732.52s: response of extremes using a mean\n2735.28s: temperature of some sort as a covariate\n2738.4s: right okay in gev models or\n2742.119s: that sort of thing and we try to do that\n2745.06s: and in fact then uh we we what we try to\n2749.5s: do is apply more or less the same kind\n2751.96s: of statistical technique you take you\n2753.88s: consider models provided prior\n2756.339s: and then you have observations which can\n2758.26s: be used to to construct to to estimate\n2760.72s: the posterior in those type of\n2763.3s: non-stationary Dev models\n2765.819s: so I have another paper which I did not\n2767.92s: mention here uh with about that and and\n2771.819s: uh\n2773.02s: but at that time we were a bit less\n2775.42s: clear on the concept of observational\n2777.88s: constraints and so the paper is not\n2779.5s: written that way but the idea is here\n2781.359s: and in fact yeah you're right we you can\n2783.94s: do that and it's it makes sense and you\n2786.88s: at the end you you get um a more\n2790.0s: accurate estimate of changes in the\n2792.4s: distribution of extremes\n2794.38s: that way yeah\n2796.9s: I'll take a look at your paper thanks\n2798.579s: again for a great time\n2800.2s: thanks\n2823.42s: I see a few hands I let you manage Cara\n2825.94s: can I\n2828.28s: I think Robert I saw your hand first if\n2830.619s: you want to go ahead\n2833.26s: hi and thanks for this talk you\n2836.74s: there are many flaws to the cmib\n2839.44s: collection of models um sort of\n2841.96s: identified that they're not really an\n2843.4s: ensemble in any way they're not that\n2845.2s: that collection of\n2846.94s: simulations uh with that collection of\n2849.46s: models isn't designed to sample\n2851.02s: uncertainty at all I'm curious um\n2853.9s: from the perspective of synthesizing\n2856.599s: observations and simulations\n2859.359s: um if you had the choice what would\n2862.9s: another collection be that would be best\n2866.8s: suited or better suited uh to\n2869.079s: synthesizing with observations\n2872.2s: the good question\n2873.819s: um\n2874.54s: in fact so we were aware of of a few\n2878.319s: papers by by Red Dog new teeth and his\n2880.96s: group about these issues of models being\n2883.54s: none non-independent in particular so\n2885.76s: the models typically share\n2887.92s: a lot of of code and sometimes even all\n2890.74s: the atmosphere or the ocean are in the\n2892.96s: same in different worlds and so there is\n2894.88s: a clear non-independence between models\n2896.74s: and so we have tried to implement his uh\n2899.5s: he's a diagnosis\n2902.56s: uh of Independence and and use it in\n2906.46s: this technique and in fact it makes\n2909.22s: almost no difference\n2911.02s: so it was\n2912.339s: a bit disappointing for us\n2914.63s: [Music]\n2914.92s: um\n2916.18s: um so the independence issue alone\n2918.64s: doesn't doesn't affect that much episode\n2921.579s: so if I had uh\n2924.099s: magic power what I would do uh to\n2928.18s: improve that is probably have a look at\n2932.22s: physics and samples\n2934.42s: uh because at the moment it's probably\n2937.3s: the only way to really explore\n2939.78s: uncertainty on a systematic way\n2943.0s: but it would mean I mean I I'm aware\n2944.92s: that there is some available literature\n2946.78s: on on PPE\n2949.18s: people do not often uh\n2952.3s: um I mean cannot often reproduce all the\n2955.42s: range of semips responses so in fact you\n2958.839s: you systematically explore uncertainty\n2961.06s: but at the same time at the end of the\n2962.44s: day maybe you are missing some some type\n2964.18s: of uncertainty\n2965.7s: and of course a very very\n2969.04s: ID or situation would would be to have a\n2972.22s: instead of semi semi models uh we could\n2976.18s: have semi PPE I mean one PPE for each\n2978.46s: model in that case we can really work\n2980.619s: with with uncertainty probably a bit\n2982.839s: better\n2983.8s: but\n2984.88s: this is a considerable effort that is\n2988.3s: maybe not not that likely to happen so\n2990.4s: uh\n2991.599s: I'm afraid we are\n2994.0s: we will have to work with semi-pensable\n2996.04s: or equivalent for a long time again\n2999.52s: foreign\n3010.74s: I think you're our next\n3012.74s: yeah hi thanks for the talk\n3015.54s: um I was I think it's sort of shown by\n3017.94s: your example comparing France to Global\n3020.76s: um uh uh the question of you know if\n3023.04s: you're only using one data set Global\n3024.78s: temperature\n3027.119s: what's the best model for precipitation\n3029.04s: might be different what's the best model\n3030.66s: for France might be different right so\n3032.579s: how how and I think this is sort of what\n3034.859s: was expressed in that piece about the\n3037.319s: hot models like how do we like\n3041.04s: the idea of a climate model is it gives\n3042.96s: you everything right\n3044.7s: um how is it by having multiple\n3047.46s: constraints or and I guess so anyway so\n3050.52s: that's the big big picture but basically\n3051.9s: like when you're working on\n3053.099s: precipitation are you finding that the\n3054.72s: same models do well or are you throwing\n3056.7s: out different models when you when you\n3059.22s: look at precipitation\n3060.839s: um so yeah\n3063.66s: um\n3064.26s: it's in fact this technique is not not a\n3066.96s: model waiting schema so most people have\n3069.78s: been trying to implement observational\n3071.22s: constraints using model waiting in model\n3073.14s: waiting there is ranking of model\n3076.26s: and you apply the same ranking for all\n3078.119s: variables and in somehow you are you are\n3080.7s: giving uh yeah really a way to a given\n3083.46s: model and it's always the same it's not\n3085.26s: the case here\n3087.3s: um\n3088.319s: and so that's part of my my yeah my hope\n3091.5s: and my response to that uh we we\n3094.28s: probably can adapt to What observations\n3098.28s: are saying and it can be the\n3100.68s: observations can have a different\n3102.68s: preference for for some models for one\n3105.839s: variable and some others for under the\n3107.7s: variable\n3109.5s: so your idea is that you would like do\n3111.96s: this kind of thing like I want to study\n3113.819s: ocean pco2 and so I would apply this\n3116.819s: approach to find the models that are\n3118.68s: most appropriate for that question and\n3121.14s: then I would if I was interested in\n3124.319s: um ocean circulation I would yeah I mean\n3127.44s: I guess one of the challenges is that we\n3129.72s: don't have good data for a lot of things\n3132.24s: right we don't have great data for\n3134.22s: motion circulation and its variability\n3136.5s: so that's that's then what's the proxy\n3140.4s: um to make that selection becomes a real\n3142.14s: question\n3143.16s: so in Yeah in our case so what what can\n3145.98s: be done to to to you know\n3149.76s: to investigate another variable in that\n3152.04s: context is just to constrain uh one\n3155.099s: variable on which we have observations\n3157.14s: and and then uh just use if you if you\n3160.559s: run the method I I quickly presented\n3162.96s: here for the two variables at the same\n3165.359s: time then the the implication for the\n3168.3s: other variable you are looking for will\n3170.579s: be based on on statistical dependence\n3173.94s: and we know lots of variables are\n3176.16s: related to the growing temperature so\n3178.02s: you can have useful information\n3180.02s: sometimes at least in that context but\n3182.28s: clearly if there is no relationship\n3184.5s: between government temperature and and\n3186.42s: the variable you are interested in this\n3188.04s: will not work in that case maybe you can\n3190.319s: try another another observed variable\n3194.099s: but yeah I have a no more General\n3197.7s: response maybe to that\n3205.38s: um I guess I also had a question related\n3206.88s: to the the hot bottles uh like the\n3209.22s: regional like with France being closer\n3211.619s: to that do you think this points to\n3214.68s: um like a bias in like how the models\n3216.78s: are tuned or like a bias in the\n3218.88s: observations or like can you say\n3220.8s: anything about that and I guess a\n3223.079s: different but possibly related question\n3224.76s: like can the method be extended to like\n3226.92s: directly use spatial information like\n3229.74s: rather than just temporal information\n3232.92s: yeah\n3234.3s: um so my understanding of what happened\n3236.28s: over front see that in five models I\n3238.44s: mean the multiple military model meaning\n3240.48s: is probably wrong in terms of the\n3241.74s: pattern\n3243.18s: so on average I was a globe there is a\n3245.7s: bit too much of roaming but but over\n3247.26s: some specific reasons that's not the\n3248.819s: case and so we need to reshape a bit the\n3251.579s: pattern to to become consistent with\n3254.099s: observations and uh and that's why the\n3257.28s: idea of just rejecting hot models all\n3260.04s: hot models without\n3261.96s: further look\n3263.4s: it might not be that good idea but magic\n3267.24s: is a\n3268.38s: the point of view here and you have the\n3270.42s: second part maybe that I forgot oh I was\n3273.0s: wondering if like well it seemed like\n3274.319s: what you were doing was uh like purely\n3277.26s: time series like can you also include\n3279.96s: spatial information yeah so that's\n3282.72s: that's one is very good uh in fact we\n3285.42s: have started using uh spatial\n3287.64s: information that is dimension too so\n3291.359s: look at one one I mean Global and just\n3293.7s: one one specific location\n3296.099s: um and\n3297.839s: um of course yeah the first natural ID\n3300.359s: you can have is okay try Dimension n uh\n3303.48s: and uh but there is a big challenge in\n3306.66s: doing that it's also it's basically it's\n3308.88s: a key issue in fact is to estimate the\n3311.4s: equivalence matrices as I mentioned\n3313.98s: so for the model error you can still\n3316.68s: consider the spread of models maybe but\n3319.559s: for the observations you need to have\n3322.44s: I mean the current the side of the\n3324.48s: current Matrix in that case becomes huge\n3326.88s: okay it's the number of of\n3330.24s: um of time steps multiplied by the\n3333.599s: number of points all over the years so\n3336.18s: it's very big Matrix and you need to get\n3339.96s: that micros more or less correctly\n3342.9s: estimated you need to be invertible uh\n3346.38s: and at the moment I'm not really clear\n3349.14s: on how to do that\n3350.64s: probably there are a few things to learn\n3353.88s: from data simulation people but but it\n3356.099s: really doesn't seem to be easy and so we\n3358.5s: were not that comfortable in in going to\n3361.14s: very large spatial Dimension quickly\n3363.119s: because we need to be very careful how\n3365.28s: we estimate that\n3371.78s: but that's a line of result we will\n3374.04s: explore for sure in the next one or two\n3376.38s: years\n3377.16s: yeah\n3379.2s: all right\n3380.819s: Carol can I ask a question real quick uh\n3383.64s: so it's just a quick question about the\n3386.28s: correlation in the prior and the\n3388.859s: observation so so wonder is that\n3391.26s: considered independent or like how I\n3393.72s: might have missed it but like do you\n3396.24s: consider kind of the auto correlation\n3397.92s: like the year after year if it's close\n3400.5s: it it helps constrain the uncertainty\n3402.96s: thanks\n3404.22s: yes\n3405.72s: um maybe I can just we we\n3409.619s: share the screen again here just to show\n3411.9s: that\n3416.7s: um\n3417.24s: in fact it's a\n3420.78s: um that space Maybe\n3423.3s: um you have you have this um I mean yeah\n3427.5s: this y Vector observations and so the\n3430.5s: noise here as I said includes in\n3432.54s: particular internal viability\n3435.0s: and here it is it is a vector so Epsilon\n3438.96s: is the same size as as y it's a full\n3441.96s: time series of of absurd values and you\n3445.319s: are considering the full command Matrix\n3447.48s: of that\n3448.74s: guy\n3450.059s: and in it includes all the all the auto\n3453.24s: correlation temporal autocorrelation so\n3455.7s: you have all the autocorrelation\n3457.26s: function in that Matrix Sigma Ops so\n3460.02s: yeah we account for that and and\n3462.72s: the implication is we need to have a\n3464.64s: statistical model to describe\n3467.099s: um the entire autocorrelation function\n3469.74s: so what we have done here was a bit uh a\n3472.98s: bit new\n3474.359s: to do so a bit new too I would say we\n3477.599s: use the um an addition of two different\n3482.28s: Auto regressive\n3484.339s: processes of other one\n3487.16s: because we find it to be very uh\n3489.9s: parsimonious in terms of coefficients\n3491.819s: you have only only three coefficients to\n3494.64s: reproduce the autocorrelation function\n3496.5s: and it was very good fit for most of the\n3499.8s: semi pre-industrial control simulation\n3502.859s: so these simulations in which you can\n3504.72s: really have a look at internal liability\n3507.839s: assess internal liability\n3510.359s: um\n3511.079s: and so we find it was a very uh\n3513.26s: effective way I mean model for instance\n3516.559s: global scale and that's what we have\n3519.0s: been using to estimating these Matrix\n3520.559s: but yes this Matrix contains all these\n3523.68s: estimates"
    },
    {
        "class": "YouTubeVideo",
        "title": "LEAP: A Deeper Look",
        "videoId": "SRSjMrAYtsM",
        "url": "https://www.youtube.com/watch?v=SRSjMrAYtsM",
        "publishedAt": "2023-04-26T16:08:47Z",
        "transcript": "0.86s: I'm a director for leap a new centers\n4.68s: reported by the National Science\n6.18s: Foundation and lip stands for learning\n8.639s: the Earth with artificial intelligence\n10.38s: and physics and what we are trying to do\n12.059s: is basically merging artificial\n14.219s: intelligence and climates we can better\n16.139s: predict the future\n18.6s: so I started this Enterprise we could\n21.0s: put it this way a little bit to be\n23.34s: honest has a bit of a mid-life crisis\n25.199s: you know I was thinking okay Academia is\n28.14s: great you know but at the same time you\n31.08s: want to see action right what we are\n33.78s: trying to achieve in the center is going\n35.54s: Beyond just science but transferring the\n39.0s: science and putting that in the hands of\n40.98s: the people so that they can actually act\n43.02s: so we are trying to lower the barrier so\n45.54s: that everyone could get access to\n47.52s: climate data across the globe what we\n50.16s: needed was to gather and to put forces\n53.46s: together right we needed to be just more\n55.379s: than myself like it needed to be like a\n57.48s: big team you know and some of the key\n59.219s: players I joined Lee because I am both\n62.879s: intrigued by the the challenge of the\n65.64s: research and also the mission to develop\n67.979s: a new discipline of climate data science\n70.619s: we see a lot of excitement from students\n72.78s: that was you know beyond our expectation\n75.78s: they told us this has been things that\n78.72s: they've been looking for they they want\n81.119s: to learn from both the client and\n83.58s: science side they want to learn machine\n84.84s: learning tools from the computer science\n87.24s: side we see a lot of students especially\n90.06s: from those in the underserved Community\n92.1s: they said they've been looking for the\n94.08s: opportunity to apply their computer\n95.64s: science skills to problems that are\n98.4s: important for their communities\n100.38s: when I was in high school I wanted to be\n103.259s: an astronaut\n104.52s: I was one of the first people to go to\n106.5s: space camp in Huntsville Alabama and\n108.36s: pretend to be an astronaut for 10 days\n110.899s: but then I realized how much we don't\n114.299s: know about the ocean and the climate\n116.82s: system here on Earth our goal is to use\n119.64s: all the available data out there from\n122.64s: sensors from satellites so we can help\n125.219s: everyone adapt to climate change I'm a\n129.06s: climate scientist and one of my jobs is\n130.56s: to try to understand what's going to\n132.12s: happen to the Earth\n133.52s: due to climate change due to Rising\n136.319s: greenhouse gases in the atmosphere and\n138.84s: to do that we need to to build a model\n141.0s: of the Earth\n142.14s: her system model is a collection of\n144.42s: mathematical models within your system\n146.16s: so it consists of an atmosphere ocean\n148.56s: land sea ice ice sheet Rivers basically\n152.52s: anything you think of you name it it's\n154.08s: within this or System model and so every\n156.06s: scientist who's out there who's say\n157.5s: measuring Stream flow of Mississippi\n159.54s: River that scientist has very strong and\n162.3s: deep ideas about what is controlling the\n164.519s: Stream flow and we need to bring that in\n166.08s: the model and then there's also a person\n167.76s: who studies the oceans you know how\n169.319s: phytoplankton grows and affects how the\n172.5s: sun's rays penetrate into the ocean and\n175.019s: we need to bring that feature into the\n176.34s: model so everything that you can think\n178.92s: about it's sort of out there in nature\n181.319s: that's been studied by scientists needs\n183.78s: to get pulled back and ingested into our\n186.0s: Earth System model so we have a full and\n188.16s: complete representation of your system\n189.84s: so that we can then predict it\n193.44s: what do I do I look at computer screens\n196.019s: I look at simulated clouds and I compare\n199.92s: them to satellite clouds and I ask if\n201.84s: they're similar and\n203.4s: often they're not so you can see how\n205.62s: clouds form in nature you can watch it\n207.599s: happen right like the the water vapor\n210.06s: Rises and then a lot of things matter\n211.459s: the water condenses around a little\n214.44s: dust particle and what the chemistry of\n216.48s: that dust particle is matters whether\n218.28s: it's organic and oily and wants to repel\n220.08s: the water whether it's dissolving like\n222.299s: salt and wants to collect the water and\n224.519s: then other things happen that are really\n226.44s: beautiful and complicated and there's\n228.0s: heat released as the water condenses and\n230.04s: waves that Ripple out and then the\n231.959s: droplets organized and they and they\n234.36s: they create patterns that the patterns\n236.4s: influence each other and it all adds out\n238.5s: to the beautiful thing we call a cloud\n239.879s: and and you're never going to simulate\n241.62s: all of that complexity but but what\n244.62s: these clouds do if the climate warms is\n246.659s: going to affect how hazardous my kids\n248.819s: future is\n250.799s: there's patterns in nature that we can't\n252.84s: simulate yet on the computer and that's\n255.42s: where we work we try to make it more and\n257.699s: more of a plausible realization of the\n259.68s: atmosphere so that we trust its\n261.18s: prediction to the Future more and more\n262.5s: if we can have better predictions about\n265.44s: what it's going to look like in the\n266.52s: future that helps us to sort of plan\n268.32s: better today I am a business school\n270.84s: Professor this idea of climate change\n273.54s: and of the importance of accurately\n275.52s: predicting climate change is going to be\n277.38s: so so so important for the business\n279.3s: World kind of especially as we you know\n281.4s: fast forward into the future so let's\n284.22s: take for example a company that makes\n286.08s: soda a supply input to that soda is\n288.479s: water it's important to know things like\n291.24s: water contamination sort of what factors\n293.88s: are that are going to influence where we\n296.1s: can and cannot get usable water in the\n299.04s: future well if we we had better answers\n301.44s: to that question and we could say what\n303.24s: this is going to look like in 5-10 years\n305.1s: that would give us a better idea of well\n307.199s: maybe where we should be building our\n309.24s: operations right now having that\n311.639s: information would help them make that\n313.5s: decision today\n316.56s: [Music]\n318.06s: when we're thinking about the climate\n320.16s: crisis we have an understanding that not\n322.86s: all people are being affected equally\n325.02s: we'll all experience the effects of\n327.12s: climate change but black and brown\n329.16s: communities lower income communities are\n331.86s: more likely to be negatively affected\n334.02s: and less likely to have the resources to\n336.3s: combat things like extreme weather so we\n339.78s: believe as with all science that it's\n341.52s: important to have a diverse range of\n343.919s: backgrounds engaged in climate science\n347.039s: work there's knowledge and expertise in\n349.44s: a range of communities that are also\n351.18s: important for us to know and understand\n353.039s: in order to do good science so we're not\n356.22s: only giving information we're also also\n358.44s: Building Bridges and relationships that\n360.24s: help us receive knowledge and\n362.039s: information that we need as well leap is\n364.199s: bringing together minds and capacities\n366.6s: that simply haven't sat in the same room\n368.82s: before I'm a climate Communicator\n370.8s: because climate matters\n372.9s: it matters enormously what we can say is\n375.72s: that we're heading in a Direction\n377.58s: from vulnerability to resilience the\n379.8s: direction from exclusion to inclusion\n382.5s: and leap I think is a Pioneer in this\n384.539s: kind of effort you you'll be able to\n386.46s: look confidently in 10 years and say\n388.02s: we're on a path now that's fundamentally\n390.84s: different than the past we were on\n392.639s: before\n399.77s: [Music]"
    },
    {
        "class": "YouTubeVideo",
        "title": "Emulating &amp; Analyzing Two Climate Model PPEs using a Simplified Additive Gaussian Process Emulator",
        "videoId": "YW3a2m1hU4s",
        "url": "https://www.youtube.com/watch?v=YW3a2m1hU4s",
        "publishedAt": "2024-03-02T03:28:07Z",
        "transcript": "7.52s: hi everyone welcome to another week of\n11.24s: uh lectures in climate data science um\n13.92s: this today will be um having our\n16.6s: internal prog research progress uh\n19.359s: presentation um from andu we'll start\n23.8s: with Dr Young um with his presentation\n27.679s: emulating and analyzing two climate\n30.0s: model herur parameter ensembles ppes\n33.52s: using a simplified additive Gan process\n36.96s: emulator Dr Young is a postdoctoral\n39.399s: researcher at leap where he works on\n41.559s: developing and applying different\n43.239s: machine learning algorithms for the\n44.84s: emulation and parameter timization of\n47.719s: climate models he previously worked as a\n50.28s: research fellow at Nang Technological\n52.76s: University and received his PhD and\n55.079s: master's degrees from University of\n57.44s: Buffalo Sunni and bachelor's degree from\n60.199s: Ling\n61.559s: University\n63.64s: welcome okay uh first of all thank you\n66.68s: for your time joining this presentation\n69.4s: so I want to introduce uh you guys\n72.04s: emulator method that does emulation\n74.6s: analysis for climate model ppes so we\n78.68s: know that the ppes are generated so that\n82.2s: we can study the relationship between\n84.84s: the parameters and model outputs and\n88.119s: they can be used to further to train the\n90.28s: emulator and then used for parameter\n92.72s: estimation so ppes are increasingly\n95.159s: being developed uh and widely used so we\n98.56s: think it's kind of important to present\n101.119s: something that's comparable and does\n103.799s: analysis uh to look at the PPS so what\n106.92s: we meant is that we want to be able to\n108.96s: not only emulate the data but also know\n111.68s: what we're emulating uh in the data set\n114.92s: so this is kind of the idea of this work\n117.719s: and also there are some limitations in\n120.039s: the more traditional ways to look at the\n122.759s: pp data set the correlation between\n125.32s: parameters and outputs could be\n127.2s: underestimated because it's just\n128.959s: somewhat linear and also if we use\n131.64s: sensitivity test uh Based on data\n134.12s: generated from the emulators the\n136.2s: emulator could are imperfect so it might\n139.04s: have errors it may or may not affect how\n141.44s: we interpret the results and we don't\n143.519s: know why and which methods are best to\n145.879s: work with uh ppes with very few\n148.28s: ensembles which is very common\n150.319s: so in this work we're introducing this\n152.239s: method apply the method to two ppes\n155.0s: compare it performance with neuron\n156.68s: Network and more importantly to to see\n159.08s: if we have some insights from this work\n161.8s: and our Target variables are just\n163.599s: different kind of climatologies but they\n165.959s: are model scores so they are kind of\n168.72s: like uh kind of a squared Arrow absolute\n172.44s: difference between the model output and\n176.319s: observations so the key idea is that\n179.04s: this method is like extremely simplified\n181.68s: from the additive gion process so like\n185.2s: the the reason we came up with this is\n187.4s: actually the fact that the ppes are very\n190.44s: sparse so normally um we have the embl\n194.72s: we only have a few hundreds but the\n196.519s: parameter space is several T in this\n199.28s: case is\n200.28s: 45 so it's very sparse so we think there\n203.72s: might be complex structures uh in the\n206.519s: data set that but they cannot be\n208.56s: preserved so why don't we just focus on\n211.36s: the simpler ones so we aim at emulating\n214.48s: this uh I call it low frequency\n216.92s: variability an example is shown on the\n219.239s: right so given a signal we're F we're\n222.159s: not focusing on the zigzag sine waves\n225.2s: we're only focusing on kind of a long\n227.76s: wavelength uh signals in the data set so\n230.799s: there are lots of simplifications as I\n232.799s: said and we uh we made it clear that so\n236.4s: this method doesn't estimate the\n238.159s: uncertainty which is a for now a\n240.48s: limitation so we decompose our Target\n243.239s: variable into additive terms and each\n246.2s: term is uh the mean of a gion process\n250.319s: that only takes one two or three\n252.68s: parameters as input and also we fixed\n255.799s: the hyper parameters of these gam\n257.88s: processes so this this might seem a\n260.199s: little bit odd but if we keep uh the gam\n264.04s: so we can kind of control it by fixing\n266.479s: it we're only emulating kind of the oh\n271.4s: sorry it's this so we're only emulating\n275.16s: kind of this uh long wave length\n276.88s: variability this sensitivity will be\n278.68s: tested\n280.08s: later uh so sorry for this back and\n283.4s: forth so this is how the method works on\n286.12s: a practical level uh so it uh so it\n290.44s: first focuses on the one parameter gion\n293.28s: processes it builds uh uh one di one\n297.88s: parameter gion process for all the\n299.84s: parameters as shown on the right and it\n302.639s: picks the parameter that gives you the\n305.36s: the least root me Square Arrow so that's\n307.68s: the parameter for this iteration you fit\n310.28s: it so you can see this red line here and\n313.0s: you pass the residuals from this\n314.72s: emulator to the next and do the same\n316.44s: thing identify a series of parameters\n319.88s: after these are done for the one\n322.0s: parameter processes we move on to the\n324.28s: two like parameter pairs it's exactly\n327.639s: the same way except we're using a\n329.56s: different measure so this measure is\n331.88s: showing like the additional benefit of\n335.68s: emulating uh the residuals from the\n337.88s: previous iteration jointly compared to\n340.479s: emulating them independently so here's\n343.44s: the the kind of the grid file is an\n345.56s: example so the X and Y axis are both the\n348.08s: parameters so they for the Triangular\n350.8s: grids here is showing like all the\n353.12s: possible Pairs and some of them can you\n355.72s: say more about what the parameters are\n357.88s: oh the parameters are just from from\n360.039s: atmospheric models yeah is that okay\n363.16s: yeah yeah okay uh so so some of them you\n365.8s: can see the red really stands out so you\n367.479s: pick them you model them you do it\n369.639s: sequentially so since the since the\n372.4s: method is additive it's very easy to\n374.759s: monitor how uh the performance improves\n378.28s: so the y- axis is kind of the residuals\n381.36s: you have after each term is added uh to\n385.0s: the emulator prediction so you can see\n387.16s: the first term the DCs here adding that\n391.36s: add to a great explanation to the data\n394.479s: and it gradually decreases it's very\n396.44s: gradual and there are three bars uh on\n399.4s: like at the like bottom of the figure so\n402.0s: the first bar corresponds to all the\n403.8s: terms that are single corresponds to\n406.36s: individual parameters and the other two\n408.199s: are kind of parameter Pairs and\n410.4s: parameter in uh parameter groups of\n412.36s: three so they do contribute to\n414.84s: explaining or to the emulator\n417.16s: performance so uh we are\n420.479s: sorry this is very sensitive we're\n423.52s: applying this method on the neuron\n425.68s: Network\n426.759s: to so to two different ppes there the M\n430.919s: the main difference is that they have\n433.0s: different number of ensembles one is 75\n436.479s: 750 is the other is\n439.84s: 260 so we are doing 80% for training 20%\n444.08s: for validation here is the results using\n447.44s: denoted using R squares so the figure\n450.28s: the comparison is on the left x-axis\n452.68s: neural network Y axis this method so the\n455.96s: the bars are showing kind of the\n457.72s: variability in R squares due to sampling\n461.199s: so I would say that the compar the\n464.36s: performance of the two methods are\n466.319s: pretty comparable especially for the\n468.72s: ones with greater R squares there are\n471.12s: some one some that are not great which\n473.24s: are marked in green so in this case it's\n475.479s: to the right so neuron network works\n478.08s: better and I want to point out this uh\n480.879s: single variable TI iwp is the total ice\n483.56s: water path so that's the amount of I in\n485.879s: the cloud somehow our method just really\n489.8s: outperforms in emulating this single\n492.36s: variable and we'll see why later uh\n494.96s: figure on the right is uh the it's\n497.12s: showing it's showing the R square\n499.44s: variability from using the same R method\n502.36s: the Y AIS is from the random sampling\n504.72s: which is basically what uh the y axis on\n507.599s: the left shows and X xaxis is showing\n511.36s: the\n512.12s: variability of the R square by varying\n515.32s: the hyper parameters so it's very small\n517.839s: so which we're happy about so it's the\n520.24s: hyper parameters if we're focusing on\n522.12s: the trend these hyper parameters doesn't\n524.519s: really matter that much uh we uh we did\n528.88s: the same I apologize for this uh we did\n532.8s: the same thing for the cam 6 PPE so it\n536.24s: has fewer Ensemble members so it's not\n538.68s: that surprise izing the performance of\n540.64s: the method deteriorates a lot and in\n543.68s: this case we think that our method Works\n546.079s: slightly better than the neuron Network\n547.959s: so you can see some more points that are\n550.079s: to the upper right so that's a good sign\n552.72s: sometimes with neuron Network it even\n554.839s: has uh negative R squares so in that\n557.64s: case the emulator did nothing but\n560.0s: introduces additional errors to the\n562.079s: prediction so it's it's a bit strange\n564.04s: but it happens sometimes and again the\n566.64s: same thing on the right so it's again\n568.56s: it's showing that the hyper parameters\n570.839s: doesn't really matter that much so so\n574.2s: this uh figure looks a bit messy but\n576.399s: basically summarizes the contribution of\n579.24s: each individual parameter here on the\n581.32s: right and the contribution of the\n583.959s: parameter groups so this so the colors\n586.8s: of the points here is basically the\n588.959s: difference uh difference of the\n591.32s: difference of the of each point in this\n594.079s: figure so uh to save you some time uh\n597.24s: looking at the this massive fig figure\n599.68s: so we notice that there's a few\n601.88s: parameters that contribute individually\n604.959s: uh greatly to the overall emulator\n607.36s: performance so that is the DCs so you\n609.68s: see lots of red points there and also on\n612.44s: the right pane you these are all\n614.839s: parameter pair or groups contributions\n617.8s: so they also uh play a role so we cannot\n621.2s: ignore the contribution of parameter\n623.36s: Pairs and this figure also explains why\n626.2s: the paramet the the we emulate the\n628.68s: variable T WP uh very good because the\n633.16s: parameter there's only this\n635.6s: parameter I think you can see my mouse\n638.92s: here there's only this this only one\n641.079s: parameter VF m s that's the only single\n644.36s: parameter that contributes to this\n647.079s: parameter so our method looks at the\n649.88s: variable one at a time but for neuron\n652.16s: Network it cares more about the overall\n654.56s: performance of the method so this\n656.72s: Improvement in this single variable is\n659.519s: somewhat neglected by neuron Network and\n662.32s: we think this is important because for\n664.16s: all kinds of ppes there might be such\n666.279s: variables exist and we know that and be\n669.6s: aware of it that might lead to better\n671.56s: emulator\n673.04s: performance so again this is too messy\n675.959s: so we organize it further more so here's\n678.44s: an example so we we group them based on\n681.16s: their contribution to the rmsd decrease\n684.399s: so the individual parameters so so what\n687.2s: I'm showing now is the the y axis is the\n690.0s: colors here so uh you can see there are\n693.12s: some parameters that obviously are\n695.56s: important but there are that some that\n698.399s: are kind of below 0.05 so we group and\n700.88s: sum them together to see what are\n702.92s: actually contributing to the um emulator\n706.519s: performance and here is the results\n708.519s: again the y- axis are the variables and\n711.079s: the x-axis are we like how it's\n714.079s: categorized so again trying to summarize\n717.24s: it you know uh the contribution tion\n719.32s: from parameter groups is not negligible\n722.079s: so in this figure this contribution are\n724.279s: the like lighter brighter colored bars\n727.16s: the yellow orange and red and also we\n730.12s: note that a group of single parameters\n733.199s: that may seem unimportant so these are\n735.56s: the light blue bars here they may seem\n738.88s: unimportant individually but since our\n741.6s: method is additive so they alt together\n744.839s: they could have a very non-negligible\n748.199s: cumulative effect on the emulator\n750.24s: performance so we think this is\n752.04s: important because for if we saw some\n755.32s: results like this uh we would say oh\n758.72s: there for the Blue Bar there's maybe\n760.32s: only two or three parameters that matter\n763.72s: but from this uh uh analysis it seems\n767.959s: that all these very low bars are equally\n770.56s: important when they are combined\n772.72s: together so uh like like uh so we're\n775.839s: focusing on the the the pp with more\n779.519s: ensembl here so remember that for the\n782.399s: for there are some green points that do\n784.079s: not perform as well so we think oh May\n786.959s: because our method looks at variable one\n789.56s: at a time so the relationships between\n792.839s: the variables is kind of ignored so we\n795.16s: say oh why don't we just predict easy\n798.079s: variables easy to predict variables and\n800.8s: put them together and make a new\n802.959s: emulator focusing on these difficult\n805.16s: variables so that's what we did and\n808.24s: figure on right is showing the\n809.68s: Improvement so the green points are the\n812.72s: performance before compared to neuron\n814.8s: Network and you see that the the yellow\n817.519s: points are the update so there's only uh\n820.16s: one exception with no uh with no\n824.12s: improvement in the emulator performance\n826.079s: all the others are pretty well and\n828.6s: comparable to the performance of the\n830.959s: neuron Network so this is more like a\n833.48s: deep dive into why um why the way\n839.92s: like why this including this easy\n841.839s: variables work but I think I'm kind of\n844.56s: short in time so I'll just pass it later\n847.639s: so now we're moving on to the cam 6\n851.12s: ppes um we we want to know kind of why\n854.92s: the method uh in this case outperforms\n857.519s: neuron Network although overall none of\n859.88s: them work uh extremely well so I we\n863.44s: think it's probably the main reason is\n865.56s: is similar to why our method works well\n868.079s: with TS\n869.48s: WP um so in the for all the variables\n872.68s: there are some variables that are just\n875.199s: just somehow just really difficult to\n878.0s: emulate regardless and because neuron\n880.6s: Network focuses on overall performances\n883.6s: these really bad variables trying to\n886.079s: emulate them very hard for the uh neuron\n889.44s: Network would kind of drag the\n891.48s: performance of the neuron Network for\n894.199s: the variables that are easier to predict\n896.48s: we think that is why and again I'm\n898.8s: showing how uh the the contribution of\n902.56s: different parameters just like uh shown\n904.72s: before for the other ppes and uh please\n907.68s: note the gray bars this is the\n909.6s: variability from uh the random sampling\n912.399s: so in this case it's very different from\n915.079s: previous uh results so only the dark\n917.48s: blue bars is kind of uh robust so you\n921.48s: can see the variability of the gray bars\n923.399s: is comparable to the contribution of\n926.04s: those parameters that contribute less to\n928.92s: the data set so it's uh probably a\n932.16s: matter of uh emble size so figure on the\n936.199s: left you seen before that's the C PPE\n938.319s: results so we have the model e ppes with\n941.72s: more uh emble so we say let's just train\n945.68s: 250 uh let's just train the data with\n948.44s: 250 points and here is the result and\n951.44s: one given fewer uh training data set you\n954.72s: see the performance of our method is\n957.16s: very comparable to neuron Network and\n960.68s: interestingly some of the performance is\n962.839s: actually more robust so you see fewer\n965.56s: variability for using our method again\n968.399s: this is because with fewer samples the\n970.639s: neuron Network may only try to memorize\n973.639s: it and not trying to so it overfit a lot\n976.319s: and not trying to kind of predict the\n978.079s: pattern so as I mentioned\n982.36s: before we're trying to emulate the model\n986.04s: score so it's absolute uh difference\n988.88s: between the prediction and observation\n990.92s: so because of the absolute difference\n993.279s: that kind of uh kind of folding or\n996.519s: compressing some useful information so\n999.04s: instead we're emulating uh the raw model\n1002.04s: output at different latitudes we select\n1004.759s: four variables for the test and U the\n1008.639s: the Y AIS is again the R square and the\n1011.839s: x-axis are the selected latitudes the\n1014.839s: the blue lines are the r squares from\n1017.88s: emulating the those scores that we shown\n1019.8s: previously so first of all you see uh\n1023.0s: there's a big Improvement for some of\n1024.919s: the variables and also you see the\n1026.76s: difficulty in emulating these uh\n1029.0s: variables varies at different latitude\n1031.28s: which we think is really interesting and\n1033.52s: we want to delve into it and there of\n1035.28s: course there are other factors affecting\n1038.6s: how emulated performance that's uh kind\n1041.199s: of ongoing so to summarize we're\n1044.52s: presenting a new method we comp we apply\n1047.0s: it to different two different ppes and\n1049.96s: its performance is comparable to neuron\n1052.919s: Network and we gain lots of insights\n1056.48s: that might be Universal for other ptes\n1059.4s: and for other emulator methods so I'm\n1061.6s: just listing it here to save some time\n1064.0s: and uh at the end I want to do an\n1066.12s: advertisement which is please join the\n1068.32s: parameter estimation focus group is very\n1070.6s: informal but it's always very\n1072.72s: informative and I learn a lot from that\n1074.88s: so thank\n1077.4s: you\n1081.039s: do we have any questions in the room and\n1083.799s: if you are online and have any questions\n1086.039s: feel free to um\n1089.32s: either we can start with Linea online\n1092.28s: can you unmute yourself I can yes thanks\n1094.84s: young um I'm interested in if you\n1097.4s: compared the results of your sensitivity\n1100.32s: test with the additive gausian processes\n1103.12s: to like a more traditional sensitivity\n1106.559s: test within neural network you had\n1107.88s: mentioned worri that is\n1111.4s: um there's someone and you'll get\n1113.96s: different sensitivities but I'm curious\n1116.2s: if you found that your method is drawing\n1118.28s: out things that were\n1120.159s: missed uh uh I I'm not sure if this\n1123.84s: answers your question but yeah we did so\n1126.4s: I was worried that oh maybe it's just\n1128.44s: our method it's just our method so what\n1131.08s: we did is so you can see here so so the\n1135.08s: parameters that contribute greatly so\n1137.4s: more than 5% % of the total standard\n1139.6s: deviation there's only about 13 of them\n1143.28s: so we train another neuron Network just\n1146.48s: using these 13 parameters and we plot\n1150.44s: its uh performance and they're shown as\n1153.679s: the crosses in this figure uh so you can\n1157.08s: see a very systematic decrease in the\n1159.799s: emulator performance so the so the sorry\n1163.96s: uh the the crosses are the performance\n1166.679s: of neuron Network without out the the\n1170.039s: quote unquote insensitive parameters and\n1173.36s: the empty blue bar is the performance of\n1175.64s: the neuron network with all the\n1177.72s: parameters so we're happy to see there's\n1179.76s: a big drop so it's not just from our\n1182.159s: method so even for neuron Network it\n1184.32s: decreases and the amount is very\n1186.52s: comparable does that answer your\n1188.559s: question yeah that's great thank you\n1193.559s: okay anyone the\n1197.24s: room\n1203.48s: there anyone else\n1213.72s: online so uh yeah so we I I was\n1216.88s: expecting people asking why the ging\n1218.88s: process wouldn't work so I just s a\n1221.48s: question and answer it myself so we did\n1224.08s: that and turns out neuron Network\n1225.679s: slightly outperforms the Goan process\n1229.32s: so and uh yeah since there's no\n1232.64s: questions uh I can explain a bit more on\n1235.4s: hyper parameters so uh imagine that we\n1239.039s: have these black points that is they're\n1241.84s: actually the sum of two sign waves one\n1244.76s: is high frequency one is low so um so\n1248.32s: you can see lot lots of colored lines in\n1250.36s: here with very different fixed Gan\n1253.4s: process\n1254.799s: hyperparameters uh so the so in figures\n1258.2s: of figure D you see the blue lines and\n1260.08s: red lines very similar but they have\n1262.2s: very different hyperparameters so that\n1265.2s: is what I meant so if you focus on this\n1268.52s: very uh kind of uh low frequency\n1272.679s: variability the the power parameters\n1275.32s: don't seem to matter that\n1281.559s: much there was like one more plot where\n1283.88s: you show like the\n1286.919s: feature uh uh there was like one plot\n1289.52s: where you showed feature of importance I\n1291.4s: think it it almost looks like uh uh like\n1295.76s: energy cont when you do like SVD or like\n1299.159s: PCA so uh is that\n1302.24s: like um you mean like something like\n1305.72s: this like kind of decompose is important\n1308.799s: previous\n1311.159s: one this like it was like an L-shaped\n1314.159s: Cod it's it's like a what like an\n1317.039s: L-shaped uh yeah yeah yeah yeah yeah I\n1320.039s: think it's we can maybe look at this\n1322.2s: figure so yeah like uh is if you do like\n1326.64s: say like so indices or like any sort of\n1329.08s: parameter oh yeah yeah yeah so you get\n1332.32s: like something similar with that uh we\n1334.36s: didn't try it but if you do the soo\n1336.52s: indices you need to generate lots of\n1338.52s: samples from the emulator so we think\n1341.6s: that that might because the emulator are\n1344.36s: not perfect so depending on its\n1346.2s: performance it may not or it may or may\n1348.679s: not affect how you interpret the results\n1350.919s: so by making it very additive it's very\n1353.08s: simple and all these bars are definitely\n1356.32s: additive under the framework of this so\n1358.96s: like basically like one of the main\n1360.559s: advantages here is like it's one of the\n1363.08s: main advantages here is that it's like\n1365.159s: much easier or like much more competion\n1367.96s: yeah yeah yeah okay\n1375.24s: yeah any other questions in the room\n1378.799s: or online you can feel free to mute\n1387.799s: yourself like that thank you for your\n1390.24s: time thank\n1396.279s: you"
    },
    {
        "class": "YouTubeVideo",
        "title": "2024 Summer Education Project 4",
        "videoId": "MIj9LstZ35c",
        "url": "https://www.youtube.com/watch?v=MIj9LstZ35c",
        "publishedAt": "2024-08-03T20:10:45Z",
        "transcript": "6.52s: hey everybody I'm Obin this is Patrick\n9.12s: and Ashley um we'll be talking about\n12.08s: finding patterns in the clouds today\n14.4s: specifically cirrus clouds and\n15.96s: specifically a spiral pattern that I'll\n18.24s: explain I'll get into I don't think I\n20.359s: need to sell anybody on the idea that\n22.72s: clouds are important and part of climate\n25.64s: but like Marcus said in his uh talk last\n30.0s: last week there's a lot of\n31.92s: uncertainty in clouds um both introduced\n35.96s: by the scale but also in the processes\n40.36s: there's a lot we don't know about\n41.8s: processes and specifically cirrus\n45.44s: clouds here are serus clouds over a New\n48.399s: York skyline are made out of ice\n52.359s: crystals and these ice crystals have a\n56.52s: ton of diverse shapes Behavior and\n60.879s: lifetimes here's um some Imaging of ice\n66.28s: crystals very teeny ice crystals stolen\n69.84s: from cirrus clouds um\n74.04s: and they um so a recent kind of state of\n80.759s: the science approach for simulating\n83.4s: clouds is uh lran Cloud models or\n86.72s: particle based models where they track\n88.64s: cloud droplet or Cloud particles as they\n91.68s: travel through the atmosphere and uh\n94.399s: paper that just came out last month\n98.24s: explains finds that a lot of the um\n101.92s: variability in these ice crystals\n104.36s: actually comes from where they've been\n106.36s: in terms of how much relative humidity\n110.36s: they passed through on their wildly\n113.68s: diverse and heterogeneous\n117.039s: trajectories this is the first LR\n120.719s: um cloud model which is paired with a\n123.479s: large Eddie simulation for driving the\n125.479s: Dynamics forward um for Cirrus and this\n128.44s: is a really rich data set of a ton of\n131.16s: particle trajectories for us to study\n133.959s: Ice Crystal\n136.4s: Evolution problem is that's a lot of\n139.879s: trajectories so we're interested in\n142.08s: seeing if there's some sort of smaller\n144.519s: amount of\n145.64s: Representative trajectories and so what\n148.599s: we just started with was doing K means\n151.319s: clustering on these trajectories these\n153.84s: thermodynamic histories that the paper\n156.92s: says contribute most uh to the\n160.519s: variability in these ice crystals and\n162.56s: the fun thing about applying K means\n164.72s: clustering on a Time series where we\n167.8s: treat every you know 35 time step um 35\n172.08s: time steps treating every time step as a\n174.08s: dimension is that the centroids of these\n176.239s: clusters are also interpretable as time\n179.04s: series themselves\n180.519s: so we get representative thermodynamic\n183.239s: histories from these centroids and we\n187.319s: see one characteristic trajectory that\n189.92s: starts very saturated but then ends in\n193.84s: very subsaturated conditions below 100%\n198.04s: humidity and we find these clusters just\n201.599s: on thermodynamic histories alone but we\n204.64s: can look at the averages of those\n206.84s: clusters with other environmental\n209.28s: variables so we clustered on relative\n211.4s: humidity or super saturation um finding\n215.08s: that these clusters are actually in\n217.12s: different places in the cloud um they\n220.84s: have very different radius\n223.56s: trajectories and also their density\n226.08s: changes and in fact one of these\n227.879s: clusters just turned into PE pure little\n230.319s: ice balls at the end of our\n235.12s: simulation and um here's uh some\n238.799s: evolving s distributions of our four\n241.519s: clusters we tried doing more clusters\n243.84s: and they all and after four they all\n247.2s: just started becoming different\n248.799s: combinations of these um but what we see\n252.28s: is that this cluster two this blue line\n255.079s: starts actually in pretty highly\n258.56s: saturated conditions and is large but\n261.359s: towards the end falls out of the\n266.6s: cloud what's even more interesting is\n269.56s: when when we applied PCA to these\n272.32s: trajectories um so going from 35\n276.039s: Dimensions that correspond to relative\n278.039s: humidity at 35 different time steps to\n280.96s: just two principal components we saw\n284.44s: that the Clusters that we got from the K\n287.199s: means are all different coherent Parts\n290.96s: along some sort of curve right this 1D\n294.12s: manifold and it's like a r shark set\n297.32s: test for scientists right what what sh\n300.0s: you see here and I already had it in the\n301.68s: title so I gave it away but Cara\n303.6s: proposed that we fit a spiral curve to\n306.88s: this um so then we could just have one\n309.96s: parameter that we crank around the\n311.32s: spiral to explain the different\n314.16s: trajectories and it's really interesting\n317.199s: that the um parameters in this equation\n322.36s: one of them converg to essentially Bey\n325.639s: the golden ratio and so um the black one\n330.0s: is our you know letting our parameters\n332.4s: run freely and this gold one is letting\n337.0s: one parameter just a scaling parameter\n338.88s: run freely and snapping the other one to\n342.88s: our golden ratio you know our like\n346.0s: Fibonacci Sequence our shells pretty\n349.6s: cool I'm not sure if there's this might\n351.28s: be just a neat quinky dink you know not\n353.08s: like a fundamental explanation for it or\n357.28s: anything and that's all right um this\n361.28s: might be um still a useful qualitative\n366.36s: descriptor of whether or not uh so this\n370.84s: Theta parameter that controls the spiral\n373.88s: um whether or not the cloud particles\n376.24s: will drop out of the\n378.56s: cloud there's some text on this let's\n380.72s: see if I go forward there we go and so\n384.24s: the climate relevance is that you know\n386.72s: these clouds which are made out of a ton\n388.4s: of ice crystals\n390.72s: um the cloud interaction you know it's\n394.24s: radiative forcing and its lifetime is\n396.52s: influenced by these crystals paths in\n398.52s: lifetimes and maybe we can use Theta as\n403.36s: a single parameter um that explains the\n407.68s: diversity of the lifetimes of these\n411.44s: crystals in these serious\n414.199s: clouds and um that's pretty much all I\n417.36s: have if you're thinking Obin this is\n419.16s: leap dude and where's the Deep learning\n422.24s: we got you Patrick and Ashley are going\n424.56s: to have both used neural networks for\n427.12s: two different um two different parts of\n430.68s: this project Patrick's gonna do talk\n433.68s: about a survey of clustering algorithms\n436.52s: and unsupervised algorithms analyzing\n438.96s: these trajectories and Ashley's going to\n441.599s: talk about um using a neural network a\n445.8s: supervised neural network to predict the\n447.84s: evolution of crystal growth\n450.12s: given these\n451.759s: trajectories so that's all I got I'm\n454.12s: actually going to stop here for one\n456.16s: question before we move on to Patrick\n458.599s: and Ashley\n461.72s: um yeah that all you\n465.039s: Anthony\n466.56s: nope cck on the\n470.44s: draw just just really quickly for the\n473.0s: sake of my clarity um when you say you\n476.319s: apply K means clustering to a Time\n477.96s: series when do you do it do you do it to\n480.72s: like the the initial distribution and\n482.879s: then you just assume that those points\n484.36s: will remain in that same cluster do you\n486.28s: apply it at each time step in the\n488.44s: evolution and if so you're not\n491.039s: guaranteed to get the same points in the\n492.72s: same cluster if you apply at each time\n494.8s: step right did that make sense it\n497.879s: totally makes sense we're actually this\n499.84s: is kind of a non-standard use of\n501.44s: clustering in that every time step we're\n504.8s: treating as a feature so it's a\n508.24s: dimension uh and the different\n511.199s: observations the different data points\n513.279s: are these particles themselves great\n517.64s: question it's a confusing use of K means\n520.24s: but I think it's kind of neat anyway\n522.64s: over to you\n527.24s: Patrick thank you Obin um yeah so I\n531.64s: chose to go uh like with my research on\n534.32s: trying to answer questions about which\n536.64s: clustering methods uh are most effective\n539.04s: on this kind of data set on these\n542.36s: trajectories um and so I started uh by\n545.32s: taking like the massive uh data frame of\n549.279s: all the variables all the time steps all\n552.399s: the super droplets and just looking at\n555.279s: uh one variable which was relative\n557.959s: humidity uh across all the time steps\n560.56s: for all the super droplets and then uh\n563.72s: running a survey of clustering methods\n566.12s: on that variable um and so like initial\n570.0s: results of just running all these\n571.959s: different clustering methods were that K\n573.959s: means and uh spectral clustering were\n576.6s: particularly effective um I have a table\n579.519s: here with silhouette score and CH score\n582.399s: which I'll talk about briefly um\n584.48s: silhouette score uh ranges from\n586.56s: negative-1 to one um uh higher the value\n590.36s: the better uh if it's above 0.5 uh it's\n593.56s: considered pretty good clustering um CH\n596.48s: score is a little more complicated uh\n598.48s: there's no kind of like threshold that\n600.44s: CH score could\n601.92s: reach uh which denotes like a good\n605.12s: clustering um but generally higher is\n607.64s: better and it's useful to compare across\n610.56s: uh like similar uh clustering methods uh\n614.079s: to see how they compare against each\n615.8s: other um yeah so that was the initial\n619.279s: results um I then decided to uh use an\n623.36s: auto encoder uh which um compressed the\n627.6s: data down into a lower number of\n630.0s: Dimensions uh we had a 35 dimensional\n632.519s: array to represent the trajectories\n634.88s: before um but uh by using this deep\n638.76s: learning method uh which could find uh\n641.2s: nonlinear relationships we can get it\n643.04s: down into a two-dimensional latent space\n645.519s: which I have plotted here on the left uh\n648.12s: and then what I did is found C mean's\n650.16s: clusters within that latent space uh\n652.92s: which you can see denoted by the\n654.44s: different colors there and then after\n657.72s: going back to the actual 35 dimensional\n660.0s: space uh and applied uh those centroids\n662.519s: and labels to uh the droplets within\n665.72s: that 35 dimensional space I was able to\n668.079s: plot the trajectories of those centroids\n670.639s: on the right um and I got much much\n673.839s: better uh results on these metrics uh\n677.0s: you can see the silhouette score is\n678.279s: around 08 it was like 04.5 before and\n682.079s: the CH score is orders of magnitude uh\n684.76s: higher at 166 uh 100 uh 100,00\n690.12s: um\n691.8s: yeah another interesting result of uh\n695.639s: using this Auto encoder is uh present\n698.32s: when we look at the representative\n700.0s: desiles uh of the Laten space so these\n702.36s: are like reconstructions of all the\n704.76s: desiles of the latent space and what uh\n707.079s: kind of trajectories would look like in\n708.72s: those areas of the latent space um and\n712.079s: what was interesting is that all of the\n713.68s: variants we have is basically contained\n716.56s: within Z1 and there's very little\n718.839s: variant on in\n720.639s: Z2 um which is a similar similar result\n723.56s: to what Obin uh got uh using his spiral\n727.24s: in that we can find like a\n729.16s: one-dimensional kind of space to\n731.079s: represent all the variants uh on these\n733.92s: uh Within These uh these histories or\n737.519s: trajectories um and yeah another or my\n741.36s: final kind of interesting conclusion uh\n743.72s: was found when I was trying to set up my\n746.04s: Laten space uh I was trying to determine\n748.88s: how many uh latent Dimensions I should\n752.04s: use uh to represent and scale the data\n754.48s: down into uh and Joe recommended that I\n757.68s: use a library called umap uh to kind of\n761.24s: project the data when it is in these\n763.32s: like 16 dimensional spaces to try and\n765.399s: visualize it um and when I was\n769.36s: projecting it and comparing it uh with a\n771.48s: much lower dimensional um latent space\n775.48s: uh we learned that there wasn't a lot of\n777.279s: like disparate clusters that were\n778.68s: generated when we projected it and we\n780.36s: weren't gaining a lot of uh detail but\n784.279s: that in both cases we have these kind of\n787.279s: continuous shapes that are formed uh\n789.639s: when we project uh this data through\n792.079s: umap which is again kind of uh another\n795.639s: reason or another uh piece of evidence\n797.68s: toward the fact that we can find some\n800.519s: way to one-dimensionally represent these\n802.56s: trajectories if we can map along these\n804.6s: shapes like there obviously are complex\n806.72s: shapes they're not incredibly simple but\n808.839s: if we we can map along these we can\n810.48s: represent all the variant in these\n812.56s: histories uh by just one one dimension\n815.519s: of just how far we travel along these\n817.92s: shapes um but yeah that's that's the\n820.88s: findings I had um I'll give it off to\n823.399s: Ashley to talk about uh making\n825.199s: predictions on the\n834.6s: data hi everyone um I'm Ashley and so\n837.88s: this summer I researched on emulating\n839.88s: the lran Ice Crystal evolution in Sir\n842.199s: Clouds using supervised machine learning\n844.68s: models so what Obin mentioned a bit\n847.199s: earlier was about the lren alas Sim uh\n850.399s: large Eddie simulation and so this is\n852.88s: the current model used to uh represent\n855.44s: the cloud Evolution and formation\n857.519s: however this type of model is very\n859.56s: timely and computationally expensive so\n862.32s: approximately like 300,000 core hours\n864.959s: are used to run a single simulation\n867.16s: which makes this not a very viable off\n869.12s: option to sustain researching in Ice\n871.92s: Crystal Evolution and so what I'm trying\n874.44s: to look into is whether or not um\n877.199s: supervised machine Lear model can serve\n879.32s: as a like a substitute emulator and\n881.959s: representing the Ice Crystal\n884.88s: Evolution and so uh I guess like the\n887.199s: biggest chunk of this project that my\n889.279s: project and I work with is just like\n891.12s: exploring the data since we are kind of\n893.079s: the first ones to um work with this data\n895.839s: set we did a lot of exploratory data\n897.72s: analysis and so like an on the right of\n901.04s: your or actually on the left um you can\n903.759s: see like the distribution of the radius\n905.48s: sizes in um over the 36 time steps and\n909.759s: then part of the um exploratory data\n911.88s: analysis was also cleaning the data so\n914.079s: we combined the trory environment to\n916.0s: data files and then for my specific\n918.6s: project I looked into predicting ice\n920.959s: Cris Evolution with supervised learning\n923.6s: and so I used 10,000 um super particle\n927.48s: samples but before I even um delve right\n930.68s: into supervised learning I wanted to\n932.56s: check and identify like the specific\n934.88s: features and targets to use and so I\n937.24s: created a correlation heat map to kind\n940.0s: of see which um coefficients were the\n943.24s: highest and so um I ended up using the\n946.199s: six features being temperature relative\n948.199s: humidity pressure Mass radius size and\n950.56s: deposition density and it targets being\n953.279s: change in mass and change in\n955.199s: radius and so the first uh model that I\n958.279s: work with was multi-linear regression\n960.44s: with the single time step prediction um\n963.36s: so with the six features and the two\n965.72s: Targets I you know evaluate the\n967.959s: performances being very poor with 0.56\n971.8s: and\n972.639s: 0.62 respectively in R square for change\n975.199s: of mass and change of radius and so this\n977.92s: kind of makes sense because um\n979.8s: multi-linear regression they're not\n981.639s: really great at or they can capture but\n984.36s: it looks like it's not good at capturing\n986.04s: complex relationships of the particles\n987.88s: microphysical property\n989.56s: and so it just kind of helped solidify\n991.48s: to not go with regression and um\n993.639s: understand like the Ice Crystal\n995.279s: Evolution and so um I guess the next\n997.6s: thing oh yeah and then I also did um\n999.399s: single time step prediction so I'm\n1000.88s: predicting the next time step of um like\n1003.639s: the initial time step and so with the um\n1006.68s: next model that I work with which is the\n1008.92s: uh fully connected feed for n network um\n1012.959s: the performance with this is a lot\n1014.519s: higher uh with the R square being 0.95\n1019.12s: and 0.89 respectively for change in mass\n1021.8s: and change in radius which is great um\n1024.76s: and it also makes sense because it can\n1026.799s: capture complex nonlinear interactions a\n1029.039s: lot better between the features and\n1032.36s: targets and um after doing like the\n1035.199s: single time St neural network I wanted\n1037.88s: to kind of solidify the features and\n1040.4s: targets before moving forward with the\n1042.199s: more complex modeling so then I also\n1044.88s: looked into like shop which provided\n1047.76s: importance of like the f features of\n1050.08s: like after the prediction so it looks\n1052.12s: like um relative humidity with with\n1053.88s: respect to ice and the MK being like a\n1056.6s: really good um indicator for these\n1059.08s: features to be used in making decisions\n1061.4s: about the relationships of the Ice\n1063.559s: Crystal\n1064.559s: Evolution and then NE the last uh model\n1067.919s: that I worked with was the multi-time\n1070.32s: step prediction so basically I took the\n1073.16s: single time step model from like the\n1076.24s: initial noal Network and kind of roll it\n1079.28s: out for like multiple time steps so it's\n1081.52s: like you're taking the output of the\n1083.88s: single time step or like the initial\n1085.72s: time step and you're using that as the\n1088.159s: input and so then it'll be like a\n1090.2s: cascading kind of effect and um in this\n1092.799s: part um my mentor Joe really helped a\n1095.12s: lot in this part because I had some\n1096.96s: debugging issues that I couldn't quite\n1098.6s: figure out but um what we figured out\n1100.64s: was um the R square of all the time\n1104.64s: steps declined um a bit over time for\n1107.76s: both mass and both change of mass and\n1109.919s: change of radius\n1112.24s: um it looks like it's like even though\n1115.28s: the accuracy is declined over time it's\n1117.159s: not too significantly declining which\n1119.2s: still makes this type of model still um\n1122.039s: promising to work with and then onto\n1125.4s: your uh left there the model um I\n1129.76s: plotted the four random super particles\n1132.799s: so you can also see like the um accuracy\n1136.12s: and the predictions the true versus the\n1138.4s: predic\n1139.52s: of the mass and the radius over time so\n1142.0s: it's kind of like you're getting to see\n1143.4s: like the specifics of the particles um\n1145.76s: over time and that concludes my\n1148.559s: presentation thank\n1152.12s: you oh really cool and I'm not just\n1155.039s: biased because I like clouds um and\n1158.679s: microphysics I was wondering or did you\n1161.36s: guys try um the K means clustering with\n1165.72s: variables other than super saturation it\n1167.96s: looked like you were mostly tracking\n1170.2s: altitude in some of those\n1172.4s: plots yeah um we only did Super\n1175.72s: saturation um mostly informed by the um\n1180.28s: kind of conclusion of kamal's paper that\n1183.08s: came out which is that it's the main\n1184.679s: driver of the\n1186.44s: variability um we did like concatenate\n1190.12s: um other\n1192.64s: variables what what did we concatenate\n1194.799s: Patrick uh super saturation and droplet\n1198.32s: radius\n1202.72s: yeah um so and like particle radius\n1206.36s: right um and it didn't did did it I\n1208.96s: think it didn't change the actual shapes\n1211.32s: of the Clusters in either Dimension much\n1213.48s: from what I remember so then we stopped\n1215.24s: looking at\n1217.2s: it I Echo that I think the like the fact\n1219.84s: that the the trajectory is can like lie\n1221.799s: on the 1D mainfold is like really really\n1223.44s: cool I was curious what this like\n1225.72s: unsupervised thing is like descriptive\n1228.2s: or like predictive in the sense of when\n1229.72s: you were saying with like the things\n1231.4s: falling out of the droplets is it like\n1233.919s: the first 35 time steps are sufficient\n1236.2s: to then kind of track the rest of the\n1238.12s: lifetime history of the droplet or it's\n1240.48s: like whether it falls out or not is like\n1242.799s: within those 35 so are you are you using\n1244.88s: the representation of 35 time steps to\n1246.919s: try to make other statements or is it is\n1249.559s: the main Insight just that like the\n1251.4s: trajectory itself is just really well\n1253.44s: described by one number which is in\n1255.44s: itself really cool yeah the short answer\n1258.36s: is\n1259.159s: um descriptive not\n1264.32s: predictive great thank you so much"
    },
    {
        "class": "YouTubeVideo",
        "title": "Deep Learning, Data Assimilation, and Uncertainty Quantification with Peter Jan van Leeuwen",
        "videoId": "DTbfZu24Jyg",
        "url": "https://www.youtube.com/watch?v=DTbfZu24Jyg",
        "publishedAt": "2023-04-21T02:29:31Z",
        "transcript": "4.92s: okay so today um we're gonna have uh\n7.919s: Peter Yan Von lugvin from Colorado State\n10.019s: who is going to talk to us about data\n12.599s: assimilation and deep learning\n14.94s: um he's currently\n16.74s: a full professor at Colorado State\n18.6s: University\n19.859s: um and\n21.779s: yeah I guess I'm really interested to\n24.18s: learn more about your research so thank\n25.74s: you again for going to speak with us\n29.58s: yeah absolutely so uh thank you uh\n33.059s: pretty uh pretty uh introduction\n36.239s: um yeah so let me just um go ahead and\n39.78s: share my screen\n43.32s: um\n44.82s: [Music]\n47.34s: so can you see this\n53.16s: can you see the presentation yeah okay\n60.84s: at this point\n63.719s: someone didn't work\n70.799s: but um okay\n74.22s: um\n87.36s: okay\n88.5s: okay I think we're full screen now\n91.259s: um\n92.34s: okay so I want to um\n95.4s: I share some ideas on deep learning\n97.56s: daily simulation and alternative\n99.0s: quantification\n101.579s: um yeah and I I stumbled on this uh um\n104.759s: about a year ago maybe two years ago and\n108.36s: and I I realized that uh yeah there was\n111.479s: actually a lot a lot that can be said\n113.04s: and done especially on certainly\n114.899s: qualification in machine learning\n116.939s: but it's um so I've got a specific I\n119.88s: specifically talk about deep learning\n121.979s: um\n123.18s: well I think that's most relevant for\n124.86s: what I want to say\n126.119s: um the idea of deep learning is uh is\n129.72s: that you estimate a set of parameters in\n132.0s: in some hierarchical function that Maps\n134.76s: an input factor to an output Vector so\n136.62s: uh it sounds a bit weird Everybody ideas\n139.56s: you have some input X AC by Mouse by the\n142.14s: way\n146.0s: okay so so this is my input vector and\n150.06s: and um I have a bunch of uh of weight in\n154.08s: in the first function and then I push\n156.239s: that function to the second function\n157.739s: with this with a set of Weights well\n159.48s: parameters\n160.92s: Etc and I continue doing that and that\n163.2s: gives me the full neural network and the\n165.72s: um\n166.68s: yeah so the the the parameters are\n168.959s: estimated from a large planning data set\n171.239s: of input development pairs typically so\n173.64s: that's I'm looking at supervised\n175.2s: learning\n176.34s: and um and any ideas to to generate a\n179.819s: fast highly non-linear function that\n181.62s: Maps input or outputs and and as of\n184.2s: schematically this is what we want to do\n186.48s: we have some input Acts\n188.7s: um we push it through the neural network\n190.08s: with with the wage Vector w\n193.08s: and then um well uh without neural\n196.68s: network we're getting our budget\n199.379s: so so with deep learning that it\n201.72s: estimates the set of parameters and um\n204.54s: but I'm just I'm just refreshing about\n207.18s: copying what I had on the previous slide\n209.28s: here the first number of lines and if\n211.68s: you look at what data simulation does it\n213.36s: also estimates something but typically\n215.76s: estimates model state so so the model\n218.459s: state is a is a big Vector of model\n220.799s: variables so not parameters but\n222.659s: variables\n223.86s: support connection estimate the model\n225.72s: trajectory so over a certain time window\n227.76s: or it can estimate the set of parameters\n230.04s: or combination of all of these\n232.739s: um and it does it typically sequentially\n234.599s: yes as the observation comes in there we\n237.239s: we do new estimation process and the\n240.239s: idea is to proved model forecast\n242.28s: and the um\n243.78s: uh so you see there's there's definitely\n246.959s: connections but there are also\n248.159s: differences between these two two\n249.659s: methods and the both are estimation\n252.239s: problems and and to me that means\n255.299s: um that as soon as I talk the estimation\n258.12s: I think in terms of Base yeah right so\n259.919s: that's the basic way to tweet estimation\n263.82s: problems at least in in in my book and\n267.0s: um uh well I haven't I've never seen it\n270.18s: um\n271.44s: um well let's just go there right I mean\n273.96s: there are other methods out there but I\n276.06s: like this so much better\n277.62s: so the the thing about this theorem it\n280.5s: is fundamental to what we're going to\n281.88s: talk about you you have to read this\n285.0s: um this equation from from right to left\n287.4s: and so the idea is that you start with a\n289.68s: prior so that is my\n292.38s: the thing I want to estimate whatever it\n294.419s: is yeah a model state or or a wage in\n299.639s: in a neural network\n301.38s: and uh or output of vanilla Network\n303.479s: perhaps is better excuse me a long time\n307.08s: so that's just no come on but this is\n309.54s: our starting point\n310.74s: and we multiplied it by double\n313.38s: likelihood so that these are these\n316.139s: contain the observation\n318.72s: and that multiplication gives us a\n320.34s: posterior PDF so the the probability of\n322.919s: density output given these observations\n324.539s: so that is that is the um the way\n327.419s: estimation work you see it's a\n329.639s: multiplication problem an estimation\n331.259s: it's not an inverse problem it's always\n332.94s: a multiplication problem and uh but of\n336.18s: course you have to know these these two\n337.62s: PDFs\n339.19s: [Music]\n342.259s: some knowledge the knowledge that we\n344.4s: have about the system and about the\n345.78s: observation is described by a probably\n348.06s: the identity function so call that PDF I\n351.539s: already did that a few times\n354.66s: yeah so that's what that means in this\n356.699s: talk and the funny thing is that all\n358.62s: data simulation methods can be brought\n360.24s: back to this base theorem yeah in some\n363.539s: in some uh approximation of other\n367.1s: deep learning\n369.18s: uh can we also bring that to Bay to base\n371.52s: here and and um\n374.28s: um I think it again so let's let's have\n376.74s: a look again at how our daily simulation\n378.66s: works so we have we have some prior and\n380.88s: typically index simulation comes from an\n382.5s: American model like the weather\n384.12s: forecasting model for instance\n386.16s: let's say the velocity\n388.02s: and of course\n389.52s: um nowadays we have we have uncertainty\n392.699s: and uncertainty estimate on that\n394.139s: forecast right it's it's becoming\n396.0s: science for Palestine so we have an\n398.16s: alternative estimate and we we combine\n400.979s: that with observations with their own\n402.539s: non-certainty to get this first year PDF\n404.58s: and that's the solution to the problem\n406.08s: and so if we look at base theorem oh I\n409.199s: see a change notation now so X is now my\n411.919s: Z on the previous\n414.24s: um slide apologies for that however the\n417.419s: the story is the same and the the the\n420.08s: denominator here is just a normalization\n422.759s: factor might we don't have to worry\n424.74s: about it and typically we don't have to\n426.18s: calculate it oops\n429.479s: yeah I guess the message from base\n431.94s: theorem is that the solution to a data\n434.759s: simulation problem is always a\n435.9s: probability density function and there's\n437.759s: no no direct inversion right you see\n439.86s: it's it's a it's a multiplication\n441.12s: problem\n443.099s: um anyway now let's look at Deep\n445.319s: learning right so typically deep\n447.84s: learning starts with a loss function\n450.419s: and it could be something like what I've\n452.099s: written down here so z i and x i are\n456.3s: training pairs X is the output f is my\n460.86s: neural network with the wave Vector W\n462.86s: and we have a whole bunch of that of\n465.18s: those training\n467.039s: um painting pairs of pairs and typically\n471.0s: um okay so when we\n473.22s: um we minimize this this loss function\n475.919s: with respect to this weight Vector W\n478.5s: that's the thing we want to want to\n480.36s: estimate and using from grading the\n481.86s: center algorithm\n483.479s: oh so you might ask why this loss\n486.72s: function line up something else y equal\n488.46s: verdict Etc well there are other loss\n491.28s: functions in use but it's good to\n493.44s: to see what the connection is with data\n495.479s: simulation here\n497.039s: but before we do that uh let's first um\n501.66s: not a little bit more deep learning\n504.24s: specifically methods that people use and\n506.759s: specifically things like over fitting\n512.18s: with this loss function and it's a least\n515.099s: squares problem with a large data set\n517.68s: and it typically gives advice to our\n519.659s: fitting if the model also is the neural\n522.12s: network that we generate is not perfect\n523.86s: and so so the online assumption is that\n526.74s: the\n527.7s: yeah whatever neural network we generate\n530.459s: it will never be perfect no network and\n533.1s: if that's the case then then we can get\n534.779s: over fitting and to avoid overfitting\n537.3s: well they sort of inform main method I\n540.54s: guess to to avoid that and one is to add\n542.58s: noise to the training data\n545.88s: and you see the question mark I I don't\n548.339s: know why you would do that and the other\n550.26s: thing is you don't use all the\n551.88s: information in the trading right so drop\n553.68s: out is an example of that um\n556.16s: SRU um\n559.92s: yeah so in Dropout you know better than\n562.92s: I do during the training you you when we\n565.86s: said uh\n567.6s: um a proportion of the of the wage in\n571.08s: this whole wage factor of the neural\n572.64s: networks you put them equal to zero\n574.98s: and um and yeah like I said to do it in\n577.98s: a random way\n579.6s: and details it has to do with the amount\n581.76s: of information in the training data and\n584.04s: the more training data you have the\n587.339s: larger uh does your Dropout probability\n590.7s: need to be to make sure that you don't\n592.8s: have overfitting there so it's really\n594.3s: you throw out part of the of the\n596.519s: information and the plane data and in\n598.5s: that way another way you should use this\n600.72s: validation data so typically you have\n603.06s: your training data your validation data\n605.82s: and testing data and the validation data\n608.04s: allowing you to be pretty stopping and\n609.72s: it's displayed to the plot here on the\n611.82s: on the right on the vertical axis we\n614.279s: have the loss function on the horizontal\n616.32s: axis we have the e-box or the the\n619.62s: um\n620.48s: so each Epoch is giving the neural\n623.94s: network\n624.779s: um all the training data and so you give\n627.12s: the network the same training data again\n629.1s: and again and the green line will give\n631.38s: you an example of what the what the loss\n634.08s: function for the training data would be\n636.48s: right it just this gets a lot smaller\n638.76s: and smaller and smaller\n640.5s: but the validation data that's an\n642.66s: independent data set if you compare that\n644.7s: to um if you if you put that through the\n646.86s: neural network and see how the loss\n648.42s: function the loss score what the loss\n650.1s: score is you'll see that it typically\n652.2s: saturates at some points that's\n654.839s: typically highly variable right a lot of\n657.0s: vehicles\n657.899s: um but you see it doesn't at some point\n660.36s: maybe after it block her under let's say\n663.24s: the validation doesn't the validation\n666.12s: loss doesn't decrease anymore so that's\n668.399s: that's in um that's where we stop the\n671.64s: training because training Works clearly\n673.92s: overfitting\n675.12s: and the third uh so the fourth way will\n677.459s: be to add organization terms to the loss\n679.44s: function\n680.399s: and I'd like to say to well go a bit\n683.459s: further with that\n685.8s: and so all these methods are are some\n688.74s: form of Prior information right if you\n690.779s: think again in terms of Base theorem\n693.899s: um perhaps in a slightly vague way at\n695.399s: this moment it is prior information that\n698.399s: you put there you see you want to avoid\n700.26s: overfitting we have some idea what that\n702.3s: is and um and and what you should do to\n705.12s: avoid it\n706.26s: the regularization if you use that that\n708.72s: makes the display information explicit\n712.019s: yeah so for instance you add to your\n713.94s: loss function\n715.56s: equivalent um loss function in the wage\n721.14s: and that and that sort of penalizes uh\n724.14s: wage that are that are non-zero that's\n726.899s: our tries to to uh what's the way to\n729.42s: sparsify your your network and the um\n732.42s: and the idea the basic idea behind is\n734.459s: that that large wage\n736.2s: typically give rise to large input\n738.42s: sensitivity and that's not what you want\n740.1s: now you want you you want your your\n742.2s: neural network to be highly non-linear\n744.42s: but still smooth function of the inputs\n747.42s: typically right not always but if you\n750.18s: look at the GSI and think about\n751.26s: geoscience is that typically what we\n752.7s: want\n753.48s: and the other thing of course is to do\n755.399s: realization by adding physics right you\n757.74s: can do there's a strong constraint but\n759.12s: with the LaGrange multiplier so this F\n761.04s: here is is a function that tell us that\n763.2s: Seth has to fulfill certain conditions\n765.36s: for instance\n767.16s: um heavy water should be below\n769.92s: um\n770.6s: water with less density\n773.519s: um\n774.3s: wow and the the concentration of of the\n777.959s: the trace gas has to be larger than zero\n780.66s: things like that\n782.279s: so you can add these constraints it's\n783.899s: called strong constraints like the first\n786.36s: equation here or second equation it's a\n788.639s: sort of a weak weak constraint and so we\n791.279s: don't we don't enforce it we don't\n794.04s: enforce that that denser water is below\n796.56s: lighter water that's typically the case\n799.019s: but it doesn't have to be their way\n801.18s: um\n802.62s: as examples of regularization theorems\n804.779s: so again\n806.339s: um\n806.94s: they bring in prior knowledge and they\n809.04s: help against other thinking\n811.5s: and we now look um compare that to\n814.019s: especially the second part that is weak\n816.18s: constrained uh physical constraints\n818.399s: sorry this physical strained in loss\n820.68s: function that is\n822.3s: um not an exact\n824.12s: relation but it gives some freedom\n827.399s: then um that starts to look very much\n829.92s: like the cost function that you find in\n831.899s: for instance method called 40 bar which\n834.24s: is one of the daily simulation methods\n835.8s: that we have or have out there actually\n838.1s: uh in the disability we talk typically\n840.899s: about the cost function in machine\n843.12s: learning about loss function but it's a\n845.04s: similar thing and you have you have a\n847.44s: term excuse me\n849.6s: oh man\n851.04s: I do related to the observations yeah so\n853.56s: there will be the training data in the\n855.6s: um in the machine learning and there\n857.399s: will be the observations over a certain\n859.8s: time window let's say six hour time\n861.839s: window in the 40 bar that is the first\n864.779s: term in the in the in the cost function\n866.82s: and then we have the regularization term\n869.639s: in the um in the um\n873.3s: deep learning that will be the prior uh\n876.839s: term the terms of Prior in the\n878.88s: informative art so these these things\n882.48s: look very similar there's there's some\n884.82s: differences for instance that you see\n887.22s: that instead of using just a quadratic\n890.1s: loss of the observation minus the model\n892.68s: equivalent\n894.72s: um in the 40 bar function we have this\n896.88s: error covariance Matrix there and the um\n899.339s: so that that allows us to have\n901.68s: observation with different error\n903.48s: characteristics uh some observations are\n905.94s: much more accurate than other we can\n907.5s: have all kinds of different observations\n909.0s: it really doesn't matter\n911.699s: um as long as what we observe as long as\n914.339s: we find the connect can find a\n915.72s: connection between the model State and\n917.88s: and that observation we can use it in in\n920.76s: data simulation\n923.519s: um\n924.3s: so that that's sort of a generalization\n926.339s: if you like what we do in in deep\n928.44s: learning and the same for the prior term\n930.6s: right instead of this Lambda here which\n932.76s: is just typically like considered to be\n934.92s: a tunable weight Factor we have here a\n938.16s: real prior information with an error\n940.139s: covariance on on our prior information\n941.639s: they're telling us how how much we trust\n944.399s: our Prime information\n947.04s: but typically in data simulation if we\n949.98s: do parameter estimation excuse me\n953.639s: if we do parameter estimation then this\n956.579s: this parameter Vector is very very small\n958.98s: Vector but in deep learning is of course\n960.839s: a big factor\n962.459s: yeah but still we we solve this cost\n965.579s: function and we solve for um a problem\n968.22s: in data simulation that nowadays it's\n970.86s: about 100 billion dimensional space so\n972.779s: so it's a big space it's a big problem\n976.56s: um\n977.579s: okay so that's about the engineer we can\n980.88s: we can we what I want to do now is I\n983.699s: want to make the connection of this 40\n985.019s: of our theme and the um and base theorem\n988.26s: and so I've written down base Theory now\n990.36s: again for the for the 40 bar here like\n992.459s: zero is the the model States didn't\n995.1s: mention it already I have a prior on the\n997.019s: model State we have the likeli term the\n999.42s: observations and uh well and the\n1001.339s: posterior so this prior term in the cost\n1003.98s: function that I shared before will be\n1006.019s: will be this one let me assume it's\n1007.339s: gaussian Adidas is well the exponent of\n1010.279s: a quadratic 4090 and if I go back and\n1013.519s: you see that this is not the last term\n1015.5s: here in that equation\n1018.259s: that the livelihood\n1020.42s: um again gaussian observation errors\n1023.36s: would be would be\n1025.88s: um a function like this again a gaussian\n1028.699s: and\n1030.26s: um well you see this Epsilon is y minus\n1032.48s: h of X so that's what we have here as\n1034.52s: the argument of the of the gaussian and\n1037.22s: this term is is indeed the term that we\n1039.679s: have here in the um but the first term\n1042.14s: in the cost function\n1044.48s: yeah and the product of these two uh\n1047.02s: gaussians is of course a gaussian so we\n1050.179s: can write a posterior write down the\n1051.74s: posterior immediately as this thing over\n1053.299s: here right so it's a very long equation\n1055.58s: but but the only thing you need to\n1057.679s: remember is there's two turn there\n1059.059s: there's an observation term and there's\n1061.34s: a term that has prior information\n1064.16s: now what we can what we do then what's\n1067.1s: about 40 Radars it try to find the\n1069.44s: mention of this posterior PDF and this\n1073.22s: maximum of course is found at the same\n1075.679s: State as zero\n1077.6s: is where this so-called cost function is\n1080.24s: minimum right so this cost function you\n1082.16s: see that's the argument of the exponent\n1085.28s: and the um yeah so minimizing this cost\n1088.82s: function gives us an x0 which is exactly\n1091.039s: the same as found by maximizing mising\n1094.28s: the posterior to the adversal in\n1095.84s: pictures of this microstair PDF and then\n1098.72s: the cost function is a sort of a smooth\n1101.24s: version well not smooth but a less deep\n1103.46s: version of that and it's mirrored of\n1105.62s: course where the maximum becomes a\n1107.059s: minimum\n1108.14s: and um\n1111.679s: yeah so that's that's what happens in in\n1114.2s: 40 bar and then and that allows us to\n1116.72s: see this connection between\n1118.34s: um yeah to see this connection uh\n1121.82s: between deep learning and daily\n1123.44s: simulation and so the regularization\n1125.0s: term\n1126.2s: in deep learning is is considered we we\n1129.559s: call that the prior information in base\n1131.96s: theorem and it contains information on\n1134.059s: the errors in the prior information\n1137.0s: but the data Misfit term is related to\n1139.94s: the likelihood and enhances related to\n1142.88s: the errors in the training data\n1146.299s: so why is it interesting to know well it\n1149.299s: can inform the generation of loss\n1151.22s: pharmacies in deep learning and we don't\n1152.84s: have to do this quadratic loss we can do\n1154.52s: other things of course it's known in\n1156.32s: that field but\n1157.58s: now we see the connection with with the\n1160.78s: errors in the uh in the training data we\n1164.299s: we might be able to uh well to go more\n1166.64s: systematic about it and the other way is\n1168.74s: it allows us to find a role to uncertain\n1170.66s: the quantification\n1171.98s: because a base Serum is about\n1173.72s: probability densities\n1176.059s: so let's go ahead and and then the\n1180.38s: specific and so so we we see the\n1183.679s: connection between deep learning and\n1185.059s: daily simulation now this is not new\n1186.919s: right this is known for maybe 10 years\n1190.4s: um\n1191.539s: and this is this is this is only the\n1193.46s: relation between deep learning and 40\n1195.98s: bar variational methods nowadays\n1200.36s: um I have you can also use for instance\n1202.52s: Ensemble common filters if you've heard\n1204.26s: about those and indeed some some people\n1206.66s: do\n1207.679s: uh deep learning with Ensemble common\n1210.74s: filters and there are some advantages\n1212.66s: and disadvantages one advantages that\n1214.7s: you don't have to do their back\n1215.9s: propagation\n1217.58s: um\n1218.419s: but um anyway\n1220.419s: like I said there's also disadvantages\n1222.679s: so\n1224.0s: um so there are many connections uh\n1226.039s: methodology method the methods\n1228.679s: biologically whatever between between\n1231.799s: these deep learning and daily simulation\n1233.419s: and so they can learn from each other\n1235.1s: and one of the things that deep learning\n1237.32s: can learn from daily simulation is is\n1239.72s: uncertain qualification\n1241.34s: so if you look look at the Deep learning\n1243.919s: problem right so we we have inputs and\n1246.26s: we have an output and we have some\n1248.299s: relation between these two and so this\n1250.34s: this equation on the bottom here\n1252.799s: but of course we know that there's\n1254.48s: uncertainty in my inputs yeah we do if\n1256.88s: in the geoscience is there's always\n1258.559s: uncertainty in observations in model\n1260.6s: output whatever we do always uncertainty\n1262.88s: we never know things for certain\n1264.799s: in terms of variables then we have a\n1267.679s: neural network and we know there's\n1268.82s: uncertainty in the weights that we can\n1270.5s: estimate the weights but it's\n1272.24s: um we we don't pin them down exactly\n1276.14s: um and the third thing is the third\n1278.6s: uncertainty\n1279.919s: um element is the is the uncertainty in\n1282.2s: the final neural network right so\n1285.26s: the way to think about this suppose that\n1288.38s: there's no uncertainty in my input\n1291.14s: I know my weights perfectly well\n1293.9s: then if I put put a new input through my\n1297.38s: neural network it doesn't mean that that\n1300.14s: I I get exactly the right answer yeah\n1302.799s: the neural network might have for\n1305.72s: instance that the data is is generated\n1309.1s: through a let's say a third order a\n1312.08s: power of the data so the head of the\n1313.76s: function that generates the data is is\n1316.22s: uh is being the third order and my\n1319.1s: neural network is um\n1321.919s: um is is based on is a function is a\n1324.679s: second order function so it takes the\n1326.36s: square of the input instead of instead\n1328.58s: of the third order so no matter what I\n1330.86s: do so even even if I know the if I have\n1333.38s: an enormous amount of training data so I\n1335.179s: have my my wage been done very very well\n1337.52s: in my neural network there will still be\n1340.64s: errors in my outputs and so this this\n1343.46s: last element is is definitely also a\n1345.98s: source of uncertainty so these are the\n1348.62s: three source of uncertainty and and what\n1351.02s: we're going to do is we're going to see\n1352.82s: how they come into the problem in the in\n1355.34s: the mathematically well-defined way and\n1357.44s: then how we can actually find them\n1362.2s: so let's first Define the problem and so\n1366.14s: the way I Define the problem is is we\n1368.24s: want to find this probability density\n1370.22s: over here\n1371.48s: so what does it mean we want the\n1372.98s: probability density of this Z then the\n1375.5s: output\n1376.34s: given a certain input vector\n1380.48s: and um but I know the input Vector is\n1383.179s: uncertain\n1384.38s: given training data but I know the\n1387.26s: training data is not perfect and giving\n1389.539s: some testing data whether that's enough\n1391.64s: the best thing that it does not um is\n1393.799s: not perfect right\n1395.36s: and the um\n1397.22s: so this is the problem that we want to\n1398.96s: solve and and the way we do it is is\n1401.6s: like I said through uh by by generating\n1405.38s: a neural network and and using that in\n1407.78s: an efficient way\n1409.94s: so let's have a look at the input\n1411.98s: uncertainty and\n1413.84s: it's actually\n1415.159s: um\n1416.36s: well the result is what you would expect\n1419.24s: um what we get out of this but but the\n1421.34s: way to get there is actually some well\n1423.5s: there's some sort of steps that I'd like\n1425.36s: you just to see what what's happening\n1427.64s: there under the foot\n1429.62s: so the idea is that my inputs\n1432.02s: is is um is it true inputs plus an error\n1436.34s: right uh I don't know the true input\n1439.58s: for the two input vectories uh I only\n1442.52s: have my my actual input Vector X and I\n1445.88s: know there's an error there\n1448.58s: and I assume that I know what the um the\n1453.08s: probability density of that error is so\n1454.82s: I know I know the statistics of the\n1457.46s: arrow in my inputs I just don't know\n1459.58s: what what the error Vector was actually\n1462.799s: drawn to generate my actual input but I\n1466.039s: know that you probably didn't see I know\n1467.419s: the statistics\n1470.48s: now unfortunately we cannot we cannot\n1473.5s: generate a whole bunch of input vectors\n1476.0s: because we don't know the truth\n1478.1s: we don't know about this and uh so we\n1480.679s: cannot do this several times to get to\n1483.08s: get on the uncertainty in here\n1485.659s: so how do we do this and and it turns\n1487.88s: out that we\n1489.38s: um\n1490.1s: let me do some sort of a trick and the\n1492.14s: trick is as follows you say well\n1493.94s: okay what I know is my X right I know my\n1497.0s: actual input vector\n1499.22s: and I know there is a two thread or\n1501.559s: somewhere\n1503.059s: um I don't remember this but I know it\n1504.98s: is there\n1506.179s: so if I take this original equation and\n1509.12s: I I rewrite it I can say that the two\n1511.22s: Vector is is actually my actual input\n1514.4s: Vector minus the error\n1517.46s: in that input vector\n1519.5s: and and now I can turn the problem\n1522.02s: around and say okay now given that I\n1524.539s: know this actually would Vector what\n1527.299s: what was the truth\n1529.58s: what where was the truth\n1531.74s: and I can think of a probability density\n1534.26s: of of where the truth has been right\n1536.96s: well which which was the original truth\n1541.52s: so that's that's what happened Saudi\n1543.62s: that's what we're going to use we're\n1545.419s: going to say okay\n1547.659s: keeps jumping\n1550.46s: um the two the two Vector is my actual\n1552.98s: input Vector plus an error and the error\n1554.72s: and mine is an error sorry and the error\n1556.94s: is is uh is is drawn from PDF and this\n1559.64s: error is of course the same drawn from\n1561.86s: the same well it's actually the same\n1563.44s: error as this one so it's grown from the\n1565.82s: same PDF\n1566.96s: the PDF is the same it's just mirrored\n1569.179s: right because then now instead of taking\n1571.64s: the truth as the sort of central value\n1573.679s: now my X is the center value and I'm I'm\n1576.74s: gonna well I can draw for instance\n1578.48s: samples of of possible two vectors\n1582.32s: but this is what we're gonna use and\n1585.38s: um\n1586.7s: and the way we're going to use it we're\n1588.38s: going to use again and again two basic\n1591.679s: um identities from Mobility Theory\n1594.64s: they're they're very standard right the\n1596.779s: marginal PDF that the person is at the\n1598.76s: marginal PDF of a is just a joint PDF of\n1601.7s: A and B and then I integrate out\n1603.679s: variable B\n1606.14s: um\n1607.279s: and and the other one is the definition\n1609.14s: of the conditional PDF at the Joint PDF\n1611.6s: of A and B I can write it as the\n1613.52s: conditional PDF of a given B times the\n1617.36s: probability\n1619.1s: this is getting annoying sorry\n1621.98s: okay that's how we're going to use these\n1624.14s: two and let's let's go uh step by step\n1627.799s: so again we are after this total\n1631.039s: uncertainty in the outputs\n1634.1s: and what I'm going to do is I'm just\n1635.6s: going to use this first rule and the and\n1638.419s: the B here in this first world that will\n1640.64s: be my two my two input vector and again\n1644.059s: I don't know what the truth is but the\n1646.88s: two input Vector was\n1649.279s: um but it but I know I I know it's\n1651.679s: probably the density now it is centered\n1653.6s: around X and it has a certain\n1655.76s: um well error distribution that that I\n1657.86s: know that's just the uncertainty in my\n1659.48s: input\n1660.74s: anyway I can so I can I bring in this x\n1663.799s: team the the two input vector\n1667.1s: but I integrate I integrate over all\n1669.62s: possible input backsplashes so this is\n1671.48s: the rdmp the first identity and that but\n1673.7s: now I'm gonna I'm gonna use a second\n1675.74s: identity so I'm gonna bring this this\n1678.919s: two Vector\n1680.36s: um I can only condition on that\n1682.82s: and that and then I get this this other\n1685.279s: PDF here\n1686.659s: um that the pr said it will be the\n1688.58s: margin of the of the two Vector a given\n1692.24s: well the the variables that are given on\n1695.12s: all of them\n1697.22s: so\n1698.419s: um\n1699.26s: and now there's there's one last step\n1701.059s: and that is uh that I realize if I for\n1705.2s: this first PDF if I know the true Vector\n1708.26s: then knowing my actual Vector input\n1711.679s: Vector doesn't doesn't help it doesn't\n1713.299s: give me extra information so I can just\n1715.64s: ignore it and so I I'm gonna drop X in\n1720.02s: that PDF and that's what we done here\n1722.6s: now for the second one the second PDF\n1725.6s: this is just all about the inputs right\n1727.94s: it has nothing to do with training data\n1730.039s: testing data this is just input and so\n1732.14s: the this PDF is is not dependent on\n1734.84s: training or testing or anything like\n1736.52s: that so um I can just kick out that\n1738.62s: conditioning\n1740.72s: and so what we now have is that the um\n1743.96s: we've\n1745.58s: we've Incorporated by this integral we\n1748.279s: have Incorporated the uncertainty in the\n1750.26s: input in in our calculations\n1753.86s: that we we know we we know this probably\n1756.2s: in the density it is the uncertainty PDF\n1758.36s: of the input and I see that I have to\n1760.76s: multiply this PDF with this one but\n1763.279s: actually it's a convolution right and\n1765.74s: and the way to see this is okay if I if\n1768.86s: I um if the if the blue line here is the\n1772.82s: is this the the probability density\n1775.22s: early on cellular input\n1776.899s: then um\n1779.12s: then I see that for each Z that I have\n1782.0s: so of course I want to know this PDF so\n1784.279s: I have to know it for for many injects I\n1787.1s: want to know the value of this of this\n1789.14s: function so I take a certain value of\n1791.48s: that and then I calculate this PDF and\n1794.72s: it will be finished in this web pdf for\n1796.7s: that value of that and then I do the\n1798.86s: integral over\n1800.539s: um the XT\n1802.159s: and then I take a different set and I\n1804.62s: have to do it again so you see this is\n1806.72s: this this integral here is a convolution\n1808.88s: and um well it's just a confirmation\n1814.539s: so multiply the blue with the red all\n1817.159s: the time so you see that the result of\n1819.2s: that will be broader than the uh than\n1821.779s: the original blue uh PDF that's already\n1824.62s: the uncertainty broadens the PDF that I\n1828.86s: um\n1829.64s: um and the bronze the PDF uh from the\n1833.12s: case when there was no uncertainty in my\n1836.36s: um in my input and we we have now a\n1839.12s: systematic way to bring that in\n1841.52s: okay\n1843.44s: now the next one I have remember we have\n1846.44s: three sources uncertainty the next one\n1848.299s: is the uncertainty in the weights\n1850.82s: that's a bit more tricky but still we're\n1852.98s: going to use it and actually we're going\n1854.659s: to use the same the same um the same\n1857.24s: ideas the same tricks\n1859.22s: and so I'm gonna I'm gonna sorry let's\n1862.1s: go back I know I'm I have this equation\n1864.679s: now I know this one this PDF I'm gonna\n1867.5s: look at this PDF here\n1871.96s: it's a certain value and I want to know\n1874.94s: how to evolve that\n1877.22s: um the calculator PDF\n1880.1s: so that's the PDF here and I'm doing the\n1883.22s: same trick right I'm bringing the W's\n1884.899s: the weights now yeah so this the W air\n1887.6s: is the weight Vector so that defines a\n1890.539s: neural network if you give me a weight\n1892.34s: Vector that's the weight Vector in that\n1894.14s: neural network and that it burns are the\n1896.899s: neural network works\n1899.24s: that's my weight vector and the um\n1903.14s: so I bring that in uh and then I'm gonna\n1906.44s: again write it as a conditional PDF of Z\n1909.86s: given W and the other stuff multiplies\n1913.039s: by the probability of The Institute\n1915.44s: weights\n1916.46s: and integrate over the weights so again\n1918.5s: you see uh now let me let me take one\n1921.74s: step and again simplifying things\n1923.74s: realizing that\n1926.179s: um if I know my weight vector\n1929.539s: then the training data will not help me\n1932.299s: it will not give me extra information\n1933.82s: and so\n1936.02s: um if the rate factor is given I I can\n1939.2s: ignore the trading data so that's how we\n1941.419s: go from here to there and here\n1944.5s: if I want to determine the weights then\n1947.419s: the testing data\n1949.58s: um will not will not help me right I\n1952.64s: calculate the weights using the training\n1954.32s: data so that's and and also the input\n1958.399s: doesn't matter right the um the specific\n1960.919s: input that may have my weights are are\n1963.02s: fully determined by my training data so\n1965.779s: I can again pick out two of these\n1968.299s: variables and I get this scene over here\n1971.96s: and the the so now we have brought in\n1975.62s: Beyond 17 weights and again it's a\n1978.38s: convolution and I'm not gonna go through\n1980.6s: over it again but you see it's just a\n1982.399s: convolution of two PDFs\n1984.799s: and again here the the original PDF so\n1987.679s: the PDF of the of the outputs and given\n1990.799s: given a certain weight and given a\n1993.32s: certain input and given the testing data\n1996.62s: um it will be broader because of the\n2000.039s: uncertainty in the grades\n2002.86s: I'm Sorry by multiplying by bringing\n2006.039s: your changing weights the resulting PDF\n2008.559s: will be broader than the one that I just\n2010.419s: mentioned sorry\n2012.88s: um okay so\n2014.98s: um what do we have now let's put it all\n2016.779s: together\n2017.98s: for the total uncertainty\n2020.019s: gee all these equations so we get a huge\n2022.059s: equation but it's it's not too bad I'll\n2024.22s: show you in a second\n2025.659s: however we can recognize the three\n2027.94s: uncertainty\n2029.86s: um sources in here have you have the\n2031.899s: uncertainty in the input is over in this\n2033.82s: PDF you understand the innovate it's\n2035.38s: over here and the uncertainty in the\n2037.299s: resulting neural network is over here\n2042.58s: um okay now let's have a look at this\n2045.94s: uncertainty in a neural network\n2048.94s: oh before we do that actually I'm first\n2051.339s: going to simplify this how we're going\n2053.8s: to use this\n2055.899s: um\n2057.52s: so we uh this is the same equation\n2059.32s: nothing new and now I'm gonna do the\n2061.839s: following I'm going to draw samples from\n2063.879s: the input in input PDF\n2066.76s: so\n2068.02s: the good thing about the fact that this\n2070.48s: PDF appears in this way the the tools\n2073.06s: input the true input\n2074.8s: and that I do not know\n2076.74s: given the actual input that I do have is\n2079.72s: that this PDF is centered on the actual\n2082.119s: input so I can just take the actual\n2083.74s: input and perturb\n2086.2s: um\n2087.359s: add perturbations to it and from from\n2090.52s: its uncertainty and generate a whole\n2092.919s: bunch of potential to inputs and this\n2096.76s: mathematical way to say that you you\n2098.74s: draw these samples and then I'm going to\n2101.619s: put it in the interval and then I see\n2103.18s: that the posterior PDF or the PDF that I\n2106.3s: want to that I'm after\n2107.92s: and throw to uncertainty in the output\n2110.92s: of the neural network is\n2113.26s: um is a weighted well it's a sum an\n2116.02s: integration of over all these input\n2119.26s: vectors so we see we have now\n2122.04s: Incorporated this PDF in terms of a set\n2124.839s: of samples and these samples are X I\n2128.079s: um\n2128.92s: uh and then there are samples of the of\n2131.44s: well the possible two vectors like I\n2134.079s: said but it doesn't really matter and we\n2135.7s: we have a recipe to generate them so we\n2137.68s: know what that is\n2140.079s: okay so that that helped us to to get\n2142.54s: rid of the um of that PDF so things get\n2144.82s: simpler\n2146.74s: and now the uncertainty in the wave\n2148.359s: Factor right we want to do something\n2149.56s: similar let me go back and we want to\n2151.839s: draw samples from this PDF\n2154.0s: now how is that done in practice in the\n2156.94s: standard way and and begging is probably\n2159.76s: the first method to do that is you you\n2162.339s: start by drawing a set of untrained\n2165.099s: initial ways right so when you do your\n2167.74s: your your your\n2169.42s: um when you train your your deep Network\n2172.24s: you start with a with a random draw of\n2176.5s: initial weights\n2178.119s: and then you have to decide the order in\n2180.579s: which you give the batches and so you\n2182.68s: have you have your full training data\n2184.359s: set to you split it up in different\n2186.099s: batches and you have to decide the order\n2188.44s: in which you give the batches to your\n2190.119s: neural network for the training and and\n2192.579s: the order matters right if you do it in\n2194.859s: a different order you get different ways\n2196.42s: weight values\n2198.64s: um\n2199.96s: so these are two random choices as soon\n2203.14s: as you made them then you can train the\n2205.18s: neural network and you can do that\n2206.98s: several times\n2208.72s: and so again training neural network is\n2211.66s: the same as finding a wave Vector right\n2214.96s: for the great version and all that work\n2217.119s: so you do it several times and that\n2219.28s: gives you an ensemble weight Vector so\n2220.96s: an ensemble neural networks\n2223.48s: and then\n2225.099s: um\n2225.88s: the um begging says Okay so this\n2230.44s: Ensemble of neural networks represents\n2232.599s: the uncertainty from the weight factors\n2235.96s: and let's investigate that let's\n2237.94s: investigate what's what's happening\n2240.339s: so again we want to draw samples from\n2242.859s: this PDF\n2244.66s: and the weight given the failing data\n2247.32s: now of course there's the battery order\n2250.48s: so let's bring in the bets or whatever\n2251.859s: we know how to bring in new variables\n2254.079s: let me just write down the joint PDF and\n2257.02s: we integrate over the new variable that\n2259.359s: we bring in\n2260.98s: and then\n2262.18s: um we're going to use base theorem to\n2264.339s: evaluate this PDF so we have the\n2266.2s: probability density of the wage and the\n2268.06s: and the the batch order and we call the\n2271.48s: batch order called an s\n2275.14s: um given the training data is\n2277.66s: um no is the probability density of the\n2279.64s: training data so it's the likelihood of\n2281.619s: the of this weight and weight vector and\n2286.119s: let's order it\n2287.56s: um\n2288.16s: given that this that we have this\n2289.839s: specific set of training data divided by\n2292.24s: the probability density of the brain\n2293.74s: data and\n2295.26s: multiplied by at the prior the prior\n2298.9s: probability of the wage and and the\n2301.54s: batch order\n2303.099s: and so this is\n2305.02s: um yeah this is what we should do and\n2307.359s: then um if we Now sample\n2310.48s: um big samples from the weight vector\n2312.46s: and and the batch order and just like\n2314.619s: begging though so we we draw samples\n2316.599s: from this PDF\n2317.98s: then the samples from from essay we can\n2321.22s: integrate them out and the um and the\n2324.52s: samples from the W they they appears\n2326.98s: Delta functions anyway so we we get this\n2329.859s: expansion over here\n2333.7s: um as I said this is the expression of\n2335.5s: the probability density of the\n2338.98s: of the weight vector and um well I've\n2342.52s: I've written it in in terms of this the\n2345.16s: samples the way Vector samples but you\n2347.56s: see that that from the mathematics\n2350.5s: um the live view charge up right this\n2352.54s: thing here shows up\n2354.7s: so\n2356.56s: um we have to take it into account if\n2358.24s: you look at what begging does begging\n2360.4s: says well this procedure means that I\n2364.72s: can write my\n2367.0s: um at the probability density weight\n2368.74s: Vector so that the the the trained\n2371.44s: weight Vector I can write it in this way\n2374.44s: but if we do the mathematics properly we\n2376.54s: see that there's a an extra waiting\n2379.18s: involved\n2380.44s: and there's this thing over here\n2382.9s: and um yeah clearly they're not the same\n2385.72s: right and and what is this well remember\n2388.0s: that the livelihood yeah so these these\n2390.7s: These are trained we can see that the\n2392.14s: observation so so this is actually\n2395.38s: um related to the loss function and\n2397.9s: assuming a um a quadratic loss function\n2401.38s: that we started out with we see that\n2403.599s: this liveluid is is the exponent of\n2405.579s: minus a half times this loss function\n2409.119s: now the loss function values for these\n2412.3s: W's they will they will they will differ\n2415.359s: and and they will differ uh typically uh\n2418.839s: well they were different quite a lot\n2423.04s: and now I'm going to take the exponents\n2425.38s: of these different loss functions and\n2428.02s: then suddenly means that these\n2429.099s: likelihood values they change they're\n2431.56s: very enormously yes or different\n2434.2s: a wage Vector will give me a completely\n2436.3s: different likelihood\n2440.32s: to give you an example right so\n2443.44s: suppose you are for weight Vector one\n2446.32s: your loss function is this this thing\n2448.18s: over here it's a 0.01 times the number\n2452.02s: of training day right so typically in\n2454.42s: deep learning you normalize the loss\n2457.18s: function with the the number of training\n2459.4s: data but the way I defined it here this\n2462.579s: it is the actual value that you get and\n2464.56s: you have to multiply by the training\n2466.18s: data\n2467.2s: I suppose we have another rate Vector\n2469.3s: that gives us well slightly larger loss\n2472.24s: function\n2473.44s: I suppose we have 10 000 training data\n2476.2s: points if we then look at the ratio of\n2478.72s: the livelihoods of these two\n2481.119s: um weight vectors\n2482.92s: then I get Dimensions something I get\n2484.96s: expanded my exponent\n2487.119s: um or e to the minus 10 which is which\n2489.579s: is which is very small number\n2491.68s: all right so even though it looks as if\n2494.32s: these these these loss values are quite\n2496.72s: similar\n2498.339s: they give quite different ways\n2501.28s: and and that means that if I sorry this\n2504.76s: wage there they are attached and this\n2506.98s: license are attached to the to these\n2508.96s: weight vectors so one way weight Vector\n2511.3s: is much more important as much higher\n2513.339s: likelihood than another one\n2516.28s: um that's what I mean but the\n2517.54s: livelihoods varies enormously but it\n2519.82s: means that effectively The Ensemble size\n2522.52s: in in begging is is well typically one\n2526.9s: there's only one Ensemble member that\n2528.82s: has much larger weight than all the\n2530.2s: others\n2531.339s: so begging actually is not a good way to\n2534.579s: get uncertainty in deep learning\n2538.0s: now this problem can be solved using\n2540.04s: ideas for particle filters using\n2541.54s: so-called proposal densities they want\n2543.64s: to go into that and there's not enough\n2544.9s: time\n2546.22s: um but it allows you to find\n2548.859s: um\n2549.48s: weight vectors that have that have equal\n2552.64s: well equal uh equal light unit\n2556.42s: so suppose so we I assume now that we've\n2559.66s: generated these waveforms so actually\n2561.579s: this sounds complicated the practical\n2564.4s: way to do this is actually extremely\n2566.14s: simple and then we I'll show you an\n2568.06s: example\n2569.32s: if there's time okay\n2571.96s: um\n2572.68s: anyway\n2573.82s: the resulting equation now is the\n2575.859s: following right so the uncertainty\n2577.599s: outputs for your neural network becomes\n2580.599s: is double sum summation over the input\n2584.02s: vectors\n2585.04s: Factor\n2589.54s: and information related\n2592.42s: onto your new weights of these functions\n2595.48s: are here\n2597.64s: and um and like I said earlier right\n2600.04s: even if I know these weights very\n2601.72s: accurate\n2602.98s: so all these wks are very similar and\n2605.319s: all these xi's are very similar that\n2607.72s: doesn't mean that this PDF is also very\n2610.24s: narrow all right yeah if I if I put a\n2612.88s: testing data through digital Network\n2616.0s: um I can still get\n2617.8s: um well I don't get the perfect fit\n2621.52s: so how do we find the uncertainty in\n2624.4s: this in the neural network and and we\n2626.74s: use the testing data for that\n2628.9s: and so it is that for each testing pair\n2631.9s: I can write the following equation\n2634.54s: um and so z i is my output output number\n2637.839s: I and it comes from out from input x i\n2641.38s: and and of course there are some error\n2643.359s: there\n2645.04s: and this F here is the neural network\n2647.26s: with weight first okay\n2649.599s: so that's what one of the testing data\n2652.06s: would give me and if would give me a\n2654.52s: value for Epsilon now I know the X I I\n2656.8s: know that it's me I know the X I I know\n2659.56s: the zip I so I know the Epsilon I I can\n2662.98s: calculate that and then so I get a whole\n2664.96s: bunch of these upside on ice so I can\n2667.0s: generate the PDF\n2669.28s: of those of those errors\n2672.52s: and if we now look at the new input\n2675.099s: Vector so now I'm just so I trained the\n2678.7s: the whole thing I've I've um with my\n2682.78s: testing data through the neural network\n2684.7s: so I have this PDF we have silence yeah\n2687.4s: it's the errors so if I now have a new\n2689.74s: input vector\n2691.78s: um and I put that through my neural\n2693.819s: network there will be an error connected\n2696.46s: to get to that a pair of values of of\n2702.339s: no I\n2704.02s: so I know my input Vector right and I\n2706.24s: just calculate the output Vector is but\n2707.92s: I know there's an uncertainty there and\n2709.78s: the decided to uncertainty is Epsilon\n2711.7s: the Epsilon is drawn from the same\n2713.319s: distribution that these are signal eyes\n2716.5s: so you see that I know my inputs I know\n2719.619s: my weights yeah this is way thresh okay\n2721.42s: so you see that the probability density\n2724.06s: of Z is the same instead of Epsilon is\n2727.119s: just Epsilon and then shift it and again\n2730.24s: this shift here is a constant sign on is\n2732.88s: a random number and zip is a random\n2734.56s: number\n2735.52s: that's how I can I can immediately write\n2737.44s: down that the probability of Z are given\n2740.26s: all these variables here it's just the\n2743.5s: same as the probability density of\n2745.72s: Epsilon it's the same probability the\n2747.88s: answer\n2748.54s: okay so from my testing day but that's\n2751.24s: the point for my testing data I can find\n2753.16s: this probably need that\n2755.619s: so we're done right this is the only\n2757.24s: thing that we need but there's some a\n2759.46s: small seller point and that is that the\n2761.319s: testing day they have their own\n2762.46s: answerable\n2763.78s: so we have to have to put the data\n2766.18s: uncert also into account\n2768.76s: but it's it's actually uh not that\n2771.22s: complicated uh if I if I take certain\n2774.579s: inputs um Vector from the testing\n2778.599s: I know that the the uh this push it to\n2781.72s: my neural network\n2782.98s: and the error that the output that I get\n2785.68s: I had the Epsilon here so I contains\n2788.56s: those two parts one is the this\n2790.599s: intrinsic error in the neural network\n2792.16s: and the other is the uncertainty in the\n2794.5s: outputs\n2795.52s: any error in the outputs and so we see\n2798.28s: that the what we get from the testing\n2800.079s: data is actually a sum of\n2802.9s: the infinity air in the neural network\n2804.64s: right the thing they actually want to\n2806.02s: know we want to know the PDF of this guy\n2808.54s: but it is better expanded by the\n2811.3s: uncertainty uh in the testing data\n2815.26s: now statistics tells us that if if one a\n2819.4s: random variable is almost two others and\n2821.5s: the two others are independent from each\n2823.06s: other then the PDF of the of the Epsilon\n2826.78s: yes of the of the left hand side is the\n2829.06s: convolution of the PDFs of the of the\n2831.16s: right hand side that's all right really\n2832.54s: well done here\n2835.0s: now we know this PDF\n2837.46s: we know this one right so this comes\n2839.98s: from the testing data this is just the\n2842.319s: uncertainty in the uncertainty in the\n2844.359s: testing data itself mainly output data\n2846.819s: we know what that is\n2848.2s: this is the PDF we want to have\n2850.54s: uh so it's a bit awkward and it's\n2852.76s: underneath an integral how do we do that\n2855.119s: well it's very simple I hope you can\n2858.16s: write this PDF as a as a community as a\n2862.839s: histogram and this one has a histogram\n2865.42s: and then I find this PDF also is\n2868.359s: histogram but it turns out if you\n2869.8s: discretize it like I just said how you\n2872.26s: work with histograms then you just get a\n2874.3s: matrix\n2876.66s: Vector problem and you have to find the\n2879.16s: X the X here so even though this is not\n2881.38s: the ideal this this DX means that I mean\n2883.96s: the PDF and the histogram of sine of T\n2887.14s: and the thing we want to have\n2889.06s: depends on Matrix is equal to uh it is\n2892.0s: back to B and B is the Instagram of the\n2894.66s: PDF but the Instagram that comes out of\n2897.22s: the testing data\n2898.599s: so with it with some smoothness\n2901.18s: constraint on the on this PDF we can\n2903.52s: solve this and we can actually solve\n2904.78s: this quite accurately yeah you can do\n2906.339s: some some testing anniversary well\n2909.819s: so with that he finally and I've found\n2912.819s: everything we have all the hours we have\n2915.22s: the area uncertain team and how to bring\n2916.839s: that in here hours in the Indian weights\n2919.96s: and now we have intrinsic errors in the\n2922.18s: neural network and the Epsilon entire T\n2925.18s: said the probability density drops we\n2927.04s: found them too so we've we've got\n2928.96s: everything we want\n2931.18s: and now simple example\n2933.819s: um\n2934.78s: we applied this methodology to to find\n2937.839s: uncertainty in how to convergence um\n2940.839s: so how to conversion the bridge not\n2943.72s: convergence but after conversion right\n2945.76s: so Auto conversion is a is a process in\n2948.4s: clouds uh Cloud droplets\n2953.04s: they bump into each other and and\n2955.839s: sometimes say they emerge and they form\n2958.0s: bigger and bigger drops and at some\n2959.92s: point these drops are so big they call\n2961.599s: them rain drops which means that they\n2963.52s: can fall out as range now so this other\n2966.94s: conversion process we understand it\n2969.819s: visibly well at a drop scale level yeah\n2972.819s: I mean there's complication with\n2974.26s: Dynamics there but we understand that\n2975.88s: losses the permatization to let's say an\n2978.88s: Les model or something else a climate\n2981.4s: model that's really hard\n2983.5s: so we use a what we do is we generate a\n2986.319s: neural network to learn that relation\n2987.76s: between blood normal concentration cloud\n2990.339s: of water content rate of water\n2991.96s: concentration and rainbow products so we\n2994.48s: have these four input variables\n2996.64s: and the auto conversion rate as outputs\n2999.88s: and that's what we're gonna do\n3001.74s: I repeated here we have\n3004.46s: aircraft data\n3006.78s: for over several days and then we use\n3010.14s: the input from the aircraft that we use\n3012.119s: that in a bin microphysics model where\n3014.339s: did my first scheme\n3017.16s: um so very high resolution scheme for\n3020.339s: um for for drop sizes\n3023.64s: um and then we generate about 10 million\n3026.3s: independent input output pairs again\n3029.339s: Auto conversion not conversion so sorry\n3031.859s: this is Microsoft whatever\n3037.26s: um so we get it um and the other\n3039.3s: conversion\n3040.68s: has um the the article version range\n3044.099s: ranges usually 1000 magnitude it's it's\n3047.16s: a highly variable thing so that means\n3049.619s: that we we always work with the um with\n3052.44s: the log 10 of our other conversion and\n3054.3s: also the other variables just to make\n3055.859s: sure that we have something that works\n3057.42s: that works well well normalized so\n3061.02s: neural network is six hidden layers 16\n3063.42s: nodes per Lane fully connected and we\n3065.339s: use redo we split the data I determine\n3068.46s: data points in six million training data\n3071.46s: two main valuation data and two more\n3073.38s: investing data and this is an example of\n3075.3s: the\n3076.26s: after training actually speaking before\n3078.359s: the training and the validation data I\n3080.4s: added the problems make sure you don't\n3083.339s: do the overfitting\n3085.98s: so we had found this expression for the\n3088.38s: uncertainty and um\n3090.54s: so\n3091.68s: we we draw a hundreds um heads of\n3095.94s: um I have an input Vector I know it's\n3098.64s: uncertain so I draw 100 samples around\n3100.559s: that input Vector so that these are the\n3102.9s: samples that I use there\n3105.42s: um I have my uncertainty in the weights\n3108.059s: so in the trained wage so I need I'm\n3111.059s: using 20 20 weights or 20 neural\n3114.0s: networks\n3115.5s: um and it turns out we just have to\n3118.22s: train the neural network such that all\n3121.5s: the loss function values are the same\n3124.68s: and if you do that then you have an\n3126.48s: equal weight\n3127.68s: um training Ensemble\n3129.78s: um\n3130.5s: yeah there's a bit more under the hood\n3133.2s: but I yeah like I said that's a bit\n3135.359s: complicated we can talk about offline if\n3136.859s: you want and we have this function over\n3139.26s: here the the PDF will be which we\n3142.02s: determined from the of the performance\n3144.78s: um on the testing data and the\n3146.94s: deconvolution that the dimensions\n3149.46s: and solving this this linear set of\n3151.5s: equations and if we do that then these\n3154.859s: are examples that's how this example\n3157.26s: three input vectors in total we did 50\n3159.839s: to to just no look at the whole range so\n3163.859s: an horizontal axis are the outer\n3165.839s: conversion rate and on the vertical axis\n3167.76s: are the probability density of that\n3169.44s: specific large compression value\n3172.079s: um so that's the blue line is the\n3173.46s: uncertainty PDF uh so this the outcome\n3177.18s: of our analysis and and the Red Dot here\n3180.119s: is the the actual uh other conversions\n3182.7s: rate yes so we in this case we know what\n3185.04s: the\n3185.9s: true value is well we if you will know\n3189.359s: the uncertainty in the red spot this is\n3191.16s: going to be small so you see that this\n3193.14s: PDF can have can be unimodal but they\n3196.14s: can also be by model you also see that\n3198.78s: the range here right so we run neural\n3200.52s: network\n3201.78s: um that that is trained on this whole\n3203.4s: range of the conversion value so here\n3205.14s: you see 10 and minus 11 and here you see\n3207.72s: 10 and minus 19 right so it's really a\n3210.54s: very large range and like I said it's\n3213.0s: full range just an order of magnitude\n3216.18s: um\n3217.8s: yeah and if you look at the sizing the\n3219.839s: uncertainty it is about it's about 0.5\n3222.059s: or around an integration by model the\n3224.579s: answer the uncertainty is much larger\n3227.22s: um and 0.5 in in units of uh of log 10\n3231.5s: uh and you know the conversion\n3234.72s: yeah but an example of what you get out\n3237.119s: if you do the full uncertainty\n3238.319s: qualification and the nice thing is we\n3240.54s: know the three source of uncertainty so\n3242.7s: we can dissect we can figure out what\n3244.859s: the different sources do so here we I\n3247.44s: show you I I take out the uncertainty in\n3250.44s: input I just look at the uncertainty in\n3252.3s: the West\n3255.8s: so each of these curves here is\n3259.74s: um corresponds to one weight Vector\n3261.96s: that's of 20 20 curves here uh giving\n3265.26s: you the infinity from 70 in the neural\n3267.599s: network\n3269.04s: um or the for the different brain\n3270.54s: factors and you see that the typically\n3272.94s: the uncertainty in the weight vectors\n3274.44s: doesn't do much how these curves are\n3275.819s: quite similar but perhaps from this last\n3278.28s: example uh where the uh the the\n3281.22s: different wave vectors do give different\n3283.619s: um\n3284.52s: 70 PDFs\n3287.22s: but yeah and so from this and if you\n3290.16s: look at the width of this PDF you\n3291.48s: conclude that the um\n3294.359s: uh that the the input uncertainty is\n3297.119s: actually governed Eddie understanding\n3298.5s: these plots is much smaller than we had\n3300.599s: before\n3301.5s: and so here's about uh well maybe half\n3305.16s: of what we had in the previous slide\n3308.4s: that's how we could we could actually in\n3310.559s: numbers here if we look at the the so we\n3313.5s: had 50 we repeat this for 50 different\n3316.2s: input vectors and and just calculate at\n3318.78s: the standard deviation of all of them we\n3320.4s: just average that and and yeah the order\n3323.4s: of magnitude uh is is again in log 10\n3326.339s: units is about a half and if we exclude\n3330.9s: um the uncertainty\n3332.64s: um\n3333.359s: an input then then the the standard\n3336.599s: deviation at the uncertainty drops by\n3338.46s: effective term\n3339.9s: if we compare with with begging uh if we\n3343.26s: do begging uh the way it's done now in\n3345.96s: the literature uh we we get an error\n3348.359s: that's about 10 of the two error if we\n3351.18s: do bettering properly so do the proper\n3353.52s: importance right so the proper\n3355.2s: likelihood in the bagging then there is\n3357.72s: non-certainty from the weights so there\n3359.339s: is non-cerned being\n3361.44s: um yeah\n3363.78s: uh and they're finally to conclude\n3365.64s: because I'm I'm running out of time I'm\n3367.26s: sorry about that we found it is possible\n3370.319s: to do fully on full uncertainty\n3372.359s: quantification on neural networks uh\n3375.24s: it's a bit tricky because it's high\n3376.559s: dimensional and the uncertainty in the\n3378.48s: training date and the testing data you\n3380.22s: have to take all that into account but\n3382.14s: if you do that there is a practical\n3384.66s: algorithm a practical way to do this\n3387.9s: um it's possible to dissect the\n3389.52s: uncertainties and um and that's useful\n3392.22s: to determine how they are supervisions\n3394.319s: here for B to reduce that error and it\n3397.2s: also can help us improve and then we\n3399.42s: will better architectures and so how\n3401.099s: should I Define manual Network\n3404.52s: and I'll show you the example maybe an\n3408.0s: important point is that that begging\n3409.619s: does not take the uncertainty properly\n3411.3s: into account neither does Monte Carlo\n3412.98s: Dropout has a similar problem deep\n3414.96s: ensembles same problem right so so these\n3418.319s: methods I'm not saying don't use them\n3419.7s: but but from certainly quantification\n3422.76s: um you have to be careful they can get\n3424.859s: misleading results\n3426.24s: but that's all I had\n3427.98s: um\n3428.7s: I'm sharing now\n3431.7s: so thank you for your time and um yeah I\n3434.52s: don't know if it's down for questions or\n3435.96s: if you have to run off\n3448.559s: yeah if you have questions\n3450.3s: um I guess please raise your hand and we\n3452.76s: can call on you\n3460.92s: I don't know it looks like there's\n3461.819s: someone in the chat too yeah okay yeah\n3463.98s: okay so so\n3466.44s: um Jeremy I saw with you so the question\n3468.599s: is do you have to make sure that your\n3470.4s: perturbations are presentative of the\n3472.68s: noise in the data collection\n3475.2s: um yeah that's that that is indeed uh\n3478.26s: that's true and then that's that's what\n3480.599s: you need you need to but at least you\n3483.059s: have to be in the same order magnitude\n3484.38s: right otherwise it's it's nonsense yeah\n3487.5s: so you have to understand your data\n3489.48s: that's true\n3492.3s: so this the second question is I was\n3495.18s: wondering uh sampling different weights\n3497.64s: would lead to more chances of multimodal\n3500.339s: distributions\n3502.559s: um not necessarily\n3505.2s: um the the\n3507.359s: um because you have to the\n3510.42s: but the the equation tell us that we\n3512.64s: have to we have to average all these\n3514.74s: weights and and um sort of means that we\n3517.319s: we in the end we average PDFs and and\n3520.26s: that can give to multimodal distribution\n3522.9s: but not necessarily it can easily stay a\n3525.059s: new model\n3526.5s: um it just yeah it just it just depends\n3528.96s: on on how wide these distributions are\n3531.059s: relative to each other\n3536.04s: and of course if I don't answer your\n3537.48s: question properly then then jump at me\n3539.819s: right you can you can shout\n3542.579s: um\n3543.66s: so Caitlin uh so what's the source of\n3546.42s: the observations and how do you quantify\n3549.839s: the uncertainty I assume exactly for the\n3552.42s: article version example\n3554.4s: um\n3555.48s: sorry the observations are from aircraft\n3557.579s: so we have aircraft measurements of uh\n3559.559s: of the different Cloud variables or\n3561.359s: Cloud normal Constitution Etc\n3563.94s: um and we can estimate even our\n3565.5s: conversion rates\n3567.24s: um\n3567.839s: and then we um\n3570.54s: and then we uh so the starting point is\n3573.48s: real observations\n3574.799s: and then we put that and those because\n3577.319s: this is not that many right it's it's a\n3579.359s: few hundred so so then we put those\n3581.52s: observations uh through a bin\n3584.04s: microphysical model that that that\n3587.7s: um that simulates the um the Collision\n3591.18s: of droplets and and and the forming of\n3593.88s: rain Rockets hey there um you know I I\n3597.78s: mean I love most places though\n3600.24s: immediately what I'm trying to say here\n3601.559s: and then that father said I think it's\n3603.72s: better for people like this like it's it\n3605.4s: just it's just the model that that\n3606.839s: calculates that now these these models\n3609.18s: have been tested uh extensively and and\n3612.119s: we use one of those very uh well tested\n3614.46s: models so we think that um\n3618.78s: that the data we generate with that\n3620.7s: model is is actually quite accurate and\n3622.859s: and good imprinting will be found in\n3624.9s: nature\n3627.5s: is it not real observations uh you can\n3630.839s: definitely criticize it there um but but\n3633.24s: it's uh it's it's probably as close as\n3635.579s: we can get to uh to uh well sort of real\n3639.0s: real data anyway in the model generates\n3642.42s: um how to conversion rate and we let the\n3643.859s: model evolve over I think 20 minutes\n3647.579s: um when we use we use the data every\n3650.16s: every five minutes to get independent\n3652.02s: data sets I mean there's just a whole\n3653.64s: bunch of times together look at this big\n3656.099s: data set\n3657.839s: and we need and we need this this this\n3660.96s: very large data set because it's it's a\n3663.119s: bit larger why do you only estimate long\n3664.92s: perhaps than that but the range the\n3667.2s: range of that parameter range of article\n3668.819s: version is so large that the uh that we\n3671.52s: really need a lot of data to make this\n3673.559s: work\n3676.74s: okay then from here ask the question\n3678.599s: does epsilon i z so that's the\n3680.88s: uncertainty in the uh in the in the\n3683.04s: output testing data included uncertainty\n3686.16s: Rising due to a distribution of shifts\n3688.26s: between the training and the test data\n3690.0s: but that's a good point\n3691.74s: um\n3694.2s: so in my head the testing data and the\n3698.4s: training data are um\n3701.16s: they should come from the same\n3702.66s: distribution right I mean that that is\n3705.359s: that's the basic philosophy of using the\n3707.52s: testing data\n3709.2s: um\n3709.92s: and the 28 but in principle they could\n3712.26s: be from from different uh um different\n3715.02s: distribution settings now if you look at\n3717.059s: the duration there is no direct\n3720.119s: connection between the testing and the\n3722.4s: and the training PDFs\n3724.319s: and so we we haven't tried it so we\n3726.839s: don't know what would happen but but\n3728.7s: there could be they could be different\n3731.28s: distributions I think I don't see why\n3734.52s: that would not work I don't see why\n3737.04s: there would be\n3738.54s: an intrinsic problem the most important\n3740.819s: thing is that you are the data that\n3743.099s: you're gonna use your neural network for\n3745.02s: I said you you generate your neural\n3747.299s: network and now you want to use it on\n3749.76s: new data the new data should have the\n3752.46s: same distribution as the testing data if\n3755.339s: that's not the case then while I said\n3758.16s: you can't use what I said and you have\n3760.2s: to you have to do something else so it's\n3761.94s: not about training and testing you have\n3763.559s: to be the same but testing and the the\n3766.5s: data you're actually going to use the\n3768.059s: machine for\n3773.4s: okay then then Robert uh asks is it\n3776.04s: possible to think about uncertainty\n3777.78s: model formulation in network\n3779.64s: architecture yes absolutely\n3782.76s: um\n3783.859s: the the way\n3786.66s: um I mean it's easy to think about it\n3788.16s: right and so that that would that would\n3790.319s: appear in the um in the formulation I\n3792.839s: had that would that would be part of the\n3795.299s: of the PDF of the weights\n3798.119s: like given the training data it's um\n3801.48s: um\n3803.04s: but but it will be an interesting\n3804.66s: problem\n3805.799s: um because the uh well the the size of\n3809.16s: the wage Vector will be different for\n3810.66s: different\n3811.559s: um\n3811.78s: [Music]\n3813.319s: for different uh samples but I don't\n3817.02s: think there's a there's a principle\n3818.94s: problem there there might be a practical\n3820.68s: problem that that you would need quite a\n3822.72s: quite a lot quite a lot of samples so we\n3824.7s: use we use 20 samples and and then we\n3827.4s: look looking at the data we realized we\n3829.2s: don't have to do a thousand different\n3831.119s: rate samples it won't give us more for\n3833.16s: this specific problem\n3835.2s: um\n3835.74s: I can imagine that there are problems\n3837.54s: that you would need more but I think as\n3839.7s: soon as you bring in architecture you\n3841.14s: probably need many more um because you\n3843.78s: need to sample architecture and and\n3845.4s: weight vectors within a certain\n3846.78s: architecture and then you also have to\n3848.7s: think about is there prior information\n3850.94s: uh about the architectures and do I\n3853.5s: process one architecture more than the\n3855.119s: other a priority\n3856.92s: um\n3858.9s: yeah it's it's yeah\n3861.24s: yeah you can get quite complicated with\n3864.119s: the interesting ending\n3867.66s: so if we've been um as it's possible to\n3870.18s: incorporate spatial temporal structure\n3872.46s: of the data\n3875.4s: I think there's no painful reason why\n3877.92s: not again if you look at the derivation\n3880.14s: there was no mention of space or time or\n3883.079s: whatever\n3883.98s: um\n3884.88s: and uh so principle you could definitely\n3887.28s: do this\n3888.559s: the um the interesting thing is of\n3890.94s: course when you use spatial data and\n3892.619s: temporal data there will be correlation\n3894.54s: between the between the data or\n3896.46s: typically actually about your\n3897.72s: geosciences and you get you get\n3899.819s: correlations between the data and if you\n3902.339s: have correlations in the training data\n3904.02s: that is that is in principle not the\n3906.78s: problem but then the standards could get\n3909.299s: a cost function as used in the in deep\n3911.7s: learning you can't use that so you have\n3914.28s: to use the more sophisticated likelihood\n3916.799s: from the uh that is also used in data\n3919.559s: simulation to incorporate the uh the\n3922.38s: correlation between the data points\n3923.819s: they're both in space and in time\n3927.119s: um yeah but you can yeah in principle\n3929.76s: you can you can make all this time\n3931.799s: varying Etc it's it's not there's\n3933.66s: there's no at least I don't see any\n3935.88s: fundamental problems there got it\n3939.54s: yeah\n3941.339s: very very nice talk feature it was very\n3943.26s: thank you yes\n3947.7s: so are there any papers that you have so\n3951.359s: we are we are about to submit this work\n3954.24s: um that's\n3958.94s: foreign yeah\n3962.7s: but uh I mean if you're interested as\n3964.5s: soon as we submit you can send you a\n3966.119s: copy if you want okay yes I would love\n3968.16s: to I would love to receive a copy yeah\n3970.079s: of course okay\n3972.26s: so uh so there's a there's a question uh\n3975.119s: from from Jerry then put\n3977.819s: um\n3982.799s: right\n3983.88s: um sorry that was just like a follow-up\n3985.319s: to the other question yeah\n3990.48s: go ahead\n3992.039s: oh it was just a follow-up question\n3993.839s: about like how turning and testing data\n3995.819s: can become contributions\n3997.98s: and that might be the case if like\n4001.7s: your tasks with uh\n4004.339s: forecasting and the test data is\n4007.4s: temporarily separated from training data\n4008.96s: in which case there would be you'd\n4010.819s: expect a different distribution\n4012.98s: um but yeah that's more of a comment and\n4015.74s: a question I guess yeah\n4018.5s: but no I I I I agree I I think my guess\n4022.94s: is that things were better if it's all\n4024.92s: from the same distribution but like I\n4027.92s: said right as far as I can see training\n4030.44s: and testing data can be from different\n4031.94s: distributions\n4033.74s: um as long as you are and the the data\n4037.76s: that you want to use your machine on has\n4039.799s: the same distribution as the testing\n4041.299s: data because it is not the case then uh\n4044.539s: well then then beyond 20 quantification\n4046.52s: that part is just wrong\n4053.48s: okay I see no more questions in the\n4055.4s: chair\n4056.24s: um\n4059.599s: so um\n4061.579s: okay well\n4063.14s: um yeah I guess we're a little past time\n4065.0s: too\n4065.839s: um thank you again for speaking today\n4067.52s: and\n4069.14s: um yeah I guess it would be great to\n4071.24s: know about the paper when you when you\n4072.859s: have it when it does get published\n4075.44s: so\n4076.76s: um I think for this journal Club we'll\n4078.44s: meet again\n4079.4s: um May 11th I think is the date for the\n4081.619s: next one\n4082.579s: um I'll follow up in the uh slack\n4085.16s: Channel though but um thank you again\n4086.96s: for attending and thanks for speaking\n4089.96s: yeah absolutely thank you for for\n4091.64s: attending it's great to have such a big\n4094.099s: audience and many questions thank you\n4095.72s: bye-bye\n4098.239s: thank you"
    },
    {
        "class": "YouTubeVideo",
        "title": "Visualizing Interpretability for Precipitation Prediction Using Shapley Additive Explanations",
        "videoId": "WqlEEF7ulEw",
        "url": "https://www.youtube.com/watch?v=WqlEEF7ulEw",
        "publishedAt": "2023-08-02T18:18:02Z",
        "transcript": "4.74s: okay so uh my research was about\n7.5s: visualizing interpretability for\n9.12s: precipitation prediction using shapley\n11.16s: additive explanations so basically\n13.44s: tackling interpretability using uh like\n16.74s: visualization\n18.9s: um so as deep learning has been used\n20.88s: more for climate simulation research\n22.439s: we've encountered an issue which is that\n24.119s: neural networks are generally vary\n25.56s: uninterpretable which means that their\n27.599s: black boxes were putting garbage in\n29.279s: we're getting garbage out and so what we\n31.5s: need to do is uh well the issue with\n34.98s: that actually is that data set and\n36.3s: representation biases can be hidden in\n38.46s: Black Box models and we could also be\n40.2s: missing results that we need for example\n42.12s: like if a certain input variable is\n44.28s: influencing a certain output variable\n45.96s: and we don't know about that because\n47.82s: there's just so many variables\n50.579s: um that's an issue that we would have\n52.5s: right now there is a large body of\n54.6s: literature uh concerning how we can\n56.76s: tackle interpretability in different\n58.079s: models\n59.34s: um and there's also ways to visualize\n60.78s: this uh trustworthiness and\n62.78s: reproducibility are influenced by\n64.86s: interpretability we need\n65.939s: interpretability to actually trust the\n67.68s: results of the model and so that's uh\n70.14s: why we tackle this\n72.659s: um the constant paper recommends uh\n75.18s: looking into interpretability and it\n77.52s: recommends using dimensionality\n78.9s: reduction and symbolic regression we\n82.14s: take a slightly different approach uh\n84.54s: using visualization which is an\n87.0s: important aspect of interpretability\n88.2s: here's like some other work I did before\n90.08s: we uh basically looked at infrastructure\n93.84s: damage uh assessing that after natural\n95.82s: disasters using computer vision and you\n99.0s: can see here that we also use\n100.259s: visualization to see which part of the\n102.24s: building contributed most to that\n103.92s: prediction\n105.72s: um specifically we're looking at\n106.979s: precipitation here and that's correlated\n108.96s: obviously with many variable conditions\n110.7s: many of those variables which are\n112.68s: included in the Clemson data set what we\n114.72s: want to understand is which variables\n116.46s: matter most and contribute most to\n117.84s: precipitation\n119.64s: so uh the methodology consists of first\n123.06s: pre-processing so focusing on certain\n124.74s: variables for training slicing the data\n126.479s: set along those variables we look at all\n128.399s: columns so like latitude and longitude\n130.14s: as well as uh we're taking the daily\n132.18s: mean of the data so that we don't have\n134.459s: too many data points\n136.5s: um we train four different residual\n138.42s: neural networks or resonates based on\n140.04s: different loss functions and input\n141.84s: combinations and we visualize the\n144.3s: importance of three inputs on one\n146.76s: resonant model using shop shapley\n149.099s: additive uh\n151.379s: sharply additive explanations dappy\n154.68s: values are based on Game Theory and you\n156.599s: can see here that the main components of\n158.16s: it are the weighting of a certain input\n160.98s: data point as well as its contribution\n162.84s: and then so we multiply those and then\n165.239s: we sum it up across all different input\n168.3s: data points\n169.739s: um there are two variations of shop that\n171.959s: we explore deep explainer which is more\n173.879s: suited for convolutional neural networks\n175.62s: and then a model agnostic version and\n177.78s: then we compared results with weighted\n179.16s: shop which is supposed to have certain\n181.04s: benefits and so the pre-processing is\n183.54s: very straightforward we combined rain\n184.92s: and snow rain for total precipitation we\n186.48s: sliced the data set along those\n187.739s: variables I discussed and then for\n190.08s: variables that are vertically dependent\n191.7s: we looked at the middle 20 levels\n195.239s: so the resident 50 model architecture uh\n197.94s: is special because well resnet as a\n200.519s: whole solves an issue with neural\n202.739s: networks that is called\n204.659s: um Vanishing or exploding gradients\n207.0s: which is that when you keep adding\n208.319s: layers oftentimes the gradient will go\n211.08s: to zero or it'll explode and so what we\n213.72s: need to do is have\n215.4s: um residual blocks which employs skip\n217.62s: connections so an activation from a\n220.2s: certain layer will be connected to\n222.0s: another feature layer by skipping layers\n224.459s: in between\n225.599s: and then so we have a lot of those pairs\n227.34s: or residual blocks throughout the resnet\n229.799s: 50 model which is called that because it\n231.239s: has 50 layers\n232.98s: um so we have like pairs of like\n234.72s: convolutional blocks and identity blocks\n237.54s: um and then at the end we have average\n239.159s: pooling flattening and fully connected\n242.7s: um\n243.48s: okay so we trained four different models\n245.64s: uh evaluated on F1 score which is the\n248.22s: harmonic mean between precision and\n249.78s: recall and then so one model we take the\n252.299s: input being Cloud liquid mixing ratio\n254.4s: surface pressure specific humidity the\n256.44s: output being total precipitation the\n258.6s: second model input being air temperature\n260.519s: ozone volume mixing ratio and solar\n262.919s: insulation and also having the same\n264.84s: output we used also two different loss\n267.84s: functions one is mean squared error loss\n269.46s: and the other one is cross entropy loss\n270.84s: comparing all four models the one that\n273.06s: is the most\n274.56s: um\n275.16s: accurate you could say or it has the\n277.139s: best F1 score is the one on the top\n279.3s: right and that's the one we use for\n281.04s: evaluating interpretability because we\n282.84s: want to be using a model that is more\n284.22s: accurate ideally\n286.62s: um so shop versus weighted shop uh the\n289.139s: original\n289.979s: um shop uh methodology is connecting\n293.96s: optimal credit allocation with local\n296.699s: explanations using the classic shapley\n298.5s: values from Game Theory which I just\n300.66s: explained before how it's like\n302.34s: it's talking about waiting and\n303.72s: contribution\n305.22s: um and then the limitation of shop\n307.199s: however is that it assigns uniform\n308.699s: weight style marginal contributions\n310.139s: which means that if you have a lot of\n312.18s: features or not many features it's not\n314.639s: going to like differentiate that\n315.9s: actually so what weighted chat does is\n318.12s: that it does make a difference there it\n319.5s: learns to pay more attention to the\n320.699s: marginal contributions that have more\n322.08s: signal on a prediction\n324.06s: um and assigns larger attribution to\n325.68s: more influential features\n327.36s: which is ultimately what we want if we\n329.46s: want to have interpretability and\n330.96s: machine learning\n332.46s: so uh here are the results from that the\n335.6s: Deep explainer the one that combines\n338.58s: deep lift which kind of like Doc\n340.5s: propagates uh all the the neurons in the\n343.56s: neural network to all the features in\n346.08s: the input so it combines that with shop\n349.02s: values so basically you use a Sharpie\n350.88s: equation so linearize components like\n352.44s: softmax\n354.36s: um and then uses a distribution of\n356.52s: background samples so what we see here\n358.08s: in the top graph is that cloud mixing\n361.08s: ratio has a very like noticeable\n363.36s: positive impact on precipitation while\n366.96s: specific humidity and surface pressure\n368.699s: seem to have a negative impact so what\n371.1s: we can see from this is that when we\n372.84s: have more Cloud mixing ratio less\n375.18s: specific humidity and less surface\n377.039s: pressure we get more precipitation and\n379.5s: then the second graph we focus on cloud\n382.319s: mixing ratio specifically and we see\n384.6s: that when the cloud mixing ratio goes up\n386.46s: precipitation or the shop value for the\n390.72s: influence influential measure of cloud\n392.88s: mix and ratio on precipitation goes up\n395.759s: um but I don't think the the ticks might\n398.28s: not be correct on that\n400.5s: um the kernel explainer is a model\n402.36s: agnostic method uses a specially\n404.28s: weighted local linear regression to\n405.84s: estimate shot values for any model so\n408.06s: the top one\n409.259s: um shows Cloud mixing ratio having the\n411.419s: highest positive effect on precipitation\n413.039s: uh with surface pressure with surface\n415.62s: temperature and specific humidity having\n417.06s: slightly less and then the bottom graph\n419.28s: here is actually\n421.319s: um using a different model where we\n423.78s: train on like a lot of different\n425.28s: variables we could see that on the first\n427.44s: 2000 predictions we have like some\n429.84s: variants in the shaft values\n433.259s: um okay and then finally we use weighted\n435.0s: shaft so the difference between this is\n436.5s: that there's a metric that the weighted\n438.0s: chat paper proposes which is area under\n439.8s: the prediction recovery error curve or\n441.66s: AUP and so that basically sums up the\n444.24s: absolute value between the difference\n445.44s: between F hat which is like the uh the\n449.099s: prediction uh minus the conditional\n451.62s: expectation which is like that second\n453.479s: expression there and you add them up\n455.22s: below or the better and so we see like\n457.44s: weighted shop as we add more features to\n459.84s: the model\n460.979s: um performs increasingly better than\n463.56s: shapley even though it even started\n465.18s: better as well\n466.38s: so basically Cloud mixing ratio surface\n469.44s: temperature specific humidity have like\n471.18s: decreasing magnitudes of effect in order\n473.28s: in that order based on the mono agnostic\n475.199s: method based on the Deep explainer\n477.06s: method it seems that like more Cloud\n478.74s: mixing ratio and less of the other two\n480.3s: have more precipitation impact\n482.88s: um and then the weighted chap approach\n484.319s: is somewhat more effective but like more\n486.12s: discuss more like exploration needs to\n488.28s: be done on that front\n490.02s: um\n490.86s: and then yeah finally next steps would\n493.08s: be applying other interpretively\n494.819s: techniques on cnns and other models\n496.919s: applying the same pipeline to different\n498.84s: input combinations the combinations that\n501.419s: I use in my models were like somewhat\n503.22s: random because like I had limited time\n505.62s: and I like I didn't have time to train\n507.06s: more models but that's probably not the\n509.28s: most ideal input combination optimizing\n511.8s: the CNN itself more because like 0.8\n514.26s: like it's not like that good and then\n516.539s: also trying the other methods uh\n520.02s: suggested in the Clemson paper\n521.82s: so yeah that's it\n529.38s: we'll take questions in the room and if\n531.839s: anyone has questions online please use\n533.76s: the Q a function or raise your hand and\n535.68s: I will unmute you\n538.8s: anyone in the room\n543.839s: I just I had a question about the uh the\n546.0s: credit allocation can you go back to the\n547.56s: slide with the expectation yeah wait\n549.66s: this one yeah yes so I was just hoping\n552.959s: to learn more about\n554.339s: um how like this is evaluated in\n557.58s: particular about like the scale of like\n559.2s: the y-axis like does the fact that the\n561.36s: difference between the actual and the\n562.98s: expected value is like so small like\n565.56s: significant and like\n567.54s: um like you just tell us more about like\n569.3s: how one might make sense of like the\n572.519s: y-axis to that plot and um whether it's\n575.16s: like relative to something\n577.26s: um or just whether it's like a really\n579.66s: good sign that those values are super\n581.04s: low uh like the specific values here\n583.68s: yeah for the AUB yeah yeah yeah yeah I\n586.56s: guess it does show like that my model\n588.42s: like itself is pretty good that like the\n590.279s: expectation and the prediction were very\n592.08s: close but uh to be honest like I I'm not\n595.8s: like fully\n597.36s: um in understanding of like the theory\n599.76s: behind this because this is like kind of\n601.92s: the last part of the project and I\n603.18s: didn't uh really look into like exactly\n605.58s: how that conditional expectation is uh\n607.62s: calculated but yeah I think that smaller\n610.98s: values are better yeah\n615.66s: yeah I have a question\n618.019s: so I can see that when you're features\n620.82s: around nigh you kind of uh the weighted\n623.88s: chap kind of helps the prediction much\n626.82s: better uh like and first is did you\n631.14s: include the vertical\n633.899s: barabos for for this work and do\n637.74s: remember which are the features for the\n640.86s: age on live app\n643.32s: um yeah actually the uh the very so like\n647.519s: for the vertical variables I kind of\n649.32s: like the reason why it's so many\n650.339s: features is that I split it up into like\n652.019s: different levels so\n653.94s: um\n654.48s: like the variables will be split into\n656.1s: like the top third of the levels and\n658.38s: then middle and bottom\n660.36s: um\n661.62s: that's actually a really good question\n663.42s: like understanding which uh which\n666.3s: variable was like right here and I could\n668.94s: like easily find that out like if I go\n670.68s: back to it but I didn't have enough time\n672.06s: to do that analysis\n675.66s: okay great work yeah thank you"
    },
    {
        "class": "YouTubeVideo",
        "title": "Advancing Environmental Modeling with Knowledge Guided Encoder Decoder Frameworks",
        "videoId": "30LUCzPekxA",
        "url": "https://www.youtube.com/watch?v=30LUCzPekxA",
        "publishedAt": "2025-01-10T21:10:48Z",
        "transcript": "3.879s: um yeah I guess we'll get started then\n5.839s: today we have Arvin visiting from\n8.639s: Minnesota so arvind is a PhD candidate\n11.759s: in computer science at the University of\n14.2s: Minnesota and today he'll be talking\n16.359s: about uh knowledge guided encoder\n18.6s: decoder Frameworks for environmental\n20.519s: modeling so yeah take it\n23.359s: away uh perfect\n26.4s: uh um everyone in the room can hear me\n28.84s: right\n30.88s: um so yeah uh as he was just talking\n32.8s: about so today I'll be talking about\n34.719s: this advancing environmental modeling\n36.559s: with knowledge guided and cod decod of\n38.44s: Frameworks uh first thing um just just\n42.92s: uh okay\n49.84s: so okay um so a need to build uh robust\n54.359s: personalized prediction models uh for a\n56.32s: set of entities or task is applicable in\n59.039s: lots of different domains\n60.76s: so to first I would like to Define what\n63.079s: an entity is or what I mean by an entity\n65.239s: uh so what I'm trying to say is entity\n66.72s: can be anything on which a driver is\n68.64s: acting and it's showing a response to\n70.2s: that particular thing so for example uh\n72.64s: an entity could be a River Basin or a\n74.88s: catchment uh where you have a weather or\n76.759s: something of that sort acting on it and\n79.0s: it's showing a Stream flow in response\n80.6s: to that particular weather or it could\n82.72s: be things like uh I mean a location in\n85.72s: the world uh where you have a flux Tower\n87.439s: in or something of that manner you could\n88.759s: have weather and Lai acting there uh to\n90.759s: produce some sort of a gpp response in\n92.439s: that place um so with we Define\n95.28s: effectively all these systems as\n96.68s: entities uh so effectively uh you can\n99.439s: think of that in that this particular\n101.56s: abstract sense you have some physical\n103.64s: driver going into the system or acting\n105.64s: on a system um you have some system\n108.36s: characteristics in um some state which\n110.719s: the system has the state may or may not\n112.96s: be observed by some satellites ground\n114.56s: observations and so on and all of them\n116.2s: together are producing some sort of\n117.759s: response uh these processes may also be\n120.479s: evolving at different time scales um\n123.0s: effectively or they may be evolving and\n124.92s: interacting at different time scales so\n126.68s: you also want to model all of that for\n128.28s: example soil moisture will be building\n129.759s: up at much faster rate than snow pack\n132.2s: which would in effect uh affect how\n134.319s: Stream flow response uh how a basin\n137.519s: would response for a particular Stream\n138.84s: flow with a particular uh physical\n140.44s: driver and so on U with that in mind uh\n143.8s: what are couple of things we usually\n145.0s: want to do when we model these things uh\n147.239s: some of the things you usually want to\n148.44s: do uh when you model any of the system\n150.519s: are you either want to extrapolate that\n151.959s: in time that is you want to know what is\n153.959s: going to happen in future if something\n155.599s: else a new input comes in or something\n157.36s: of that sort in the same site or you\n159.4s: want to probably extol it in space you\n160.92s: want to be like okay I have some\n162.48s: observations in 10 different places I\n164.12s: have a new location 11th location how is\n166.72s: the system going to behave there or you\n168.84s: could be you would probably want to do\n170.319s: both uh so that that is you want\n171.84s: extrapolate in space and time and both\n174.879s: um but there is a fundamental limitation\n177.68s: with physics based models here which is\n179.0s: what we'll typically use use for all\n180.519s: these things uh that is if you look at\n182.519s: the two acces here uh you have an axis\n184.56s: for entities that each row corresponds\n186.36s: to an entity uh you can think of them as\n188.64s: locations or some patch and space for\n190.4s: now and uh you have a y uh x- axis which\n193.599s: is time so a fundamental limitation with\n196.519s: at least to an extent with physics based\n198.2s: model is that you'll probably have to\n199.799s: calibrate for each of these entities\n201.56s: separately you can't share the knowledge\n204.319s: very effectively and so what that means\n206.68s: is anytime I want to make prediction on\n208.08s: one of these rows in Orange I'll\n209.959s: probably have to train that model in one\n211.319s: of these rows and blue uh the advantage\n214.239s: which knowledge card in machine learning\n215.48s: or machine learning in general has is\n217.159s: that you probably going to share all\n218.439s: your parameters in whatever you're\n220.12s: training uh that'll help you extrapolate\n222.48s: or share knowledge to make better\n224.319s: predictions in these kinds of different\n226.879s: situations for example if your situation\n229.319s: was to let's say predict just do\n231.599s: extrapolation in time you would do\n233.519s: something like multitask learning where\n234.879s: you'll treat all of these different\n236.28s: sites as stas and you'll have a single\n238.799s: model uh which will have a shared set of\n240.36s: parameters between them which will'll\n241.68s: use to make predictions on all of these\n243.92s: tasks or let's say you want to do\n246.159s: extrapolation in space uh you could do\n248.159s: something as simple as zero shot\n249.4s: learning uh for example uh let's say you\n252.48s: have hundreds of sites where you had\n253.68s: lots of data and youve trained your\n255.159s: model and everything and let's say you\n257.04s: go to a new site where the only thing\n258.44s: you know about that site is things like\n260.639s: what kind of uh soil it has what kind of\n262.639s: climate zone is it in or what kind of EC\n264.36s: region is it is it and so on can we use\n266.72s: that information just that Ecco region\n268.4s: soil or climate zone information to\n270.199s: transfer the knowledge across if you can\n272.4s: do that that is some uh that's\n274.16s: particularly that's an example of zero\n275.759s: shot learning or let's say uh you have\n278.88s: some observations there maybe it's a\n280.4s: site where you have sparse observations\n282.199s: even very limited observations can uh do\n284.44s: wonders for you that is you can use that\n286.12s: limited observations along with the well\n287.639s: observed sites to make better\n288.68s: predictions in those sites uh and that\n291.039s: is what we term as F shot learning and\n293.36s: all of these different ml techniques in\n295.0s: general uh can help you make significant\n296.88s: predictions and extrapolation in time\n298.56s: space and space and time as opposed to a\n300.44s: physics based model where you had to\n302.199s: calibrate these parameters\n304.039s: individually so with all of these in\n306.759s: mind traditionally uh okay um sorry I\n310.639s: forgot this so these extrapolations uh\n313.12s: along with generalization to new Tas are\n315.72s: some of the things which you actually\n317.12s: want to do with things like Foundation\n318.479s: models and that's why Foundation models\n320.759s: are becoming really really popular um in\n323.96s: most fields in general especially after\n325.759s: Char came in um typically traditionally\n330.479s: uh in environmental ml uh these problem\n332.68s: problems are modeled As an X toy\n334.08s: approach that is you have a query for\n336.199s: now you can think of query as just some\n337.84s: sort of an input going into the system\n339.479s: and query is just typically the terms we\n341.08s: use now it's just an input going into\n342.8s: the system and you have the system\n345.4s: producing an output to that particular\n347.4s: input uh through some sort of pror model\n351.0s: yes this direct X toy approach Works uh\n354.28s: but what that often means is it's very\n356.039s: limited in ability to how how you can\n358.12s: incorporate context and new knowledge\n360.8s: and often times one of the most uh used\n364.639s: way of adding in context is just to do\n366.4s: it in some sort of an auto regressive\n367.759s: fashion uh where you'll just take your\n369.759s: output and you'll feed it back uh as an\n371.759s: input uh along with your normal input to\n374.16s: make a new forast or something like that\n376.96s: manner uh the question is can we do\n379.84s: better and the answer to that or what I\n382.479s: think the answer to that is that you\n384.16s: just use your standard encoder decoder\n385.599s: approach we've been doing encoder\n387.4s: decoder like models in machine learning\n388.919s: for more than a decade now um so what\n392.039s: encoder decoder naturally is designed\n394.12s: for utilizing context so what do I mean\n396.44s: by context context could be these things\n398.039s: like historical drivers historical\n399.72s: response uh simulations characteristics\n401.919s: and so on so what what I mean by context\n404.759s: is any information you have any\n406.68s: information you have which can help you\n408.479s: make more structured or more effective\n411.36s: prediction from query to uh response so\n414.199s: any information which helps you make a\n415.72s: better qu response prediction is what we\n417.44s: term as context here uh most often times\n419.84s: it'll just be some past input and output\n422.0s: in that site or characteristics on that\n424.52s: site and because you have structured it\n427.28s: this way you have a separate encoder and\n428.96s: a decoder uh you can handle variety of\n431.56s: information as context and it's much\n433.96s: more well suited for sequence sequence T\n436.84s: especially if you want to run this\n438.039s: decoder in an auto regressive fashion of\n439.72s: that sort Manner and because you're also\n442.639s: separating this uh query um and context\n445.599s: um you can do a lot more things with\n447.319s: this context processing and query\n448.479s: processing uh the first benefit is\n451.0s: basically now you have additional\n452.12s: Avenues uh for knowledge guidance why\n454.56s: you have an have an additional Avenue uh\n456.639s: the easiest thing is just that if you\n458.919s: were doing just a single model uh from\n461.039s: an input and output and if you wanted to\n462.599s: do something for example Auto regressive\n464.639s: you would have had a decoder only model\n467.159s: uh or so what that would mean is you\n469.56s: probably are doing some sort of a causal\n471.039s: modeling if you're using RNN or Lis\n473.24s: you're just doing a causal modeling or\n474.72s: if you're using Transformers you're\n475.84s: probably doing causal attention so what\n478.24s: that means is even if I want a read the\n480.12s: context in along with query I'll have to\n482.52s: do causal attention on that context so\n485.4s: by separating this now I can even do by\n487.639s: directional uh modeling if I want into\n489.479s: the encoder and I can process in other\n491.28s: context in whatever fashion I want the\n494.08s: the processing. context could be\n495.4s: knowledge guided uh another Advantage is\n498.599s: that because I'm encoding that uh into\n500.639s: some sort of a latent space um I can do\n503.159s: multiscale processes better and if you\n505.0s: imagine that State uh this context to be\n508.08s: the state of the system you can do data\n510.72s: simulation much more effectively\n513.0s: um uh another Advantage is if I Define a\n516.12s: probability distribution over that lad\n517.68s: in space uh to effectively Define how my\n520.519s: predictions behave I can also do a very\n523.0s: principled anity\n524.8s: evaluation and because the model is so\n527.959s: flexible and you can handle different\n529.48s: varieties of things it's really really\n531.04s: suitable for foundation\n532.72s: models um yeah go ahead are you going to\n535.399s: go into uncertainty quantification does\n536.959s: that fit into the encoder part uh\n538.959s: uncertainty quantification would be done\n540.32s: on the latent space so you'll Define a\n542.04s: probability distribution over this\n543.24s: latent space uh and by defining that uh\n547.04s: what we saw is you can do better than\n549.0s: compared to things like Base by backr\n551.24s: dropouts and so on so it'll help you do\n554.279s: it in a reasonably structured manner\n555.92s: let's\n557.64s: say can I move\n561.6s: on yeah and elements of this approach\n564.48s: the encoder decoder thing are already\n565.839s: being used um by lots of people some of\n568.399s: the examples are one of our papers from\n570.24s: about two years ago and this is a very\n572.24s: recent paper uh by Google which was\n575.279s: doing flood forecasting using a similar\n577.399s: let's say encoded decoder approach or\n578.64s: elements of it so with that in mind uh I\n581.8s: was just talking about some benefits\n583.2s: here in the previous slide so we were\n584.959s: trying to see if we can actually show\n586.519s: those benefits some of those benefits so\n588.959s: we have done multiple experiments or\n590.72s: different um let's say papers over over\n594.6s: the time uh the first one is we were\n596.44s: trying to see if we can add additional\n597.88s: Avenues of knowledge guidance and we did\n600.32s: that through uh prediction of gpp in\n602.0s: sparsely observed or unobserved\n603.279s: locations uh through a method called\n604.92s: Tamar so each of these I'll be going\n606.399s: into details in the next couple of\n607.56s: slides so I just wanted to\n609.399s: briefly uh show what are the methods and\n611.88s: what benefits uh we wanted to we saw\n614.12s: from them for the multiscale process\n616.0s: thing uh we worked on a project called\n618.36s: fhnn in collaboration with Noah um we\n621.76s: were able to see that we able to do\n623.2s: better uh operational streamflow\n624.6s: forecasting uh by a modeling multiscale\n626.8s: processes better and we were able to do\n628.6s: data simulation better better uh for\n630.56s: uncertainty quantification we were able\n631.92s: to see that we can better uh quantify\n634.2s: uncertainty for Stream flow compared to\n636.04s: things like Base by backrop and U\n638.079s: dropouts that work was done in\n639.839s: collaboration with USG and the last one\n641.839s: is what I did uh mostly over my summer\n644.399s: this year uh with ORNL um was a\n647.56s: basically we were trying to build a\n648.76s: backbone along these methods so that\n650.639s: this backbone can in future be trained\n652.16s: with a lot more data to make a\n653.44s: foundation model which is what I'm doing\n654.72s: right\n656.16s: now for the first thing so the idea\n659.6s: behind the first paper the stam RL is\n661.32s: very simple so we just talked about an\n663.48s: enqu dequ approach um if you think about\n665.88s: how a traditional physics based model\n668.0s: behaves um you have some model you have\n670.2s: some respective parameters for that\n671.68s: which you want to calibrate and once you\n673.279s: have those parameters you probably are\n674.639s: running that decod or a forward model\n676.279s: using that parameter so what we are\n678.36s: thinking is can we have a coupled system\n680.72s: of an invert c a forward model so all\n682.56s: you're doing is in the first block let's\n684.68s: say you have an inverse process where\n685.92s: you have input and output you're using\n687.72s: them together to figure out what\n688.8s: parameters the system should have and\n691.12s: then you're leting using using that\n692.72s: system parameters along with the model\n694.639s: parameters to make your final prediction\n696.16s: through a decoder uh that's all it's\n698.44s: pretty simple so what we realize what we\n701.48s: effectively doing is during training\n703.0s: you'll train both of these forward uh\n705.079s: decoder and the inverse model encoder\n707.04s: together on well observed sites so that\n709.32s: once that's strain on well observed\n710.6s: sites all you need is a few observations\n713.48s: in a new site to effectively get the\n715.6s: parameters for those sites and since we\n717.519s: have learned how to get these parameters\n719.279s: across sites you're sharing that\n720.399s: knowledge to figure out how it will\n721.8s: behave on the new site and once you have\n724.16s: that set of parameters you can just use\n725.6s: them uh to get your final output through\n728.079s: a\n728.72s: decoder um excuse me so this is what\n732.6s: that architecture looks like so it's\n734.12s: pretty simple the modulation network is\n735.839s: our encoder and this basically this blue\n739.04s: part in the base Network modulated one\n741.32s: is what is our decoder so all we are\n743.079s: doing is you're feeding some input in\n745.399s: and as you can observe it's a\n746.8s: bidirectional thing it's not really a\n748.24s: cause and modeling per because we are\n749.639s: not restricted uh you get some sort of a\n752.279s: parameter and you're using that\n753.72s: parameter to effectively modulate your\n755.32s: forward model to give different outputs\n757.16s: depending on what kind of characteristic\n759.56s: that site has uh we tested it on\n763.279s: multiple things uh some synthetic data\n765.36s: set Stream flow gpp and so on here I'm\n767.12s: just showing gpp so this is daily gpp\n769.48s: prediction uh on fluxnet uh there was uh\n773.839s: a paper here in leap um about an year\n776.199s: ago um uh by uh Pierce group and on uh\n780.16s: called meta flux so where he was using\n781.68s: mammal to make predictions uh for gpp U\n785.079s: so we use the exact same testing sites\n786.72s: as what he had uh before uh his whole\n788.88s: data set was created um we saw that you\n791.639s: can do significantly better on GP\n793.32s: predictions compared to traditional uh\n795.16s: metal learning approaches like mammal\n796.48s: multimodal mammal and so on uh we have\n798.72s: lot more other baselines in the paper\n799.959s: here I'm just showing uh closest uh\n802.839s: approaches and what we saw was we can do\n805.44s: significantly better usually 10 to 30%\n808.12s: uh better and the method is much more\n811.24s: simple and it's 10 times faster um so\n815.199s: that showed us promise that it's indeed\n816.88s: feasible and then we thought like okay\n819.92s: but the constraint here is that we\n821.72s: needed limited information to make the\n823.36s: prediction uh and often for most sites\n825.519s: in the world you won't really have any\n826.959s: observation so we were trying to see if\n829.279s: can we extend this method can we do\n831.079s: something so that we can make an ungag\n832.68s: prediction on sites where you don't have\n834.199s: any\n834.959s: observations uh so along that we tried a\n837.6s: very preliminary approach so all we did\n839.279s: we had an encoder uh the encoder we were\n841.12s: feeding an e region climate zones lack\n842.88s: long as some sort of a static feature uh\n845.519s: the model embeds that uh into some\n847.48s: representation space and uses the same\n849.24s: modulation network uh to make a\n850.88s: prediction nothing fancy yet and even by\n853.68s: doing that really really simple approach\n856.399s: uh with uh without any observations we\n859.199s: were able to do pretty good on gpp and\n860.839s: rco and flux net and we also compared\n863.759s: those results with what was already\n865.199s: reported in metaflux as a whole data set\n866.92s: in the first place and even though\n869.16s: metaflux used data for those 17 sites to\n872.079s: make predictions we were still able to\n873.68s: do equivalent or better to that even\n875.16s: without using any data from those sites\n877.8s: and for a completely independent\n879.16s: perspective we also tested our approach\n881.48s: and what metaflux predicted on Amir flux\n884.04s: and the results were drastic there uh so\n886.56s: both of them in a mar flux case did not\n888.079s: have access to that sort of data there\n890.04s: both of them are effectively acting\n891.519s: independently as engaged and there we\n894.399s: see more than 100% Improvement actually\n896.68s: it's like about 70 80 depending on on\n899.16s: which site you're working with uh so\n901.36s: this show us promised that it's indeed\n903.0s: possible so we are now effectively\n904.6s: working on a slightly more advanced\n905.92s: method uh using that Tam's perspective\n908.079s: to get and uh eventually a product out\n911.8s: which can show\n913.639s: G um the next thing uh so basically the\n917.519s: conation is that you can incorporate\n919.399s: knowledge better uh and this is just uh\n922.12s: one step forward showing us that you can\n923.88s: indeed do it for the next thing uh we\n926.12s: wanted to see can we model uh these\n928.399s: processes evolving and interacting at\n929.959s: multiple temporal scills so this was the\n932.56s: work F fnn uh which was done uh with\n935.0s: Noah operational forecast\n938.16s: Center again the idea is the same uh you\n940.92s: have an encoder uh you have some sort of\n942.72s: a context going in which in this case\n944.36s: was historical weather and historical\n946.199s: Stream flow and once you use then you\n949.24s: use your model uh to effectively get\n951.279s: multiple one of these latent States here\n953.6s: what we are saying is let's imagine the\n955.0s: processes is evolving at different time\n956.6s: scales let's just model those different\n958.6s: time SC SC uh as latent uh States uh and\n962.0s: they'll be evolving latent States and\n963.48s: then you can use them together in a\n964.8s: decoder model to make a final prediction\n968.04s: and so the basic idea\n970.92s: was uh is that uh once you\n973.56s: hierarchically factorize that now you\n975.399s: can have much more longer context\n977.519s: because typically these models had have\n979.319s: recen Biers and by now factorizing at\n981.6s: different SC time scales you mitigate\n983.44s: that recency bias a little bit and you\n985.759s: also have a slightly a small step\n988.279s: forward on explainability because you do\n990.399s: know that the process evolve at\n991.56s: different temporal scales so maybe you\n992.759s: can get\n993.56s: closer um by doing this now you're able\n997.44s: to do better multiscale processing and\n999.44s: because you're if you imagine this to be\n1001.759s: the state of the system itself you can\n1004.16s: assimilate into that state and that's\n1006.44s: how it enables data simulation uh we did\n1009.639s: some sort of a simple data integration\n1011.319s: we didn't do any Colman filter uh or 3D\n1013.639s: y 4D y of that manner all we did was\n1015.839s: let's just feed in uh the input and\n1017.639s: output and try to figure out what that\n1019.279s: state should be and use that State uh to\n1022.0s: make a prediction so like initialization\n1023.959s: of\n1025.039s: that\n1026.559s: and the we actually we evaluated that on\n1030.559s: 17 operational River s sites in nor\n1033.16s: Central River forecasting for no uh some\n1035.88s: of the things we were compared to the\n1037.12s: physics based models the actual NWS\n1039.439s: historical forecast the uh the forecast\n1041.439s: which actually went to real users uh we\n1044.4s: evaluated that with simple lstm lstm AR\n1046.72s: NR\n1047.84s: approach here's we what we saw um if you\n1050.64s: look at all the sites uh pretty much on\n1053.039s: every metric um we were able to do\n1055.24s: better than uh your typical ml based or\n1057.72s: physic based\n1058.72s: model\n1060.76s: um excuse me on pretty much every metric\n1064.559s: and I think the graph is something you\n1066.2s: should be looking at so the first thing\n1067.76s: is um models require much much longer\n1070.72s: context to make good predictions so the\n1072.16s: whole idea is that if this has event has\n1073.84s: happened before or something like this\n1075.799s: has happened before anywhere the model\n1077.08s: should be able to learn that behavior\n1078.36s: and effective ly replicated so all we\n1081.28s: are seeing is um all the 0 to 7\n1083.88s: effectively show the lead time after\n1085.52s: that for a flooding event actual\n1086.919s: flooding event and the Stars correspond\n1090.679s: to the true observations lstm lstm and\n1093.4s: lstm RL are three different methods uh\n1095.84s: lstm a lstm and lstm AR um lstm just\n1098.96s: stands for auto regress lstm so where\n1100.48s: just readed and the observations you\n1102.12s: made back into the model not really the\n1104.48s: predictions per se um then lspm RL\n1106.799s: corresponds to R and as you can see\n1109.88s: starting from even Day Zero uh our model\n1113.28s: was the pretty much the only one which\n1115.159s: was able to get the Peaks uh\n1117.2s: right um and that was consistent across\n1120.48s: every single\n1122.76s: uh uh lead time and as you got closer\n1125.24s: and closer to you and we actually became\n1126.76s: much more uh accurate let's say and the\n1129.76s: other thing we uh thing which is\n1131.36s: important is that if the situation is\n1133.28s: changing the model should be able to\n1134.72s: quickly assimilate information and\n1136.159s: correct itself and become better uh uh\n1139.0s: so for that let's say all the models are\n1140.64s: initially off so all of them are over\n1142.0s: predicting all of them are thinking the\n1143.039s: flood is going to be much more large in\n1144.32s: this figure twoo but then you make one\n1146.96s: observation on lead day one somehow um\n1150.48s: our model figures out that what this\n1152.88s: means to me is that now I have to my the\n1155.08s: flood is over I have to go down I have\n1156.88s: to correct correct it and it corrects us\n1159.08s: much more quickly than others and as you\n1161.64s: go to one more lead step it's pretty\n1163.12s: much perfect and others are still\n1164.24s: catching up yes it's eventually catch up\n1166.799s: but it's taking time and that's a time\n1168.28s: you don't have especially when you're\n1169.679s: trying to predict whether the flood is\n1171.159s: going to end or you're going to have a\n1172.0s: new event and of that\n1173.4s: s um then we compared it to the actual\n1177.12s: forecast which was produced by NWS for\n1179.08s: all of these floods uh so we compared\n1181.28s: with 12 floods which happened over that\n1183.44s: decade and what we realized is for out\n1185.919s: of seven out of 10 without any human\n1187.64s: intervention just by machine running on\n1189.6s: it was able to beat experts who manually\n1192.72s: tuned that model uh for that particular\n1195.36s: event to make prediction before it uh\n1197.36s: goes out to public\n1199.799s: uh and another Avenue forward is what we\n1202.6s: realized is that an expert can also work\n1205.2s: on our model to make a better prediction\n1207.36s: uh so that's a path forward potential\n1209.0s: path forward and even without doing that\n1211.6s: uh Beyond first 12 hours uh even experts\n1214.08s: are not able to beat uh what our ml\n1216.799s: model is\n1217.76s: producing so this was effectively just\n1220.0s: to show that we can assimilate some\n1221.799s: information we can fact effectively re\n1224.36s: uh retain long-term information through\n1225.72s: some sort of\n1226.64s: factorization so now let's move on to\n1229.44s: the uncertainty part so effectively what\n1233.28s: we' have seen so far is that we have\n1234.84s: some sort of an encoding and then you're\n1236.64s: using that encoding along with a decoder\n1238.0s: to make prediction we haven't really\n1239.919s: talked about uncertainty so can you do\n1241.84s: some sort of a structured uncertainty\n1243.2s: for all of these things because they're\n1244.36s: important so one easy way to do this is\n1246.76s: that you can define a probability\n1247.88s: distribution of that datat in space\n1249.2s: itself and then use that to make uh give\n1252.36s: you a prediction on certainty bounts uh\n1254.76s: and that's all we did uh so we inferred\n1257.039s: an entity specific uh attribute uh as\n1259.6s: distributions over Laten space and\n1263.28s: effectively then use that distribution\n1265.28s: along with the decoder to make\n1266.72s: predictions uh an additional advantage\n1269.0s: of modeling it as a distribution is that\n1270.559s: now you can do zero shot predictions you\n1271.96s: don't really need these observations you\n1274.279s: can just sample from seven different\n1275.799s: clusters of something of that s and just\n1277.52s: say okay this is how this cluster would\n1279.159s: behave uh this if this region Falls in\n1281.36s: this cluster this this how it behave and\n1283.0s: so on and as for some results uh this\n1285.96s: just to show some uncertainty bounds\n1288.559s: blue is what we got uh red is what you\n1290.72s: would have got with a standard\n1291.799s: deterministic Dropout uh sorry actually\n1294.12s: red is what you would have got with Base\n1295.32s: by backrop uh and yellow is what you get\n1298.52s: with a standard\n1299.6s: Dropout and as you can see close to\n1302.039s: Peaks close to um whenever it's supposed\n1304.2s: to go down it pretty much matches U and\n1306.48s: it's pretty systematic and\n1309.0s: regular um the bands are more precise\n1312.919s: um better matches two data distributions\n1315.799s: so it's increased uh more reliable and\n1318.64s: and another thing is uncertainty\n1319.96s: increases during High Stream flow events\n1322.0s: uh which is how it's supposed to be\n1323.52s: because uh it's Contex context aware and\n1325.72s: when you're near highest stream flows\n1327.279s: which is not something which you have\n1328.6s: observed regularly in your data you're\n1329.84s: probably going to be more certain\n1332.36s: anyways excuse\n1334.559s: me uh the last thing was um okay we have\n1338.4s: seen all of these we have said okay you\n1340.279s: can have an encoder you can have a\n1341.44s: decoder you can in include knowledge in\n1343.2s: different Fashions and so on can we use\n1345.08s: all of these to build some sort of a\n1346.24s: foundation model uh\n1349.12s: so towards that step I just wanted to\n1350.84s: Define what a foundation model is so\n1352.24s: that you're not confused so by\n1353.919s: Foundation model we mean uh we uh\n1356.559s: basically mean any model which aims to\n1357.96s: generalize uh learn a generalizable\n1359.679s: representation from large scale and\n1361.48s: diverse data so through some sort of a\n1363.32s: pretext task preex tasks are usually\n1365.799s: some sort of pseudo objective which are\n1367.2s: artificially designed that enables\n1368.52s: learning from data that is plentiful but\n1370.52s: may not be of high quality or may not\n1371.84s: have labels uh some of the key\n1373.919s: capabilities you want from a foundation\n1375.48s: model after it's built uh is that uh it\n1377.679s: can handle potentially or noisy or\n1379.039s: unlabelled data for initial training and\n1381.0s: it can be specialized for specific task\n1382.679s: through fine tuning with only limited\n1383.84s: amount of data or even run in zero short\n1386.48s: fashion um there's a huge interest in uh\n1390.679s: climate and weather Foundation models\n1391.96s: now these are just some of them uh in\n1393.559s: the last two years um the most common\n1396.52s: pre tring excuse me the most common pre\n1398.0s: trining task they use is multivariable\n1400.32s: uh multivariate variable step\n1401.559s: forecasting without without Master\n1403.48s: construction so all they say is I have\n1405.559s: step one step two's output in time I\n1407.44s: want to predict what step three step\n1408.76s: four is going to be and so on so that\n1409.96s: that's effective with a pre-training\n1411.12s: task and some of the downstream tasks\n1413.24s: they evaluated on things like our\n1414.96s: forecasting downscaling climate\n1416.279s: projections and so on just using the\n1417.64s: representation they built using the\n1419.159s: pre-train task but the pro uh the\n1421.88s: problem is many of these Foundation\n1423.2s: models uh okay it's not a problem per se\n1425.159s: it's an advantage at this point many of\n1426.559s: these Foundation models offer orders of\n1427.96s: magnitude speed up with similar or\n1429.36s: better skill over traditional weather\n1430.72s: models but uh they do it in some sort of\n1433.039s: not regressive fashion again the same\n1434.919s: problem exists again you have\n1436.12s: difficulties feeding in different types\n1437.88s: of context so the question is can we\n1439.88s: identify a different preing task that is\n1442.159s: more suited for more wide variety of\n1444.48s: Downstream task so e approach there is\n1448.0s: that uh preing task can leverage\n1449.76s: underlying unknown cause and\n1450.88s: relationships in the data itself let's\n1452.559s: say you do know that there is a variable\n1454.679s: which causes your variable of interest\n1457.0s: to change you can have that along with\n1460.039s: your traditional variable going into\n1461.559s: some sort of a blackbox for now and uh\n1464.52s: if you make an assumption that that\n1466.08s: variable is better predictable or is\n1467.919s: available in the future you can use them\n1469.48s: together to make eventually a better\n1471.08s: forecast so this could be things like\n1473.84s: let's say you have a product product\n1475.679s: running at a lower resolution uh which\n1478.399s: you know is reasonably good uh but\n1480.399s: you're not able to do a high resolution\n1482.12s: prediction of some other product and but\n1484.84s: if you have both of them in the past you\n1486.159s: can build some sort of relationship\n1487.52s: between them and when you go into the\n1489.44s: future you can use that low resolution\n1491.039s: product to just\n1492.08s: downscale um and we saw that this in\n1495.96s: this works uh through to uh other papers\n1499.12s: we' have been working on one of them is\n1500.919s: now published in icdm which I'll be\n1502.279s: presenting uh so it got accepted in that\n1504.52s: and so I'll be presenting it in two\n1505.679s: weeks uh the other one is a knowledge\n1507.64s: kinded Foundation model we were working\n1508.88s: on for remote sensing which also showed\n1510.72s: that this kind of pre-training is inde\n1512.36s: better than a standard pre\n1514.039s: trining um so I'm just expanding into\n1516.44s: that EXO thing because that's what uh I\n1518.72s: worked on uh with orl so effectively\n1522.399s: it's the same thing so uh for now let's\n1524.48s: just uh forget about uh this\n1525.96s: architecture more details on the paper\n1527.64s: because we don't have time uh you can\n1529.559s: just imagine that you have an encoder\n1530.919s: and a decoder some input going in and\n1532.84s: this time around what we are trying to\n1534.159s: say is there are some co-variates you\n1535.96s: have um this covariates are what will\n1538.799s: determine your eventual output and this\n1542.08s: covariates could be think like okay um\n1544.919s: you want to know projections under\n1546.039s: different scenarios right usually so\n1548.12s: let's say you have five scenarios in\n1549.48s: mind so if you know how something\n1552.96s: happened in past with a particular\n1554.36s: scenario and its consequence now you can\n1556.6s: model them together and if you have 10\n1558.64s: different scenarios in the future you\n1559.84s: can make different different forecasts\n1562.12s: for different different scenarios in the\n1563.64s: future so all you need is those\n1565.399s: different forecast scenarios and you\n1567.159s: know those forecast and the response\n1568.559s: scenarios in the\n1570.88s: past uh first experimental setup we just\n1573.679s: tried to see with real data this is not\n1575.88s: focus so we just imagined let's just say\n1578.279s: we have some gold standard observations\n1579.799s: available in the future can our model\n1581.84s: indeed uh learn that relationship and\n1584.32s: use that to make better predictions so\n1585.799s: we again tested it on the same kind of\n1587.919s: uh data set for carbon flux predictions\n1590.08s: compared to traditional uh time series\n1592.76s: approaches I was able to use that\n1595.039s: information and there are other\n1597.08s: approaches as well which use that\n1598.44s: information for example the St edlm and\n1600.64s: so on what we realize is that we can use\n1602.44s: it better and we can also use it uh in\n1606.24s: scenarios where the data is noisy so we\n1608.2s: also realized that the our model is more\n1609.799s: robust noise so all of that and the\n1611.52s: paper I'm not going into details here um\n1614.24s: and the phenomenon was consistent across\n1616.52s: pretty much every prediction Horizon we\n1618.0s: tried starting from a short-term time\n1619.76s: scale of a day to 7 Days uh to 120 days\n1622.679s: into the future uh we also tested it on\n1625.44s: other Standard Time series benchmarks\n1626.88s: because you have to for an ml paper um\n1629.799s: uh and there also we saw consistent\n1631.32s: results uh it was pretty much uh\n1633.679s: improving on every other uh Baseline\n1635.64s: which is there for this particular task\n1637.6s: or even the baselines which are not\n1638.88s: built for this task so what does that\n1641.36s: tell us so what tells us basically now\n1643.399s: we can use this as a backbone and we are\n1646.0s: currently in a process of using this as\n1647.36s: a backbone to build a time series\n1648.6s: Foundation model right now focusing\n1650.2s: mostly on land surface stuff uh but\n1652.36s: eventually we are trying looking to\n1653.52s: scale it up more and even in land\n1655.2s: surface right now I'm just\n1657.399s: focusing okay uh that's all I have for\n1659.84s: today uh any\n1671.48s: questions hey uh thanks a lot for the\n1673.799s: talk um I have a bit of a yeah technical\n1677.279s: question because I haven't fully\n1678.519s: understood how you're implementing um\n1680.44s: the context I'm sorry I'm jumping back\n1682.44s: to this study on gpp where you compare\n1685.039s: to or Rico for where you compareed with\n1686.96s: meta flux right yeah um and principle\n1690.519s: what I was wondering is so if you don't\n1693.72s: have data for a certain s side yeah how\n1696.799s: do you make sure that also your context\n1698.84s: is not just extrapolating right I mean\n1700.44s: because also your context information\n1701.84s: can be extrapolating and saying whatever\n1705.0s: so then mean meaning also context\n1706.919s: information might not be used useful if\n1709.039s: it's a site that is completely\n1710.44s: unobserved but maybe I misunderstood how\n1712.519s: you okay actually you're right uh you're\n1714.679s: saying what if your context itself was\n1716.32s: an extrapolated thing you're not using\n1718.0s: anything useful so the whole idea again\n1720.039s: if that is the case you probably are not\n1721.44s: going to be able to make a prediction\n1722.559s: there so the whole point is do I have\n1724.2s: something it can be noisy uh it doesn't\n1726.399s: have to be perfect do I have something\n1728.24s: which is giving me information which is\n1730.159s: more than what exists for that site so\n1732.919s: even if you do have projections often\n1734.399s: times it's probably Guided by some\n1735.88s: principle that's helping you make\n1737.64s: project uh let's say okay for example uh\n1741.399s: in this case we just use e regional\n1743.6s: climate uh according to your effectively\n1746.519s: whatever you just said it's probably a\n1748.0s: projection maybe wrong but the whole\n1750.279s: idea is that maybe it's close enough and\n1753.12s: if it's close enough it's still better\n1755.559s: to use it than not to use it because\n1758.399s: when you're not using it you effectively\n1759.559s: don't have any information to make that\n1761.159s: prediction so even if you do have noisy\n1763.2s: you can get close because eventually we\n1764.48s: are trying to get as close as possible\n1767.039s: and our experiments tell us that we can\n1770.72s: okay I guess then it would be\n1771.72s: interesting maybe also to enhance the\n1773.24s: context there like AB more and that's\n1776.0s: exactly why yeah potentially then also\n1778.039s: to say okay you know we are out of what\n1780.36s: we can predict now like maybe there's\n1782.6s: some studies where they basically look\n1783.88s: at areas of applicability Right Where\n1786.88s: what is the area where we okay uh so\n1788.48s: there are two perspectives to look at it\n1789.96s: so that's another reason to why model\n1791.32s: that as a probability distribution the\n1792.96s: next one uh that way you also tell us\n1795.519s: effectively tell when you're not certain\n1797.799s: about that\n1798.88s: context um and the additional thing is\n1801.24s: because you have now disentangled there\n1803.039s: a lot more other knowledge guidance you\n1804.279s: can give whatever you know you can put\n1805.88s: in to make a better extrapolation does\n1808.6s: that make sense or yeah yeah it does\n1810.559s: okay ex\n1817.48s: aot are there any questions in the zoom\n1821.96s: maybe okay\n1829.32s: hi thank you great talk\n1841.919s: uh uh I cannot hear her um\n1859.44s: uh thank you great great it was really\n1862.24s: great talk I I wonder how did you do\n1864.519s: with your training data like for deep\n1866.72s: learning models sometimes they require a\n1869.279s: really large amount of data yeah so I\n1871.88s: wonder how do they deal with that\n1875.24s: problem um as in\n1878.2s: um if you have very large data you're\n1880.32s: probably going to use either small back\n1881.72s: size or you're going to have small patch\n1883.36s: size right is that what you're asking\n1884.679s: for or I'm trying to understand um\n1889.679s: like like the training data set\n1894.08s: like uh you mean how do I transform them\n1897.12s: to a usable ml format I don't really\n1899.279s: it's the question is not really clear um\n1901.639s: Can\n1902.36s: someone\n1907.96s: sorry do you mean your data is really\n1910.08s: large how am I inputting that into mod\n1912.039s: is that what you're asking yes like are\n1916.44s: tring so lot okay for foundation model\n1920.96s: for foundation model initially right now\n1922.679s: I'm just training with the different\n1923.679s: different time series data sets yeah the\n1925.0s: data set is large it's huge\n1927.72s: um yeah so yes I'm training with very\n1930.6s: very diverse large scale data set um not\n1933.159s: large scale like climate large scale uh\n1934.96s: large scale like time series large scale\n1936.44s: so it's probably in\n1946.36s: terabytes and sorry\n1948.44s: I'll quickly jum jump not back but to\n1950.88s: the question of the uncertainty\n1951.919s: quantification yeah um have you I mean I\n1954.679s: think it's always nice to see you know\n1956.519s: uncertainties look more reasonable right\n1958.279s: I mean that's like check is there any\n1960.84s: way to then properly quantify that like\n1964.32s: whether it's celebration like I don't\n1965.88s: know what do you do with the\n1967.48s: uncertainties right now that we have\n1969.24s: some sort of uncertainties I mean I'm\n1970.96s: usually also always careful with Dropout\n1973.24s: as a means to get proper uncertainty\n1975.72s: quantification yeah well dropouts aren't\n1977.519s: really that good uh doing mon drop right\n1981.84s: um and they the bands are not good with\n1984.88s: monol\n1985.96s: drops they're not uncertain where it's\n1988.039s: supposed to be uncertain for example\n1989.679s: like when you don't know what it is yeah\n1992.2s: but I understood for instance I thought\n1994.039s: that also in your framework you somehow\n1995.519s: using Dropout in order to generate the\n1997.519s: The Ensemble have a Dropout uh so we are\n2000.08s: effectively modeling that as some sort\n2001.639s: of a normal distribution so yes we do\n2003.159s: have a bios we are saying our latent\n2004.88s: distribution is some normal distribution\n2006.48s: and we are sampling from that okay okay\n2008.48s: because I thought maybe at the start you\n2010.2s: at some point you said you could\n2011.279s: basically apply Dropout to the context\n2013.08s: to basically generate oh okay that was\n2015.32s: wrong okay let me explain that so all\n2017.08s: we're doing is that let's say you create\n2019.039s: a deterministic Laten space we're saying\n2020.639s: that Laten space let's regularize it by\n2022.76s: making it closer to a gion and just\n2024.559s: sample from that question simple similar\n2026.2s: to variation similar to variation you\n2028.679s: can convert it to a normalizing flow do\n2030.279s: more transformations to make it a more\n2031.919s: complex distributions but effectively\n2033.519s: you're still sampling from Aion okay\n2035.76s: okay gotcha\n2041.84s: sorry you might have said this how do\n2042.96s: you um get the ovarian or the or the\n2046.96s: variance for those\n2048.639s: gaussians uh initially we just assume\n2050.76s: was Z one go um you just assume uh we\n2054.119s: just assume a 01 gion we do a c\n2055.839s: Divergence to effectively make sure that\n2058.24s: is a Z1 most of\n2064.919s: that yeah\n2069.159s: yeah goe a lot of time have you also\n2071.52s: looked at\n2073.0s: basically maybe separating like or\n2075.52s: trying to quantify both sort of the\n2078.28s: context\n2079.76s: uncertainty the predictive uncertainty\n2082.079s: like kind of trying to split this and be\n2084.72s: like okay you know here we're more\n2085.96s: uncertain because of the context and\n2088.04s: here we're more uncertain because of the\n2089.679s: actual model uh we have not because I\n2092.48s: mean you can play around with it right\n2093.56s: you could introduce both of um we have\n2096.639s: not and that's a good idea um me\n2102.56s: see it's pretty straightforward to\n2105.079s: quantify from a model uncertainty I'm\n2107.079s: just trying to see how will you modify\n2109.56s: thir uncertainty from\n2111.079s: context because you don't really have\n2112.839s: the real uncertainty for context right\n2115.04s: that's fair I mean you can try to to\n2116.76s: learn some sort of probalistic you know\n2120.16s: I mean there are ways of course right\n2121.56s: you could try to do data impementation\n2123.56s: on your context right I mean you can\n2125.76s: there are means to but again we're\n2128.24s: dealing with time series data here there\n2129.76s: aren't really a lot of techniques to do\n2131.32s: that for time series\n2133.92s: um data augmentation based on\n2136.28s: certainties well explored in images not\n2138.68s: so much for time series yeah go\n2142.359s: ahead thanks but it is I mean since\n2145.72s: you're you're sampling from a Galaxy and\n2147.2s: that's basically a prior for your\n2149.4s: exactly exact yeah yeah yeah so but then\n2151.52s: you you haven't have you ever done like\n2152.88s: the inverse step Where You observe the\n2154.599s: time series and you can refine that\n2156.839s: prior uh no we have not not yet uh like\n2159.68s: plausible is that uh I think it is yes\n2161.88s: yeah uh you can have learnable priors\n2163.64s: you don't have to rest put any prior\n2165.96s: learn PRI are also\n2167.48s: learnable okay um I guess in that\n2171.2s: case yeah you'd be refining you could be\n2174.28s: pushing your context V your latent\n2176.88s: variables to points that were different\n2179.04s: than what were input exactly\n2185.52s: yes any last questions before we wrap\n2190.28s: up if not then uh yeah thanks for the\n2193.2s: talk again"
    },
    {
        "class": "YouTubeVideo",
        "title": "Measuring And Enforcing Diversity In Machine Learning with Adji Bousso Dieng",
        "videoId": "r12fod3WZ78",
        "url": "https://www.youtube.com/watch?v=r12fod3WZ78",
        "publishedAt": "2023-05-05T14:19:13Z",
        "transcript": "3.84s: so let's get started so it's a great\n6.24s: place\n8.42s: she's coming from not too far from\n11.099s: Princeton and she actually graded it\n13.86s: from Columbia University so it's a great\n16.139s: pleasure to have her back here uh she\n18.72s: won many awards including a Google\n20.52s: Fellowship\n21.96s: um was nominated as one of the writing\n24.48s: star in machine learning by the\n26.22s: University of Maryland she's very active\n28.619s: also with the Google has close\n30.779s: collaborations with them also doing a\n33.239s: lot of work uh in terms of social impact\n36.48s: on AI and how we can actually uh\n38.219s: basically use that at scale at the\n41.1s: global scale\n42.719s: um and so we're very pleased to and she\n44.16s: did in the graphics Lab at Princeton's\n45.96s: very happy to hear you about like\n48.059s: measuring and possible diversity in\n49.86s: machine learning and we talked a lot\n51.6s: about that and issues that lead into\n53.34s: data sets and viruses and data so very\n55.379s: much\n56.66s: thank you\n58.62s: um thank you for the nice introduction I\n61.68s: welcome everyone Thanks for for\n63.68s: attending the talk uh so I lead the love\n67.5s: vertex at Princeton the goal is to you\n70.38s: know highlighted AI it's for it to be\n73.2s: basically a connector within different\n75.24s: fields in the Natural Sciences after my\n78.42s: PhD I decided that I wanted to leverage\n81.6s: Ai and develop method that can actually\n83.939s: be useful to some to some interesting\n87.119s: domain in the Natural Sciences are those\n89.159s: domains so we look at you know we have\n91.92s: collaborators in chemistry uh Material\n94.259s: Science Biology and I'm hoping that this\n97.079s: tool can open up some collaborations\n99.06s: with protein climates\n101.4s: um so when you know this is the thing\n104.88s: with this domain scientists about\n106.68s: problems they run into\n108.54s: one thing that kept coming up one way or\n111.899s: another was diversity and so I started\n115.259s: looking at uh how to effectively measure\n118.5s: diversity so that we can enforce it in\n120.84s: different areas in models in algorithms\n123.72s: and things like that simulations and so\n126.299s: today I'll walk you through the story\n128.7s: about how this work came to be\n131.4s: um basically\n133.68s: one motivation one from motivation for\n136.52s: wanting to look at diversity studying\n139.26s: diversity how to measure it is that in a\n142.319s: lot of things that we do in machine\n143.7s: learning the scientists we do need to\n146.459s: enforce diversity for example\n148.02s: integrative modeling if you're building\n150.06s: a generative model over some domain you\n153.599s: would want that generative model to not\n155.459s: only give you one type of output but to\n158.34s: give you a broad type of output for\n160.8s: example imagine that you're building\n162.9s: agility model of molecules so that you\n165.66s: can\n166.44s: you know run that generating model\n168.18s: multiple times so get multiple candidate\n170.22s: molecules and then you wanna\n171.959s: you want that good sets of candidates to\n174.3s: be divert enough that when you go to the\n176.28s: lab and test for those candidate\n178.379s: molecules and their properties that you\n179.94s: actually can do discovery that you can\n181.86s: find something interesting if it was if\n183.9s: the JD model was only returning one type\n186.06s: of molecule with one type of property\n188.099s: that you can see how that won't be very\n190.68s: useful\n192.0s: um sometimes they may be interested in\n194.22s: another type of task Active search for\n196.92s: example where you have this very high\n199.319s: dimensional states that you want to\n201.9s: search over for example if you\n204.48s: people are interested in climate here\n206.04s: let's say you look for patternists or\n208.019s: some solvents that are more prone to\n210.06s: sustainability you would want for this\n212.34s: Active search to find you a diverse set\n214.68s: of those catalysts or those solvents\n217.5s: that you're looking for so diversity\n219.06s: comes in there as well reinforcement\n220.62s: learning we all know about exploitation\n222.78s: exploration\n224.519s: um trade-off diversity comes in there as\n226.739s: well\n227.76s: um sampling for example chemists or a\n231.0s: lot of clients if they run these\n232.14s: stimulation molecular stimulation and\n234.659s: what happens in that setting is that\n236.76s: when you do molecular Dynamics your\n238.739s: simulation gets stuck in one\n240.48s: configuration so you can get stuck in\n243.239s: that configuration for extended amount\n245.4s: of time which sometimes you cannot\n247.799s: afford so there's the need to actually\n249.86s: accelerate this simulation so that you\n252.12s: can explore different basins of your\n254.819s: energy landscape the diversity comes in\n257.1s: there as well you want to be exploring a\n259.32s: diverse set of basins instead of just\n261.06s: getting stuck in one if you're doing\n263.04s: data sub sampling that's also another\n264.72s: area that diversity comes in you know\n267.12s: you have a broad types of things a large\n269.88s: collection for example a large\n271.44s: collection of\n273.6s: um of molecules or other items that\n276.6s: that's in your data that you would look\n278.16s: into so you're assigned it and you want\n280.199s: to just you can afford to run your\n282.3s: experiments on all those molecules you\n285.0s: want to just sub sample a few of a\n288.12s: smaller collection of them so that you\n289.56s: can you know that's something that's\n290.82s: tractable that you can run in the\n292.199s: experiment so there's a need for\n295.08s: drawing a diverged set of sub-sample\n297.78s: from a larger collection or imagine you\n300.54s: doing Monte Carlo you're doing Monte\n302.759s: Carlo information\n303.96s: typically what we do is we get to draw\n305.759s: randomly from the distribution we're\n307.56s: doing taking the expectation over an\n309.6s: average dose to do Monte Carlo if we\n312.54s: could if that distribution is highly\n313.919s: multimodal we want to actually you know\n316.68s: we cannot grow an infinite number of\n318.18s: samples from it to get an accurate uh\n320.46s: estimation typically what you do is get\n323.039s: a smaller sample from that distribution\n324.84s: in Google we would need that sample to\n327.36s: be diverse so that we can have a more\n330.24s: accurate estimation so it comes it looks\n333.3s: it's a concept that alerts behind a lot\n335.639s: of the things we do in machine learning\n337.259s: and in science and so we'll look into\n340.259s: how to how to how to measure that so\n343.199s: what would we want out of a diversity\n345.6s: metric that's the first question to ask\n347.34s: what's actually diversity\n349.56s: um we would want for it to be\n351.0s: interpretable\n352.259s: what that means is that we would like\n354.0s: for diversity magic to be what's called\n356.34s: an effective number meaning that if I\n359.699s: have a collection of five different\n361.8s: elements I want the diversity metric to\n364.86s: return by\n366.0s: so that I can actually interpret new\n367.919s: things we want for it to be maximized\n370.5s: when all the samples are dissimilar so I\n372.72s: give you a collection we want for the\n374.639s: diversity metric to be maximized when\n376.5s: all all the elements in the collection\n378.479s: are very different from each other\n380.94s: and we want it to be minimized when all\n383.58s: the elements in the collection are the\n385.199s: same\n386.34s: um another thing we would want is we\n388.979s: would want for it to be reference free\n390.72s: what I mean by reference fee is that we\n393.6s: don't want that diversity metric to need\n396.18s: to use an additional probability\n398.34s: distribution in order for it to be\n400.68s: completed or another reference data set\n403.259s: in order for it to be computed and in\n405.66s: machine learning we run into a lot of\n408.259s: metrics that actually do need this\n410.46s: reference in order to be completed but\n412.44s: we want flexibility so we want our\n414.3s: diversity metric to be reference free\n416.58s: because we are not trying to measure\n418.62s: goodness objects we don't have a\n421.08s: property distribution like the test that\n422.699s: and we're trying to see how we fit it\n424.319s: we're not doing that we're just\n425.52s: interested in evaluating diversity of a\n427.5s: collection\n428.28s: so we want also flexibility meaning we\n432.0s: want this metric this diversity I give\n434.46s: you any collection I want to be able to\n436.259s: give you what the diversity so you want\n437.94s: for it to be domain anistic because that\n440.34s: you can use it in any domain without\n442.259s: needing to Define probability\n443.52s: distribution these are just high level\n447.139s: of things we would naturally want out of\n449.759s: a diversity metric\n451.74s: um so the next step the next step of the\n454.5s: story was okay now that we know what we\n457.259s: would want out of diversity\n459.36s: at a high level how do we actually\n461.16s: Define it then we have to look into the\n464.46s: the field that actually you know studies\n467.16s: diversity a lot which is ecology I\n469.8s: studied biodiversity and try to see how\n472.199s: diverse the population of species is and\n474.72s: that's important for preservation and\n476.58s: things like that in ecology when you\n479.039s: when you look into the literature one\n481.38s: thing that it's coming\n483.419s: diversity is defined as an effective\n485.639s: number of species before one of our\n487.319s: disadrata naturally and it's exponential\n490.62s: of entropy there's a lot of literature\n493.68s: um sustaining why that is a good thing\n496.08s: and why that gives you an interpretation\n498.479s: as an effective number of positions and\n500.759s: they refer to do things as Hill numbers\n503.699s: basically a real number will be\n506.759s: exponential of entropy and here I'm\n509.16s: showing the Rainy entropy of order q and\n512.64s: depending on how you choose Q you you\n514.86s: are choosing how to weigh the\n518.039s: contribution of rare species versus\n521.039s: common species the diversity metrics so\n523.979s: here here is the what is the parameter\n526.92s: that's controlling how you weigh the\n529.38s: propensity of these different species\n531.899s: so when Q equals 0 for example all\n534.24s: species are given equal weight and so it\n536.82s: would return the hill number will return\n538.74s: a diversity of a diversity industry the\n542.22s: size of the support that's not very\n543.839s: informative when Q equals one which is\n546.24s: an interesting case\n548.04s: the the the hill number returns A\n550.5s: diversity that weighs the the species\n552.72s: according to their to their prevalence\n554.7s: so we'll see how we get back to this\n557.64s: um\n558.48s: given given this definition we will try\n562.019s: naturally to Define diversity remember\n564.24s: we're given collection of samples a\n566.459s: traditional observations a data set we\n568.8s: would naturally Define the diversity by\n570.66s: trying to put a distribution over that\n572.94s: collection of samples and then Define\n575.76s: diversity as the exponential of entropy\n578.64s: Channel entropy which is what we\n580.08s: typically deal with in machine learning\n581.519s: so it's negative expectation under this\n584.399s: distribution over the samples log of the\n586.62s: the distribution\n588.24s: um so this would be naturally something\n589.92s: we would directly get out of this\n592.92s: definition exponential\n595.14s: but this is\n597.06s: this is very limiting even though that\n599.279s: you know you recover the form of entropy\n601.56s: in a lot of areas in machine learning in\n603.72s: variational inference this is how you\n605.58s: define the entropy of the variational\n607.56s: distribution the distribution used to\n609.42s: approximate the the true posterior in in\n613.38s: in work that I have worked on trying to\n615.54s: regularize dance to be more diverse to\n618.24s: use Shannon entropy as well I actually\n620.519s: did work on that so you would Define the\n622.74s: entropy like this and you're trying to\n624.18s: find a way of approximating it and in\n626.459s: many other works this is how we deal\n628.14s: with with entropy this is not\n630.3s: collectible because\n632.7s: um we have to define a distribution of\n634.56s: the samples which we don't want to do\n635.94s: and secondly\n637.8s: um\n638.519s: these entropies for models that are\n641.1s: interesting enough is more tractable\n643.38s: you're going to complete attractively so\n646.2s: how can we find a way of defining\n649.62s: entropy that makes these things\n652.74s: that that gives us these things that we\n654.959s: want\n655.8s: so we looked at different forms of\n657.899s: entropies and got to Quantum statistical\n661.2s: mechanics which they Define\n664.079s: one broad uh entropy that uses\n667.88s: entropy the one who went entropy no\n671.88s: Quantum mechanism or any of that is just\n675.06s: the traits of some Matrix K turns\n678.54s: location where K is called identity\n681.6s: Matrix and it's used to describe the\n684.06s: quantum system so this was great for us\n686.579s: because we're like okay this is using a\n688.14s: matrix it's not using a probative\n690.0s: distribution so maybe we are on to\n692.339s: something let's try to see how you can\n694.019s: leverage this to Define A diversity\n696.06s: Matrix a scanner that doesn't have a\n697.68s: reference or anything like that\n699.24s: if we look at k\n701.64s: and think of K as a similarity Matrix\n704.279s: use K as a similar kinetics and it's\n706.98s: density Matrix saying it let's let's\n709.079s: take the similarity Matrix as playing\n711.12s: the role of the density Matrix and using\n714.0s: it as a way to describe the system here\n715.92s: is a set of samples then we actually get\n718.56s: to what we want we can Define them\n722.48s: diversity as the exponential of the\n725.399s: volume and entropy that would be that\n727.86s: would be something called one diversity\n729.959s: if you think with the way ecologists\n732.6s: call diversity so it's V and B that's\n734.88s: that's how the vending name came this is\n736.92s: one human diversity\n738.959s: um so we got to the venues for that way\n741.0s: it it's defined formally like this let's\n743.7s: assume you're given a collection of\n745.019s: observation X1 x n\n747.48s: um and you assume that you are given a\n750.24s: similarity function in the form of a\n752.1s: kernel that we assume is positive some\n754.26s: Independence such that the the the\n757.279s: similarity between X and itself is one\n759.839s: and the the kernel Matrix the kernel\n763.139s: similarity Matrix that results from\n764.88s: using this pairwise similarity function\n767.579s: is\n769.38s: k i j so the I and J is entry of the\n772.62s: Matrix is the similarity between x i and\n775.079s: XJ and so you call Lambda one or two\n778.139s: Lambda and the eigenvalues of the\n779.94s: normalized Matrix K so it's just a\n782.339s: divided by the number of uh elements in\n784.62s: the collection and the vendive core is\n786.6s: defined as the exponential\n788.76s: of the one Lumen entropy which you can\n791.82s: easily show is the exponential of the\n794.16s: channel entropy of the eigenvalue of K\n797.42s: and so\n799.2s: we have extended one entropy we're using\n803.16s: in light Matrix outside of the quantum\n805.56s: wall and we can use this vented core\n808.44s: also as a numeric in ecology because it\n811.32s: doesn't exist in ecology even though it\n813.72s: was inspired by ideal from ecology and\n816.72s: it's also what it's also a real number\n819.66s: of the things that they defined\n821.88s: um and so we got something that that we\n823.98s: said okay this looks reasonable let's\n825.6s: try to test it and see if italicize the\n828.18s: properties we want\n829.74s: we extend it to the probability weighted\n832.56s: version this is in the case where all\n834.66s: your samples aren't created the same\n836.22s: that there is a probability distribution\n837.6s: over them what you what gives changes in\n840.899s: the setup is that the Matrix similarity\n843.54s: Matrix now is defined by weighting it\n845.459s: with the probability assigned to each of\n847.2s: the observations we want to deal with\n849.24s: this case in in the presentation but\n851.519s: this is an extension of it\n854.22s: um\n854.82s: so what you get is that exponential of\n857.579s: entropy is the hill number is\n859.68s: interpretable is the effective number of\n861.36s: dissimilar elements in the collection so\n863.339s: if the similar if two elements in the\n866.22s: Collision are are different\n868.139s: so they have stimulated zero and the\n871.38s: vended score is Max\n873.24s: if all the elements\n875.519s: in the collection are dissimilar then\n877.92s: the vended core is maximized and equal\n879.66s: to n you can get that by just plugging\n883.26s: plugging um\n885.36s: the similarity Matrix will end up just\n887.519s: being identity with you know identity\n890.699s: and you plug in exponential minus 3 Q of\n893.76s: angle of K you will recover n\n897.42s: and if they're all the same do the same\n899.579s: you would get a vended code that's equal\n901.56s: to\n903.18s: and another thing that's nice here is\n904.92s: that this number is unchanged if you\n907.8s: duplicate\n909.959s: um certain elements of a category in the\n912.6s: collection meaning if I have\n916.1s: cats dogs elephants\n919.019s: in my similarity is just in terms of\n921.959s: what type of animal I have then if I add\n924.6s: more cats or more dogs or more then I\n926.699s: still have three other diversity metric\n930.36s: um so this is what this is showing do\n932.579s: two properties that\n934.86s: as I eat as I add more more different\n939.12s: items more categories into my collection\n941.639s: the vended core increases\n946.019s: and that even if I duplicate certain\n948.06s: elements of the same category it still\n950.459s: remains that number\n952.079s: so it's illustrating those two\n953.639s: properties\n954.66s: another property that I didn't talk\n956.82s: about before is that\n958.92s: with the vertical you can compose two\n961.139s: different similarities Notions of\n963.66s: similarity so for example if you're a\n965.339s: chemist and you want to adaptable\n966.839s: structural similarity and chemical\n970.079s: um diversity and chemical diversity you\n972.6s: can compose the two kernels and be able\n974.76s: to capture that here we did this in the\n976.44s: toy settings where we had one similarity\n978.899s: that was thoroughly focused on on shape\n981.54s: so you see that here there are three\n983.399s: shapes the vendor score will return\n985.38s: three in the second case there are three\n988.56s: colors so the wind call would return\n990.54s: three in the third case we are composing\n993.6s: both color and shape so it's reflected\n996.0s: in the vendor which is which has\n997.44s: increased now from three to four\n999.48s: this other metric called internal\n1001.699s: diversity is the metric that was being\n1005.06s: used in ml to measure diversity if\n1007.22s: defined as the internal diversity of the\n1010.04s: collection X1 up to X N is one minus 1\n1012.92s: over N squared some i j of the is\n1016.16s: basically one minus the weighted average\n1018.38s: of the similarities of the sample it\n1021.079s: turns out that that's actually not\n1022.699s: capturing some of these intuitive data\n1025.04s: that we would want out of a diversity\n1027.14s: metric for example here the internal\n1029.78s: diversity of this collection in this\n1032.0s: setup Remains the Same despite all these\n1035.059s: changes despite the fact that it's\n1037.579s: normal that we get the same diversity\n1039.38s: here because it actually just\n1042.02s: changing from one similarity to the\n1044.36s: other one was we had three different\n1046.22s: shapes so diversity three the other one\n1048.439s: was three different colors of\n1049.76s: diverticity but when you combine those\n1052.04s: internal diversity isn't able to reflect\n1054.2s: that because we just averaging\n1055.76s: similarities\n1057.14s: um\n1058.4s: we will see all the\n1064.16s: we will see all the failure more of that\n1066.02s: of that diversity that that being used\n1068.179s: in in so many settings one of them being\n1070.88s: in doing generative modeling of\n1072.5s: molecules where you actually do care\n1074.78s: really about capturing diversity well\n1077.12s: it's being used there and it's not\n1078.86s: capturing some of those things that you\n1080.9s: want\n1082.1s: um\n1082.76s: another property is that\n1085.7s: if you have a collection of collections\n1088.88s: the Wendy score of the aggregated\n1091.4s: collection only depends on the in the\n1094.039s: individual diversities of this\n1095.419s: collection and their propensity so\n1097.82s: that's what this property is saying it's\n1099.32s: just the geometric mean of these of the\n1102.5s: vending scores of these of these\n1104.419s: different of these different collections\n1108.1s: this was another simulation just trying\n1111.02s: to understand that this metric is really\n1113.12s: doing something sensible so we simulated\n1115.82s: a mixture of gaussians and we try to con\n1118.82s: to control\n1120.62s: three different things that would affect\n1122.84s: intuitive diversity of that probability\n1125.299s: distribution so one was number of mixed\n1127.76s: two components as you grow the number of\n1129.98s: mixture components in your mix of the\n1131.72s: essence the diversity should grow so\n1134.299s: this is being reflected involved of ND\n1136.4s: score and the internal diversity the\n1138.98s: second thing you can control in terms of\n1140.48s: diversity for a mixture of glasses is\n1142.16s: the mixture of proportions\n1143.72s: as you\n1145.28s: make the mixture mixture proportion more\n1148.16s: uniform the diversity should grow which\n1151.16s: is reflected involved when they find the\n1153.02s: internal diversity a third thing you can\n1155.419s: control is the per component variance so\n1158.539s: if you increase the poor component\n1160.28s: variance of your mixture of the actions\n1162.14s: the the diversity should also increase\n1164.539s: this was reflected in the vending score\n1167.539s: but the internal diversity had the same\n1170.6s: diversity score for all uh all those\n1174.14s: settings which is also another failure\n1176.179s: mode that we wanted to illustrate\n1179.96s: this is a trivial property which is that\n1182.96s: it referred mutant The Collection the\n1185.78s: the the order of the collection it\n1188.419s: doesn't change internal diversity also\n1191.96s: I believe and they are more proper\n1195.02s: paper that I I recommend looking into\n1198.919s: um so okay now that we are comfortable\n1201.98s: with it capturing certain desirable\n1205.58s: features of property and we're hoping\n1207.799s: that we will be using it we need to\n1209.419s: listen to the computation part of things\n1211.22s: in terms of computational time\n1213.38s: complicity and convergence rates in\n1215.84s: terms of time comparative or NQ 01\n1219.14s: because you need to compute similarity\n1221.9s: of Civil Right similarity of the\n1223.82s: collection but that's o n Square what o\n1226.52s: and Q is Computing the eigen values\n1228.679s: that's what I think of n cube in terms\n1231.14s: of evaluation if you think you are in a\n1233.36s: reasonable setting where you don't have\n1234.559s: a gigantic set of a gigantic collection\n1237.5s: this is fine\n1239.36s: which were our settings in the\n1241.1s: experiment but if you are in a situation\n1243.38s: where you have millions and millions in\n1245.9s: your collection becomes unfeasible to do\n1248.96s: this so there's that time requirement\n1251.2s: one thing though is that if you\n1254.419s: Define your similarity as a DOT product\n1256.94s: then you can you can\n1259.46s: dial it down to all of b square and\n1261.799s: where D is the the dimension of your\n1264.32s: features\n1265.34s: the some of the a lot of the experiments\n1267.44s: we tried we were in that setting but\n1269.96s: some of them we were not you know\n1272.0s: setting will Define the similarity as a\n1274.52s: DOT product for example in gram\n1276.86s: similarity which we use for some of the\n1279.38s: text experiments people don't do that so\n1281.299s: we would be in the old setting\n1284.96s: um the convergence rate is good it's 1\n1287.36s: over root n\n1289.039s: um you can you can you can read this in\n1291.32s: the papers or in the version two of the\n1293.12s: paper we would update it there\n1295.52s: um complete\n1301.22s: it's connected to determinant to a point\n1303.799s: processes in machine learning if you\n1305.659s: talk about diversity this is something\n1307.52s: good that people would automatically\n1309.02s: think about\n1310.1s: because there's a minute to a point of\n1312.02s: Point processes are stochastic processes\n1314.48s: that have been used to model diversity\n1316.28s: in different models or for example for\n1318.44s: subset selection but it's different from\n1321.679s: when the score in the sense that ah even\n1324.2s: though they're both parameterized by\n1325.58s: kernel in DPT you use the determinant of\n1329.419s: the similarity Matrix as a way to define\n1331.52s: the likelihood of the sample of\n1333.62s: selecting a subset whereas\n1337.52s: this is actually zero when you add one\n1340.52s: duplicate\n1341.72s: or when when you when you add duplicate\n1344.0s: the value score would still give you the\n1346.28s: same number meaning it will if it's the\n1349.46s: same like we said before it is the theme\n1351.679s: observation from one category that\n1353.96s: already exists the the diversity is\n1356.179s: unchanged naturally for the DPP will\n1358.46s: return zero as soon as you have a\n1359.9s: duplicate which is not good it's not\n1361.82s: something that that we would want if we\n1363.74s: were to use it to measure diversity so\n1366.799s: that's the difference another difference\n1368.0s: is in the interpretation part for\n1370.82s: determinator Point process there's a\n1372.74s: geometric interpretation interpretation\n1374.6s: of it is a determinant so you can think\n1376.64s: of it as a volume whereas for the value\n1379.22s: score we thought of it as an effective\n1381.2s: number which is\n1382.76s: more directly interpretable than volume\n1385.34s: when it comes to diversity\n1389.96s: um the caveat in in addition to time\n1393.14s: complexity is that you cannot use it to\n1395.12s: measure quality of samples\n1397.22s: that's naturally what it was not built\n1399.62s: for it was built purely to measure\n1401.9s: diversity\n1403.039s: and that's something to keep in mind\n1404.48s: because if I give you a completely\n1408.32s: random\n1409.46s: only is completely random random set of\n1412.1s: image of this noise would have a higher\n1415.039s: diversity than if it actually you know\n1417.919s: things that are have the high quality so\n1420.74s: this is not to be used to expect to\n1422.96s: measure sample part you would have to\n1424.94s: pair it with a metric of sample quality\n1427.28s: if you're in computer vision you can\n1429.08s: pair this with Inception score the\n1431.36s: Inception core will will give you\n1433.22s: quality perceptual quality tells you how\n1436.34s: good the image looks whereas the\n1438.559s: venditure will tell you how diverse the\n1440.6s: samples you're giving up those are\n1442.76s: different things\n1443.96s: but worth keeping in mind\n1446.84s: another thing is that it depends on the\n1449.24s: Kernel\n1450.5s: so your kernel isn't sensitive\n1453.62s: you wouldn't get good scores if your\n1457.159s: corner is way too sensitive everything\n1459.5s: becomes picked up as a different sample\n1461.6s: so you would also get meaningless goals\n1464.059s: so it's really important to to to get\n1466.7s: the right the right turn\n1468.559s: if you are in a domain your your domain\n1471.14s: expert or something people typically\n1472.94s: know how to measure similarity for\n1475.34s: example in\n1476.48s: in chemistry they have this thing called\n1478.159s: tanimoto similarity that works on a lot\n1481.94s: of settings so if you're in a domain\n1484.22s: where you have something like that that\n1486.08s: actually is known to be sensitive to\n1488.72s: what it should be sensitive to then you\n1490.039s: should be fine but\n1492.14s: keep in mind that if the the kernel\n1494.48s: isn't isn't just sensitive as it should\n1497.48s: then you may get you know unintuitive\n1499.4s: results one thing to illustrate that\n1501.38s: here is looking at colored mnists\n1504.44s: basically you just color some of the\n1506.78s: digits of at least here we try to\n1509.299s: reflect diversity in the coloring so\n1512.419s: here there's one color\n1514.46s: so that's five two colors that's the six\n1517.58s: and then three colors and then four\n1519.98s: colors so normally if we have a kernel\n1522.98s: that works\n1524.24s: that works just fine we would see an\n1526.279s: increased diversity as we move from five\n1529.22s: six seven to eight which is the case for\n1531.5s: that Colonel but for this kernel that\n1533.779s: use Inception force on these images\n1536.9s: you you get an intuitive results meaning\n1539.779s: that here five is assigned more\n1542.299s: diversity than six for example which is\n1544.88s: not the case\n1546.679s: it's just to illustrate that you know\n1548.419s: it's important to get the kernel\n1550.58s: behaving reasonably so one solution that\n1553.7s: we're exploring is actually building\n1556.22s: so that we don't we don't uh\n1558.679s: so that we're hoping that the data\n1560.419s: itself informs the right email ID\n1562.88s: measure we're looking into that right\n1564.86s: now\n1566.96s: so I'll show a bunch of results\n1569.179s: in terms of applying this in different\n1571.64s: domains for a lot of these what we just\n1574.7s: chose was for the images it was\n1576.74s: inceptions for\n1578.419s: um Inception embeddings so there's this\n1581.299s: I3 uh big neural network that people use\n1584.179s: to get image embedding we just use those\n1586.58s: they're from the I3 network\n1589.659s: of the big models so we use that\n1592.46s: whenever we're dealing with images for\n1594.38s: molecules we use tanimoto\n1598.1s: tiny motor similarity for\n1602.12s: for the text ones we use engram\n1604.76s: so different different kernel similarity\n1607.64s: depending on the domain you are in here\n1609.679s: what I'm showing are results on\n1612.26s: molecular generative models this is a\n1614.539s: this is a setup where diversity is\n1616.22s: really key so we want to have a metric\n1618.559s: that can inform us of the diversity of\n1620.779s: our generative model there's a benchmark\n1623.059s: of molecular derivative models in that\n1625.64s: Benchmark there are different type of\n1627.86s: models one was the hme model another one\n1630.62s: was an adversary Auto encoder and then\n1632.779s: in the third column there I'm showing\n1634.46s: the actual view data set\n1636.679s: what we're showing here is the coder\n1638.84s: Matrix of we took 250 molecules and\n1641.48s: looked at the the the kernel and you can\n1643.82s: see the duplicate in the in the colors\n1646.279s: so the more yellow indicates that there\n1649.88s: are duplicates that spread that are\n1651.919s: present in the real data set that tells\n1655.279s: us what we should be targeting so you\n1657.559s: can see that this this model for example\n1659.779s: this daily model have way more\n1661.76s: duplicates than the real data set but\n1664.159s: that the real data that has more\n1665.659s: duplicates than this versus your auto\n1667.7s: encoder model so we're trying to see the\n1670.1s: the diversity for fix of that so the\n1673.1s: vending score is assigning lowest\n1675.799s: diversity to this one as it should be\n1678.279s: the next less diverse one is the real\n1681.26s: data set as it should be and then this\n1683.6s: this model is assigned the biggest\n1685.46s: diversity as it should be for internal\n1687.74s: diversity you get a you get an\n1689.84s: unintuitive result meaning that it\n1692.72s: assigns biggest diversity to this one\n1695.9s: that has duplicates this because you\n1697.82s: averaging related so it assigns biggest\n1700.039s: diversity list which should be the worst\n1702.32s: and it assigned the neck that one is\n1704.659s: this one fine and then the the real data\n1707.059s: set so\n1709.46s: this was a domain where this score is\n1712.1s: being used and it's returning wrong\n1714.14s: results and people didn't know about\n1715.94s: them\n1716.84s: I think the difference is that we\n1718.52s: actually looked at a field the\n1720.98s: scientific field that studies these\n1723.26s: things well and actually you know looked\n1725.6s: at their mind instead of just applying\n1728.84s: things out of the blue\n1732.26s: so this is the these are results on\n1735.14s: creative models of images so we have\n1737.36s: digital images we wanted to see how\n1739.76s: actually diverts are they and also\n1741.46s: Computing the diversity of the data sets\n1744.14s: for those genetic models because now we\n1745.64s: can do that we don't need a reference so\n1747.62s: you can just take any data set trained\n1750.08s: for on which this generative models have\n1752.48s: been trained on and and get an actual\n1754.46s: ground proof on the diversity\n1756.86s: so we did that for different families or\n1758.72s: models and different data sets we use\n1761.0s: people 10 image net elephant cat Elson\n1763.94s: bedroom build Adventure Mark data test\n1765.5s: Envision\n1766.94s: um so for each one we have\n1769.22s: reported the vended score of the data\n1771.5s: set using that as a Target to see how\n1773.779s: diverse the genetic models are the\n1776.6s: result is that they're all less diverse\n1779.179s: than their original data set\n1782.36s: generally or leftovers and original data\n1785.659s: so they were trained on but that\n1787.64s: depending on the model family on the\n1789.62s: data set something to be more different\n1791.48s: than one there's no clear-cut definition\n1799.94s: also diffusion models tend to do well if\n1802.76s: you look at iddtm here\n1806.179s: one row goes for both tables vertically\n1814.34s: one thing where we wanted to evaluate\n1816.74s: the metric on is what's called more\n1818.419s: collapse which is a problem that\n1820.1s: generative adversary networks run into\n1822.02s: these are used in in weather prediction\n1825.08s: like deepmind has this now cutting a\n1827.779s: paper where they were predicting the\n1829.34s: next 90 minutes of rain and they use the\n1832.94s: gun for that guns are known to collapse\n1835.76s: meaning that they would just tend to\n1837.5s: return from the same mode instead of\n1839.24s: returning a different set of things and\n1841.1s: the way people used to measure that that\n1843.679s: failure board is to use a cold number of\n1846.62s: moles no M the number of modes to find\n1849.799s: it to compute it as a metric you would\n1851.899s: have to run you would have to pick uh\n1855.799s: labeled data you have to label data you\n1858.98s: fit a classifier on the training data\n1861.44s: and you try to predict the classes of\n1864.5s: any new image that you that you that you\n1867.14s: give it as input for example images from\n1869.24s: the gun and it will try to predict the\n1871.399s: label for that image\n1873.26s: and you count the number of more at the\n1875.659s: at the number of unique labels predicted\n1878.179s: by the classifier the hope is that the\n1881.24s: more modes more different modes they\n1883.22s: classify predicts the more diverse the\n1885.38s: gadgets the problem with that is that\n1887.6s: first of all you need to train a\n1889.039s: classifier when you're doing evaluation\n1891.14s: when you're doing evaluation second one\n1893.539s: is that because you need to train a\n1894.86s: classifier you need label the data those\n1897.02s: are all limitations and third of all the\n1899.96s: classifier doesn't need to be good it\n1902.48s: can just predict random labels and you\n1904.46s: say this gun is\n1906.32s: this God is is divorced when it is not\n1908.899s: so you also rely not only on a\n1911.0s: classifier but a really good plan right\n1912.799s: so those are three limitations which\n1915.5s: means that if you could find a way of\n1917.84s: evaluating more collapse without\n1919.76s: requiring to train a classifier without\n1921.86s: requiring a labeled data set then it\n1924.44s: would allow us effectively you know\n1926.5s: evaluate this this\n1930.799s: and we are able to do that with the\n1932.659s: event before\n1933.799s: that's why I'll see it on the domain\n1936.02s: um it's telling us here that\n1939.14s: the number of modes for these two guns\n1942.14s: that are supposed to not collapse number\n1945.2s: of motivating they evolve capturing all\n1947.24s: the modes the total number of more is\n1949.279s: one thousand on this data set the number\n1951.38s: of moles metric is telling us that these\n1953.24s: guns are all covering all the modes so\n1955.82s: we would conclude that they are\n1956.96s: different but the value core is telling\n1959.179s: us that they're actually less diverse\n1960.919s: even though number of moles is 1000\n1963.679s: touches they're actually less diverse\n1965.659s: than than the original data set which\n1968.419s: means that we have found something that\n1969.74s: more sensitive to the to the nuances of\n1972.5s: the prediction\n1974.539s: um\n1975.559s: this is just another data set in Vision\n1978.32s: where we were also doing some data set\n1980.24s: and as we're looking at uh looking at\n1982.52s: what these data sets look like in terms\n1984.5s: of diversity the reason why I found this\n1986.72s: one interesting is because Celebi is\n1989.419s: also an important Benchmark Envision the\n1992.36s: important Benchmark data set and the\n1994.399s: will report told us that um\n1997.159s: the labels in these data sets that are\n1999.62s: associated with men you would find more\n2001.779s: diverse examples than the labels that\n2004.48s: are associated with women which also you\n2007.24s: know now we have indication that maybe\n2009.039s: they are biases in this data set that we\n2011.679s: were not able to detect it before that\n2013.659s: we can detect now in an unsupervised way\n2015.82s: and maybe we can you know rework the\n2017.919s: data set so that it's less biased\n2021.64s: um some people recently used the vendit\n2024.58s: core to do more balancing in generative\n2027.519s: models I found it insightful because I\n2029.86s: used to think only of these two\n2032.019s: in terms of distribution and genetic\n2033.76s: modeling I used to think of more collab\n2035.98s: meaning that we have the blue Target\n2037.779s: distribution\n2040.059s: that's the two data distribution and you\n2042.039s: want to build the generative model that\n2044.62s: recovers the Curve\n2046.659s: so that would be more coverage would be\n2048.94s: our goal but typically\n2051.48s: reality models even the state-of-the-art\n2054.52s: ones like dependent models they do make\n2056.919s: some of the most guns are the worst ones\n2059.08s: but some of the other ones also need\n2061.179s: more some of these modes that would be\n2063.339s: called more collapse it is one case of\n2065.379s: multiple app but actually when it comes\n2067.54s: to diversity\n2069.099s: and I if I got it only after reading\n2071.619s: this paper that we want more balance\n2074.08s: we don't actually want to\n2076.48s: if you're doing generator modeling and\n2078.099s: even samples divert sets you actually\n2080.2s: want to sample all the potential modes\n2083.32s: with equal weights\n2085.0s: so that if I have let's say my data set\n2087.399s: in the data set of faces like Saturday\n2089.879s: and there are people with darker\n2092.56s: complexions That You observe maybe just\n2094.24s: three people out of the one million\n2096.0s: observation then if you build a genetic\n2099.88s: model that would recover the curve you\n2102.7s: don't have diversity you still have the\n2105.04s: buyer whereas if you do more balancing\n2107.92s: then you know it operates the the\n2111.099s: observations in the data set that are\n2113.02s: less prevalent\n2114.52s: so this was very very insightful and\n2116.619s: they found a way\n2118.0s: they use the poverty wages when they\n2120.52s: score in order to do that for a set of\n2122.38s: samples\n2123.78s: so let's go to another way of enforcing\n2126.82s: diversity in our utility models making\n2128.74s: them more diverse but this one is a\n2131.14s: different domain it's in the simulation\n2133.72s: molecular stimulation\n2138.22s: okay\n2140.98s: so there's this thing called molecular\n2142.72s: simulation the setting there is that we\n2145.18s: want to be able\n2147.46s: to estimate the physical quantities from\n2150.099s: from properties of molecules and those\n2152.859s: properties relate to how a molecule\n2156.22s: transitions from one conformation to the\n2158.56s: next\n2160.119s: um and so\n2161.98s: what we what we do typically in order to\n2164.92s: evaluate those properties we run\n2166.54s: molecular Dynamics\n2167.98s: simulations but what happens is that\n2171.22s: here I'm showing one molecule that has\n2173.14s: two conformations to switch from that\n2175.54s: conformation to this conformation you\n2177.64s: have to jump through this huge energetic\n2179.44s: behavior and that prevents them from\n2182.079s: jumping typically they get stuck in one\n2184.119s: so you won't be able to compute good\n2186.28s: properties and so how do we leverage the\n2190.119s: vending scoring or that you jump this\n2192.22s: energy things and it is very very that's\n2194.8s: what we will do\n2204.82s: so to give a little bit more context we\n2207.82s: are dealing with a molecular system and\n2210.579s: the assumption is that um\n2214.96s: the the molecule is described as a set\n2218.32s: of atoms in 3D so you call it X and it\n2221.74s: leaves it's an entity that lives in r3n\n2224.92s: um and it's distributed at equilibrium\n2227.44s: as a boltzmann distribution the bozemann\n2231.64s: distribution is just proportional to the\n2233.74s: exponential of minus the energy\n2236.4s: multiplied by some temperature term\n2239.52s: controlling the temperature of the\n2241.78s: system\n2242.68s: and so the goal will be\n2245.56s: to sample from this distribution and\n2248.2s: you're hoping to get a diverted examples\n2250.119s: so you get different confirmations of\n2252.46s: the molecule\n2253.9s: um typically people use land event\n2255.82s: Dynamics\n2257.8s: um with replica sampling so you sample\n2260.14s: multiple times\n2262.0s: and you assume that those are\n2265.24s: independently drawn copies of the same\n2268.359s: molecule and they follow this joint\n2271.18s: distribution that is the product of the\n2273.22s: individual distribution these individual\n2275.56s: distributions they can all follow the\n2277.42s: same temperature or sometimes you choose\n2279.52s: different temperatures so that you can\n2281.079s: you know observe you have a greater\n2283.06s: chance of observing different\n2285.04s: confirmations the four parallel\n2286.54s: tempering and what they do is just one\n2288.52s: molecular\n2289.48s: run London and Dynamics so what we will\n2292.359s: do here\n2293.44s: is instead of just sampling them\n2295.24s: independently we sample them from a\n2298.18s: coupled distribution\n2300.28s: meaning that we would multiply The Joint\n2302.74s: distribution with the Wendy score of the\n2304.96s: sample of the different replicas and the\n2308.44s: energy that corresponds to this Ensemble\n2310.599s: would be just the log of it basically so\n2312.94s: you would have some the sum of the\n2315.579s: individual energy terms you you are of x\n2319.42s: i so those individual terms but then you\n2322.0s: have the the log bended quarter which is\n2324.64s: remember the eigenvalues of the\n2326.5s: similarity Matrix induced by the samples\n2330.22s: um so that's the Lambda log Lambda I and\n2332.56s: then given this energy each\n2335.98s: of the replica each of the sampled\n2338.859s: molecules follows they evolve over time\n2341.98s: according to this stochastic\n2343.96s: differential equation so d x i for the I\n2346.96s: element in the collection the x i p over\n2349.839s: DT is negative gradient of the energy\n2353.26s: divided x i so this is the force\n2356.44s: basically the gradient of energy and\n2358.9s: then there's the the gradient that's\n2361.0s: coming out of the vending term we call\n2364.0s: it the vanity Force\n2366.099s: um it divided by some term gamma and\n2367.9s: then you add the drift term which is\n2369.579s: given by a window process so the vending\n2372.94s: Force here is just the negative the\n2375.52s: negative derivative of the log band is\n2377.44s: four\n2378.339s: if you get rid of it you would evoke\n2381.64s: these samples individually if you add it\n2384.82s: you're telling them\n2386.859s: don't hear this repulsion between the\n2390.099s: different\n2391.06s: configurations right imagine a particle\n2393.88s: evolving over some space from landscape\n2396.96s: this second term the vanity force is\n2400.359s: some repulsion force that that basically\n2402.64s: forces them to not be identical and that\n2405.64s: will allow us to also converge faster\n2408.76s: so here what you're seeing\n2411.16s: is a\n2414.42s: setting this is called The Print\n2416.5s: potential it has four basins so this is\n2419.44s: basically think of it if your problems\n2421.3s: and you could think of it as just a\n2422.92s: project description in four picks\n2424.66s: businesses will think of it as an energy\n2426.64s: with four basins equivalent in the same\n2429.339s: you see the replica sampling method\n2431.619s: which is what people typically a lot of\n2433.78s: people use in molecular Dynamics it gets\n2436.18s: stuck it cannot cross this other energy\n2438.64s: boundary in order to cover all the modes\n2441.28s: wherefore if you're using the algorithm\n2443.56s: doesn't cause any sampling that adds a\n2445.42s: preposition Force you actually do get\n2447.82s: and it does that quickly\n2449.74s: quickly it explores these all these four\n2452.079s: modes whereas for replica sampling for a\n2455.26s: number of steps going up to\n2457.3s: how much\n2460.24s: more than\n2462.579s: it's still not getting there\n2471.46s: close to three thousand\n2474.88s: twenty five hundred yes and a long time\n2477.7s: in the hospital not covered all the\n2479.98s: older mods\n2481.839s: um\n2482.68s: these are more these are more results on\n2486.46s: more real molecular system alanine\n2489.099s: dipeptide that's a that's a baseline in\n2491.56s: biology that people study when they're\n2493.9s: looking when they're looking at these\n2495.28s: sampling techniques\n2497.02s: um this is the ground truth we are\n2498.76s: trying to recover this is a 2d map 2D\n2501.28s: heat map of the different you know\n2503.26s: different angles torsion angles of this\n2505.54s: molecular system so basically this\n2508.359s: system just flips between two\n2510.64s: conformations depending\n2512.8s: on these angles and this is the ground\n2514.599s: proof we're trying to recover the the\n2517.18s: free energy surface and we got this by\n2519.64s: running the simulation for a very long\n2522.16s: time because when you when you run long\n2524.02s: driven Dynamics for a very long time it\n2526.359s: does converge it's the problem is just\n2528.4s: that people don't have that long of a\n2530.2s: time so they want things something that\n2532.18s: runs faster and that was the goal here\n2533.8s: but this is ground proof you can see\n2536.32s: that the vending sampler gets to that\n2539.26s: ground proof for T equals even one\n2542.26s: nanosecond we already recover all the\n2544.66s: modes whereas for replica sampling we do\n2547.18s: have to wait until 10 nanoseconds to be\n2549.46s: able to start observing the the the the\n2551.68s: final mode ah nanoseconds is a long time\n2555.339s: scale for these simulations actually\n2557.92s: um\n2558.94s: so this is just the free energy another\n2561.64s: um another observable that people\n2563.74s: usually are interested in the free\n2565.78s: energy difference\n2567.579s: um because\n2569.74s: um\n2570.82s: yeah it tells you something about the\n2572.619s: the system and so here the idea would be\n2575.32s: that you recover the ground through free\n2577.3s: energy difference over a reduced amount\n2580.18s: of time and you get that with the Wendy\n2582.579s: sampler with the Wendy sampler compared\n2584.44s: to the uh replica sampler that takes\n2587.56s: longer to recover the ground proof which\n2589.359s: is this dashed line\n2591.96s: this is showing how it's doing that this\n2595.0s: figure is showing that\n2598.06s: the value sampler quickly\n2601.18s: managed to jump the energy barrier so\n2603.819s: it's doing that transition the number of\n2605.98s: transitions for the first few\n2607.599s: nanoseconds you see how the vending\n2610.0s: sampler already has done a lot of the\n2613.06s: transitions between the different\n2614.2s: configurations whereas that's not the\n2616.599s: case for the replica sampler when you\n2618.7s: extend now the amount of time because\n2621.7s: the replica sample will now start having\n2623.44s: this transition but by that time the\n2625.78s: wind Temple has already converged so\n2628.42s: that's the that's what this figure is\n2630.4s: informing as well this is a third a\n2633.46s: second system real molecule system\n2635.68s: that's called crno25 is a bit more\n2638.44s: challenging than Alana and I bet died\n2640.18s: and we're observing the same gains in\n2642.28s: terms of convergence speed\n2646.54s: so these two things that I discussed\n2649.06s: today the references are these two\n2651.16s: papers the first one is the vendor core\n2653.8s: diversity evaluation metric for machine\n2655.66s: learning that I worked on with an\n2657.4s: amazing CA student at Princeton Dan\n2659.56s: Pittman and the second one is then the\n2662.319s: sampling for molecular stimulations\n2664.02s: diversity as a force for faster\n2666.22s: convergence and better exploration that\n2668.859s: I worked on with two amazing students\n2672.359s: and a great collaborate of mine Simon\n2675.16s: Olsen and these are both on the review I\n2678.28s: would be excited to explore you know\n2681.46s: beyond this even how we can work on\n2683.98s: solving climate related things thank you\n2692.46s: thanks so much thank you uh any\n2695.14s: questions really starting with the early\n2696.46s: various scientists in the room\n2701.02s: has to make and maybe if someone then if\n2704.02s: you you're like monitoring just uh the\n2706.54s: message online\n2708.88s: I think it was a great presentation\n2710.5s: thank you so uh I was wondering what the\n2712.9s: implication of having in metric uh\n2715.0s: that's miserable like the Bendy uh score\n2717.52s: yeah uh is uh in terms of trading\n2720.52s: machine learning large machine learning\n2721.9s: models yes so uh does it help us during\n2725.8s: the data selection phase\n2729.599s: or I can reintegrate such a score into\n2732.579s: the loss function says that we don't\n2733.96s: have to sort of do that's you know I\n2737.38s: mean I'm trying to sort of stress this\n2739.96s: to like Active Learning yeah but then\n2742.96s: can we just interviewed into the last\n2744.88s: option somehow so that we don't need to\n2746.619s: like human selection is always\n2750.0s: and what I mean yeah so yeah yeah we're\n2754.42s: working on those things we're leveraging\n2756.22s: it right now on many projects\n2759.7s: um but what you said is that one thing\n2761.68s: that that it seemed very in these are\n2764.14s: very different domains for example if\n2765.76s: you have low result if you are in a low\n2768.22s: result study and you want to train your\n2771.46s: model uh and get good enough performance\n2774.22s: typically what people do is they're\n2776.26s: looking this thing called it is a\n2778.0s: distillation you want to get a a smaller\n2782.079s: version of your data set and you want to\n2784.42s: be able to train a model say a\n2786.099s: classifier and get a performance that's\n2789.339s: reasonable compared to if you train on\n2791.56s: the whole data set of course training on\n2793.54s: the whole data set will always yield\n2794.92s: better performance but you're hoping\n2796.96s: that you've selected the subset of the\n2799.42s: data such that you get a reasonable\n2801.64s: performance compared to easy train to\n2803.5s: the full moon so that's an important\n2805.42s: setup for low resource settings you can\n2808.119s: imagine using the venditure to do that\n2810.099s: selection\n2811.0s: so that you get you know a diverse more\n2813.76s: in a sample that you're hoping that\n2815.38s: captures the essence of the full data\n2818.2s: set and and Achieve that so that's one\n2821.26s: like the training larger the the data\n2824.26s: set part but in terms of model\n2826.56s: algorithms everywhere here\n2829.24s: yeah\n2830.619s: Monte Carlo\n2832.54s: um active third Genie modeling all of\n2834.819s: these are are very relevant in a lot of\n2837.04s: uh in a lot of machine learning\n2840.7s: machine learning related machine\n2843.099s: learning machine learning for science\n2844.42s: the event is sampling actually isn't\n2847.06s: machine learning at all it's it's\n2848.56s: chemistry chemical physics because\n2850.54s: there's no data in there it's good\n2852.099s: simulation yeah so if to just to say\n2855.16s: that you know\n2861.41s: [Music]\n2867.579s: I was curious about the like some of the\n2870.16s: examples of your show whether it was\n2871.24s: shapes and color and things like that\n2872.92s: after it's how you can wait like which\n2874.359s: one is maybe more important to the\n2876.28s: diversity score you know oh\n2880.72s: um this one\n2882.339s: uh this one yeah\n2884.38s: yeah so here what we did was just say if\n2887.02s: it's the same shape for here for here it\n2890.26s: is the same shape\n2891.76s: okay is one otherwise zero so wherever\n2894.64s: you see yellow is one otherwise it's\n2896.2s: that black zero for me it is the same\n2899.319s: color is one it is not the same it's a\n2901.78s: different type zero for there we said\n2903.76s: one half if it's one or the other that's\n2906.04s: where you're seeing red that's one half\n2908.079s: yellow is there the same shape and the\n2910.72s: same color and zero otherwise\n2913.24s: so I guess depending on how you define\n2916.06s: the code or you can import you can\n2917.859s: enforce that you can enforce what you\n2920.319s: weigh or what you're doing that's where\n2921.76s: the domain knowledge comes in if it's a\n2924.099s: double-edged sword in that you do want\n2926.68s: to have the you want to let the user\n2929.02s: have an a say in terms of what diversity\n2932.26s: they want to capture so whether they\n2934.42s: care more about structural diversity or\n2936.339s: chemical diversity vice versa if they\n2939.22s: care more about the color of the images\n2940.839s: or the actual content of the image you\n2944.319s: know the user has a say on that but the\n2946.48s: bad side of that is that you are asking\n2948.7s: the user for that\n2950.859s: so some users may want to be able to may\n2954.76s: want to spit by that other maybe like I\n2956.5s: don't care I just want to get something\n2958.42s: so you that's the kernel part it's the\n2961.599s: thing that still bothers me a little bit\n2963.28s: I think learning it will will lift that\n2965.74s: off\n2974.26s: yeah\n2975.94s: you could almost think of an end as\n2978.339s: a yeah\n2991.3s: yeah yeah\n2993.099s: or maybe some mix of the two where you\n2995.44s: get input but also combining with the\n2997.54s: Learned part I'm not sure and compose\n2999.76s: the two oh no yeah\n3003.96s: any other questions\n3012.38s: very interesting too by the way thank\n3014.88s: you um I was wondering like what if you\n3016.74s: have like um a really fat like very\n3019.74s: extreme events and then you know\n3021.24s: something let's say I'm thinking just\n3022.8s: like prices temperature historical and\n3025.02s: you might be Valiant or something\n3026.339s: especially the tail of the district yes\n3028.5s: would that affect your metric and your\n3030.96s: diversity metric so the vending score is\n3035.04s: um remember the beginning when I\n3037.02s: mentioned Hill numbers where was this\n3041.339s: where was I here yes so when if you want\n3045.0s: to cut give more\n3047.22s: if you want to give more weight to rare\n3049.74s: samples so you don't mean we are rare\n3051.78s: events are really important you would\n3054.42s: pick a different version of the Venice\n3056.28s: score that's not Q equals one Q equals\n3058.319s: one is the vending score would\n3059.94s: correspond to Advantage score with like\n3062.04s: the the similarity Matrix thing\n3064.559s: that construct but you would have to\n3066.72s: pick a q that's less than one in order\n3069.18s: to you know give more importance to to\n3072.18s: rare rare items if you want to give more\n3075.24s: important to common items you would pick\n3077.16s: Q equals infinity\n3078.54s: which is just one over one over Maximum\n3081.3s: of the eigen values\n3082.859s: yeah the the Q equals one is a nice\n3085.26s: trade of between that in those two\n3087.42s: extremes\n3089.22s: great thanks so much\n3095.0s: thank you\n3097.44s: foreign"
    },
    {
        "class": "YouTubeVideo",
        "title": "Machine Learning for Ocean &amp; Climate Modeling: advances, challenges &amp; outlook with Laure Zanna",
        "videoId": "3y00LhyACV4",
        "url": "https://www.youtube.com/watch?v=3y00LhyACV4",
        "publishedAt": "2022-09-23T13:44:40Z",
        "transcript": "5.299s: okay well thanks everyone for coming\n8.28s: today uh to our second uh iteration of\n12.66s: the lectures in private data science\n14.519s: here at Lee uh and today we're uh really\n18.119s: pleased to have the lead geoscience\n20.1s: director uh professor borzana as our\n22.619s: speaker uh Laura got her undergraduate\n25.92s: um degree at television University and\n27.779s: her master's at Weissman and then her\n29.64s: PhD at Harvard uh she was previously\n32.399s: professor at Oxford University and then\n34.86s: in 2019 she relocated here to the Big\n37.559s: Apple and is now professor at NYU\n40.2s: and she is going to tell us about\n42.6s: machine learning for ocean climate\n45.12s: modeling advances challenges and Outlook\n47.36s: and uh yeah thanks everyone for being\n49.86s: here again looking forward to talking\n55.079s: all right great uh Thanksgiving for the\n57.12s: info and thanks everybody for being here\n58.44s: online I see a lot of people online as\n60.36s: well which is great but it's also uh\n62.16s: kind of nice to have a a live audience\n64.08s: so I'm able to talk really it's it's\n67.619s: very much kind of you know geared toward\n69.54s: early career scientists so you know\n71.7s: student postdocs whether they come from\n73.74s: climate or machine learning so really\n75.96s: feel free to interrupt if you have\n77.64s: questions if I bring up joggins and\n80.04s: really the kind of the whole point of\n81.42s: the talk is to try to show you a little\n82.92s: bit not just the very simple picture of\n85.439s: oh everything works and machine learning\n86.939s: is going to solve everything and and\n88.5s: we're going to fix climate model but\n90.0s: I'll tell you a little bit about the\n91.2s: kind of some of the struggles uh that we\n93.36s: faced over the years by using machine\n94.86s: learning to try to improve region and\n97.079s: climate models and so I'll tell you as\n98.82s: well where I feel you know there are\n100.259s: some advances that we can make on both\n101.82s: sides and what I think many people can\n103.74s: contribute no matter what their\n105.6s: background is so as Galen mentioned so\n107.579s: I'm at NYU but I'm really a geoscience\n109.68s: director but I'm not really talking with\n111.24s: that hat on today I'm really kind of\n113.64s: talking about you know some of the the\n115.38s: work we've been doing in a project that\n116.939s: that many of us are part of with Pierre\n119.28s: and Ryan and many others on trying to\n121.439s: bring machine learning to improve uh\n123.72s: climate model especially kind of the\n125.46s: physics database so it's called M\n127.079s: squared line and that's really going to\n128.399s: be a lot of the word that I'm going to\n129.599s: discuss is going to come from you know\n131.459s: many collaboration in that in that\n133.14s: project and hold on because it's still\n135.3s: zoom up here so I need to hide all the\n137.16s: panels\n139.2s: yeah\n140.099s: okay so a little road map I'm gonna try\n142.44s: I'm gonna start a little bit of him\n143.64s: introduction again just you know with\n145.92s: telling you a little bit what climate\n147.78s: simulations are what model errors are\n150.0s: why do we care what do they matter and\n152.28s: talk a little bit about missing physics\n153.78s: which is what we're going to try to\n155.099s: capture uh with with the mail\n160.14s: um then of course how can we fix that\n162.18s: right how can we fix those model errors\n164.34s: how can we improve climate models inputs\n166.44s: and so one possible solution is to use\n168.66s: data machine learning and physics\n170.58s: together try to bridge the gap between\n172.08s: those things and this is what we're\n173.099s: going to talk about\n174.06s: so as I say my goal is really to try to\n175.98s: illustrate some of the specific examples\n178.56s: that we learned over the years with pros\n181.319s: and cons as I said I'm going to tell you\n183.18s: things that didn't work as well uh and\n185.16s: we're contribution from daytime machine\n186.66s: learning and climate Sciences\n189.239s: and so I'm gonna Identify some of those\n191.7s: problems and tools that we developed\n193.2s: that might be of you know used with men\n196.08s: many people in this room I hope uh and\n198.959s: you know anyone from the deep community\n200.22s: and others and of course the work is in\n201.959s: collaboration with many great people\n204.36s: um especially kind of former uh students\n206.4s: and postdoc uh Andrew Russ and Bolton uh\n208.739s: Pavel Perez organ and uh ziwali and many\n211.739s: other collaborators\n214.14s: okay so I'll tell you a little bit about\n215.519s: myself because technically you know\n217.08s: those are our leap uh kind of faculty\n220.5s: meetings right so and since I'm the leap\n222.42s: your science director should know who I\n224.28s: am so as Gary mentioned she talked about\n226.68s: my degrees but I'm really a physical\n227.94s: oceanographer so I work on trying to\n229.98s: understand how the ocean works and how\n231.72s: it works within the climate system and\n233.4s: so this movie here showing the warming\n236.22s: of the ocean in the past 150 years and\n239.28s: so it's kind of you know reconstruction\n241.5s: so where it pops and it's kind of\n243.599s: yellowish it's where a lot of the heat\n245.58s: has been taking up and stored by the\n247.14s: ocean so there's a clock up there that\n249.239s: goes from uh\n250.879s: 1870 up to present and you can see kind\n253.92s: of you know some places highlighting\n255.72s: right so say the North Atlantic is kind\n257.699s: of you know kind of popping up uh quite\n260.34s: often on on a real time scale the\n262.56s: Southern Ocean down there is another\n264.24s: place and really most of my work is\n266.22s: trying to understand how the illusion\n267.479s: takes up heat wipe wounds how it moves\n270.54s: the heat around same for carbon and\n272.34s: oxygen and how the ocean also influences\n275.46s: the atmosphere so really trying to think\n277.02s: about the coupled climate system so\n278.88s: that's been driving my work uh you know\n281.22s: for a long time now\n283.38s: um really trying to understand how the\n284.639s: ocean Works uh how it impact the climate\n287.759s: but also how can we model it okay so\n290.28s: it's a big Source it's a big sink of\n292.68s: heat we're trying to understand how it\n294.24s: works and that's really what motivated\n295.62s: you know most of my research and kind of\n299.1s: trying to understand how the ocean Works\n301.02s: um you know slowly brought me to you\n303.96s: know trying to understand how climate\n305.4s: modeling works as well because a lot of\n307.32s: the work that we do involves models both\n309.9s: simulations of the climate and so in\n312.54s: Oxford I used to actually give a talk on\n314.22s: the climate modeling and then use three\n316.979s: quotes to try to illustrate a little bit\n319.02s: of our philosophy so the first one is a\n321.18s: book from George bucks which you know\n323.039s: many people see the second part of that\n324.6s: quote or modeler all models are wrong\n326.88s: some models are useful kind of like the\n328.86s: first part of the quote the move that\n330.9s: can be expected from any model is that\n332.52s: it can supply useful approximation to\n334.08s: reality so it's only an approximation\n336.36s: everything we're going to look at is\n338.16s: going to be an approximation you just\n339.72s: we're not looking for the truth\n341.46s: necessarily we're looking for something\n343.44s: that can help us understand how the\n345.96s: world works and for us the world is\n348.36s: going to be the climate system and so\n350.039s: kind of a simple way to think about it\n351.9s: it's not about adding a perfect answer\n353.28s: but having something useful that you can\n355.5s: work with\n357.3s: the second one is is kind of an\n359.16s: interesting one now that I work with\n360.419s: data uh as uh you know from Samuel\n363.24s: accounting another uh you know\n365.18s: mathematicians saying uh the purpose of\n367.32s: model is not to feed the data but to\n368.82s: sharpen the question so you could almost\n370.8s: say this is a paradox right we're going\n372.3s: to talk about machine learning and data\n373.979s: driven models how is it that it's not\n376.44s: what we're trying to do so I actually\n378.0s: see data science as a way to sharpen the\n380.28s: question right so you aren't taking data\n382.68s: where you have a lot of information and\n384.18s: you try to come up with the simplest\n385.5s: possible model to explain the data set\n387.66s: that you have so and of course whether\n390.84s: it works or not it is a scientific you\n393.6s: know Advance because if it didn't work\n395.28s: that means your hypothesis was wrong if\n397.38s: it does work then you need to scratch\n399.06s: your head on why did it work right and\n401.34s: that's a way to sharpen the question one\n402.96s: way or another\n404.34s: second one apart from the scientist but\n406.08s: it's uh basically from uh Paul Anderson\n408.479s: which says Adam yet uh to see any\n411.36s: problem however complicated which when\n413.16s: looked at in the right way didn't become\n414.84s: still more complicated it's kind of the\n417.0s: way I think about climate models in the\n418.44s: climate system in general and so we're\n420.12s: going to go through that kind of a\n421.319s: little bit of a you know roller coaster\n423.3s: of uh feelings about different models\n425.46s: and different ideas as we bring data\n428.1s: models and physics together try to\n430.5s: explain a little bit how we can bring\n432.12s: machine learning and data\n434.46s: so as I say I'm a physical oceanographer\n437.28s: um so the usual is composed of many\n439.02s: scales right so going from the left here\n441.96s: uh relatively small scale where things\n444.3s: dissipate so it can be quite small what\n446.52s: we're very familiar with is the right\n448.319s: hand side of this plot here which is the\n450.3s: base and scale ocean circulation so it's\n452.58s: really thousands of kilometers it's\n454.139s: driven by the wind uh and buoyancy\n456.78s: gradient meaning Heating and fresh water\n458.639s: drives a large calcium circulation\n460.62s: that's what transports you know many of\n462.78s: our tracers uh in the ocean and then as\n465.06s: you go towards uh the left then you have\n467.039s: smaller and smaller scale mesoscale\n469.02s: Eddies over here are 10 to 100\n471.0s: kilometers are basically\n473.58s: um they're wiving if you want their\n475.199s: existence from the large scale flow and\n477.479s: its instability they are kind of\n478.74s: turbulent features\n480.539s: um and they actually extract a lot of\n482.039s: energy but they also weigh for the ocean\n484.38s: to transport heat carbon and other\n486.06s: traces so they put a pretty big role in\n488.58s: the ocean circulation and many people in\n491.099s: this remote experts are in mesoscale\n493.199s: edits and there is a pretty good reason\n494.16s: for lives they really all don't want in\n496.44s: understanding how the climate works yeah\n498.06s: they play a big role on where heat is\n499.8s: being taken up and how\n502.02s: and so this is kind of really a big part\n503.879s: of the problem that we're going to go\n505.199s: after there's this idea of the mesoscale\n507.599s: interacting with the large scale through\n509.34s: it if you can't resolve them in a\n511.139s: climate model then you're gonna miss a\n512.94s: big piece of how the ocean works and how\n515.94s: the climate system works\n517.56s: and so you know movie is always good so\n520.919s: this is a movie so it's a little bit\n522.539s: true I think it's partly because of the\n523.919s: connection so this is a climate\n525.959s: simulation from the gfdl group so it's a\n529.44s: simulation run it's a couple climate\n531.12s: simulation run at 10 kilometer\n532.86s: resolution so basically you have a you\n535.56s: know bunch of pillow boxes one uh\n538.14s: basically 10 kilometer by 10 kilometer\n539.82s: horizontal resolution and it solves the\n542.1s: full uh equations for the ocean\n544.399s: atmospheres Eis and so on and here what\n547.26s: you can see is the sea surface\n548.399s: temperature so kind of pretty amazing\n551.1s: right you can see the Gulf Stream\n552.24s: detaching you know from the U.S east\n553.92s: Coast you see a lot of kind of turbulent\n556.019s: and filaments uh kind of you know\n558.06s: popping up everywhere and they come from\n559.8s: the instabilities\n561.24s: and again they're quite important in\n563.339s: taking up uh you know in basically\n565.08s: steering and mixing uh different traces\n567.36s: in YouTube but this is really how\n568.98s: climate simulation works we take super\n571.14s: complicated equations that we can't\n572.7s: solve by hand uh we break them down into\n575.04s: pieces okay and so you have a little\n577.38s: example here on a climate model right\n579.959s: right so break down into pieces and in\n582.06s: every one of those boxes we try to\n583.98s: approximate the equations that we have\n585.959s: but of course the physics that you can\n588.3s: resolve and all the processes that you\n589.68s: can resolve is limited by the size of\n591.24s: the grid box that you have so this is\n593.58s: going to be your indication anything\n595.019s: that is happening below the grid box\n596.58s: size that you have is not going to be a\n598.74s: reasonable okay and that's one you know\n601.44s: big problem for us\n603.54s: and the fact that some of those\n605.22s: processes are not resolved then the fact\n606.959s: that the equations are only approximate\n609.019s: means that the models are what we call\n612.06s: biased meaning they have errors in them\n614.16s: when we compare them against other\n615.48s: donations so I didn't want to pick and\n617.94s: choose one model I picked three so it's\n620.519s: not you know I don't have a favorite so\n622.26s: I don't want to complain about one\n623.82s: modeling Center three models so three\n626.279s: different climate models basically\n628.2s: developed by three different modeling\n629.7s: centers uh on this plot here and we're\n632.7s: showing the sea surface temperature so\n635.22s: the surface of uh the temperature of the\n637.56s: surface of the ocean minus that of\n640.08s: what's observed okay so basically if you\n642.48s: had a perfect model hopefully the error\n645.18s: will be zero so in temperature and so\n647.279s: this is the column balance that we have\n648.6s: here and you can see this is clearly not\n650.519s: the case right so in some places the\n652.98s: models are warmer or cooler by by five\n655.2s: degrees\n656.579s: um and so those are pretty big numbers\n658.5s: right so the largest temperature that\n659.94s: you could get are about 30 degrees at\n662.16s: high latitudes it's much lower than that\n663.779s: so you end up with errors in your\n665.82s: simulation compared to observations that\n667.74s: are quite large\n669.959s: and again what's interesting is if you\n672.36s: look at those three models some of the\n673.8s: errors are actually identical right so\n676.2s: let's say in the North Atlantic over\n677.459s: here you have this uh you know blue uh\n680.82s: blob here that is a pretty common error\n684.54s: in many generation of climate model and\n686.64s: still shows up\n688.2s: um and one of the reason is actually\n690.42s: pollution process is not being properly\n692.519s: resolved there and the coupling between\n693.839s: the ocean and atmosphere are being older\n695.399s: one\n696.12s: and so just to show you again in picture\n698.519s: model error will come from all the\n701.579s: missing physics so everything that is\n703.38s: happening below the green box size of\n705.3s: the climate models so those turbulent\n707.94s: entities that I showed you before clouds\n710.459s: radiation all those things are actually\n712.5s: not result from the grid of the climate\n714.959s: models that we have the second thing is\n716.88s: of course numerics right we add you know\n719.88s: in a math world we add continuous\n721.86s: equations that technically you could\n724.5s: solve by hand but we can't because\n726.3s: they're just too complicated so we've\n728.339s: approximated them on the grid\n730.98s: um and so those approximation also leads\n733.26s: to wear okay so those are two basic\n735.839s: reasons that we have errors in our\n737.7s: simulation one is approximation of\n740.0s: continuous equations onto a discrete\n742.62s: grid another one is anything that is\n744.839s: happening below the green box size is\n746.64s: not resolved I need to be approximated\n750.54s: okay so I showed you what I call bias or\n754.62s: errors in simulation compared to\n756.6s: observations now you know is that it um\n759.779s: if I run the model into the future I\n761.7s: don't know what the future looks like\n762.779s: right so we have no clue what the future\n764.94s: looks like so if we basically pretend uh\n769.32s: that we're gonna have a given emission\n770.88s: scenario in the future how the climate\n773.22s: models will respond to that okay so the\n775.26s: different climate models all get the\n777.12s: same for singing quotes and what we can\n779.399s: show is if we plot sea level as a\n782.339s: function of time and look at the\n783.779s: projection so look into the future the\n786.66s: shading that you see for a given color\n788.76s: is going to be different run of\n791.16s: different climate models filling the\n793.139s: same Force\n794.82s: so what are the different lines\n796.62s: represent so different lines different\n799.26s: climate simulations different climate\n801.18s: models okay like before so I showed you\n803.04s: only three but there are many nowhere\n804.779s: right so there are many climate models\n806.16s: so over here that's the historical\n808.5s: period where we have true measurements\n810.24s: and so you can see already the models\n812.22s: are a little bit all over the place and\n814.32s: then when you go into the future then\n816.12s: they continue having a relatively large\n818.399s: spread so this kind of you know spread\n820.98s: between different model continue into\n823.139s: the future\n826.29s: [Music]\n829.2s: yeah so they continue so each line is a\n831.959s: climate model so over the historical\n834.72s: period we know what the forcing is and\n836.76s: then you continue them into the future\n838.26s: with with an additional Force\n845.06s: in this\n847.62s: protection\n849.54s: okay that's a good question I should let\n851.94s: me explain that again each color is\n853.62s: actually a different scenario so it's a\n855.24s: different fall scene\n856.62s: okay so the blue line is a weak for\n859.74s: saying the red line is a strong one and\n862.44s: then the shading are actually many\n864.48s: different uh climate models so for a\n867.839s: given scenario you have a given color\n869.82s: and then the spread is going to be the\n871.74s: different simulation coming out of that\n873.24s: scenario right so you have as many line\n875.82s: in that kind of red shading that you're\n877.56s: having a blue shading and that you have\n879.48s: here already so appropriate\n881.16s: yeah thanks for clarification any other\n883.139s: questions\n884.22s: so are they all forced to agree like\n886.139s: around year 2000 is that because the\n887.76s: observations are really well really good\n889.26s: then consider so okay so that's a good\n891.18s: question so every time that you look at\n893.339s: something usually we do them relative to\n895.139s: a given period and they took at that\n897.3s: given period that's your reference date\n898.92s: so everything is going to be centered\n900.66s: around that line and then this spread is\n902.22s: going to work from there so that's\n903.6s: completely out of the query you could\n905.579s: pick a different date we like to pick\n907.56s: you in recent periods because\n909.12s: observations aren't bad so that's kind\n911.459s: of a nice way to calibrate it yeah\n913.139s: that's a good question\n914.94s: anything else yeah\n917.339s: what are the two scenarios of\n919.56s: models and outcomes Yeah so basically\n921.959s: the amount of forcing that it's going to\n924.6s: be put into the climate model right so\n927.54s: the uh different amount of CO2 rare\n929.579s: results and so on will give you two\n931.38s: different projection because different\n932.88s: greenhouse effect will have different\n934.62s: warning\n935.94s: and here we're really looking at sea\n937.68s: level in the ocean and the reason that\n939.54s: sea level is going up right it's going\n941.1s: up for two weeks so we have multiple\n942.72s: reasons but mainly over that period and\n945.72s: in those simulation one is because the\n947.82s: ocean is warming so water expense right\n949.98s: so basically sea level is going to go up\n951.779s: and the second reason is melting right\n954.0s: so basically melting uh by sheets might\n956.639s: be the second reason\n958.38s: so so potential you could have made the\n961.56s: same visualization on the left hand side\n963.6s: when you have a real data also move the\n966.899s: lines into the red and blue\n969.66s: so in the real world but in the real\n972.24s: world we know where the policy was right\n974.16s: so it's no difference in our I mean in\n976.98s: good we have a pretty good estimates of\n978.66s: water forcing there so for the for the\n981.12s: historical period we're pretty good if\n982.86s: you were thinking about patio climate\n984.48s: for example right so that could be a\n986.579s: another way to think about it the fourth\n988.56s: thing is known but as a number so would\n992.1s: be a possibility to actually think about\n993.66s: different uh different trajectories\n997.079s: any other questions\n999.0s: oh yeah I like questions about it it's a\n1001.639s: lot more fun the future the four things\n1003.5s: would also be\n1005.3s: stimulated by other parts of the\n1007.699s: department\n1009.699s: okay so here okay so that's a good\n1012.079s: question so right now in those\n1013.459s: simulations so the fourth thing is\n1014.959s: really kind of you know externally\n1017.199s: forced so kind of CO2 and so on and so\n1019.759s: forth now the current climate models are\n1022.22s: playing out with new things what if we\n1024.439s: melt out of Antarctica a different depth\n1027.559s: so that's a different type of forcing\n1029.12s: that is induced you know by increasing\n1031.579s: greenhouse gases but the models don't do\n1033.26s: that don't do that properly because they\n1035.0s: don't have active machines so can you\n1037.16s: actually mimic that and so that's yeah\n1038.66s: so that's another type of simulation\n1040.04s: there are quite a few out there yeah\n1044.12s: okay great\n1046.04s: um so now let's continue on our path of\n1048.559s: trying to understand what's resolved\n1049.94s: what's not in the climate model and how\n1051.679s: can we fix it so this is the same\n1054.08s: climate model I show you the fancy movie\n1056.36s: from earlier right that was one at 10\n1058.46s: kilometer resolution\n1060.32s: um and so now same equations so to speak\n1062.6s: right so same ocean equation we're still\n1064.58s: looking at surface temperature in that\n1066.02s: plot but now the model is one at three\n1068.179s: different resolution so the one of the\n1070.7s: writers the original one 10 kilometer\n1072.98s: resolution the one in the middle it's\n1075.26s: run at 40 kilometer resolution so now\n1078.08s: your read box is much louder right so\n1079.94s: that means processes that are below that\n1082.52s: scale are not free so you can see it's\n1084.38s: getting smoother right it's getting more\n1087.38s: viscous if you go to the one on the left\n1089.78s: so now it's a grid box of 100 kilometer\n1092.299s: by 100 kilometer so the one on the left\n1095.72s: and the one in the middle is roughly the\n1097.28s: resolution of current the current\n1098.6s: generation of climate problems okay so\n1101.179s: they're quite viscous uh right they're\n1103.46s: not as turbulent as the one you have on\n1105.02s: the right and the fact that you're\n1106.64s: missing all those filaments and\n1108.02s: turbulence it's not just that your movie\n1109.82s: does not look as good uh but it's again\n1112.58s: you're missing important and critical\n1114.38s: processes that are mixing part of the\n1117.14s: ocean the interact with the eyes\n1118.52s: actually they do have a direct impact on\n1120.44s: how much ice uh you can mount where a\n1122.66s: rem Antarctica over here and I still\n1124.34s: that movie from uh Julius actually quite\n1127.28s: a long time ago and I always show it\n1129.26s: it's one of my favorite animation to\n1131.48s: talk about resolution and climate models\n1134.299s: um okay so now the fact that we can't\n1137.12s: resolve those processes again does that\n1138.62s: mean that it's the ends and we don't do\n1140.36s: anything so the way we've been doing you\n1142.64s: know kind of What's called the\n1143.66s: parametrization or the closure problem\n1145.34s: which is representing all the processes\n1148.52s: that are not resolved in a climate model\n1150.799s: so again up here you have clouds you\n1153.14s: have radiation you have you know\n1154.88s: basically boundary layer processes and\n1156.799s: so on uh and in the ocean or the\n1159.02s: turbulent mixing processes that I told\n1160.64s: you about\n1161.66s: so we need to come up with a\n1162.86s: representation for that so we need to\n1164.96s: come up with a way\n1166.7s: capture the effect of those turbulent\n1169.28s: features or Cloud on the large-scale\n1171.88s: quantity of the climate system we care\n1174.02s: about say temperature or you know\n1176.36s: precipitation and so on and so forth as\n1178.82s: a function of the things we know the\n1180.62s: function that the model can result so\n1183.2s: only on the grid that you have at course\n1185.12s: resolution\n1186.02s: so you know that's been the business of\n1188.6s: you know climate modeling and\n1189.799s: parametrization for decades this is not\n1191.6s: new uh it's been going around for quite\n1194.12s: some time shown some great improvements\n1196.82s: in you know different part of climate\n1198.679s: models but they you know the traditional\n1200.419s: closure of trying to come up with a\n1202.039s: mathematical approximations I've still\n1204.26s: shown us that they still lead to\n1206.48s: uncertainty at the end of the day both\n1208.34s: in present day climate but also in\n1210.62s: future projections so the question is of\n1212.9s: course can we do better right and that's\n1214.94s: kind of one of the big thoughts so what\n1216.919s: I'm going to focus on is one example of\n1218.9s: those ocean turbulent entities that I\n1220.88s: told you about before so again kind of\n1222.919s: same ideas right so if you run a\n1225.14s: simulation at relatively high resolution\n1226.76s: you have all those turbulent features\n1228.86s: over here they're going to be a pretty\n1231.02s: important player for the client system\n1232.58s: but the majority of our climate models\n1234.799s: are run at those kind of closer more\n1237.38s: viscous resolution so what can I do to\n1239.66s: capture the effect of those you know\n1241.34s: small scale smaller scale turbulent\n1243.26s: features onto the large scale so it\n1245.419s: gives me the same physics so just want\n1247.94s: to make one comment is I'm not trying to\n1249.559s: make this picture looked like the one on\n1252.86s: the right because I'm not trying to you\n1255.08s: know create fake images I'm really only\n1257.72s: trying to capture the force that those\n1260.9s: turbulent features have on the large\n1262.88s: scale fruit and so it's our you know\n1265.039s: kind of if you think about Newtons all\n1267.14s: right so you're basically trying to\n1268.94s: apply an additional Force so you can\n1270.86s: accelerate the currents or that you can\n1273.08s: increase the temperature but you don't\n1274.76s: necessarily get more structure in your\n1276.98s: image so to speak okay\n1281.179s: so again just to show you a little bit\n1283.1s: this kind of spread that comes out of\n1285.2s: those ocean Eddies so this is kind of a\n1287.78s: very specific you know uh quantification\n1290.48s: of how much heat goes into one part of\n1293.059s: the Southern Ocean in different kind of\n1295.22s: models so on the x-axis a bunch of\n1297.32s: different planet models and on the\n1300.2s: y-axis is the amount of heat that we\n1302.24s: have\n1303.44s: so the total is the black line so for a\n1306.32s: bunch of different model you can already\n1307.52s: see that the total heat that goes up is\n1309.919s: quite different can change by a factor\n1311.72s: of two or three okay so that's again\n1313.58s: already because you know ocean warming\n1315.679s: means sea level so different model can\n1318.5s: give you a factor three difference in\n1319.82s: the amount of sea level that you'll get\n1321.799s: now what's it the red dots is what's\n1324.919s: actually resolved by the equation\n1326.6s: meaning things that we didn't\n1328.0s: approximate so things that are not below\n1330.679s: the grid box size uh and you can see the\n1333.26s: closer to zero than anything else so\n1335.6s: what the model result actually has\n1337.46s: almost no contribution on the amount of\n1339.5s: heat that the ocean is taking up and all\n1342.14s: the other dots and I'm not going to\n1343.22s: explain what they are but they're all\n1344.48s: related to those turbulent that is they\n1346.52s: are the ones that actually contribute to\n1348.2s: most of the guitar tech and they're the\n1350.24s: one that contribute to most of the\n1351.679s: spread that means that everything that\n1353.48s: is parameterized everything that has\n1355.34s: been approximated in a kind of a dark\n1358.34s: fashion uh both the driver of Epic but\n1361.94s: also the driver of the spread meaning\n1363.98s: that that's the thing that gives out\n1365.539s: different answers so really kind of\n1367.76s: trying to narrow this down coming up\n1369.38s: with an approximation that are better uh\n1371.659s: and also reduce that spread is\n1373.159s: definitely an older one problem uh when\n1375.08s: it comes to climate and that's really\n1376.88s: what we're gonna we're gonna focus on\n1378.38s: these parts right so trying to represent\n1380.539s: those level scale IDs that contribute to\n1382.76s: the heat up Tech and how they transfer\n1385.28s: energy uh and how they affect the\n1387.26s: large-scale transport by using data\n1391.46s: Okay so\n1394.159s: how can we do that well we have data the\n1397.4s: data come from simulations in our case\n1399.08s: right so because in many instances we\n1401.299s: have a lot of simulation that we can run\n1403.4s: either in small domains uh or you know\n1407.299s: some of the simulation I showed you\n1408.679s: before that climate models have run but\n1410.72s: they're not typical but we still have\n1412.52s: data right so in our case we have\n1414.02s: equations that we can solve and we can\n1416.0s: simulate a lot of data and generate a\n1418.46s: lot of it\n1419.9s: um we have new algorithms all right so\n1421.58s: those algorithms are great to capture\n1423.2s: complicated relationship uh from data\n1426.34s: and basically what we're going to learn\n1428.9s: is this closure this you know\n1432.08s: parametrization that tells me what is\n1435.02s: the effect of those turbulent Eddies on\n1437.36s: the loud Gap so I'm looking for false so\n1440.48s: basically if you were thinking you know\n1442.28s: the Eddies are kicking the fluids I'm\n1444.5s: looking for that I'm looking for the you\n1446.24s: know the kick that the Eddies are\n1448.52s: basically doing on the large scale on\n1450.919s: the large-scale equations of motion lots\n1453.679s: of people have been working on this\n1454.94s: right on this problem of using machine\n1457.4s: learning with data uh to come up with a\n1459.799s: new closure so a new representation of\n1461.96s: processes that are not resolved you know\n1464.36s: many in the atmosphere and the ocean\n1466.46s: again many people in this room are\n1468.559s: definitely kind of you know uh been\n1470.24s: leading uh the field in those areas and\n1472.76s: so I'm gonna rather than tell you again\n1474.44s: as I said only what works I'm gonna\n1476.539s: probably show you a little bit what\n1477.679s: doesn't as well\n1479.0s: so for you know we've been working on\n1482.36s: that with you know people in my group\n1484.76s: for quite some time we started I think\n1486.32s: in 2016 or 17. uh we did a lot of stupid\n1489.38s: things early on we still do by the way\n1491.059s: but we got better uh and then you know\n1493.4s: the few first thought that I gave on\n1495.44s: this topic I used to come up and you\n1497.059s: know show video an in-depth study of\n1499.4s: something super important players to\n1500.96s: make conclusions at the end uh I give a\n1503.48s: few of those thoughts and then every\n1504.5s: time then I try something in a different\n1506.0s: model then everything I said the year\n1507.86s: before actually was wrong\n1509.78s: um and so I could keep on doing that for\n1511.52s: a long time I think it can work but\n1513.2s: rather than continuing we decided to\n1515.059s: pose for a second and take a little bit\n1517.159s: of a step back and I'll show you a\n1518.419s: little bit first what we've done and\n1519.799s: when we decided to stop we probably\n1521.059s: should have stopped before so input data\n1524.6s: and we use data from pretty much any\n1525.919s: model that you can come up with some\n1527.419s: that you know we build in-house some\n1529.22s: that were existing very complicated very\n1532.1s: simple we thought that it was one of the\n1533.9s: biggest challenges and it still is and\n1535.7s: I'll come back to it\n1537.08s: uh methods um pretty much any flavor of\n1540.679s: machine learning algorithm that exists\n1542.72s: we probably try some kind of flavor of\n1544.52s: it some deep learning that has you know\n1546.86s: basically thousands of parameters that\n1548.419s: can capture very complicated\n1549.5s: relationship to things much simpler like\n1552.08s: regressions spouse regressions and\n1554.12s: things like this I'll show some examples\n1556.4s: we um you know we're trying to build\n1559.039s: closers that are deterministic meaning\n1561.14s: you have a one-on-one mapping you don't\n1563.12s: need input to that one output or\n1565.159s: probabilistic a given input you learn a\n1568.22s: probability so you learn basically\n1569.6s: multiple outputs in one goes try to\n1572.059s: represent the uncertainty\n1573.98s: we tested it on different climate\n1576.14s: regimes where you have different you\n1577.82s: know CO2 forcing different Reynolds\n1580.4s: numbers so the Reynolds number is a way\n1582.02s: to represent turbulence right so with\n1583.7s: Quantified children so you know very\n1585.26s: different level of children's and you\n1587.419s: know different configuration and we\n1590.059s: implemented it because when you learn\n1591.38s: the closure you need to go and put it\n1593.059s: back into a course resolution model we\n1594.98s: did simple complicated and so on and so\n1597.44s: forth and as I said I think pretty much\n1599.72s: every paper that we wrote after we wrote\n1602.179s: it then we try something else and\n1604.039s: everything was wrong\n1605.72s: um so we decided to go back and go to\n1609.62s: basically the bread and butter of kind\n1612.02s: of simple model of turbulence try to\n1614.539s: capture that captures most of the effect\n1615.98s: that we have and we settled on Pi 2G\n1618.919s: which is a model that was developed by\n1620.72s: Ryan and others uh it's open tools it\n1623.9s: really kind of captures most of the\n1625.88s: physics that is necessary for us to have\n1627.74s: it's also very flexible it's in Python\n1630.559s: and you know you can do a lot of stuff\n1632.059s: with it and so really our goal was let's\n1634.64s: not try to find the best monetization\n1636.44s: but let's actually try to find a way to\n1639.32s: understand what we're doing right so\n1640.88s: really trying to focus on physical\n1642.26s: mechanism and interpretation in a simple\n1644.299s: framework test robustness of the method\n1646.82s: and the results you know how much can we\n1648.799s: push the ideas forward and also not\n1650.779s: something that you know is verifiable\n1652.64s: and has some incidental quantification\n1654.5s: and so here you have kind of you know\n1656.539s: those kind of troubling flow field that\n1658.4s: you can generate with that model it's\n1659.84s: very cheap and you can do a lot of stuff\n1661.94s: with that and the gun was really to try\n1664.159s: to develop data set metrics and\n1666.44s: benchmarks uh for us first to understand\n1668.96s: but also to openly give to the community\n1672.44s: so that's going to be the motivation\n1673.7s: take a step back trying to look at you\n1676.52s: know what we learned\n1678.679s: so how do we do that so we need to\n1680.9s: consider two steps here okay so we're\n1682.88s: gonna generate data from this kind of\n1684.74s: very simple turbulent model\n1687.2s: and we're going to learn a closure all\n1689.0s: right so we're going to learn that kind\n1690.2s: of missing full saying that the course\n1692.24s: resolution model should have uh if we\n1695.24s: wanted to behave like a high resolution\n1697.7s: model but without the computational\n1699.14s: costs so we're going to have some inputs\n1701.419s: that come from numerical simulations\n1703.7s: we're going to use some machine learning\n1705.2s: algorithm to try to learn this missing\n1709.46s: turbulent forcing that we want to put on\n1711.98s: the right hand side of the course\n1713.059s: resolution\n1714.14s: so that's step one right so step one\n1715.82s: involves machine learning\n1717.32s: the data is there we've generated it\n1719.419s: we're gonna you know learn what's\n1721.34s: missing from the course resolution model\n1722.9s: and rather than do it the way we've been\n1725.84s: doing it for decade which is oh I know\n1728.179s: that turbulent should do X and Y let's\n1729.679s: write a mathematical operator we just\n1731.84s: kind of ask the data what is you know\n1734.059s: this forcing should look like\n1737.539s: or at least how can I best represent it\n1739.76s: with machine learning now when I have it\n1742.52s: then that's not the end right when I get\n1745.22s: that full saying now I need to make sure\n1746.539s: that if I put it on the right hand side\n1748.4s: of a climate model into it for us it's\n1751.039s: by 3G run at a causal resolution while\n1754.159s: it should improve the model right so\n1755.539s: that's the goal so step two when we have\n1758.12s: this you know new forcing we set it a\n1760.76s: sign we saved it uh we're gonna take our\n1763.46s: you know simulator our climate\n1765.2s: simulators at course resolution we're\n1767.12s: gonna run it with this additional\n1768.679s: forcing so this additional kick that\n1770.84s: comes from the turbulence that is not\n1772.279s: result we're going to get an output this\n1775.039s: output here hopefully is better than the\n1777.98s: output that I had before which was\n1779.72s: blurrier uh but at the same resolution\n1783.5s: does that make sense I'm gonna post for\n1785.48s: a second yeah\n1787.399s: great so first part we're going to learn\n1789.559s: a missing forcing with machine learning\n1791.059s: algorithm second part we're going to\n1793.34s: plug it in a course resolution model and\n1796.46s: cross our fingers that we actually do\n1798.2s: better uh then the course resolution\n1800.48s: model by itself or a course resolution\n1802.34s: model with an old parameterization so\n1805.76s: it's simple step one in that very simple\n1807.559s: mode so some of the things I'm going to\n1810.2s: tell you can be not the most exciting\n1812.72s: thing but we actually realize that we're\n1814.22s: the most important one first is how do\n1816.32s: you calculate this missing Force so you\n1818.899s: need to basically filter and cause grain\n1820.94s: your data so it's quite boring to some\n1822.74s: extent but it's actually a pretty\n1824.299s: important step because the way you're\n1826.22s: going to do that you're trying to\n1827.059s: actually extract what's missing from\n1829.64s: something of course resolution compared\n1831.08s: to a high resolution film so don't\n1832.82s: bother with the equation but at the end\n1834.32s: of the day we're looking for something\n1835.76s: that is basically the difference between\n1837.86s: two non-linear products shall not easy\n1840.14s: to calculate now how do you filter and\n1842.24s: cause grain well there are many options\n1844.52s: and uh interestingly so here I'm showing\n1847.82s: a field of what's called potential\n1849.26s: volticity so it's basically a\n1851.48s: combination of\n1853.76s: um you know two quantities so to speak\n1856.159s: one that is related\n1857.72s: um you know to the velocity and one that\n1859.58s: is related to the stratification in the\n1861.38s: ocean so it's a nice way to combined\n1863.24s: Dynamics and thermodynamics in one\n1865.22s: variable that is conserved in usually so\n1867.74s: here we're filtering this Beyond this\n1869.36s: high resolution field onto a course\n1871.52s: resolution you know data which is what\n1873.86s: we're looking for so we have three\n1874.94s: operators\n1876.62s: um I'm not gonna you know bother on\n1877.94s: telling you what is what but each one of\n1879.38s: them I mean at the end of the day you\n1880.58s: know by eye they kind of look the same\n1881.779s: right the pictures look the same when\n1883.279s: you do it on the on the voltage default\n1885.2s: now that's not what I'm trying to get\n1886.64s: where I'm trying to get this kind of\n1887.899s: missing forcing over here so now I'm\n1889.88s: gonna try to look on What's Missing\n1891.62s: right of course resolution for field to\n1895.88s: actually have the same properties as\n1897.14s: high resolution with those three\n1898.82s: operators and that's the field I'm\n1900.679s: getting out from the three different\n1901.94s: operators so I'm calculating the same\n1904.22s: quantity except the bar that I have over\n1906.08s: here is a slightly different filtering\n1909.08s: operation\n1910.22s: so the missing forcing that I call the\n1913.279s: truth actually depends on how I do my\n1915.559s: filtering so this is again it's another\n1916.94s: most exciting thing on the planet but\n1918.86s: already tells you that the first step\n1920.36s: that you're gonna you know you're gonna\n1922.039s: think about is really what is it that\n1925.22s: I'm looking for what is the true missing\n1927.98s: forcing and what I'm gonna learn is\n1930.38s: going to be one of those and we're going\n1931.94s: to see that there is a sensitivity when\n1934.279s: we plug it back into a climate model and\n1936.679s: how it works I see why I'm making your\n1938.6s: face it is the most exciting thing on\n1940.94s: the planet too I know I know I know but\n1943.52s: I think a few of us sound that camp I'm\n1946.039s: not exactly sure that everybody is with\n1947.96s: us but hopefully I'll motivate it enough\n1950.179s: that it is the most exciting thing on\n1951.98s: the planet yeah\n1954.08s: um\n1956.179s: okay so we have three possible three\n1958.88s: possibilities right still a missing\n1960.799s: forcing still technically something I\n1962.899s: should put on the right hand side of the\n1964.1s: climate model so something I should\n1965.72s: learn so now let's try some machine\n1967.64s: learning algorithm to learn this missing\n1969.86s: Force\n1971.179s: so one test is a good old neural network\n1974.74s: so complicated deep learning\n1977.6s: convolutional neural network the inputs\n1980.059s: are going to be the fields that I\n1982.1s: mentioned before those potential\n1983.419s: volatility field can think about them as\n1985.34s: you know velocities and temperature if\n1986.899s: you want same thing\n1988.34s: many layers I don't want to really talk\n1990.679s: about the architecture because you know\n1992.48s: you can play with that as much as you\n1994.58s: want then the output is going to be our\n1996.919s: missing forcing right what we're trying\n1998.419s: to learn and so we're going to minimize\n2000.039s: some kind of loss function to try to\n2001.899s: find the best representation with a\n2003.82s: convolutional neural network of that\n2005.62s: missing Force\n2007.539s: um you can build in physical constraint\n2010.059s: to make sure that everything is\n2011.14s: conservative so you can do a lot of\n2012.7s: things with neural network nowadays that\n2015.1s: you couldn't actually many years ago you\n2016.72s: had to hack them now actually packages\n2019.0s: are involved in a way that we don't need\n2020.559s: to hack things anymore and so we can\n2022.299s: build physical constraints in a in a\n2024.22s: simpler way\n2025.299s: so that's one that's one option right so\n2027.94s: neural network you're gonna end up with\n2029.5s: thousands of parameters they're really\n2031.539s: good at capturing very complicated and\n2034.0s: complex relationship or you know quite\n2036.22s: textured data\n2037.779s: now the small issue I have with them I\n2040.72s: still like them a lot and I use them a\n2042.22s: lot it's very difficult to interpret\n2044.019s: right I end up with thousands of\n2045.76s: parameters there are some methods out\n2048.04s: there for the subway parameterization we\n2050.26s: haven't been able to you know really\n2051.879s: extract any useful information from them\n2054.58s: by themselves so another option that\n2057.04s: we've done was trying to actually learn\n2059.02s: directly equations from the data\n2062.26s: so here is one example of that I'll show\n2064.659s: you an example later on so one is\n2066.76s: genetic programming and so this is a\n2068.8s: symbolic uh you know algorithm and the\n2071.619s: idea is you try to evolve some kind of\n2074.56s: you know random expression initially to\n2077.02s: learn this missing force and so\n2078.58s: basically you're trying to mimic\n2079.839s: Evolution so you're going to have a\n2081.58s: bunch of trees right and so the\n2083.26s: algorithm can take multiplication and\n2085.06s: addition and things like this of the\n2086.919s: different you know data that you give it\n2088.78s: it's going to try to come up with a\n2091.0s: simple expression so a parsimonious\n2093.159s: expression there's very few terms that\n2095.74s: will try to mimic\n2097.72s: your edits so basically again in a very\n2100.42s: crap you know very crude way it's going\n2102.82s: to try to learn an equation that can\n2104.8s: describe your missing forcing given the\n2107.56s: input data\n2108.88s: so it's you know pretty powerful uh it's\n2111.339s: been used you know in many examples\n2113.74s: um of you know uh physics and I know\n2115.78s: can't use some of that to try to you\n2117.76s: know kind of get some understanding of\n2119.619s: more complex model\n2121.18s: um you know people at Colombia have\n2122.619s: developed some of those methods based on\n2124.24s: on genetic algorithm try to you know\n2126.46s: learn laws of physics and so the\n2128.26s: question is can we learn a new\n2129.94s: parameterization from data uh with this\n2132.88s: type of algorithm and of course you know\n2135.04s: the big question mark is can we learn\n2136.42s: new physics as well and I should clarify\n2139.18s: when I say learning new physics quite\n2140.8s: often The Operators that you get are the\n2142.42s: one that you know right because we're\n2143.68s: not Reinventing math\n2145.38s: but can you understand better how the\n2148.06s: scale interaction is actually working\n2149.74s: how the energy is changed is exchanged\n2151.839s: between different scales that you're\n2153.22s: trying to capture or dissipation is\n2155.02s: changing in those closures so it's sort\n2156.88s: of a different way to actually ask uh\n2159.16s: something about it now the slight issue\n2161.98s: with those type of algorithm they are\n2163.66s: not made for the problems that we have\n2165.82s: so one issue uh is that they know\n2168.7s: nothing about spatial scales and we need\n2171.7s: derivatives we need spatial derivatives\n2173.38s: right so we had to build in something\n2175.42s: about spatial derivative for this case\n2177.7s: it was very easy because it was on its\n2179.38s: spectral space so it's just multiplying\n2181.72s: by a number but we've actually now\n2183.64s: changed the algorithm to work in real\n2185.38s: space as well so you still need to have\n2187.359s: those algorithm to work for physics\n2188.859s: problems so that's always one thing to\n2191.26s: keep in mind the second thing is it's\n2193.24s: still an algorithm it does not know\n2194.98s: physics so sometimes it does some silly\n2197.619s: things like it's going to add two\n2198.76s: quantities at different units that's not\n2201.16s: good right I mean this is the first\n2202.48s: thing you learn in school check your\n2204.579s: units that tells you if you made a\n2206.44s: mistake so we had to basically kind of\n2208.839s: try to hack this as well in a way that\n2211.3s: we can actually stop the algorithm when\n2213.64s: it does something that is absolutely not\n2215.44s: physical and so we do it as an iterative\n2217.66s: matter\n2218.8s: but the idea is you come up with an\n2221.079s: expression and I'm not going to talk\n2222.339s: about you know the physics of it but you\n2224.02s: come up with an expression that\n2225.4s: hopefully you can interpret and talk\n2227.68s: about the physics so two different type\n2229.72s: of model one that is pure deep learning\n2232.48s: thousands of parameters another one that\n2234.76s: has fewer parameters and that you can\n2236.74s: openly interpret in a mathematical\n2240.099s: so now step two right so I learned\n2242.44s: models\n2243.88s: um I need to plug them back into a\n2245.74s: simulation as well right so they need to\n2247.54s: do well both offline so when I learned\n2250.66s: them and then when I plug them back in\n2252.28s: and so one of the characteristics we're\n2254.32s: looking for is we're looking at kinetic\n2256.24s: energy as a function of time the gray\n2258.52s: line is the cross-resolution model and\n2260.859s: the black line is the high resolution\n2262.119s: model so you have more energy in a high\n2264.52s: resolution model than in a pulse\n2265.839s: resolution model and that's why we're\n2267.28s: trying on machine learning networks to\n2269.32s: do right we're trying to energize\n2270.46s: different\n2271.839s: so this is really what we're doing\n2275.02s: so I'm gonna show you two sets of tests\n2277.78s: one that is offline so meaning before we\n2280.48s: plug it back into the planet model just\n2282.88s: to see if the machine learning algorithm\n2285.16s: you know the machine learning models\n2286.42s: that we learn are actually good right so\n2288.94s: that's kind of Step One\n2290.56s: so\n2292.619s: hypothetically if I were to plot error\n2295.24s: versus complexity\n2297.28s: I would expect a model you know with\n2299.68s: thousands of parameter to probably give\n2302.079s: me a lower error on what I'm learning\n2304.24s: than a model that has only one parameter\n2306.7s: right so if I have a very complicated\n2308.619s: you know function and I try to come up\n2311.56s: with a linear approximation and that's\n2313.119s: what a primary error is going to be\n2314.44s: pretty large if I'm trying to capture\n2316.3s: something from nonlinear function right\n2318.22s: so the error is probably going to be\n2319.72s: loud if I just come up with a linear\n2321.4s: approximation of it so again\n2324.04s: hypothetically if I were coming up with\n2326.2s: a physics parametrization I'll probably\n2328.3s: look like this you'll have one parameter\n2330.099s: and you know if you were looking at how\n2332.44s: it matches with the missing forces we'll\n2335.079s: probably have low correlation and then\n2336.88s: when you go to a neural network you\n2338.2s: probably have very high correlation and\n2339.88s: if you have the data driven you know\n2342.76s: equation Discovery you're probably\n2344.079s: somewhere in between because you have\n2345.28s: quite a few and this is exactly what we\n2347.5s: find offline so here a lot of data are\n2350.38s: driven parametrization in the metrics\n2352.3s: based on what we learned so here's the\n2354.64s: neural network so we have r squared and\n2356.38s: correlations when you have a high score\n2357.82s: that means you're doing well so the\n2359.74s: neural network you know basically 0.9\n2362.38s: and above for everything so it does\n2364.119s: really well because you give it tons of\n2365.92s: freedom to learn something okay so\n2368.32s: amazing you learn what it's supposed to\n2370.78s: learn\n2371.92s: the symbolic expression all right\n2375.099s: um lure right but still pretty good so\n2377.56s: you know you're still going down uh in\n2379.9s: terms of you know the error but\n2382.72s: um you know still still does pretty good\n2384.579s: if you look at the physics within one\n2387.16s: um terrible right just offline like it\n2391.359s: really off\n2393.04s: um and that's all I find right so right\n2395.2s: now you could say if I plug that into a\n2397.54s: climate model then technically the\n2399.579s: neural network should be superior to the\n2402.4s: symbolic expression to the physics the\n2405.579s: right time advisation right so that\n2407.02s: would be like a first guess\n2410.02s: you can get it's probably not going to\n2411.339s: happen right so here we are so now we\n2415.119s: took those three models and we run three\n2417.82s: simulations so this is a high resolution\n2421.3s: snapshot\n2422.8s: um this is the low resolution so less\n2424.839s: kinetic energy it's a little blurrier\n2426.52s: and things like this now we took the\n2428.38s: same pde so the same equation uh with\n2431.38s: the same resolution of this course\n2432.64s: resolution model and we add that forcing\n2434.5s: that new forcing that we learned so over\n2436.78s: here this is the physics-based\n2438.28s: parameterization in the middle the one\n2440.68s: with the neural net on the right the\n2443.56s: hybrid symbolic expression by I\n2446.5s: they all do well right even though\n2449.38s: offline I would have said the physics\n2450.94s: base is going to be a disaster so\n2452.92s: clearly that does not correlate very\n2455.02s: well so that's one thing if I look at\n2457.839s: other metrics that are more physics\n2459.88s: based so rather than eyeballing right so\n2462.76s: I'm still eyeballing but not on a\n2464.74s: snapshot so again the kinetic energy I\n2466.54s: showed you before\n2467.68s: black is the high-res low res is the\n2470.8s: gray one every single one of them gives\n2473.079s: me roughly the high level of kinetic\n2474.88s: energy I wanted now they're not all\n2477.16s: behaving the same way right you know\n2478.96s: Network shoots off like super fast\n2482.02s: um so it seems that it's time scale are\n2483.82s: much faster uh than kind of the more you\n2487.48s: know equation based one so capture\n2490.18s: something different about the physics or\n2491.8s: it just you know tries to go too far too\n2494.859s: fast\n2496.24s: um if we look at the different uh metric\n2498.64s: say the distribution so quite often\n2500.859s: we're interested whatever we're thinking\n2502.3s: rather than thinking about children so\n2503.859s: we're thinking about the climate system\n2505.18s: we're trying to understand you know\n2506.98s: extreme events right and temperature\n2508.54s: precipitation so we like to look at\n2510.7s: probability distribution function in\n2512.5s: that case\n2513.339s: so here's a probability distribution\n2516.099s: function of the you know variable that\n2517.72s: we're considering so the green one is\n2520.0s: again the course resolution one the\n2521.859s: black one is uh the high res so the high\n2525.52s: res are longer tail meaning more\n2527.38s: extremes\n2528.88s: now in this metric they're not all equal\n2531.46s: right so basically the neural net is\n2534.7s: does better at the probability\n2536.32s: distribution than the equation based one\n2539.079s: so depending on the metric that you're\n2541.0s: considering you can start seeing some\n2543.04s: differences and here it's eyeballing\n2545.2s: yeah\n2546.04s: yeah you might be getting to this but\n2547.24s: does it also so if you use a different\n2549.099s: lower resolution you know I bought you\n2551.38s: know if the boxes size was different\n2552.88s: would that also change which one was\n2554.619s: better and yeah so we did all of that\n2557.079s: yeah so I'm not going to show any of\n2558.52s: that here I think I can remember by that\n2560.02s: slide but yes there is a sensitivity to\n2562.18s: the resolution uh on which one does\n2564.579s: better and and actually\n2566.68s: yeah I'm going to talk about\n2567.76s: generalization in a second not for\n2569.5s: different resolution but for different\n2570.7s: physics so there is definitely a\n2572.32s: sensitivity but one of them quite often\n2574.72s: performed better all the time compared\n2577.839s: to the others\n2579.04s: I'll get to that in a second\n2581.079s: so eyeballing pretty good you know\n2583.48s: overall but some are better than than\n2585.099s: others so my point again offline\n2587.619s: correlations right and things like this\n2589.24s: do not directly translate into online\n2591.52s: performance so now there are two options\n2593.44s: either when you're actually picking the\n2595.0s: wrong offline metrics which that's my\n2597.339s: view I think uh or really it's magic and\n2601.599s: I don't think it is Magic\n2603.339s: um because I do think it is capturing\n2604.839s: something that is real we're just quite\n2606.76s: having fun the right metrics to fly\n2611.56s: the one that shoots up really quickly is\n2613.3s: your networks right neural networks\n2616.0s: maybe because that's because your\n2617.56s: network is trained awesome statistical\n2619.18s: equilibrium solution and it is suddenly\n2621.52s: saw a red upgrades I'm like oh what am I\n2623.44s: doing yeah so that's a great point so we\n2625.3s: thought the same\n2626.38s: but we actually gave it also data from\n2630.04s: the transient part\n2631.72s: and it still shoots off yeah\n2634.24s: but great hypothesis but yeah they don't\n2637.72s: work we we thought the same yes it has\n2641.079s: something else that I don't know it\n2642.76s: likes to be fast\n2645.9s: so one thing again that you know I say\n2649.24s: we're kind of speeding up and looking at\n2650.92s: stuff and coming up with hypothesis is\n2652.599s: one thing that we've learned as well is\n2654.04s: do not just eyeball\n2655.54s: right this is kind of one thing that\n2657.22s: I've learned and I learned it actually\n2658.359s: from you know some of our post Labs that\n2660.52s: came from computer science like don't\n2662.44s: just eyeball come up with a real you\n2664.66s: know metrics of things that you really\n2666.099s: want to compute and do it in a careful\n2668.2s: way and so for us on kind of you know\n2670.839s: the climate side there are many metrics\n2672.52s: we can think about so usually when\n2674.26s: you're trying to improve climate models\n2676.18s: out two steps the first step and I would\n2678.7s: say you know that's my personal bias is\n2680.8s: I want to improve physics okay that\n2683.2s: might not translate into improving model\n2685.66s: error but I still want the model to\n2687.46s: actually get the physics right and so\n2689.68s: for us getting the physics right is\n2691.78s: getting this kind of weird quantity\n2693.22s: which is the flux of kinetic energy from\n2695.859s: a small scale into large scale so this\n2697.78s: kind of weird curve that you have here\n2699.7s: so in a high resolution model this curve\n2701.98s: has a higher amplitude meaning we take\n2704.14s: energy from the small scale from the\n2705.7s: turbulent features and we push it\n2707.92s: upscale all right so that's how the\n2709.9s: small scale influence the large scale\n2711.28s: that's really what a closure is trying\n2713.56s: to capture and so well rather than just\n2716.38s: eyeballing to curve we can come up with\n2718.48s: a metric that actually computes the\n2720.339s: distance between the two curves so the\n2721.839s: simple score right simple similarity is\n2724.3s: called that actually computes if you're\n2726.28s: doing well and especially when you want\n2727.78s: to compare with many models you want to\n2729.819s: add something that is robust rather than\n2731.26s: just eyeballing things\n2732.7s: so that's metric number one right and\n2734.92s: that can be one of them there are many\n2736.48s: of them each one of you for your problem\n2737.98s: you should think about what's the\n2739.54s: physics you're trying to improve and try\n2741.579s: to compute What's missing\n2743.079s: now again as I say when you improve\n2744.579s: physics you don't necessarily improve\n2745.78s: the climate models and climate model\n2747.4s: developers know that also well usually\n2750.099s: when you fix one thing of the physics\n2752.079s: you usually break about 20 others and\n2754.18s: you don't necessarily improve your\n2755.38s: client simulation but we still aim for\n2757.42s: it right so the second thing is you want\n2759.339s: to improve the direct variables that you\n2761.02s: care about as I said the distribution of\n2762.88s: precipitation over North America or in\n2765.88s: the temperature over Europe\n2768.04s: so here's another way to calculate in\n2770.079s: metrics and improving variables is you\n2772.359s: can calculate basically differences\n2773.5s: between probability distribution\n2774.819s: function right so there are many metrics\n2777.52s: and distances to compute that but that's\n2779.38s: another score that you can think about\n2781.119s: and of course you can have many of those\n2783.46s: access right so you want your\n2784.72s: parameterization to capture as menu of\n2787.24s: those metrics as possible depending on\n2788.859s: the problem that you have and that\n2790.119s: you're interested in\n2793.54s: so now let's try and look at performance\n2795.339s: right so we took almost parameterization\n2797.44s: so let's take a step back for a second\n2799.54s: you remember we have three different\n2801.22s: type of filters right so we have three\n2803.079s: different ways to compute a\n2804.339s: parameterization\n2805.66s: we can also play with the type of input\n2808.119s: that we put in right different you know\n2811.839s: different fields of their gradients and\n2814.0s: so on and so forth and trying to learn\n2816.16s: you know this missing forcing and we're\n2819.04s: gonna measure it in two ways in this\n2820.78s: kind of boxes so when we go up here this\n2824.319s: is gonna be really really good and we're\n2826.18s: pretty happy when we're done here it's\n2828.4s: really bad okay and we're gonna end\n2830.8s: those two axis one is going to be how\n2832.599s: well do we do for this physics\n2834.819s: aspect right so how much do we capture\n2837.099s: this transfer of energy from small scale\n2838.96s: to large scale and over here how well do\n2841.9s: we actually capture the probability\n2844.54s: distribution function and the extremes\n2846.579s: after we plot them\n2848.619s: so again\n2850.0s: let's see what happens so it's going to\n2851.92s: be a hundred and something simulations\n2853.839s: you're going to see a lot of dots all\n2855.7s: right so three different neural network\n2858.88s: with the three different type of\n2860.319s: filtering\n2861.579s: this thing that is called back scatter\n2863.56s: this is the physics-based\n2864.94s: parameterization that was developed\n2866.38s: about a decade ago that does perform\n2868.359s: very well as well as well so and then a\n2870.7s: couple of hybrid ones that we came up\n2872.68s: with so data driven equation discovered\n2876.76s: okay so first huge spread right so let's\n2880.78s: start with that some of them are\n2882.76s: terrible uh down here some of them do\n2885.88s: quite well so a few things that I want\n2888.46s: to point out so one of them the\n2890.8s: sensitivity to the filtering is huge so\n2894.52s: if you look at the different colors\n2895.72s: right so green red and pink so the pinks\n2899.02s: are all over here\n2900.579s: then you know the green that are all up\n2902.68s: here and the reds are all up here so\n2904.48s: each one of them is like a different\n2905.619s: inputs and you know different\n2906.94s: constraints but really you can see the\n2909.7s: three clouds of dots which are three\n2911.98s: different filters\n2913.24s: so one filter is better than another\n2915.819s: and that's kind of pretty much a given\n2918.28s: without even changing anything about the\n2920.2s: architecture the type of filter that you\n2921.88s: use can already kind of tell you on\n2923.98s: which part of that plot you're gonna be\n2925.54s: if you're going to be done here or over\n2927.7s: here\n2929.02s: um you know sadly for quite some time\n2931.119s: I've been using this filter that puts\n2933.16s: you over here so uh it was a good thing\n2935.56s: that we stopped and start to rethink a\n2937.48s: little bit how we do our filtering so\n2939.099s: that already tells you that then of\n2940.48s: course you know the input that you're\n2941.5s: going to use can give you a huge range\n2943.78s: of spread right so it can give you a\n2946.96s: huge range of performance on how well\n2949.0s: you're doing improving physics and\n2950.859s: improving the variables that you can so\n2953.319s: this first step of really learning or\n2955.96s: figuring out what you're trying to learn\n2957.46s: can have a pretty big influence on what\n2958.96s: you're looking at and of course we can\n2960.52s: only do those type of tests in simple\n2962.859s: models right and that's why we took a\n2964.72s: step back to actually be able to\n2965.98s: actually pinpoint and develop this new\n2968.079s: sets\n2969.22s: now if we look at you know some of the\n2971.079s: physics-based parameterization and the\n2972.88s: date that ribbon one and one of the CNN\n2974.619s: we have quite a few of them that perform\n2976.3s: extremely well up here okay so the ones\n2979.06s: that we saw before you know they do\n2980.98s: quite well and you know we're pretty\n2982.96s: pleased with that but again you can get\n2984.94s: things that are really important\n2987.52s: now is it done is it over well we need\n2992.02s: more tests right so one more test is\n2993.88s: what happens if we keep the same\n2996.4s: closures that we've learned from a given\n2998.98s: configuration right given equation we\n3001.14s: learn our approacher now we want to plug\n3003.18s: it back onto the same model but\n3006.24s: same physics but a little difference\n3008.88s: into some of the parameter of the\n3011.16s: simulation so in the ocean with the same\n3013.859s: equations you can get different type of\n3015.54s: regime things that look a little bit\n3017.28s: isotropic with lots of turbulence and\n3019.68s: things like that lots of turbulence but\n3021.06s: also structured so Jets right so those\n3023.7s: two solutions are solutions to the same\n3025.56s: equation with some kind of different you\n3028.44s: know tuning of parameters so to speak\n3031.02s: so now the pictures are very different\n3032.94s: so this is a high resolution a low\n3035.7s: resolution that is you can barely see\n3037.92s: any jet there are no turbulence now this\n3040.38s: is the low resolution plus the\n3042.599s: physics-based parameterization\n3044.7s: I see no difference comparable cross\n3046.74s: resolution right\n3048.18s: um seems to have made nothing uh no\n3050.52s: improvements whatsoever if we look at\n3052.68s: the neural network now it's a disaster\n3054.72s: right uh it was one of our top\n3056.88s: performing one but now it's actually\n3058.92s: trying to behave like a homogeneous\n3061.2s: German style future so basically try to\n3063.839s: overdo it so you know that's you know\n3066.059s: one big problem the hybrid symbolic\n3068.7s: expression so the equation is double one\n3070.319s: actually does quite well still under\n3072.24s: that so more robust right a few more\n3075.66s: only a few parameters by learning this\n3077.46s: equation discovered one but definitely\n3079.319s: more robust different regimes so less\n3082.74s: parameter you might not get the best\n3084.48s: scale offline but you might actually\n3086.16s: have something that is robust across you\n3088.5s: know different skills\n3090.0s: so I have no idea how many one on time\n3091.619s: yeah okay so let me close with a few\n3094.079s: thoughts uh because I think I'm at the\n3096.0s: end so you know there are a few things\n3098.04s: here that we can say right so Framing\n3099.54s: and setup is is very much Paramount\n3101.88s: right to what we're doing so always\n3103.559s: taking a step back and thinking about\n3105.059s: how do you want to frame you know your\n3106.92s: problem uh how you want to think about\n3108.66s: it and so again the right valuables and\n3110.7s: the filtering so Ryan was saying a few\n3112.859s: of us are interested so there's a\n3114.18s: package GCM filter can help you to use\n3116.64s: Ocean Models with you know geometries\n3118.319s: and so on so actually uh deal with this\n3120.54s: filtering issues uh and how to do it\n3122.579s: physics constraints are pretty important\n3124.98s: but they're not enough right so\n3126.66s: developing new tools is going to be very\n3128.16s: important and so that's why this kind of\n3130.02s: you know dialogue between different you\n3132.0s: know different different uh Community is\n3133.8s: super important and that goes back to\n3135.18s: the point of robustness\n3137.46s: data set evaluation and metrics I\n3139.68s: believe they have to be best and robust\n3141.599s: and so again every time we have to step\n3143.22s: back you know try to think about what is\n3145.02s: it that we're trying to improve uh and\n3147.119s: it might not be the same for you know\n3149.04s: for the problems that you're going out\n3151.68s: and one thing I've been showing and I'm\n3153.599s: not going to show it because just I'm\n3154.74s: running out of time but needs mix and\n3156.599s: match actually works meaning that if I\n3159.24s: learn a parametronization with a given\n3160.859s: data set and I implemented in a\n3163.2s: different model which was not the same\n3165.359s: model I trained on we actually find that\n3167.4s: it works to say the only problem is you\n3170.099s: need to be tuned everything quite often\n3171.599s: and so the old problems are the same as\n3174.18s: the new one so the new ones are the same\n3177.24s: as your problems all right and so that's\n3179.339s: that means that you know there are a lot\n3180.96s: of tuning and a lot of ideas around\n3182.46s: tuning that are going to be pretty\n3183.72s: important\n3185.7s: so just uh I'm going to skip the\n3187.619s: implementation in things but I just want\n3189.96s: to say a couple of stuff so I mentioned\n3191.7s: earlier that you know we had a lot of\n3193.2s: projects called M squared line and you\n3195.18s: know part of that project has been\n3196.5s: really trying to find also the right\n3197.7s: balance between you know machine\n3199.559s: learning physics to improve climate\n3201.54s: model and I think it's going to take you\n3202.859s: know quite some time and that's it\n3203.94s: that's why we need a community\n3205.44s: so I just wanted to you know bring up a\n3207.24s: couple of stuff that might be helpful to\n3209.46s: some of you so one of them is you know\n3211.319s: how do you move forward as a community\n3212.64s: when you speak different languages right\n3214.5s: so one thing that we try to put together\n3216.66s: was this Jupiter book\n3219.18s: um that you know was developed by the\n3220.559s: team members pis and the early career\n3222.48s: scientists that goes literally through\n3225.3s: our proposal which is how do you come up\n3227.64s: with machine learning parameterization\n3229.319s: uh using data and here really the goal\n3232.559s: is to teach machine learning experts\n3234.42s: what a parametralization here what a\n3235.98s: climate model is what a numerical scheme\n3238.02s: is and also the climate scientists how\n3240.3s: do you train a neural network how does\n3241.74s: it work how do you play with it so this\n3243.359s: is all online and open source and and\n3245.339s: you know you can uh you know use it and\n3247.92s: hopefully it might be useful for those\n3249.42s: of you who actually try to learn one\n3251.819s: piece of that problem so I think you\n3253.8s: know we're doing the common language and\n3255.119s: sometimes it takes a little bit of time\n3256.26s: but I think it's worth it other tools\n3258.72s: that we have online is all those machine\n3260.099s: learning algorithm and trained model\n3261.48s: right so we're trying to put them out\n3262.859s: there so they're on GitHub and so you\n3264.78s: know I think it's very important for\n3265.92s: people to learn how to leverage many of\n3268.44s: those tools so whether there are so\n3269.94s: somebody else right but quite often it\n3272.64s: requires a little bit of work and effort\n3274.319s: so again making sure that finding the\n3276.54s: right connection across different\n3277.74s: Community I think is going to be very\n3279.119s: important and hopefully some of the\n3280.8s: focus will that will happen in over over\n3282.9s: the coming month will help with some of\n3284.88s: that and so hopefully some of the tools\n3286.92s: we have developed might be of use to\n3288.96s: some of you and you know finally you\n3291.0s: know we're thinking of Frameworks right\n3292.559s: sometimes we are stuck with one thing\n3294.78s: and we keep pushing it forward and we\n3296.819s: think we're on the right path and\n3298.2s: sometimes taking a step back for a\n3300.54s: second or rethinking you know are those\n3302.339s: the right hypothesis and the right thing\n3303.78s: we're looking for\n3305.099s: um I think it's always a little bit\n3306.3s: important especially when you move into\n3307.68s: a new field that moves very fast\n3310.38s: and so you know I think we need\n3312.839s: everybody right so so I think it's a\n3314.7s: great time to be creative whether you\n3316.619s: come from computer science data science\n3318.48s: stats climate I think that a lot of you\n3320.7s: know great problems and challenges ahead\n3322.74s: of us and you know many open question\n3324.839s: but also a lot of excitement right we\n3326.88s: are developing new ideas as we go along\n3329.16s: and I think it's a very exciting time to\n3330.96s: be a doctor keep and I'm very excited\n3334.2s: so thanks a lot everyone\n3341.46s: here\n3361.76s: data for the machine to use do you think\n3365.339s: the correct building might depends on\n3367.319s: the numerical methods of the of the\n3369.48s: modeling I imagine the QV might be a\n3372.54s: through the spectral one and then I'm a\n3375.9s: tgcm is this final volume\n3378.059s: then there might be different 100 yeah I\n3381.54s: actually believe that we need a good\n3383.04s: understanding of the model that we're\n3384.24s: going to plug it back in and both the\n3386.099s: one that we developed from so yes I\n3387.96s: believe that there's a strong\n3388.8s: correlation between the numerics and the\n3391.079s: filtering and that's one thing that\n3392.94s: we're able to find by doing things with\n3395.28s: different numerics and different jobs\n3396.96s: yeah absolutely yeah 100\n3400.2s: and another one okay\n3407.42s: totally now they're supposed to be\n3409.74s: commutes with like the potential say\n3412.319s: taking Divergence or something as well\n3414.599s: those ones that you've tried and agreed\n3416.88s: yes yes that's one of them yes\n3418.68s: definitely\n3420.359s: then is it the better one other words in\n3423.359s: between oh yeah it's an in-between one\n3429.24s: other questions here yeah\n3436.88s: so I try to appreciate the culture\n3440.04s: because of a closer I've managed me\n3442.02s: about the input\n3443.46s: um could be low dimensional from the\n3445.5s: long resolution and the output is also\n3447.72s: the low resolution and the closure is\n3450.0s: trying to capture the high dimensional\n3451.859s: so machine learning and especially deep\n3455.099s: learning is really good at Parish riding\n3459.0s: um High dimensional complicated\n3461.4s: relations so\n3464.339s: maybe you can elaborate a little bit\n3466.38s: about you have a low dimensional input\n3469.14s: and low level output like where does the\n3472.14s: High dimensionality\n3474.72s: um\n3475.619s: come in so that what is particularly\n3479.04s: trying to learn what is the high\n3481.2s: dimensionality in our relationship yeah\n3483.42s: so that relationship is actually High\n3485.52s: dimensional right so even though you\n3487.68s: mapped it onto a coarser and lower\n3489.72s: dimension\n3491.04s: because you're you're not learning the\n3493.14s: viable itself you're only learning the\n3495.54s: kick that that variable will have on the\n3498.599s: low resolution model so that mapping is\n3500.76s: exactly kind of the high you know the\n3503.04s: high dimensional system of the high\n3504.359s: dimensional relationship that you're\n3505.559s: looking for except that you never go\n3507.66s: back onto the high resolution resolution\n3510.54s: you're only trying to capture this High\n3513.0s: dimensional relationship in a blue\n3515.28s: dimensional space\n3516.839s: and that's why yeah that's why deep\n3518.4s: learning is very good at it is because\n3519.839s: the granularity of the problem is\n3521.88s: actually a high dimension\n3524.94s: and the people online and make\n3526.92s: themselves and ask their questions is\n3528.78s: that possible or can she hit\n3538.799s: I can I can read them can you read them\n3541.619s: okay can you just read it out so\n3542.819s: everyone can see sure uh by improving\n3545.099s: the performance of course resolution\n3546.66s: climate models with them now I'm\n3548.64s: essentially training the parameter or\n3550.92s: building better physics-based\n3552.48s: boundatorization and course resolution\n3554.04s: model yeah so that's a great question so\n3556.5s: in this example that I showed we learned\n3558.54s: in learning new parameterization so\n3560.819s: we're not tuning an existing parameter\n3564.48s: of an existing parametralization now\n3566.7s: other people I mean are tuning\n3569.46s: parameters in our case we didn't but\n3571.92s: this is something we're actually doing\n3573.18s: both with all the new using\n3574.98s: reinforcement learning\n3576.78s: um yeah that's a very good question\n3577.799s: second question how do you think how is\n3581.28s: spatial and temporal resolution\n3582.839s: satellite observation can help improve\n3585.059s: uh course resolution climate model with\n3587.16s: the amount technique so that's a great\n3589.02s: question uh I think it's going to be uh\n3591.18s: it depends a little bit on the output\n3593.04s: that you're looking at for the ocean I\n3595.68s: don't think we have enough uh spatial\n3597.9s: resolution with the satellite that\n3599.4s: symmetry that we have to even capture\n3601.44s: the mesoscale field it might change in\n3603.599s: the future you know very much so our\n3606.9s: view has been to try to use a lot of\n3609.839s: Truth data coming up simulation and then\n3612.9s: trying to see if we can bring some of\n3614.64s: the observation in by retruning so more\n3617.52s: transfer learning or something like this\n3619.02s: but choosing observation alone again for\n3621.839s: the ocean is just that we don't have\n3622.92s: enough resolution yet that's answering\n3624.96s: the question\n3629.04s: uh hello Laurie uh this is Eric gal I\n3632.28s: just I just read these two questions\n3633.96s: thanks so much for answering these\n3636.119s: questions on Amazon from the University\n3638.4s: of Maryland I don't do stuff in climate\n3641.22s: modeling but uh and I've put I've been\n3644.099s: doing research in remote sensing on\n3646.44s: domain so uh I I was interested in like\n3650.579s: because the go of leap is to try to uh\n3653.64s: uh make the best use of satellite\n3656.64s: observations or other type of Divisions\n3659.22s: to climate modeling so uh how because in\n3663.78s: your presentation you only use the high\n3666.72s: resolution climate simulation as the\n3668.64s: input and it didn't mention any you know\n3671.28s: a satellite or any other observations so\n3674.52s: I was wondering how like the high\n3677.52s: resolution satellite observations can be\n3679.799s: used to improve the physics space their\n3683.04s: permitarizations\n3684.599s: yeah absolutely thanks a lot for the\n3686.52s: questions and yeah I mean as mentioned\n3688.859s: that's true I only use data coming up\n3690.78s: out of simulations I I do believe again\n3693.299s: for the ocean the estimator is probably\n3695.88s: one of the best you know uh tools that\n3698.16s: we have out there I'm a huge fan of it\n3699.599s: but to capture the subgrid Dynamics\n3702.44s: unfortunately we just by itself\n3704.76s: satellite data won't be enough for us\n3706.559s: right now it might very much change in\n3708.299s: the future but by itself I don't think\n3710.339s: it's enough I think it can complement\n3711.839s: the numerical simulation at least that's\n3713.94s: my hope and something we're trying to\n3715.2s: test and I agree I think when they need\n3717.119s: it's very important to find out how we\n3718.98s: can reach you know different type of\n3720.78s: data together uh to improve closures\n3723.839s: yeah I'll just uh this is Gary McKinley\n3726.299s: deputy director I believe uh you know\n3728.16s: there are other projects within leaf\n3729.66s: that are looking at uh clouds looking at\n3732.9s: the carbon cycle looking at other things\n3734.819s: and then those satellite data are a\n3737.88s: significant input so\n3739.74s: um there's a lot more going on in the\n3741.839s: project\n3746.359s: so I was wondering about the role of the\n3749.28s: atmosphere in crafting or like you know\n3752.119s: determining or governing the structure\n3754.38s: of some of those uh you know some of\n3756.24s: those beautiful movies you showed right\n3757.44s: so you know what we're what we're\n3759.24s: considering the atmosphere only you know\n3760.799s: we kind of think about of the SST as\n3762.48s: like a boundary condition but it really\n3764.099s: does craft into some of the features and\n3765.72s: files in the lines and the structure we\n3767.7s: see and so my first part was to what\n3770.22s: extent does that um should that come\n3771.839s: into play when one is trying to come up\n3773.579s: with a parameterization of the ocean and\n3775.319s: then my second question is when you\n3776.76s: develop you know parameters offline I\n3779.16s: put them online\n3780.24s: is it possible you might have like a\n3782.64s: really good prioritization but you can't\n3784.619s: talk with the deficient atmosphere at\n3786.599s: present and it's necessary it's making\n3787.74s: you look like you're bad but it might be\n3789.359s: better because it's tuned against a\n3791.16s: deficient atmosphere current position or\n3793.26s: set of parametrizations great questions\n3796.559s: um so for the first one\n3798.359s: um how is the role of atmospheric\n3800.099s: forcing onto um you know ocean\n3801.54s: turbulence so I think it's definitely\n3803.099s: one of the drivers right so\n3805.5s: um actually one of my projects in leap\n3807.72s: is to look at you know LC interaction\n3809.819s: including you know the turbulence style\n3811.859s: so that's something really we are trying\n3813.839s: to push\n3815.099s: um of course a month of data is pretty\n3817.38s: tricky here right because both the\n3819.839s: atmosphere and and the ocean need to\n3821.76s: have high enough you know connection to\n3823.74s: actually capture that driver so that's a\n3825.48s: great question and definitely one that\n3827.099s: you know is a question mark they are\n3829.14s: some papers out there that have been\n3831.059s: looking at you know the exchange between\n3833.22s: the Eddies and the atmosphere and so on\n3834.9s: and so forth especially in Gulfstream\n3836.819s: and Croatia region so definitely a lot a\n3839.28s: lot of both scientific question not even\n3841.079s: just on the closure problem but just\n3842.88s: open scientific question on the\n3844.26s: interaction and the coupling so great\n3846.78s: question definitely one that we are\n3848.579s: planning on tackling now the question is\n3850.68s: yeah we developed amateurization in\n3852.42s: isolation\n3853.5s: and not just of the atmosphere right of\n3855.54s: all the other scales it's a multi-scale\n3857.64s: problem so every time we're breaking\n3859.2s: things into pieces and I think that's\n3861.24s: one of the issues right we're going to\n3862.44s: talk to other skills other pieces of the\n3865.26s: climate system and you might be missing\n3867.9s: something super important so that's why\n3869.88s: what we're trying to do is to use as\n3871.92s: many type of data sets as possible so\n3874.799s: again some quite idealized all the way\n3876.72s: to things that are complicated that have\n3878.22s: more and more interactions to see how\n3880.68s: robust we are but also how can we\n3882.48s: capture those additional interactions\n3883.98s: that we didn't capture before try to\n3885.96s: improve it yeah it's a great question\n3887.28s: yeah\n3890.7s: you can have a clear variation\n3893.339s: um\n3894.599s: can you go back to the slide where\n3897.059s: um\n3898.559s: um the\n3902.099s: it hasn't take really any notes on like\n3904.98s: resolve versus like unresolved um\n3911.359s: tell me more\n3916.079s: the wall with like the red and blue\n3917.88s: dolls\n3919.02s: red and blue I don't know I mean it's a\n3921.24s: very simple one\n3924.48s: yeah yeah\n3933.78s: okay yeah\n3937.02s: sorry there's so many dots in my plots I\n3939.96s: was my fault don't worry\n3944.28s: we're getting there this one yeah\n3951.92s: so you take your um you take your\n3954.42s: differential equation right\n3957.0s: um and part of that equation uh will I\n3959.88s: have a term that is what we call the\n3961.92s: advection term so that's a normal term\n3963.78s: that is the dot product between the\n3966.599s: velocity and the gradients of velocity\n3968.4s: or the gradient of temperature and\n3970.44s: that's that's a term of the dynamical\n3972.96s: equation coming up from the navigation\n3974.76s: so that's what we mean resolved meaning\n3977.04s: we're not coming up with an\n3979.14s: approximation for that it's 100 unagreed\n3982.74s: calculated on a grid now everything else\n3986.16s: only other blue and kind of pinkish dots\n3989.819s: all of that is not directly part of your\n3992.88s: continuous you know navigation are those\n3996.48s: approximation of all the processes that\n3998.76s: are happening that are below the grid\n4000.799s: box size that we literally came up with\n4003.92s: a closure\n4009.73s: [Music]\n4013.059s: yeah I'm not even that's why I didn't\n4015.68s: want to explain it it's a whole bunch of\n4017.78s: turbulent mixing processes in the ocean\n4020.359s: vertical horizontal and along what we\n4023.24s: call isopycles which are density layers\n4026.0s: so all the things that are below the\n4027.5s: grid box size that the model does not\n4030.02s: resolve does not capture if you guys in\n4032.359s: your paper you're talking about Jess and\n4033.799s: Eddies and so I just saw those two were\n4035.359s: two types of chests and like just\n4037.52s: different type of eddies contribution\n4040.22s: yeah foreign\n4069.45s: [Music]\n4078.7s: is not calculated as an average of many\n4082.94s: many implementation it could be the the\n4085.76s: error for a particular observation right\n4088.94s: so here it's an average over many years\n4092.0s: of the simulation so the system test\n4094.22s: temperature average over many years of\n4096.259s: that simulation minus\n4099.679s: many years of csfs temperature from\n4102.08s: observation what we call a climatology\n4104.299s: basically kind of the steady state\n4105.799s: confusion so that's actually similar but\n4108.259s: my question is is that if the closure\n4112.339s: taking to the input the input is not the\n4115.279s: all the forcing all the process as you\n4117.679s: said it's not it does not include other\n4119.359s: person then in the closure of stuff\n4122.06s: stick I have some stochastic that means\n4125.9s: that you have a certain for certain\n4128.359s: internal location or for certain thing\n4130.219s: you have been reducible error so when\n4133.219s: you when you measure a particular\n4135.739s: prediction against a real high\n4138.199s: resolution simulation that you may\n4140.239s: actually always have arrow and and and\n4143.42s: then that error may have a different\n4145.04s: variability even different initial\n4147.56s: conditions so therefore when you\n4149.0s: consider metrics you should\n4155.679s: we're saying that the anticipated in\n4159.739s: reducible variability you should call\n4161.42s: that success rather than a failure it's\n4164.06s: like for example some of the location\n4165.44s: may just naturally have higher\n4167.54s: variability than nothing\n4169.04s: that's so that's a great question so\n4170.96s: I'll try and boil it down in a few\n4172.1s: pieces so there are different sources of\n4173.96s: uncertainty come from some come from the\n4176.779s: natural viability of the climate system\n4178.46s: right and so the world has many\n4181.16s: realization and so that's one part of if\n4183.98s: you want the error\n4186.02s: um and so yeah being able to you know\n4188.299s: dissociate between what's internal\n4190.279s: versus what's you know coming from the\n4192.5s: missing forcing is definitely one piece\n4194.239s: so here we're really focusing on a piece\n4196.64s: of the missing physics now you know how\n4199.34s: much of that is random or stochastic\n4201.44s: we're still trying to mimic turbulence\n4203.48s: right uh really really deterministic\n4207.14s: right so so this is something we have to\n4209.42s: also take into account\n4211.219s: um there will be part of the reducible\n4213.08s: error because at the end of the day\n4215.0s: doesn't matter how Magic Machine\n4217.04s: learning is or data Sciences we only do\n4219.5s: an approximation\n4220.88s: and so there will be a piece that is\n4223.1s: irreducible\n4230.6s: correct so\n4235.58s: that's correct yeah so yeah I mean some\n4237.8s: of our work would do derive stochastic\n4239.659s: parametrization and we do take into\n4241.28s: account the stochasticity as one of the\n4243.14s: area absolutely\n4247.04s: yeah I think uh I have actually two\n4250.4s: questions about a rental by the way uh\n4252.86s: the first one is I'm just asking the\n4255.14s: question also myself like are we being\n4257.54s: fair you know when we evaluate models\n4259.52s: right in the sense because we can Define\n4262.159s: as many glasses as you want you know and\n4263.9s: as you said here there's a zoo of them\n4265.64s: right and then you basically machine\n4268.159s: learning is Big yeah but what is your\n4269.9s: target where's your cost right so I\n4271.76s: don't know I appreciate you I'm not the\n4273.08s: princess you could add your momentum and\n4275.06s: then you might want to look at your TV\n4276.5s: and you could have like different terms\n4278.0s: and you can think different types\n4279.58s: different spatial skills as well right\n4281.96s: so what do we choose right yeah\n4284.48s: absolutely\n4286.04s: um I I'll go back to my kind of so my\n4288.98s: boring answer is we need to have as many\n4291.26s: as we need and four different\n4294.5s: for different problems you will have\n4296.48s: different targets I you know for a long\n4299.3s: time I've been thinking about this idea\n4300.739s: of you know seamless you know simulation\n4302.9s: can actually get a model that will be as\n4305.179s: good on whether timescale that will be\n4306.86s: on climate time scale right if you add\n4308.659s: you know as many resources as you want\n4310.58s: then you know given the limited\n4312.8s: resources and the solution we're coming\n4314.06s: up with then we're seeing that it is a\n4316.58s: very difficult problem so I believe at\n4319.1s: the end of the day you know that's why\n4320.179s: the human part comes in\n4322.04s: it's not like machine learning when we\n4323.54s: Define a loss here we have to be there\n4325.28s: in California how we Define the metrics\n4327.38s: we're looking at and again are we\n4329.6s: targeting physics or are we targeting\n4331.34s: you know\n4332.54s: say your probability of temperature so\n4334.46s: then you can make decisions or you can\n4336.199s: build infrastructure you might not want\n4337.76s: to add the right physics but you might\n4339.44s: wonder why the right variables over a\n4341.48s: short amount of time and I think that's\n4343.159s: why the human component comes about is\n4345.14s: how do you frame your problem\n4347.3s: yeah it's a tough one and then make it a\n4350.42s: pretty good question also ready to\n4351.739s: Chances is it just a matter of\n4353.6s: resolution can we just sit back relax\n4355.64s: wait for a few years come back you know\n4357.98s: and then everything is solved you know\n4359.9s: we have some big gpus on tpus yeah I\n4363.08s: mean we all know that there are many\n4364.4s: pieces of the system that we will never\n4366.32s: solve right even if we increasing\n4369.02s: compute power that part of the system\n4370.58s: for which we don't even have equations I\n4372.86s: mean you know when I talk about the\n4373.88s: ocean I always make the comment that we\n4375.26s: don't even have a given equation\n4377.9s: you know for the atmosphere you have the\n4379.4s: idea of gasoline you know how to relate\n4381.02s: you know temperature pressure and other\n4382.699s: things to the ocean we do a terror\n4384.5s: extension\n4386.36s: so you know this is one of the basic\n4388.76s: properties of you know of the ocean\n4391.1s: so I think we should try it on I think I\n4394.4s: would love more resolution but then I\n4397.159s: can think about sea level wise around\n4398.659s: the coast where many of the processes\n4400.88s: are really you know the boundary layer\n4403.46s: scale so you know we're going to run a\n4405.38s: climate model for 100 years\n4407.659s: I think we should go after everything\n4412.699s: online okay so I'm reading\n4418.4s: hello hello Lori uh Erica from\n4421.159s: University of Maryland again\n4423.56s: um so two questions the first is based\n4425.9s: on the a previous question about and\n4428.42s: resolved processes so I I understand\n4431.78s: like for subgrade processes uh the\n4435.199s: parameters are not calculated or uh\n4438.739s: projected continuously uh within the\n4441.739s: time time step so you need to uh uh have\n4445.58s: this have this have this variables uh\n4449.48s: approximated oh what you are doing is\n4453.32s: try to use machine learning to to\n4455.84s: improve the parameterization process oh\n4459.26s: so I guess in the machine learning based\n4462.34s: parameterization is better than the\n4464.84s: traditional parameterization so my\n4466.4s: question is open Forum machine learning\n4468.86s: technique how people develop this\n4471.86s: parameterization process\n4474.26s: yeah a great question so quite a few\n4477.86s: different ways um so I'll take you know\n4480.08s: a simple example which is mixing\n4482.6s: um so we know that mixing should happen\n4484.159s: kind of at the molecular scale and so\n4486.38s: mathematically it's going to be the\n4487.64s: laplacian of the variable that you're\n4489.679s: looking for now we know mix we can't\n4491.9s: resolve those scales right but we know\n4493.699s: that turbulence part of the turbulence\n4495.199s: does mix so at the end of the day it\n4497.42s: should be diffusing stuff\n4498.92s: so people just assume you can keep the\n4501.14s: same operator and you'll just crank up\n4503.12s: the number in front of it so I'm\n4504.86s: exaggerating a little bit but you know\n4506.96s: this is kind of you know one way so\n4508.88s: trying to think about what is the effect\n4510.56s: of the process you're missing and trying\n4512.96s: to come up with a mathematical framework\n4514.94s: or representation for it and then you\n4517.219s: always end up with a free parameter that\n4519.86s: you either you know try to fit with data\n4523.1s: if you have enough data time if you're\n4524.659s: lucky uh or you run menu Miracle\n4526.94s: simulation and try to actually come up\n4528.38s: with scaling laws for it and so on and\n4530.48s: so forth so there are quite a few ways\n4532.46s: to kind of come at it it's really a mix\n4534.08s: between you know Theory understanding of\n4536.719s: the process and then you know some\n4539.239s: assumptions about what you can do with\n4541.52s: it\n4542.6s: and and this is something you know many\n4544.4s: of us it's not a criticism for\n4545.96s: amateurization I've developed some\n4547.699s: myself so you know this is also the way\n4550.1s: we think about it and with machine\n4551.719s: learning we commit at it from data we\n4553.76s: end up with something then we still need\n4555.32s: to understand it so even when we came up\n4557.239s: with the equation discovered one we had\n4559.1s: to take a step back and think about it\n4560.6s: what are the equations that we're\n4562.159s: getting do they mean something\n4563.36s: physically and I think that's still\n4565.219s: remain a very important piece of it\n4568.159s: yeah yeah that makes sense thanks and\n4570.739s: the second question is so here uh the\n4573.739s: direction is you use machine learning to\n4576.5s: try to get some new physics and plug it\n4579.08s: into the currently uh existing physics\n4581.96s: models while another document is people\n4584.36s: build a completely new artificial\n4587.36s: intelligence based Network to train the\n4589.64s: network and plug some Physics into the\n4592.04s: artificial intelligence or some Network\n4593.78s: neural networks so do you think this is\n4596.78s: something promising like probably in the\n4599.42s: next few decades people develop another\n4601.28s: new set of Earth System model building\n4604.219s: up on the artificial intelligence like\n4607.76s: do you think this is promising\n4610.28s: I mean there are many groups that are\n4612.739s: trying right so I think you know\n4615.38s: um I think it is an exciting part of you\n4618.02s: know many of the project is how do you\n4620.239s: find the right balance between the two\n4622.46s: um I think again I think for all of us\n4623.84s: the jury is still out right we're\n4625.159s: developing new tools and new ideas and\n4627.739s: you know some of some of them will work\n4629.3s: better than others and some will work\n4631.04s: better to answer certain type of\n4632.659s: scientific questions While others will\n4634.64s: answer a different piece of it\n4639.679s: did Shanise have a question yes do you\n4642.92s: know how the biases across data set\n4644.96s: influence uh the ml performance how the\n4648.739s: biases\n4652.06s: uh since we're on this slide it shows\n4654.739s: sea surface temperature biases and\n4657.44s: um it's across the board for multiple\n4659.06s: models so when you um you know use these\n4661.699s: high resolution data sets that have\n4663.86s: common biases do you account for that in\n4666.5s: the um your your algorithm's\n4668.54s: performances uh wonderful question so\n4672.26s: here definitely it's a you know those\n4674.179s: are course resolution simulation what we\n4676.34s: try to do is for higher resolution\n4677.719s: simulation where some of those biases or\n4680.42s: many of those biases are corrected and\n4682.82s: we try to stay away or we try to pick\n4685.4s: pieces of the data set where the biases\n4688.04s: are not large\n4689.179s: so yeah that's a excellent question on\n4691.94s: the high resolution model that we're\n4693.26s: using are still models so that means\n4695.9s: even though they have more resolution\n4697.34s: they do better they still have a lot of\n4700.219s: errors in them yeah it's a wonderful\n4701.96s: question yeah"
    },
    {
        "class": "YouTubeVideo",
        "title": "Parameter Estimation for Improved Capacity of Community Land Model for Actionable Science",
        "videoId": "spv58mqzibA",
        "url": "https://www.youtube.com/watch?v=spv58mqzibA",
        "publishedAt": "2023-04-28T02:48:19Z",
        "transcript": "12.5s: [Music]\n15.08s: he's a senior scientist and section\n17.64s: ahead\n18.779s: um of the land uh working group\n20.58s: attendance been doing a lot of amazing\n23.22s: work on CLM the Community Land model\n25.199s: like looking at a lot of developments\n27.3s: and making a lot of great science there\n29.34s: he was interim director at uh encount uh\n33.54s: until very recently yeah\n40.98s: um yeah we are very much looking forward\n42.6s: to uh to your talk so it's been doing a\n44.76s: lot of interesting work on basically\n47.16s: modern development within the community\n48.66s: land model and the community resistance\n50.94s: model and there has been a lot of\n52.68s: development these days that then\n54.0s: capturing to look at especially relating\n56.34s: to the primary influence environmental\n58.559s: tuning and how can we and can we even do\n61.079s: that automatically so very much looking\n63.18s: forward to it thank you great thank you\n66.119s: so thank you it's fun to be here it's\n67.799s: fun to after how many years three plus\n70.439s: years of lead to actually come finally\n72.299s: visits at Columbia\n74.76s: um getting ready and so I really enjoyed\n77.1s: um you know working within the lead\n78.84s: project and so I'm going to get the\n81.24s: chance for the first time throughout\n82.86s: this project actually talk about the\n84.36s: work that we're doing\n85.86s: I suppose like the bigger CSM picture\n87.72s: and I realized that I didn't change the\n90.24s: title from a previous talk so I don't\n91.799s: have the word parameter estimation in\n94.799s: the title which is what this will be\n96.479s: about but um but the actual science part\n98.88s: is part of this presentation so this is\n101.22s: adapted and as always uh work has done\n104.28s: by a lot of different people uh in this\n106.259s: case I really want to thank\n108.119s: um Daniel Kennedy\n110.04s: um\n111.36s: uh Katie Dagon and Lydia Hawkins Lillian\n114.18s: Hawkins is a postdoc who's working in\n116.28s: leap and Daniel and Katie our project\n118.32s: scientist and Carter who worked with me\n121.02s: um and I've kind of moved into career\n123.899s: stage where you know I'm not doing\n125.159s: hardly anything and so really they're\n127.14s: the ones we've all work and some\n128.34s: actually happening to get used to be\n129.84s: presenting other people's work\n131.7s: um that's the way it goes uh but they\n133.68s: did all the work and\n135.18s: um in a lot of ways put put together a\n136.739s: lot of the presentation as well so kudos\n138.66s: for them\n139.739s: okay so big picture climate science is\n142.98s: in transition in my opinion in a lot of\n145.379s: people's transition uh opinion you know\n147.42s: we're moving away from and this is Lee\n149.28s: I'm telling you guys what you've already\n150.599s: you know leap\n152.94s: um is getting the space so you know\n154.68s: we've known you know for a long time\n156.66s: that climate change is happening we've\n157.98s: proven with our system models uh how\n160.68s: much climate change is going to happen\n163.08s: um under different scenarios of missions\n165.72s: um so the question is no longer you know\n167.4s: is climate change happening or gonna\n169.68s: happen it's really\n171.12s: um a change to to the question of you\n174.06s: know how what are we going to do about\n175.44s: it\n176.459s: um and how is it going to impact people\n177.66s: so you know to take climate related\n179.76s: action\n180.72s: um people need to know how where and\n183.18s: when humans and ecosystems are going to\n185.04s: be exposed to Hazard so this is the leap\n187.14s: uh sort of uh reason for for being is to\n190.739s: understand us how we're going to adapt\n192.12s: using uh understand we're going to adapt\n195.0s: and then we have to ask you know you\n196.86s: know if what extent can be reliably\n198.18s: predict these changes on of time and\n200.76s: spatial skills\n202.379s: and additionally and that's where kind\n204.36s: of there's this big meeting tomorrow\n205.319s: with the business community in New York\n206.879s: you know there's a lot more stakeholders\n208.56s: now who are interested in climate\n209.58s: information Cloud analyst companies\n211.379s: coming up all over the all over the all\n213.06s: over the place\n214.68s: um so it's in transition\n216.78s: um and that was that I was organizing at\n218.819s: workshop last\n220.68s: um fall called the land surface modeling\n222.239s: summit we've got all the years all the\n223.92s: years of modeling land groups together\n226.22s: to talk about how we can advance our\n229.22s: models faster to to be able to address\n231.599s: these questions and at the end of the\n232.86s: meeting we had this sort of the summary\n234.659s: meeting which I was I was organizing so\n236.4s: I thought I sort of don't like those\n238.379s: things at the end of meeting where\n239.519s: you're trying to say we're getting the\n240.48s: next steps I'm like okay we're going to\n242.22s: write a boring synthesis paper about all\n243.959s: the needs for for\n245.54s: the landfalls and you know to address\n247.62s: these questions and somebody said come\n249.599s: on let's stop that really what it is we\n251.879s: need to you know we need to save the\n253.68s: world we're talking ourselves in the\n255.06s: back of we land modelers are going to\n256.44s: save the world every Community is\n258.239s: required to save the world we think\n259.859s: we're going to contribute to that and\n261.479s: the questions are big right we need to\n262.979s: really address these questions will we\n264.78s: have enough water right order one\n266.46s: fundamental question it's not like who\n268.08s: cares about grammar estimation it's like\n269.58s: will we have enough water\n271.199s: will we be able to produce enough food\n272.82s: right that's the question\n275.16s: um and we'll be able to produce that\n276.3s: food sustainably\n278.4s: um where and when will people and\n279.84s: ecosystems experience marketing events\n282.479s: or to one question and from the land\n284.759s: side and the ocean side where are we\n286.38s: going to put the cargo we need to pull\n287.58s: carbon out of the atmosphere to reach\n289.5s: our low\n290.759s: um climate change goals absolutely has\n292.86s: to happen there's no way you can reduce\n294.66s: emissions fast enough for strong enough\n296.16s: to do it without pulling carbon out of\n297.96s: the atmosphere and the question is you\n299.82s: know if we can hold our carbon out of\n301.38s: the atmosphere will it stay there you\n303.06s: know there could be fire there could be\n304.56s: dropped there could be Beetle killed\n306.3s: because these are like order one really\n308.16s: fundamental questions we have to address\n309.6s: it's no longer like we just got to make\n311.639s: incremental advances we need to charge\n313.56s: ahead very fast to help answer these\n316.199s: questions\n318.0s: and you know there's a lot of ways to\n319.8s: answer these questions but a fundamental\n321.24s: tool that's everyone in this room is\n322.56s: really aware is is the model they're\n324.72s: often required to answer these big\n326.28s: questions about the coupled Earth system\n330.06s: um and the model is in the center of the\n331.919s: the project it's a CSM the community or\n334.199s: System model which is a model that I've\n335.52s: been working on developing over the\n336.9s: course over the last 20 years or so\n339.479s: um and it's you know obviously a complex\n341.4s: model of the representation of your\n342.84s: system\n344.039s: um and land is an important part of this\n346.08s: and I want to argue that land you know\n349.199s: land processes are going to be quite\n350.82s: important to understand these actionable\n352.68s: Sciences mitigation these adaptation\n354.479s: questions\n355.8s: so there's a fundamental question our\n357.3s: filter processes and land models\n359.039s: important for understanding climate\n360.479s: change and I work at ncar we have all\n363.06s: the air systems scientists represented\n364.74s: there so we have you know the running\n366.36s: joke you know the oceanographers are\n367.919s: where the most important and they go oh\n369.3s: it's just the land doesn't matter you\n370.5s: know the atmosphere scientists do that\n372.12s: too and my wife happens to be an\n374.52s: oceanographer\n376.02s: um and so we have this this conversation\n378.12s: in the kitchen you know she's like why\n380.039s: you know why you exist\n382.68s: um lots of reboots you have to ask me\n385.319s: that but one of them is scientifically\n386.88s: are you sure that's really necessary\n388.74s: okay\n389.699s: I respond\n391.38s: of course it's necessary land is a\n393.539s: critical interface which Humanity\n394.919s: affects and is affected by adaptive\n397.68s: mitigates Global Environmental change\n399.84s: humans live on the land\n402.419s: and also land is where you know the\n404.22s: energy changes the water changes that\n405.96s: are being processed which then\n407.52s: controlled in near surface climate which\n409.199s: is what humans are being infected by so\n411.36s: you know land is not going to\n413.039s: necessarily control the big climate\n414.6s: changes but it's going to be really\n415.74s: important to understand that you know\n417.24s: the impact\n418.979s: I don't really need to make an argument\n420.539s: here we're all aware that this is like\n421.979s: all a fully coupled interactive problem\n425.22s: um and furthermore in in our community\n427.86s: people are getting more and more uh\n430.08s: interested and able to represent humans\n432.12s: in the system so that we can ask these\n433.56s: you know questions about\n436.139s: um about adaptation and mitigation\n437.699s: related to how humans are going to\n439.38s: actually do those things and so in CLM\n442.86s: we put a lot of effort in the last few\n444.24s: years to to include Land Management\n446.46s: processes so we have a global crop model\n448.979s: which represents eight different\n450.24s: actually now 10 different cup types when\n452.099s: we include biofuels\n454.319s: um you know we uh irrigation we treat uh\n456.84s: fertilization uh we've got for wood\n459.12s: Harvest on land which is really\n461.16s: important in the the forests are\n462.66s: producing the the the fiber that we need\n465.0s: to you know to build buildings uh we\n467.099s: have Urban environments where humans\n468.479s: live and where the climate change\n469.74s: impacts are the strongest so we\n471.0s: represent anthropogenic fire we should\n473.22s: suppressional analyze a suspended\n474.84s: questions apply so we have these\n476.699s: processes\n478.08s: um so we think we have a model that can\n479.639s: be used actionably\n481.319s: but one of the challenges is because if\n483.66s: you take the model and move it into a\n485.4s: location or if you try to study a\n487.38s: particular location almost invariably\n488.819s: you can try to study are the Heat Wave\n490.74s: that's more properly represented in you\n492.78s: know some place in India the answer is\n494.28s: going to be no right and so then people\n496.319s: say well it's not useful for me because\n498.24s: it's not accurate enough and that's\n500.039s: where he kind of get to this this\n501.36s: question of grammar estimation well I\n503.52s: guess you have to make this one more\n504.599s: point\n506.4s: um here's another example of of you know\n508.979s: what we need to have an actionable model\n511.139s: that we can use gravitation so the\n513.24s: question will we have enough water in\n514.68s: particular in the west the Colorado\n516.539s: River will we have enough water\n519.0s: um from the Colorado River going in the\n520.919s: future and obviously in the last few\n522.18s: years it's you know the answer is\n523.62s: looking like uh no\n525.959s: but if you ask whether or not versus the\n527.64s: model available to help us answer this\n529.2s: question answer that is also unfortunate\n531.3s: though so this is a plot that showed\n533.76s: um on the on the\n535.459s: y-axis is the runoff from the Upper\n537.66s: Colorado River on the x-axis of the\n540.06s: precipitation change\n542.16s: or a precipitation amount of the\n544.14s: basement and what you see is the\n545.76s: observations are here in the black line\n547.2s: there at the bottom so for a unit\n549.24s: difference in precipitation for you know\n551.22s: one year to the next what is the\n552.899s: difference of runoff from from the you\n555.839s: know in the observational Vector so you\n557.279s: see a slope there that kind of tells you\n558.72s: give you some inference of what climate\n560.64s: change with you if you had an increase\n561.54s: in precipitation any show with the\n564.12s: models again first of all the models are\n565.5s: really biased and precipitation if\n566.88s: that's the first problem\n568.62s: um you know a lot of models are sending\n570.0s: way too much precipitation uh in this\n572.22s: region what we also see is that the\n574.26s: slope uh is not the same so that means\n577.08s: that the hydrologic sensitivity the\n578.7s: amounts the runoff change you get for a\n580.92s: unit change and precipitation is\n582.48s: incorrect which means that you can't\n584.459s: just take the runoff straight out of the\n586.019s: earth System model and use it to make\n587.7s: projections and like a water management\n589.26s: model if you wanted to so that's a\n591.6s: problem right this is not an actionable\n593.22s: model so these are the kind of things\n595.8s: we're trying to address through uh\n597.48s: primary estimation okay so that brings\n599.82s: me to\n600.899s: um\n602.04s: you know to to our tour effort\n604.2s: um the community lab Mall parameter\n605.7s: coordination experiment this is an\n606.959s: effort that sort of preceded a deep and\n608.82s: then it's been uh is being Advanced by\n610.92s: the week I'll get into that in a minute\n612.18s: but we're trying to quantify you know\n614.459s: the parametric uncertainty\n616.38s: um and work towards automated\n617.519s: calibration so that we can have a model\n619.14s: that we can then quickly bring into a\n621.24s: new situation a new science question and\n624.0s: be able to get it accurate enough to be\n625.92s: able to you know actionable science\n627.3s: coming out of it\n629.16s: okay so the land model has has grown in\n632.82s: complexity quite substantially over the\n634.56s: last\n635.399s: um well 20 years since I've been\n636.779s: involved and working uh at Angkor and\n639.899s: the comprehensiveness is also doing so\n641.459s: these are great like we have more\n642.6s: science in here we have more feedback we\n644.16s: have more interactions it's more faceful\n646.2s: to the real system but coming along with\n648.54s: that is a is a really dramatically\n650.04s: increasing number of in a lot of ways\n652.019s: uncertain in many cases uncertain\n653.459s: parameters and so what on the right\n654.779s: there shows you know the complex set of\n656.94s: energy water and hydrochemical cycles\n659.339s: that representing the model and the\n660.54s: bottom indicates\n662.1s: um landscape scale processes like\n663.779s: transfers uh land use change and and\n666.42s: considering urbanization and things like\n668.82s: that how Rivers connect water across the\n671.579s: landscape\n672.66s: so sea level five the version we're\n675.18s: currently using is csm2\n677.339s: um the biochemical version which is the\n680.1s: most comprehensive version\n681.66s: um has over 200 parameters that's an\n684.06s: intense number of parameters and in fact\n685.62s: it's even worse than that because about\n687.3s: 30 of those parameters that we call\n688.98s: plant functional pipe parameter\n691.14s: and we have uh 17 plant functional types\n694.2s: in the model plus another eight but\n695.82s: they're crop types so you multiply that\n698.459s: 30 parameters with your PFT parameters\n700.32s: times 17 add that to 200 and you know\n702.959s: we're getting up to something like 400\n704.459s: 500 parameters in the model so it's an\n706.56s: intense parameter space\n708.6s: um which you know quite hard to manage\n711.54s: and yeah I just want to tell a story\n713.519s: here about the development of csm2 which\n717.0s: I used in the presentation I gave when I\n718.92s: was fortunate enough to get the CSM\n720.54s: distinguished Achievement Award for\n721.74s: building cl5 and and\n724.079s: point I was making here is we started\n725.82s: off with a with the model this is the\n727.74s: additions to the model for CEO and four\n730.38s: which is while using csm1 I'm not going\n732.42s: to go through them they're adding\n733.62s: processes a lot to ask different\n735.0s: questions about permafrosts and carbon\n736.74s: and nitrogen Cycles\n738.18s: um we had a bicycle that the analogy\n739.86s: there in my school to add some stuff on\n741.18s: it but it could still move as we move to\n743.1s: co 4.5 in the interim version on our\n745.56s: path to csm2 we added a whole bunch of\n747.48s: additional new things all again trying\n750.06s: to you know build a more comprehensive\n751.86s: representation of your system the\n753.54s: bicycle is getting more looked down and\n755.76s: by the time we got to see on five the\n757.56s: community had grown we're adding a whole\n759.12s: bunch more things including stuff coming\n760.56s: out of the hairs group\n762.36s: um and we found at that time when we\n764.459s: were trying to put them all together for\n766.019s: for csm2 that we essentially couldn't\n769.38s: control it we couldn't get it into a\n772.079s: configuration that was giving reasonable\n773.579s: results even though the physics the new\n775.8s: body chemistry was all like founded in\n777.899s: good a Good Foundations when you put it\n780.6s: all together we were not getting good\n782.639s: simulation results and part of that was\n784.92s: you know the ceilingual teams\n787.019s: successfully integrated this big pile of\n788.639s: clm5 developments from Eastern Community\n790.139s: but all these new uncertain parameters\n791.94s: especially related to the plant\n794.1s: Hydraulics I mean the Pierce group\n796.079s: related to nutrient Cycles youth\n798.18s: parameters which were not well\n799.56s: constrained in literature I'm not well\n801.6s: constrained by observations\n803.76s: and you know several things are\n805.5s: happening one of them one thing that was\n807.24s: happening is that we were finding that\n808.5s: in significant fraction of the parameter\n811.32s: space\n812.459s: um plan for not surviving through\n814.019s: spinner so we have a relatively complex\n815.82s: process to get the model carbon cycle\n818.22s: spun up soil carbon vegetation carbon\n820.5s: State spun up in the pre-industrial\n822.06s: conditions\n823.26s: and it takes a long time it would take a\n825.0s: week basically to spin the model up each\n827.279s: time what we're finding is that we make\n829.26s: our best guesses on parameters we'd run\n831.42s: the model and find enough you know large\n833.459s: boxes that have not survived through the\n835.139s: spin-up and so what this plot shows here\n836.94s: everything that's in purple means it\n839.279s: didn't live so this particular nuclear\n841.38s: procedure for a tree is on the large\n843.12s: stream\n844.38s: um you know everywhere that's its domain\n845.94s: essentially whether living anywhere\n847.26s: wasn't surviving in the tropics this\n849.36s: broadly deciduous tropical tree which\n851.459s: only surviving in the Deep Tropics where\n853.56s: it's actually a broadly evergreen trees\n855.66s: is the ones that actually live there the\n857.22s: ones are supposed to be living in the\n859.56s: like for hell weren't surviving spin-ups\n861.6s: so this was a problem we couldn't come\n863.16s: up with a configuration of the model\n865.32s: so we said okay we have Vince Anderson\n868.92s: was was our scientist there he's a he's\n871.98s: a anyone who knows and I'm not sure who\n873.6s: would know him but he's an extremely\n875.16s: smart guy you know he's one of like all\n877.139s: of you are going to be you know who has\n879.42s: the data science knowledge the machine\n881.339s: learning knowledge he's like I can solve\n883.32s: your problem I am I'm very very smart\n885.6s: and we all agreed you're very very smart\n887.82s: so he's like I'm going to come in we're\n889.199s: going to you know crime an observation\n890.519s: by Machine learning and we've got like\n892.26s: three months to solve this problem okay\n894.54s: so that we are totally naive we're like\n897.12s: okay this this can happen\n899.22s: many times every time new parameter set\n901.98s: this one's going to be perfect you guys\n903.3s: are gonna have the best model ever\n904.26s: nothing survives thinner\n906.839s: another two weeks more ideas try again\n909.06s: we went through four or five Cycles\n910.56s: because we can't do that many because it\n911.82s: takes a long time\n913.079s: meanwhile we said okay if Ben doesn't\n915.36s: succeed we do need to have a backup plan\n917.639s: so the rest of us myself and Rosie\n919.62s: Fisher and a bunch of other experts were\n920.94s: like painfully like hand tuning like I\n923.22s: think it looks like if we had a little\n924.54s: bit lower nutrient limitation we do a\n926.399s: little better in the Arctic and you'd\n927.42s: like try that out and it was like it was\n929.339s: terrible it was like scaring\n932.76s: and I was also involved in that I was\n934.68s: also running interference with our team\n936.48s: scientists who's like where is your\n937.86s: model where is your model where is your\n939.3s: model so this is the little joke I did\n941.699s: when I got this award the reenactments\n943.98s: it was in January 25th 2017 a\n945.959s: reenactment because this was during the\n947.399s: coveted times so the scene we were\n949.079s: desperately trying to finalize csm2 in\n951.6s: order to take advantage of the Cheyenne\n953.22s: Yellowstone overlap so those are super\n954.839s: computers and we had the new\n956.639s: supercomputer was coming online and we\n958.56s: were going to run all our cmap\n959.76s: simulations which is like many many\n961.86s: millions of core hours on on Yellowstone\n964.199s: in the low period finally so we had this\n966.42s: window right to do everything so uh\n969.3s: multiple extensions and they said you\n971.459s: can give us one last weekend to sort out\n972.899s: our parameter problem otherwise we'd\n974.699s: have to revert back to ceiling 4.5 which\n976.74s: was working but that was like taking\n978.6s: five years of people's effort right I\n981.06s: was gonna have to throw it I was gonna\n982.079s: have to go back to the community and say\n983.1s: we failed all your work sorry Pierre out\n986.04s: the window okay so\n988.139s: um so on the Friday before the weekend\n990.06s: you've also know our our lead um sort of\n992.579s: Tech Guy set up two new spin-ups\n995.04s: um one with the latest of events\n996.839s: management attempts military best\n998.22s: cantune parameters on Monday morning 6\n1000.68s: 45 AM we both get in the office super\n1003.079s: early and like Keith comes into my\n1004.399s: office and shows me to build the ml\n1005.899s: Calgary plans mainly dead plants didn't\n1008.12s: work another information I said that's\n1010.22s: okay it's okay we got a backup we got a\n1012.259s: new backup we're really confidence\n1013.22s: backup check the other parameter set the\n1014.959s: hand tuned one 10 minutes later he says\n1017.48s: um plants in the backup hand tune\n1019.279s: parameter or not surviving either uh-oh\n1021.98s: so this is my reenactment I actually was\n1024.26s: in my office this is my home office I\n1026.54s: closed the door with my head at the\n1028.4s: table I considered the resignation\n1030.14s: letter\n1033.14s: um 30 minutes later he uh writes back\n1035.419s: and says subscribe to that I'll get my\n1037.339s: code analysis code Dr friendly said it's\n1039.319s: great uh my bad okay so that's not\n1043.28s: sustainable right we can't survive it\n1045.02s: emotionally we can't survive it from a\n1046.64s: real world like we need something better\n1048.14s: and shooting this isn't going to work\n1050.0s: anymore\n1051.02s: um it's difficult to diagnose structural\n1052.46s: structural improvements it's challenging\n1054.38s: to incorporate new parametizations\n1056.6s: um if you have to read hand tune every\n1057.86s: time it's a practical records and\n1059.539s: knowledge base I mean none of us were\n1061.94s: there had enough experience and all they\n1063.559s: know which parameter to tune in each\n1065.179s: aspect of the model and it definitely\n1067.34s: scale with it with increasing reflection\n1068.84s: right this is just going to keep getting\n1069.98s: worse and worse and so back from all\n1072.08s: problems the second big motivation is is\n1075.62s: um\n1076.46s: is you know we don't really know what\n1078.679s: contribution the Prime Minister needs\n1080.299s: having on the overall uncertainty of the\n1081.62s: system there's been a few my studies\n1083.72s: related but really it's not really\n1085.1s: Quantified and the right should just\n1087.14s: sort of canonical figure from SEMA 5\n1089.48s: actually about showing the land carbon\n1091.7s: uptake over\n1093.2s: um over the into the future\n1095.9s: um and it's big the spread across this\n1097.82s: will see the file the spread is intense\n1099.74s: it's actually equivalent to 60 years of\n1101.66s: fossil fuel emissions so essentially\n1104.299s: we're getting very little useful\n1105.559s: information from the land and our\n1106.76s: understanding of how much carbon is\n1108.559s: going to be taken up\n1110.539s: um and that's really important did that\n1111.919s: tells us how much our permissible\n1113.12s: missions are to get to a certain climate\n1114.86s: Target so if we're not accurate here we\n1117.32s: have no real sense of what our missions\n1119.059s: need to be and it's it's a big signal\n1121.1s: it's about it's about a third of the\n1122.539s: overall total time and uncertainty\n1124.88s: um you know much of the rest is coming\n1126.32s: from clouds\n1127.82s: so we don't know how much is coming from\n1129.32s: an attorney with instructional errors\n1130.94s: and the third one is like what I\n1132.679s: mentioned beginning if we have a\n1133.82s: capability to tune these models quickly\n1137.6s: um then it's really increases\n1138.799s: accessibility for actual science and you\n1141.32s: know just on the right there I'm\n1142.28s: listening the kind of thing that we'd\n1143.66s: like to be able to answer uh but of\n1145.58s: finding it difficult to do because we\n1146.84s: can't get an actor in this model\n1149.6s: and another motivation it's not really\n1151.52s: motivation but it's an opportunity is\n1152.96s: that there's really an unprecedented\n1154.22s: availability of Earth observations right\n1155.9s: now I'm sure you guys are all aware of\n1157.76s: that you know the number of satellite uh\n1160.64s: uh observations that are out there is\n1162.22s: intense now it's hard to even keep up\n1164.299s: with all the new satellites that going\n1165.799s: up and a lot of them are are giving us\n1167.6s: really detailed interesting information\n1168.919s: about land processes and then of course\n1171.38s: there's a network of powersites around\n1172.82s: the country and around the world\n1174.679s: um there's a great new neon\n1177.02s: um data set which is you know really\n1178.76s: robust uh data sets\n1181.16s: um from Tara sites with you know really\n1182.78s: rich way of data there's lidar\n1184.94s: information they can tell a lot of\n1186.08s: forest structure there's just a lot more\n1188.24s: observations on the word even just a\n1190.58s: decade ago\n1192.74s: and the last piece is that there's new\n1195.26s: integrated metrics packages that they're\n1197.0s: available and this is a project called\n1198.38s: Island International land model\n1200.0s: benchmarking project it's a project I've\n1201.559s: been involved in uh with the GUI\n1204.32s: um to build the metrics package that\n1205.76s: allows us to routinely evaluate\n1207.86s: um diverse system models and this seems\n1209.84s: like an obvious thing to do right why\n1211.22s: haven't you done this but back when I\n1213.14s: was building cm4 I literally when we had\n1215.36s: to ask a question about how good is our\n1216.98s: gross primary productivity a key\n1218.72s: variable in the model we would sit\n1220.64s: around in a room stare at maps and go\n1223.52s: looks about right\n1225.2s: that was it no observations nothing just\n1227.72s: like it seems reasonable it's higher in\n1229.82s: the topic than the latitude that is what\n1231.679s: we have now with all this new data we\n1233.72s: actually have the ability to go back and\n1236.0s: actually you know develop metric\n1237.559s: packages so this is a cool package where\n1239.179s: you have a graphics and scoring system\n1241.1s: for we meet square error bias you little\n1243.799s: cycle phase uh spatial patterns internal\n1246.26s: variability for 35 different land\n1248.419s: variables 90 different Global Regional\n1250.94s: data sets we can run this quickly you\n1253.039s: know it takes a couple hours and we can\n1254.36s: run through and this shows all their\n1256.1s: system models across the top coming out\n1258.08s: of cm6 and then you know here's the 35\n1260.78s: Plus variables and each color here\n1264.08s: indicates how good your model is\n1265.94s: relative to the other models in that\n1267.919s: comparison\n1269.84s: um\n1270.679s: and it's actually a synthesis of all the\n1272.66s: scores that are coming from from this\n1274.1s: this different list here so it's\n1275.78s: actually an interactive package where\n1277.16s: you can click in and go deep down and\n1278.78s: get a bunch of information layer by\n1280.039s: layer by layer through the model so we\n1281.96s: have these packages which then means we\n1284.0s: have a possibility to to calibrate\n1287.179s: because we actually have enough\n1288.5s: information to potentially constrain the\n1290.12s: models\n1291.38s: okay so our approach you know it's a\n1293.9s: standard approach for calibration\n1294.919s: calibration model calibration is not\n1297.38s: something new like people have been\n1298.52s: doing this for a long time hydrologists\n1299.84s: have done it for forever\n1301.7s: um It's relatively new in the in the\n1303.14s: earth System model world and you know\n1304.82s: the gifts the gift team has done this\n1307.1s: recently and then maybe heard a talk by\n1309.08s: them but if you haven't I'm sure you\n1310.159s: will soon\n1311.48s: um you know pretty successfully you've\n1312.98s: done it for the atmosphere model We are\n1314.78s: following the same methodology it's not\n1316.4s: it's not like we're coming up with a new\n1318.08s: methodology they're just different\n1319.28s: challenges on land and there are on the\n1321.14s: atmosphere and I'll get to those\n1323.0s: um so you know you run an ensemble of\n1325.58s: simulations with parameter perturbations\n1327.32s: you might write with a loud microcube or\n1329.48s: some other method just sort of expand\n1330.74s: the parameter space you define your\n1332.72s: metrics one or more metrics\n1335.24s: um you do machine learning emulation of\n1337.4s: the of those metrics based on those on\n1339.679s: that the simulations with that concerned\n1341.78s: with all the parameters\n1343.64s: um you can strain the parameters and\n1345.26s: then you have a optimized okay so this\n1347.059s: is the standard approach we're trying to\n1348.44s: do uh within CLM\n1351.02s: and so after you know our failed attempt\n1353.6s: for it to do this let's see on apply for\n1355.58s: csm2 we took a step back and said okay\n1358.22s: we're going to do a bigger more\n1359.419s: systematic and so Katie Dagon Ben\n1361.64s: Sanders and Rosen Rosie Fisher myself uh\n1364.46s: did an effort on a much smaller problem\n1366.14s: so we we worked with the what we call\n1368.48s: the prescribed vegetation version of the\n1370.1s: model prescribed satellite phonology\n1372.08s: version of the model so we're not\n1373.64s: running with full advisory chemistry so\n1375.26s: it's a much simpler problem the model\n1376.58s: doesn't have a big spin-up problem\n1378.86s: um it runs fast\n1380.72s: um and the number of parameters is you\n1382.22s: know less than half the number of\n1383.299s: parameters you have in the global so we\n1385.64s: were able to show that using you know\n1387.86s: that volume that sort of cycle that we\n1390.08s: could do some calibration on the model\n1391.58s: so this shows on the bottom right here\n1393.86s: is uh the default CLM for gpp growth\n1396.919s: primary productivity of the default\n1399.2s: versus the optimize and you if you if\n1401.48s: you look carefully you can see that\n1402.62s: there has been reductions in the bias uh\n1405.5s: for GBP and if you actually look at the\n1407.12s: global mean by production reduced\n1409.1s: substantially\n1410.24s: what we also see is that you look really\n1412.64s: carefully it only really improved in a\n1414.74s: few regions this particularly tropical\n1416.659s: apron in this place tended to be the\n1418.159s: place that improved much of the world\n1420.02s: actually got worse the Amazon is sort of\n1422.0s: debatable when it got better worse\n1423.38s: better in some places worse than others\n1424.64s: the middle attitudes exactly the same so\n1426.799s: you know we kind of showed that we can\n1428.84s: get something better but we didn't get\n1430.64s: to a point where like this is a model we\n1432.26s: really feel is like a great\n1434.36s: representation of the Earth\n1436.34s: so we learned a lot during that project\n1439.28s: um but what were we missing well first\n1440.72s: of all it was this satellite technology\n1442.34s: version so it's a simplified version\n1444.02s: it's not the version we want to use for\n1445.94s: for projections so it's you know it's\n1448.58s: useful uh we do use it quite a bit in\n1450.74s: our science but it's not it's not the\n1452.539s: full model which we use most often\n1455.299s: um was also in all sampling we just did\n1457.039s: six parameters\n1458.84s: um and a hundred Ensemble members so\n1460.22s: it's relatively small problem\n1462.679s: um limited number of metrics that we're\n1464.059s: using you know we're decisions about\n1466.159s: that cost function were not properly\n1468.32s: accounting for uncertainty and also not\n1470.179s: you can see that we didn't really\n1471.32s: properly Capital regionality\n1473.48s: um and the choice of a calibration\n1474.98s: Target the spring limited to just the\n1476.9s: carbon and water flux\n1480.14s: um so that's why we then initiated the\n1482.24s: CLM PPE project\n1484.22s: so\n1485.9s: um\n1486.86s: this required quite a bit of work so we\n1488.659s: start on this two and a half years ago\n1490.28s: or so\n1491.36s: um and the first phase is is what I'm\n1493.159s: calling infrastructure development so\n1495.5s: um we need a fast spin-up to deal with\n1497.659s: that spinner problem we need to expose\n1499.28s: all the parameters so when we start this\n1501.799s: project about half of the parameters\n1503.36s: were hard-coded in the model which is\n1504.919s: obviously bad practice but the models\n1507.08s: developed you know 15 20 years ago when\n1509.059s: people weren't thinking about this so\n1510.62s: all the parents had to even be\n1511.88s: identified it's actually not even that\n1513.44s: easy to identify all the parameters\n1515.24s: what's the parameter model I actually\n1516.5s: have a lot of conversations about what\n1517.76s: other parameter you have to identify all\n1519.62s: the parameters you have to pull them all\n1520.7s: to go you have to put in the sem files\n1522.559s: it takes you know real work\n1524.539s: um identify parameter arrangements for\n1525.98s: 200 plus parameters obviously I can't\n1528.2s: identify parameters for 200 plus cameras\n1530.24s: so it took a whole team of people\n1531.38s: experts to find the parameters and then\n1534.08s: we need to build an ensemble analysis\n1535.76s: scripting\n1536.779s: and you know all those things are\n1538.1s: important I think the real key one is\n1539.779s: the fast spin-up right\n1541.58s: um so recently computationally\n1543.86s: prohibited it took about 1500 years for\n1546.02s: us to spin up CLM to equilibrium\n1549.5s: um that's a long simulation right\n1551.0s: there's no way you can run thousands of\n1552.919s: simulations when you have to do a 1500\n1554.659s: year simulation that takes over a week\n1556.1s: to run uh Mr security of our computer\n1558.38s: time to talk with that possible in real\n1560.059s: time so we did two things we did first\n1563.24s: we did a cluster analysis and we were\n1565.46s: able to find that we could reasonably\n1566.659s: replicate the global\n1568.64s: um response with only 400 good cells\n1571.279s: which is really helpful so the land has\n1573.86s: a nice feature that it's not really\n1575.36s: dynamic in the sense it's not good cells\n1577.52s: do not interact with each other so\n1579.44s: they're essentially a bunch of column\n1580.64s: models and so you can actually view this\n1581.96s: you couldn't do this in the ocean it\n1583.159s: wouldn't work couldn't do it in the\n1584.299s: atmosphere wouldn't work but on land we\n1585.799s: can do this so we can run up to 400 pit\n1587.419s: cells\n1588.5s: um and then we also have a matrix\n1589.7s: solution the spin up which came out of\n1591.2s: each of those group in Northern Arizona\n1592.76s: University\n1594.08s: um which allows have a matrix solution\n1595.52s: so basically mathematical Solutions in\n1597.26s: the spin out which allowed us to much\n1599.12s: faster to get the spin up and you know\n1600.62s: decrease by 10x so overall we had about\n1602.96s: a 200 X increase in speed which then\n1606.2s: made it impactable we could actually\n1607.82s: spin up a model thousands of times\n1609.799s: recently\n1611.659s: so then we get a one at a time grammar\n1613.46s: Ensemble starting there to you know it's\n1615.08s: 200 plus parameters so we need to\n1616.7s: constrain it somehow we started with and\n1619.1s: one thing we did which is a little bit\n1620.48s: unique here I think that hasn't even say\n1623.12s: General the hydraulic Community as we we\n1625.159s: ran a control so in the present-day\n1626.779s: climate and present-day CO2\n1629.419s: um one at a time but we also ran the\n1631.34s: climate of 1850 in the future climate\n1633.2s: and we also ran the CO2 of 1850 and the\n1636.02s: CO2 of a future climate and we also ran\n1638.539s: I think three nutrient deposition this\n1641.059s: allowed us then to ask these questions\n1642.86s: like\n1643.82s: if you look at the low side parameters\n1645.919s: especially did the plants die so we\n1648.2s: could then you know before we even get\n1649.76s: started in a big Latin hypercube\n1651.32s: Ensemble constrict the parameter ranges\n1653.419s: so we work and have a situation where\n1654.919s: big big fashion of the primary side\n1659.659s: and so then you know we can when you do\n1662.24s: that\n1663.32s: um\n1664.1s: sorry okay so I'm gonna have a few\n1665.84s: things about why one at a time\n1667.52s: because you know a lot of people go\n1669.5s: straight to that hypercube um because\n1671.6s: that's where you can get the parameter\n1672.86s: interactions and really understand\n1673.82s: what's going on we did one at a time at\n1676.159s: first because first of all is 200\n1677.48s: parameters it's also an easy to\n1679.039s: interpret the data set so it can easily\n1681.2s: apply 200 parameters just see what is\n1683.12s: the effect of the man I mean the max\n1685.279s: value\n1686.36s: and then for certain variables right we\n1688.4s: can that screen variable that right and\n1690.26s: so screen parameters out and so for\n1692.179s: example the leap rate index which is\n1693.799s: important quantity which I'll get to in\n1695.779s: a moment\n1696.919s: um you know about 140 of those\n1698.84s: parameters had no impact on Lei so you\n1701.48s: already you can say we don't need to\n1702.62s: worry about those for family calibration\n1706.159s: um\n1707.12s: and you know doing a lot in hypercube of\n1708.799s: 200 plus parameters just didn't seem\n1710.48s: like it was going to be feasible\n1712.7s: and also it allowed us to ask these\n1714.919s: questions about response when we ran\n1717.26s: these environmental perturbations we can\n1718.58s: ask these questions about you know which\n1720.08s: parameters control the response to a\n1721.7s: curvation so this part is here in the\n1723.679s: top 12 parameters and I'm not going to\n1725.72s: tell you what they are it doesn't really\n1726.86s: matter in this case but for the CO2\n1730.159s: fertilization effect so not just the\n1732.02s: mean state but actually the thing we\n1733.82s: often really care about most which is\n1735.32s: how much are plants going to take up\n1736.88s: carbon under increased CO2\n1738.86s: and so that's kind of a nice new feature\n1740.84s: of this is that we can actually look at\n1742.039s: the primer perturbation and you know\n1743.779s: when you're doing a climate change\n1744.74s: problem that's actually what you're\n1746.419s: trying to understand is which parameters\n1747.679s: are going to control the response to a\n1749.299s: climate perturbation\n1750.799s: so this is I think a nice way of\n1752.48s: demonstrating it with parameters control\n1753.98s: salt water 10 centimeter key variable\n1756.26s: model hydrology parameters in the mean\n1758.419s: hydrology primary show up at the top\n1760.399s: that's not surprising\n1762.14s: um but also plant parameters which is\n1764.059s: also maybe not surprising if you think\n1765.32s: about it plants are controlling how much\n1767.36s: water is being used in the soil and so\n1769.1s: it's not surprising that plant brand\n1770.48s: isn't being near the top of the list\n1772.52s: if you look at the internal variability\n1774.2s: you see that it's actually mostly plant\n1776.24s: parameters which are controlling the\n1777.44s: atrian overability which kind of makes\n1778.94s: sense because plants are the things that\n1780.559s: are varying intra annually\n1783.02s: um the soil is not really varying into\n1784.52s: randomly the soil texture for example\n1786.38s: and there's also other things like soil\n1788.059s: about them\n1788.98s: organic matter if you look at the\n1791.12s: response to CO2 fertilization it's all\n1793.76s: plant parameters and again that makes\n1795.26s: sense because\n1796.64s: um you know those plant parameters are\n1797.779s: the ones that would be\n1799.46s: um\n1800.0s: you know controlling the CO2 impact on\n1802.58s: on photosynthesis and water use\n1805.039s: and then finally the response to climate\n1806.84s: you see some some hydrology cameras but\n1809.059s: you also see some acclimation calendars\n1810.74s: so there's some equations in the model\n1812.12s: which\n1813.26s: um account for acclimation of plants to\n1815.36s: changes in temperature so plants slowly\n1818.0s: acclimate and start you know if it kind\n1820.399s: of gets out of their normal range they\n1822.2s: can adjust and still you know produce\n1824.299s: well even when slightly outside their\n1826.22s: range so the acclimation parameters end\n1827.72s: up being important so I just think this\n1829.279s: is interesting that you know each\n1830.779s: responsive perturbation yields a\n1832.22s: different set of parameters\n1833.779s: and the reason this is important that\n1835.64s: you're going to try to do\n1837.02s: you know like a lot hypercube you're\n1839.24s: going to want to include those\n1840.14s: parameters that are controlling the\n1841.34s: response in your overall hypercube right\n1843.919s: you don't want to just blow those out\n1844.88s: because if you just can you're just\n1846.5s: trying to calibrate to a mean response\n1848.12s: you're not going to be able to\n1849.62s: understand the full picture uh climate\n1851.419s: change picture\n1852.44s: the other nice thing that this one at a\n1854.0s: time experiment allows us to do is to um\n1857.24s: you know evaluate which parameters\n1858.799s: matter across different biomes and again\n1861.919s: this is interesting results especially\n1863.84s: for land modelers it says it's a\n1865.52s: different set of parameters that control\n1868.399s: um control in this case gpp gross\n1871.159s: primary productivity in a tropical\n1872.96s: rainforest\n1874.48s: and the tropical rainforest it's the\n1877.52s: parameter that control plant water use\n1879.679s: in the coral Forest where there's less\n1882.62s: light it's the primary to control\n1883.94s: lightness efficiency so that you know\n1885.679s: not surprisingly you know the plants are\n1888.08s: sensitive to how light is used and in\n1890.48s: the temperate grassland it's the plants\n1892.399s: are controlled Soul water availability\n1893.6s: so that tells you how likely it is to be\n1895.88s: affected by drought so\n1897.98s: none of this is surprising but it's\n1899.419s: really interesting ability to like probe\n1901.82s: the model and understand is the model\n1903.799s: working right if you haven't lined up\n1905.779s: like this it probably would have been a\n1906.86s: little bit disturbing but fortunately it\n1908.179s: did\n1909.679s: and then finally in this point\n1912.08s: um War findings a lot of people are\n1913.64s: really enjoying having this data set\n1915.62s: exist and so Daniel Kennedy has built an\n1917.899s: interactive visualization tool so you\n1919.52s: can go in and look at any of our top 20\n1922.399s: variables and ask you know what is the\n1924.74s: impact of Medline slope for example it's\n1926.659s: a plant parameter\n1928.52s: um on on the total whatever variables\n1930.62s: this is total OA so you can see you know\n1932.779s: the change in metal and slope in this\n1934.159s: case on the decrease and you can look at\n1935.84s: the spatial patterns of that so you can\n1937.7s: go through and interactively so I think\n1939.08s: that's going to be a resource that\n1940.22s: people are really going to use and we're\n1941.899s: working on that we'll be include that in\n1943.46s: the publication\n1945.679s: and in the sense of build it and they\n1947.779s: will come World\n1949.64s: um the CLM PB project is already\n1952.52s: initiated a whole bunch of spin-off\n1953.779s: projects so just the fact that we\n1955.1s: created this one at a time Ensemble with\n1956.72s: all these different environmental\n1958.1s: perturbations there's now 10 different\n1960.14s: groups around the world which are using\n1961.7s: this output to either start their own\n1963.74s: calibration effort to use an\n1965.36s: understanding some aspect of the model\n1967.039s: there so\n1968.059s: to get it at end card I think within\n1970.159s: lead the the idea is to build things\n1972.08s: that are going to like affect a bigger\n1974.6s: group than just\n1976.039s: the team that you're working with right\n1977.6s: and so that's what we try to do at ncar\n1979.279s: for sure within CSM and it's really you\n1981.679s: know we're happy when we see this kind\n1982.94s: of things happen\n1984.86s: so now for the last 10 minutes or so\n1988.399s: um I'll get into the into what leap is\n1990.2s: doing where Linea Hawkins came into the\n1992.36s: in the project and so this is what we're\n1994.519s: calling phase to you so we've finished\n1995.96s: the infrastructure development we've\n1998.0s: based the one at a time grammar\n1999.38s: perturbations\n2000.94s: um and now we want to get into\n2002.019s: calibration right and understanding\n2004.059s: primary interactions\n2006.159s: um\n2007.059s: so we're going to start off with with uh\n2009.58s: your decisions about how to how to\n2011.559s: define which parameters we should use\n2013.179s: for the hypercube you know the most\n2015.039s: important parameters\n2016.72s: so obviously when you when you're doing\n2019.539s: calibration you have to decide what do\n2021.22s: you calibrate before right we have a lot\n2022.899s: of things we can calibrate for in a\n2024.7s: complex model like CLM complex model\n2027.159s: like Pam complex model like like mom\n2030.46s: um so we've identified our what we call\n2032.44s: our 12 key variables which we think\n2034.36s: there's there's observational\n2035.5s: constraints\n2037.179s: um and this with some potential that we\n2038.919s: can calibrate for so that's a lot\n2040.659s: calibrating for 12 variables is going to\n2042.519s: be ambitious\n2044.86s: um you know I think they have done this\n2046.24s: to a certainly in in the gist model with\n2049.0s: the atmosphere I'm not sure how many\n2050.02s: variables are covered in four but\n2051.28s: multiple variables but we wanted to\n2053.379s: start off with more simply\n2056.619s: um we also want to you know when we're\n2058.419s: trying to figure out what parameters to\n2059.859s: look at we need to consider which are\n2061.78s: the most important parameters for a\n2062.98s: range of different things so we look can\n2064.54s: look at the global mean come up with a\n2066.22s: list of parameters we can look at the\n2067.54s: global entry annual variability come up\n2069.159s: with a list of parameters look at that\n2070.78s: you know General cycle look at the biome\n2072.46s: level means look at the responsive\n2074.139s: protegations so we're kind of\n2075.159s: constructing our limited set of\n2077.26s: parameters so that it kind of captures\n2079.359s: how's the ability to capture all these\n2081.58s: different features uh all at once\n2084.639s: so our initial Focus instead of trying\n2086.56s: to go you know to trying to calibrate\n2088.72s: all 12 of those things uh right off the\n2091.24s: bat is to start with with a literary\n2092.859s: index calibration and the reason we're\n2095.139s: doing that is because it's it's\n2096.339s: challenging\n2097.9s: um but we also think it's trackable\n2100.06s: um and also it's a foundational variable\n2101.619s: you can see on five you see and I'll get\n2103.48s: to that in a second and there's actually\n2104.859s: a pretty good observational constraints\n2106.119s: we've been observing Eli for for a\n2108.58s: couple of decades now so we have some\n2110.2s: reasonable uh observation constraints\n2113.26s: so what is labor index just for anyone\n2115.119s: who doesn't know it's the amount of leap\n2117.16s: area per unit digital area so this just\n2119.26s: shows you uh from the top down you're\n2121.54s: looking down uh from space you know\n2124.18s: plant a where you might have a Libre\n2125.98s: that covers about 40 of the ground that\n2128.26s: would have a deep frame of 0.4 uh the\n2131.02s: one on the right has the least area of\n2132.4s: point eight and if you have multiple\n2134.02s: layers of leaves you can have numbers in\n2136.66s: excess of one which means you know\n2138.579s: basically no light is getting through\n2140.32s: and so it closed canopy fourth which\n2142.18s: might look something like this might\n2143.32s: have a lead very index of about four\n2144.94s: just to get you oriented a grassland\n2146.92s: would be closer to one or two\n2150.099s: and it's an important variable because\n2151.599s: you know it's correlated with a lot of\n2153.339s: environmental variables like\n2154.359s: photosynthesis and carbon update fire\n2155.98s: emissions blatant heat flux Albedo\n2159.46s: um and is affected by by water drought\n2161.74s: temperature human management coog\n2163.66s: conservation so it's kind of a pretty\n2165.579s: synthesizing variable in the model it's\n2167.74s: also a variable that got really wrong in\n2170.38s: clm5 so that's another incentive to uh\n2173.14s: to do it so when we you know went\n2174.82s: through the selection process\n2177.28s: um we came up with this list of\n2178.42s: parameters and what's nice about this\n2180.46s: with some parameters and again I'm not\n2181.66s: going to explain why this grammar is but\n2183.7s: just to indicate that it kind of spans a\n2185.92s: bunch of different things like it's not\n2187.48s: all but it's in those parameters it's\n2189.4s: like some of them are quite Essentials\n2190.9s: parameters some of them are hydrology\n2192.4s: parameters plant water use vegetation\n2195.28s: phenology lead physiology respiration\n2198.7s: allocation nitrogen uptake and snow so\n2202.48s: it kind of spans the kind of things we\n2204.579s: think would be important uh for leaf\n2207.28s: area in there so that's kind of also a\n2208.78s: comforting to see and also useful the\n2211.119s: other thing I want to point out here is\n2212.26s: that several of these are PFT level\n2213.94s: parameters which means that there's a\n2215.74s: different value for each of the 17\n2217.24s: different functional types and so we\n2219.099s: need to try to make a decision about how\n2221.02s: to handle that and so we didn't want to\n2223.599s: you know take these this this uh 23\n2225.82s: parameters and then be added all the\n2228.28s: parameters\n2229.42s: that had some PhD variation and then you\n2231.88s: know expanded by 17 you did you end up\n2233.859s: with 200 parameters or something like\n2235.9s: that in your hypercube and again you're\n2237.76s: not too big so we kind of limited to we\n2240.16s: took three of these parameters I can't\n2241.54s: remember which ones allowed it to be PFT\n2243.7s: varying the other ones were sort of\n2245.56s: modifying up and down uniformly\n2247.78s: end up with a situation we have 23\n2249.52s: parameters three PFT level 32 effective\n2252.099s: parameters we had a clever way to reduce\n2254.14s: that 17 down to three\n2256.54s: um times a 15 placing factor for the\n2259.66s: hypercube it's a 500 stimulation so a\n2262.3s: tractable number of simulations to run\n2266.02s: another unique thing about mad models is\n2269.2s: um is that the the land is not an\n2271.9s: equilibrium with the current climate\n2273.16s: State and the vegetation is not\n2274.3s: including current on the state so if you\n2275.92s: ran two equilibrium at present day you'd\n2279.16s: probably got 10 to 15 to 20 percent\n2280.839s: higher in everything\n2285.06s: so we didn't want to have to account for\n2288.339s: that in our calibration so we ran every\n2290.26s: one of these what we call transients so\n2291.82s: we ran that from 1850 up to present day\n2294.04s: in addition to the spin up so just\n2295.839s: another you know unique complication\n2298.48s: and I guess I'm kind of getting it as\n2300.04s: you kind of see as I'm going through so\n2301.24s: I'm getting the point that\n2302.68s: you know you can bring data science to\n2304.48s: these problems but if you don't have\n2305.619s: domain Specialists it's impossible so it\n2307.72s: really has to be a two-way interaction\n2308.98s: right a domain specialist would never\n2310.599s: know that it's off the top of their\n2312.339s: heads like they would never know that\n2313.48s: but you need to take this extra step\n2315.64s: okay just if you look you know we're on\n2317.38s: those 500 simulations and look at the\n2318.82s: really key variable in the land which is\n2320.32s: the net cumulative Carbon on land over\n2323.56s: the historical period and so\n2325.48s: the way this looks in most Earth models\n2328.0s: are doing it close to rights is that\n2329.619s: you've been losing Carbon on land up\n2331.66s: until about 1950 to 1970. that's due to\n2334.0s: land use change all the cutting down a\n2336.88s: forest that we've done and harvesting\n2338.56s: wood out for us have led to a loss of\n2340.72s: carbon on land but in the last\n2343.24s: 50 years or so carbon has been starting\n2345.579s: to come back on land and that's due to\n2347.32s: the CO2 fertilization effect\n2349.66s: um which is masking some of the\n2351.46s: deforestation which is still going on so\n2353.5s: overall the net effect ends up being\n2355.3s: pretty close to zero over the historical\n2356.859s: period\n2358.06s: um on land\n2359.68s: um and what this just shows if you just\n2361.54s: ran all those parameter sets and\n2362.859s: calculated that value we see this\n2364.599s: massive range right you're assuming all\n2366.22s: those primary sets were equally valid\n2367.599s: which of course not all of them are but\n2368.92s: this is the range this is actually a\n2370.54s: range that's in that in excess of the\n2372.16s: range from the from the cm6 models\n2376.119s: okay so then you know in the step of\n2378.4s: calibration we're now at the point where\n2380.26s: we're going to let hypercube we can\n2381.7s: identify metrics and um emulation\n2384.82s: and I'm going to put the slide up here\n2386.2s: cautiously because I don't personally\n2387.94s: understand you know emulation algorithms\n2391.42s: um like that's to say that you know\n2392.74s: Katie and linear are are testing\n2394.72s: different how many layers and finding\n2396.52s: that not every emulator is creating the\n2398.74s: same this is probably totally not used\n2400.9s: to you here but\n2403.0s: um I was a little bit surprised by this\n2404.32s: by some of these emulators are like\n2405.76s: performing really really poorly uh some\n2407.68s: of them are performing you know\n2408.82s: reasonably well so this is part of the\n2411.04s: experience that we need to develop and I\n2413.56s: guess guess has gone through this as\n2414.94s: well uh we can hopefully learn from them\n2417.4s: um\n2418.18s: but you know not all emulator they're\n2419.8s: creating the same so that's step one\n2421.9s: um but once you do have an emulator\n2423.4s: that's reasonable you can then ask\n2425.14s: questions about you know nonlinear\n2426.7s: interactions across your parameters and\n2428.2s: just so the two plots that kind of\n2429.64s: indicate that this shows the maximum\n2431.619s: plan conductance versus leap area index\n2433.54s: and so you see there's some there's some\n2435.7s: nonlinear relationship\n2437.619s: um which is sort of what you expect and\n2439.18s: almost kind of hoped for to see uh out\n2441.22s: of the results and then another right is\n2443.2s: showing maximum conductions versus the\n2445.18s: leaf carbon nitrogen ratio\n2447.52s: um and um in the contrary to the leaper\n2449.56s: index and again you see that there's not\n2451.06s: you know there's a relationship between\n2452.5s: the two as you have increasing leave\n2454.48s: carbon nitrogen ratios you have lower\n2457.18s: leap area\n2458.56s: um as you increase the max plan\n2459.76s: conductance which means water can be\n2461.38s: used more efficiently you have an\n2462.76s: increase in leap area and those two\n2464.38s: things are operating competing with each\n2466.06s: other\n2467.14s: okay so we can learn about that and then\n2469.48s: there's but then okay I want to sort of\n2472.0s: pinch for the last few minutes here\n2473.38s: about you know some of the challenges\n2474.82s: were uncovering as we're trying to get\n2477.04s: towards calibration and the the news is\n2479.44s: we don't have calibration yet\n2481.66s: um in case anyone's wondering\n2483.52s: um but we're getting closer\n2485.32s: um there are challenges that you know\n2486.88s: you probably have thought about if we've\n2488.26s: been involved in calibration the equity\n2489.76s: challenge is always going to be there\n2491.26s: many different parameters sets are\n2492.88s: likely going to give you a reasonable\n2494.02s: answer\n2495.22s: um and you have to you know cope with\n2496.54s: that yeah multiple targets is\n2498.52s: challenging uh local variables multiple\n2501.099s: different time scales it's hard to get\n2502.66s: multiple things to work right in the\n2504.64s: model\n2505.54s: um the regionality problem which I\n2506.859s: mentioned a few times before and\n2508.119s: essentially the title of the planet\n2510.04s: functional type problem and then also\n2512.02s: you have structural errors in your model\n2513.52s: which is going to make it in a lot of\n2515.44s: cases like impossible there's no way to\n2517.3s: get there okay so let's just ask the\n2519.28s: question can we resolve the global\n2520.78s: biasing Lei so it turns out CLM\n2523.9s: um was producing Lai it was almost\n2526.359s: Factor two too high so Global being\n2529.54s: valuable two and the actual\n2532.06s: um Global observations indicator should\n2533.98s: be about one so my hypothesis is that we\n2538.42s: because we are hand tuning the model and\n2540.579s: we are trying to avoid this plants dying\n2542.38s: and pre-industrial conditions we were\n2544.54s: like you know not intentionally leading\n2547.359s: you know pushing us ourselves towards\n2548.98s: the model to be overproductive sort of\n2551.079s: compensate for that problem in 1850. um\n2553.599s: so we weren't smart enough to figure out\n2555.04s: how to come up with a parameters that\n2556.359s: would work\n2558.04s: um but if you just take a simple thing\n2559.9s: can we get to a Libre index of one and\n2562.72s: don't even do any emulation just go look\n2564.52s: at your 500 simulations take the one\n2567.22s: with the minimum error we can find out\n2569.079s: that yes we have a version uh that can\n2571.72s: match Lei globally exactly perfect we're\n2575.14s: good we're done right that's not no\n2576.579s: problem as you can see\n2577.96s: um and this is what the parameter set\n2579.04s: looks like\n2580.18s: um again you know the 30 almost 30\n2582.339s: parameters here\n2583.78s: um and their normalized value\n2586.3s: um and uh you know Lai is exactly 1.03\n2589.24s: which is like exactly what the\n2590.5s: observations say they are if you look at\n2592.48s: it it kind of makes sense uh which is\n2594.7s: also encouraging that this this F root\n2596.68s: Leaf is a allocation parameter which\n2598.359s: basically says put more of your carbon\n2600.819s: than you get into roots\n2603.52s: rather than leaves and so if you do that\n2605.8s: you're going to get more carbon\n2606.819s: underground which means small Vari that\n2608.68s: makes sense uh Leaf longevity is another\n2610.66s: parameter so we're basically saying all\n2612.64s: our leads are just turning over all the\n2614.14s: time you know it's like constantly\n2615.52s: growing dying growing time growing time\n2617.8s: so you know here's a parameter set we'll\n2620.44s: just give you equivalent of the eye\n2622.66s: um but here's also another parameter set\n2624.46s: again not emulating anything just saying\n2626.319s: the closest one bias is exactly zero\n2628.839s: almost exactly zero again\n2630.52s: you know exactly totally completely\n2632.5s: different values nothing nothing even\n2634.18s: looks quasi-similar okay this is not\n2636.28s: going to be surprising to anyone\n2637.3s: probably but yeah obviously you have to\n2640.3s: be careful that you're gonna have Equity\n2641.74s: management problems\n2643.839s: if we do try to do that calibration you\n2646.18s: know this is the default bias of the CLM\n2648.7s: then we just say let's actually do it\n2650.44s: you know emulate and build a cost\n2652.48s: function and calibrate for the minimal\n2654.64s: error in global mean Lei this is what\n2657.579s: you get so the global mean Lei in this\n2659.92s: case is almost zero but what you see is\n2662.02s: all we've done is we've like cranked it\n2663.4s: up in the tropics and we've killed\n2665.2s: everything off in the Boreal so that's\n2666.7s: obviously not a viable that's not a\n2668.26s: viable model\n2669.7s: um if you calibrate for the minimum\n2671.26s: error that's just the tropical forest\n2672.579s: Lei that actually does a little bit\n2673.9s: better\n2675.099s: um you know you're getting a reasonable\n2677.099s: Lei in the tropical forest region but\n2680.14s: now your parameters are not giving you\n2682.06s: good values in the mid latitude so\n2683.92s: that's that's another problem you have\n2685.359s: to handle\n2686.92s: and then say if you want to try to\n2688.359s: calibrate you know in different parts of\n2690.7s: the world and also for different\n2692.8s: variables\n2694.42s: um here's an example this is my last\n2696.16s: slide basically last science slide\n2698.92s: um so this is what shows here is three\n2701.2s: different regions tropical rainforest\n2703.119s: temperate seasonal forest and Temperate\n2704.98s: Grassland\n2706.599s: um and the circle and the Green Dot is\n2708.76s: probably a lot easier to see there is\n2710.619s: the observational value for gpp versus\n2713.319s: Lei and some uncertainty estimates and\n2716.619s: so what you see here is that a few\n2718.78s: things wanting to see that you know it\n2720.4s: looks like these are all the different\n2721.9s: values for the parameter experiment that\n2724.48s: a lot of hypercube\n2726.4s: um doesn't seem like we have a lot of\n2727.96s: overlap which is which is unfortunate we\n2729.94s: do have some more lack of the\n2730.9s: temperancities on the forest it's not\n2733.66s: great for temp for the temporary\n2735.04s: grassland\n2736.119s: if you do try to calibrate on the\n2737.8s: temperate season the fourth which seems\n2739.119s: the most promising so you take you know\n2740.98s: these are the points that are the\n2742.68s: parameter sets which look like the most\n2745.18s: reasonable uh it'd be like where the\n2747.16s: primary sets line up on the tropical\n2749.56s: rainforest\n2750.7s: perhaps a surprise Wing is totally like\n2752.619s: not giving going to give you a good\n2754.18s: value the same thing with a couple\n2755.38s: Investments so again these are probably\n2757.48s: not like super surprising but you have\n2759.16s: to go through these steps to understand\n2760.68s: what are the targets what are the what\n2763.119s: are the metrics what are the cost points\n2764.5s: you need to build to sort of constrain\n2766.18s: the model\n2767.92s: okay so that's where we're at so Lenny\n2770.319s: is making good progress I think we're\n2771.76s: going to get there\n2773.5s: um hopefully uh but the idea is what is\n2777.04s: is uh I think the really important thing\n2778.72s: here is that repeatable is that\n2780.46s: everything we're doing we're doing\n2781.54s: carefully uh building the tool that runs\n2784.599s: so that anybody can run it we're\n2785.74s: checking if somebody else can run it\n2787.839s: um you know we've come up with fast\n2789.28s: model we've got a set of observations we\n2791.079s: have sound American methods and primer\n2792.52s: priors automated workflow completes the\n2795.099s: parameter and modeling sites quick\n2796.839s: repeatable and transparent that's really\n2798.52s: the idea here\n2800.079s: um I think if you don't do this we don't\n2801.4s: want to do another one-off paper we'll\n2803.56s: be right here we can calculate the model\n2805.0s: and then never do it again right this is\n2806.859s: what we expect to do like routinely\n2808.96s: going forward once we get to this\n2811.54s: so I'm just going to finish there and\n2813.22s: summarize and say you know systematic\n2815.38s: model calibration obviously is really\n2816.88s: important to Cloud Model development and\n2818.56s: it's been hindered by a variety of\n2820.06s: challenges uh computational Power and a\n2823.06s: lot of challenges I talked about today\n2824.319s: but we're kind of getting around we'll\n2825.7s: have a few examples now where people are\n2827.2s: getting to the point where you might be\n2828.4s: able to do Global grammar calibration\n2831.04s: land models in particular have their own\n2833.44s: set of problems\n2835.42s: um they're very large parametric space\n2837.4s: and the structural internees\n2840.28s: which impacts you know the assessment\n2842.2s: emerging climate features such as Line\n2843.579s: Pharmacy hydraulic sensitivity so we\n2846.46s: need to do this if we want to have\n2847.66s: better estimation but it's a challenging\n2849.52s: problem\n2850.48s: machine learning animation can help us\n2852.16s: optimize resources and reduce\n2853.48s: objectivity and model calibration\n2856.54s: um the clm5pp commute data sets are\n2859.0s: resulting in many option projects only\n2861.04s: publicly available soon and already a\n2863.98s: lot of people are using it and then when\n2865.06s: people have access to Cheyenne\n2866.92s: um I'd like to put them on on the on the\n2868.78s: on the Jupiter head\n2870.7s: um and we're making progress towards\n2872.319s: open source model calibration tools and\n2874.48s: our real goal is driving towards some\n2876.64s: level of landlord acceleration for csmp\n2878.74s: which we're targeting csm3 is targeted\n2881.38s: for fall 2024 is what we're talking\n2883.3s: about now so I will stop there thank you\n2887.2s: thank you\n2892.079s: any questions\n2909.7s: really interesting I'm wondering if you\n2911.56s: thought at all about how these PBS can\n2915.819s: give you some insights into the largest\n2918.46s: priority structural errors to look at\n2921.76s: yeah\n2924.46s: yeah well I think we had example there\n2927.7s: just right there at the end that\n2929.859s: um you know seeing situations where we\n2932.619s: do not have we do not have a a parameter\n2935.619s: in our parameter space which is going to\n2937.06s: get us into the into the into the\n2938.619s: reasonable range we've you know only\n2940.9s: just started looking at that this was\n2942.4s: sort of the first we've all seemed like\n2943.54s: that but it would be interesting to do a\n2945.16s: systematic sweep of all the climate\n2947.68s: variables and see how often you know we\n2950.44s: essentially have nothing in our hyperque\n2952.359s: which can get us into the into this case\n2953.98s: and then once once once you've gotten to\n2956.02s: there\n2957.339s: um\n2957.94s: yeah then I'm not sure what you do\n2959.319s: exactly\n2960.839s: three yet but definitely that's the kind\n2963.46s: of thing that um I just say that for you\n2967.18s: know this is the first time\n2969.28s: we have done like a full parameter Suite\n2971.74s: of the model you would think that by now\n2973.3s: we would have done it but we we haven't\n2974.74s: and part of this you know because 100\n2976.839s: over 100 of the parameters were not even\n2978.94s: you know exposed so we couldn't even\n2981.339s: make through this thing so I had to go\n2982.839s: through that you had to say we're going\n2984.099s: to bite the bullet we're going to spend\n2985.119s: six months\n2986.38s: finding all the parameters pulling them\n2988.0s: out and so I'm guessing a lot of groups\n2989.56s: around the world are also just be like\n2991.06s: it's too much work but we're finding\n2993.52s: we're really glad we do right and so now\n2995.68s: now with the rule right if you're\n2997.0s: putting in a new conversation you've got\n2999.16s: to obviously put in an explosion so I\n3001.92s: feel like we're just about at the\n3003.359s: beginning of like unders of how we're\n3004.98s: understanding how we're going to use\n3005.94s: this\n3006.96s: it's a good question though yes one\n3008.88s: question\n3011.359s: can I see it\n3015.02s: yeah\n3016.859s: you're gonna hold up\n3022.8s: can you hear me\n3029.88s: oh are you online all right can you hear\n3032.64s: me\n3037.68s: can you hear me ask my question now\n3043.74s: in the meantime I'll ask uh sort of a\n3046.14s: question\n3047.4s: um so\n3048.599s: by the way has anyone done a Time series\n3050.48s: analysis on this light\n3052.76s: yeah\n3058.819s: oh yeah\n3061.68s: um\n3063.98s: a lot of the things that you're going\n3066.18s: through of course we've gone over as you\n3067.98s: might imagine some of the decisions that\n3069.66s: we've made are the same you know like\n3072.24s: things like uh well we have that\n3073.559s: structural mismatch we've had to deal\n3075.119s: with that sort of issue with the sort of\n3077.52s: space of the outputs and constructing\n3079.98s: the likelihoods\n3081.66s: um but other things like uh like the\n3084.359s: parameters that are less are more\n3085.68s: sensitive we we've made like different\n3087.54s: decisions right so we just did\n3089.579s: everything and there's you know there's\n3091.559s: certain reasoning behind that but I\n3093.42s: think in general like what we what we\n3095.819s: don't have and what I'm really\n3096.66s: interested in is sort of construction of\n3098.4s: you know what's and it might be\n3100.5s: motivated by reading this paper on page\n3102.24s: and workflow but you know there's\n3104.04s: there's sort of a workflow for this sort\n3105.78s: of uh client model tuning that's that's\n3107.819s: very specific to our field our sort of\n3110.64s: problems so uh yeah that's not really a\n3113.339s: question isn't anyway it's yeah it'll be\n3116.04s: fascinating to see like the decision you\n3117.599s: make and be nice to have these\n3118.559s: conversations\n3119.579s: yeah I think I mean that's where we're\n3121.8s: trying to push towards right is that the\n3123.3s: gain knowledge from you guys and\n3124.8s: hopefully you'll get some knowledge from\n3125.88s: us too that's that's where the to be\n3128.579s: successful we have to learn from each\n3130.38s: other otherwise then why are we doing\n3132.18s: why do we have that probably I\n3134.22s: completely agree so\n3135.78s: just so you know so you guys know uh we\n3138.72s: are having a cross-working Obsession of\n3140.64s: the CSM workshop on primary estimation\n3143.819s: which means the atmosphere group and the\n3145.619s: land group are the ones who most active\n3147.18s: will be there and you know there's\n3148.98s: remote participation so hopefully you\n3151.02s: guys can make it or obviously everyone's\n3152.7s: welcome to come to the CSM Workshop it's\n3154.319s: a fun meeting but also they'll be online\n3157.319s: also it'll be online it'll be hybrid\n3158.819s: yeah yeah\n3167.92s: [Music]\n3176.24s: so I mean you mentioned of course it's\n3178.68s: super hard right to calibrate the model\n3180.24s: when you have so many parameters and you\n3182.28s: can end up in a space where you have two\n3184.26s: completely different runs with really\n3186.24s: reduce bias they're completely different\n3188.099s: parameters some groups have adopted\n3191.04s: different strategies which is rather\n3192.54s: than looking for the best set of\n3194.88s: parameters rule out as many as you can\n3197.52s: is that the strategy that you've been\n3199.5s: thinking about for men or in general and\n3201.96s: do you think it's valuable or yeah yeah\n3204.78s: I mean we're I put that I think why\n3207.599s: Daniel and Katie and Lydia put that\n3209.46s: example up through the sort of Stark and\n3211.079s: you know really captures people's\n3212.52s: attention but obviously you know we\n3214.2s: would never like consider either those\n3216.24s: parents has to be realistic parameters\n3218.819s: um but yeah no I think that's what what\n3220.74s: we're what we're trying to do and I\n3222.359s: think that's also what Marcus\n3227.78s: you know we are not going to get to one\n3230.099s: parameter set that's gonna it's gonna\n3231.66s: work and I think you know one of the\n3234.359s: things we'd like to do is you know\n3235.619s: constrain it down to 100 parameter sets\n3238.44s: that we like we think a reasonable doing\n3240.3s: as good as we can for a range of\n3241.859s: different variables and then you know in\n3243.48s: land only mode at least run that through\n3245.64s: the full\n3246.66s: you know Carbon Cycle trajectory you\n3248.52s: have in the future and see what the what\n3250.14s: the range is right I think that even\n3251.52s: that would be an interesting result\n3253.619s: ideally we can get to the point where\n3255.54s: and I think this is talking about doing\n3257.22s: this too is trying to run with you know\n3260.22s: multiple parameter sets within a cement\n3262.26s: context\n3263.52s: right that would be cool right that's\n3265.68s: never been done\n3267.66s: um so yeah run with you know it has to\n3269.88s: be models right maybe four or five\n3271.68s: parameter sets that you like and and at\n3274.44s: least have some sort of parametric\n3276.059s: uncertainty within the model but yeah\n3277.559s: there's no one answer obviously we know\n3279.18s: that that's 100\n3281.099s: um the challenge with doing that with\n3283.559s: that idea is at least in our model you\n3285.059s: have to spin each version up\n3287.339s: and that's hard we don't so there's\n3289.559s: another thing like we should probably\n3290.579s: spend the time to really automate the\n3292.38s: full process but the reason spin up is\n3294.839s: hard is you have to it has to be\n3296.64s: iterative\n3297.78s: and so you got to run the you know run\n3299.64s: the full system archive some information\n3301.2s: for the force the land of the ocean then\n3303.18s: run then for a long period of time then\n3304.74s: do it again and again until everything\n3306.0s: comes people living and so it's right\n3308.22s: now it's a human\n3310.02s: there needs to be human in the loot\n3311.76s: currently which anytime that you have to\n3313.859s: have a human Loop you can bite further\n3315.24s: away\n3316.92s: we have a question from Tom says thanks\n3319.26s: for a great talk this might be a nightly\n3321.66s: question but why must you start your\n3323.579s: spin-ups from scratch each time why\n3326.28s: can't you instead start from known\n3328.2s: equilibrium solutions from older models\n3330.78s: to start from or maybe solutions for\n3333.18s: simpler models that have some of the\n3335.16s: faster time Tails removed\n3337.98s: so\n3339.24s: um\n3340.14s: we we actually do I didn't really say\n3342.66s: that we don't start from we have a\n3345.18s: situation we call cold start\n3347.22s: cold start is when you don't have any\n3348.839s: information you have a brand new model\n3350.099s: and you just give it some like\n3352.319s: quasi random not random but you know\n3354.24s: some some human decided initial\n3356.94s: condition values for a bunch of\n3358.44s: different pools\n3360.059s: um and we often you know when we have a\n3362.339s: branding model to start with that but\n3363.48s: every time after we've got a simulation\n3365.22s: that works uh then we always just do\n3367.74s: interpolate our initial conditions so\n3369.839s: the answer that is that we do and that\n3371.46s: will reduce the time scale spin up and\n3373.619s: that's actually accounted for it in this\n3375.0s: here I didn't really explain it\n3376.14s: completely\n3377.4s: um\n3378.18s: your simple or analytical Solutions\n3381.78s: um from some model could work or you\n3384.059s: could possibly try to if you had\n3385.68s: observational estimates of your soil\n3387.24s: carbon States and your vegetation carbon\n3388.8s: States you could potentially try to try\n3390.72s: to spend it up but our experience has\n3391.98s: been that you don't it doesn't really\n3394.079s: work that well you don't really save\n3395.46s: much time because there's always\n3397.38s: the challenge with the spin-up is\n3399.059s: actually another one is that\n3400.74s: you know some relatively significant\n3403.02s: facts on good so spin up really fast\n3404.46s: especially the tropics turnovers really\n3407.28s: fast it'll spin up in 100 years but in\n3409.8s: the high latitudes in the permafrost it\n3411.599s: can take you know thousands of years and\n3413.28s: so and some some good cells are never\n3415.5s: spinach we actually have more criteria\n3417.0s: to say we assume that five percent have\n3418.619s: never been in company\n3420.3s: for reasons that we've never really\n3421.74s: fully understood I think it's really the\n3423.24s: fire but\n3424.559s: um so\n3426.119s: anyway so you know we've we've gone\n3428.4s: through this art for a long time I guess\n3430.14s: it's an art the spin-up process is an\n3432.059s: art there is no one solution and we have\n3434.04s: our process now but\n3435.9s: yeah it could you could have a big\n3437.76s: research project to come up with a\n3439.5s: better skills method and that's what\n3441.059s: they did in in northern Arizona and it\n3442.859s: is accelerated by 10 times\n3446.099s: questions\n3448.26s: uh two questions first if I was\n3451.2s: wondering so one at a time the chairman\n3454.2s: has been done I wonder if like two other\n3456.839s: nine has been done so compare that with\n3459.599s: one at a time perturbation to see if\n3462.18s: parameter interaction really matters\n3464.46s: because and the other question is why\n3467.579s: are you asking me the parameters versus\n3469.2s: seems like it's almost certain that the\n3471.839s: optimum solution has the more than one\n3474.42s: right so I was wondering have you like\n3477.48s: run into like bio model or like\n3480.059s: multi-model uh like estimations or can\n3483.9s: that be as a sign you show all it's\n3486.78s: really revealing some more complicated\n3488.7s: instructor and family yeah\n3492.3s: um so we've not done it two at a time\n3494.099s: but we um\n3496.02s: what we did within the Latin hypercube\n3497.94s: right we ran with\n3499.44s: 30 30 some parameters and and we could\n3502.079s: look at the parameter interaction\n3503.099s: effects and linear has a method that she\n3505.74s: can break it down you'd have to get her\n3507.059s: to come here and explain and what we're\n3508.98s: finding is that there are grammar\n3510.3s: interactions as you inspect but um we're\n3513.9s: kind of lucky that they're not humans in\n3515.579s: the land model actually they're not like\n3517.5s: you know it's not like 50 it's a\n3519.48s: parameter interaction I think it's more\n3520.859s: than 15 to 20 range which means we're\n3524.4s: not like in a super non-linear space a\n3526.799s: lot of time\n3527.94s: um and then you're right that there\n3529.68s: could be multiple modes and I think\n3531.24s: that's you know I'm not sure we're far\n3533.46s: enough along to know really how often\n3535.799s: we're going to encounter the multiple\n3538.44s: locations where you find a good\n3540.24s: parameter set\n3542.04s: but it'll be anticipate we will find\n3544.14s: that you know my the question of course\n3546.0s: and I'm I am curious to talk with with\n3548.04s: one of the kids experience more is that\n3550.079s: as you do try to caliber with more and\n3551.88s: more variables and more of our metrics\n3554.16s: you should have fewer places where\n3557.22s: there's actually reasonable parameters\n3558.42s: this is what I would guess\n3560.52s: um or the other alternative is you find\n3563.099s: you can't find any parameters that's\n3564.42s: actually give you anything that's better\n3565.68s: than the control I guess that could be a\n3568.2s: possibility too\n3570.119s: yet\n3573.599s: oh hey this this is great uh so just in\n3577.079s: in addressing what you would have spot\n3578.94s: up um we did I think we had fewer brand\n3582.059s: information but it turns out that we put\n3584.28s: observational error you know then that\n3587.04s: opened up the possibility uh the\n3590.16s: mistakes\n3594.92s: that maybe some more more mentors but I\n3598.2s: had a couple questions so uh\n3600.599s: um so you had lots of parameters uh that\n3602.76s: you removed I guess it was like 140.\n3605.4s: um so do you think any of those might\n3609.059s: have\n3610.44s: um mattered if the default settings or\n3613.2s: the other the defender that you've\n3614.88s: contained or changed you know to address\n3617.4s: in a different state yeah\n3619.859s: yeah uh yeah we don't have we can't\n3623.04s: answer that question what we've done so\n3624.66s: far but yeah you can totally imagine\n3626.4s: that some of them would matter\n3628.98s: um\n3629.94s: we were also using expert judgment here\n3632.46s: which I didn't really say which is that\n3633.96s: you know you look at the parameter list\n3635.339s: and we looked like is there a parameter\n3638.52s: that we kind of thought was going to\n3639.66s: matter that's not in here\n3641.339s: uh and in fact we added one parameter I\n3643.74s: think it was an expert judgment\n3645.48s: parameter we just said we're really\n3646.619s: surprised this parameter doesn't matter\n3647.94s: and we're kind of concerned about not\n3649.68s: having it in our set\n3651.72s: um I don't know how you would really do\n3653.099s: that without a lot of computational time\n3655.2s: to figure out but this was you know we\n3657.119s: selected those patterns just for leaper\n3658.74s: index now if we go to multiple variables\n3661.38s: we would have to redo that exercise\n3663.599s: and at some point you're going to find\n3665.28s: out that you're going to need you know\n3666.839s: 50 100 200 parameters I mean actually I\n3669.599s: do feel like we're going to find out\n3670.559s: about 100 of those parameters\n3671.9s: essentially just don't matter much in\n3674.099s: almost any condition that we feel like\n3675.54s: we're going to calibrate a quarter yeah\n3677.099s: it's fun because we have 36 cars and\n3680.52s: when we got to 36 yeah which was shot\n3683.16s: we'll Cyclone cap one parameter that\n3685.2s: never mattered at all right exactly\n3689.46s: um but so the other is two more\n3691.38s: questions\n3692.18s: so the spinner we're running into these\n3695.339s: suspicious\n3697.22s: or configurations it took two years to\n3701.88s: get two of those to work with in the\n3704.28s: whole ESL\n3709.98s: um but but\n3711.599s: I wish we were able to learn this more\n3713.579s: quickly it would wouldn't would not work\n3716.04s: and so my question was do you know if\n3719.04s: your early results or you know when you\n3720.9s: were doing spin up\n3722.52s: um were predictive of the final results\n3724.619s: back it would have at least you know\n3726.78s: where you could sort of use some\n3728.7s: information and it wouldn't be realistic\n3730.26s: it was like some sort of radiation\n3731.88s: mapping in front of these not to firearm\n3734.28s: results\n3736.24s: [Music]\n3736.92s: um\n3737.46s: yeah I think that you know that's a step\n3739.859s: that we're planning to take right I mean\n3741.66s: we haven't done this where you take your\n3742.92s: optimized parameters haven't run back\n3744.66s: through the model to ensure that it\n3746.52s: gives you a reasonable result\n3749.099s: um\n3749.76s: so we would but we can it's a little\n3751.5s: easier in the land\n3752.88s: world because we can do it all in land\n3754.74s: only mode\n3755.88s: and if it works in land only mode which\n3757.68s: is cheap and fast\n3760.079s: um it's unlikely it's going to screw up\n3761.64s: a couple model of natural I think it not\n3763.5s: a viable model\n3765.48s: result\n3793.5s: [Music]\n3817.26s: yeah one of the things that always uh\n3821.579s: surprised me about the model the fact\n3823.44s: that we're trying to do so many things\n3824.46s: at the same time right and in the oceans\n3826.92s: that for example if there's a mortgage\n3829.5s: FPL now maybe 10 years ago but they\n3831.78s: showed that you could build a very\n3833.339s: reduced form ecological model uh that\n3836.339s: would give you a reasonable simulation\n3838.26s: of the carbon cycle even though it\n3840.059s: wouldn't give you maybe all the output\n3841.38s: that you needed to predict Fisheries or\n3843.119s: other things like that right so\n3845.46s: I guess one of the challenges you're\n3847.14s: also dealing with is the fact that\n3848.579s: you're trying to so many things all at\n3850.5s: once right uh but if you only cared\n3853.74s: about the land harvesting for example\n3856.26s: um\n3856.92s: or something I don't know what and where\n3859.319s: the trees are or something like that\n3860.96s: would there be a more reduced form\n3863.4s: version of the model that would be\n3865.14s: useful and that would be worth working\n3867.24s: on or like how how much could you go\n3869.28s: between reducing complexity to the full\n3871.559s: complexity in this process and I don't\n3874.26s: know if that's a very good question no\n3875.579s: it's an interesting question is you know\n3877.799s: it's the kind of question that comes up\n3878.819s: why you know that stuff\n3880.98s: I don't know I think it's a hard\n3882.54s: question to answer right that um\n3885.96s: you know I I haven't caught that answer\n3888.18s: which is which is that um if somebody\n3890.819s: wants to do that do you support model\n3892.5s: you know in a university setting that's\n3895.14s: like totally appropriate they should go\n3896.52s: ahead and do it and that at Ang bar and\n3898.92s: the other major or system modeling\n3900.599s: centers you know\n3902.579s: we're the only groups that can really\n3904.079s: handle the complexity and so that we are\n3905.819s: going to spend our time in complexity\n3907.2s: it's not a super satisfying answer but\n3909.359s: that's the way I split that in code\n3911.099s: because I can't also think about\n3912.42s: building reviews for models and so\n3915.0s: yeah it's it's totally a reasonable a\n3917.52s: reasonable question there is I should\n3919.38s: say that there's a model called karma\n3922.02s: which is a pretty simple model I think\n3924.18s: they\n3925.02s: I'm not sure if they're using some form\n3926.46s: of it in the cleaner project but but you\n3928.92s: know it's got a really limited number of\n3930.48s: sets of parameters and it's easily\n3932.76s: manipulate so they just go through they\n3934.319s: do like all this they just get away with\n3936.54s: it they just run huge ensembles and it\n3938.94s: runs really fast and it takes a you know\n3940.74s: it runs on monthly time scale and so\n3942.839s: there is it does kind of exist and you\n3945.119s: can imagine situations where you kind of\n3947.22s: couple our two efforts together\n3949.2s: um given enough money and resources\n3956.0s: thank you\n3958.36s: [Music]\n3965.64s: [Music]\n3975.44s: if you consider using ugc uh later will\n3980.16s: the interaction between tourist sales\n3982.319s: matter uh don't think that the question\n3984.78s: again\n3986.28s: um why do you\n3988.079s: technology\n4001.38s: [Music]\n4006.619s: yeah so so first of all to clarify the\n4009.38s: first project we did there was blood by\n4011.18s: K Dagon back in 2020 was with satellite\n4014.299s: technology but everything since then\n4015.559s: we've been running with BGC which is the\n4017.66s: big step forward that we've made is that\n4019.52s: I think the first group that's really\n4020.72s: ever tried to to do to the land model\n4023.0s: with a full BGC model\n4025.099s: um and with the BCC there's no more\n4027.38s: interactions good so the good cell with\n4029.48s: BGC than there is in the in the um in\n4033.26s: the satellite technology mode and and\n4035.42s: really the only interaction\n4037.16s: the only interactions there would be in\n4038.9s: the real world are lateral flow of water\n4041.72s: and potentially a lot of coral piece but\n4043.94s: that probably doesn't matter on the on\n4045.74s: the scales we're working on so there\n4047.059s: could be some lateral flow of water\n4049.039s: our our thinking is that the scales\n4052.46s: we're running at are more than our\n4054.02s: thinking it's really the schedule\n4055.039s: running at it's redistribution with\n4056.72s: integrated cell that's what matters and\n4059.0s: I could give a whole nother to talk\n4060.14s: about how we're trying to deal with\n4061.28s: redistribution of water within a good\n4062.78s: cell we have this thing called the\n4064.22s: representative health model which wasn't\n4066.2s: part of this because it's a Next\n4067.28s: Generation complexity model but we do\n4069.98s: account for that in terms of vegetation\n4072.14s: the only way that it really matters is\n4074.2s: Siege dispersal and potentially buyer\n4077.299s: could move from Goods of a good sale and\n4079.88s: again in our in our most advanced\n4081.44s: version of law which is not the one I'm\n4082.64s: showing here those things are being kind\n4085.039s: of considered but you know if we get to\n4087.02s: that stage and we have to deal with that\n4088.76s: kind of calibrating the model it's like\n4090.2s: all bets are off so we'll see right now\n4092.299s: we can't get a global configuration\n4093.619s: that's really working in that more\n4094.88s: complex model but it's where we're going\n4097.58s: hopefully that answers your question\n4100.219s: yeah that's great too\n4103.759s: um going back to this kind of but you\n4105.799s: know so things was interesting it could\n4107.54s: be observation for you with like one dot\n4109.52s: right yeah that you could say I mean we\n4111.859s: have huge Alternatives as well because\n4113.299s: early AI is actually quite complex and\n4115.46s: you can even talk about like camping and\n4117.199s: all of that mess you know where you know\n4119.179s: it can be very difficult to get their AI\n4121.16s: right and so we don't really know\n4122.9s: whether that's true then then what it\n4126.08s: means is that kind of the observations\n4128.06s: becomes really bottleneck in the\n4130.1s: military they're getting the absolute\n4131.839s: value could be a really really complex\n4133.699s: whereas maybe looking at the spatial and\n4136.52s: temporal variation might be an interior\n4138.14s: task and maybe that fits the model\n4139.759s: better in a sense you know because I\n4141.739s: remember at the time there were\n4142.88s: discussions about you know soil moisture\n4144.679s: and a lot of them people say oh that's\n4146.779s: your model simulator if it doesn't match\n4149.0s: that model so I'm really sure it doesn't\n4150.62s: matter it's real world simulator but as\n4152.299s: long as regulate things that are\n4154.46s: important to you maybe that's okay you\n4156.319s: know like as long as you get a special\n4157.819s: example of the ability and yeah this\n4159.92s: would like to hear them oh absolutely\n4162.259s: yeah 100 that's really where we're\n4163.88s: heading and right now I feel like we're\n4165.859s: building in workflows and processes you\n4168.92s: know your cost function once you you\n4171.38s: know got yourself an ability to you know\n4173.0s: have a cost function and then calibrate\n4175.04s: towards it they can switch out that cost\n4176.96s: function and make it anything and so\n4178.46s: we're just trying to build a skill set\n4179.96s: which some other groups already have\n4182.54s: um and demonstrate that we can do what\n4184.1s: we think you know do it right and do it\n4185.839s: but then yeah then the big actually the\n4188.239s: more one of the most interesting parts\n4189.5s: of it is going to be assign what did you\n4190.88s: mentioned or set of metrics and totally\n4192.859s: we are actually thinking about Trends in\n4194.179s: Lai uh seasonal cycle of Lei\n4198.32s: um you know it's actually the max Lei\n4200.54s: which we're looking at here and you'll\n4201.5s: match those annual means kind of a weird\n4202.88s: variable for Lei uh so all those kind of\n4205.28s: things that we're thinking about and\n4206.42s: then for every variable you're gonna\n4207.92s: have to decide what are the obligations\n4210.98s: really can tell you right some a lot of\n4213.14s: the data sets don't really provide good\n4214.46s: internal variability but they provide\n4216.739s: seasonal some data set sometimes so\n4218.78s: that's going to be where the the point\n4220.64s: is going to be and and there's that's\n4222.08s: going to be art because there's going to\n4223.64s: be no one answer I think there can't\n4227.3s: allow you to do it systematically\n4232.239s: thank you\n4234.679s: foreign"
    },
    {
        "class": "YouTubeVideo",
        "title": "Capturing Convective Atmospheric Profiles Using Variational Encoder-Decoders by Samarth Agrawal",
        "videoId": "yUa88ZVlo7g",
        "url": "https://www.youtube.com/watch?v=yUa88ZVlo7g",
        "publishedAt": "2023-08-02T18:18:14Z",
        "transcript": "5.58s: so hello uh my name is Sammy I'm an\n7.859s: undergrad here at Columbia and my\n10.44s: project was I'm trying to capture\n12.0s: atmospheric profiles I'm using\n14.219s: variational Auto and Twitter encoder\n16.44s: decoder networks\n18.06s: um so I'm not going to go too much into\n20.46s: the background because it's very similar\n22.14s: to um what has been presented but\n24.24s: essentially the motivating question from\n26.4s: my research was we have this regression\n28.619s: task of very high dimensionality where\n31.019s: we're trying to resolve the macroscopic\n33.899s: influences of convection and I was\n36.899s: animated by can we use the power kind of\n39.54s: a data driven deep learning approach to\n42.18s: have a fast solution to this regression\n45.42s: problem but also retain insight into how\n48.3s: our regression is out uh generated and\n50.34s: how the model is performing and can our\n52.739s: model help us understand convection\n54.239s: itself better and so those were kind of\n56.28s: my goals in Outsourcing this to machine\n59.039s: learning\n60.42s: um and so to do that I focus\n62.46s: specifically on as I said vae Networks\n65.519s: and so in case you're unfamiliar the\n68.58s: goal of vaes is basically to force an\n71.52s: information bottleneck by having a layer\n74.52s: in the middle that is very small and\n77.82s: um this essentially approximate uh\n80.46s: non-linear principle component analysis\n82.56s: and so we're trying to capture the\n84.36s: variance in our data by compressing it\n86.88s: into this kind of bottleneck and then\n88.92s: decoding it solely from that limited\n90.6s: information and then one other\n92.1s: noteworthy thing about vaes is it\n94.38s: encodes inputs as distributions and so\n97.259s: instead of just learning on vectors we\n99.36s: interpret those vectors as the means and\n101.579s: standard deviations of gaussian\n103.14s: variables and so when we sample from\n105.06s: this lower dimensional representation\n107.04s: which is referred to as a latent space\n108.78s: it kind of gives us this degree of\n110.579s: control over our generative model and so\n114.36s: if we're talking about extremity if the\n116.64s: model does its job well we can sample\n118.74s: how extreme we want our generations to\n120.479s: be by controlling that learned Sigma\n123.18s: parameter and so vas are really\n125.579s: something really try to understand\n127.099s: macroscopic drivers of convective\n130.02s: processes because by trying to interpret\n132.3s: what the dimensions of the latent space\n134.34s: correspond to we try to understand\n137.099s: um\n137.7s: what is most significant for the model\n139.739s: in the decoding process and so the\n141.84s: encoder and decoder are trained jointly\n143.459s: on a combination of regularization of\n146.28s: trying to get um smooth properties that\n147.84s: I'll talk about later and actual\n149.34s: accuracy of the task\n152.16s: so\n153.66s: um for my data set I was focusing on\n156.54s: these inputs and output variables and so\n159.42s: there are 44 Dimensions to the input\n161.16s: vectors and 43 for the output um perhaps\n163.62s: if I continue the project I would try to\n165.12s: capture the full range of variables\n167.76s: um and I took daily averages\n172.319s: so this is more specifically the\n174.36s: architecture that I focused on\n175.68s: throughout my work\n177.18s: um one thing to note is in this veg\n179.519s: Network or variational encoder decoder\n181.86s: we are not simply just trying to\n183.9s: reproduce the data as would be the case\n185.58s: in normal views but simultaneously\n187.56s: trying to solve the regression task so\n189.72s: essentially we're hoping that a model\n190.98s: does two things at once first it tries\n193.56s: to map the input itself and kind of\n196.26s: reproduce it from the bottleneck and\n198.18s: second it tries to solve the actual\n200.04s: regression task by having these um y hat\n203.159s: vectors and so although this might make\n205.379s: it harder for the model the hope is that\n207.42s: that makes the latent space learn more\n209.819s: important features because it has to\n211.62s: capture semantically important\n213.0s: information for both the input space and\n215.4s: the output space and so um that's really\n218.099s: the goal of doing this\n220.08s: um I also benchmarked the model um\n222.12s: because I couldn't use the Clemson\n223.459s: benchmarks uh because of differences in\n226.5s: methodology and data processing and so I\n228.659s: just trained really quickly a linear\n231.0s: Network and a vanilla artificial neural\n233.22s: network each with 32 hidden layers and\n235.739s: one to two layers depending on the two\n237.18s: networks um it was Trend with the atom\n239.04s: Optimizer\n240.36s: um the second thing I want to mention\n241.5s: that's going to be kind of a theme to\n242.819s: the presentation is this trade-off\n244.62s: between accuracy in terms of mean\n246.959s: squared error and KL Divergence which\n249.959s: tells us how different the distributions\n251.879s: we've learned are from our prior\n253.799s: Distribution on how we expect our\n255.84s: distribution to be uh\n257.699s: uh shift and so this is kind of a\n260.579s: regularization term that tries to\n262.32s: enforce properties within the latent\n263.699s: space so that when we generate\n265.68s: um things are smooth and sensible and\n267.78s: these are um in Conflict so the more you\n270.12s: try to make the lens best regular the\n272.22s: harder it is to actually get the\n273.24s: regression task and that's uh turned out\n275.4s: to be really important when I was\n276.54s: comparing different models so for my\n278.22s: analysis I focused on one specific one\n280.139s: to keep things consistent\n281.82s: um but I actually had very different\n282.9s: results\n283.979s: um depending on different uh choices and\n286.8s: architecture\n288.479s: so this is just really quickly to\n290.34s: highlight that point where what I did\n292.32s: for the model that we're focusing on is\n294.18s: ideal this beta parameter from a very\n297.0s: low value to a higher value and so\n299.46s: initially I'm just telling the model to\n301.08s: reconstruct the data and as more time\n303.3s: passes I'm trying to make it care more\n304.919s: and more about regularization and so as\n306.9s: you can see this KL Divergence starts to\n309.24s: initially go up but then really goes\n311.22s: down but as it gets lower we start to\n313.5s: see our reconstruction loss actually\n315.3s: start to creep up\n317.82s: um so these are my empirical results\n319.8s: um as you can see the encoder Network as\n322.199s: expected did uh perform slightly worse\n324.6s: than the uh standard neural networks\n327.6s: because of the influence of that\n328.8s: information bottleneck but not\n330.9s: significantly worse and so we have this\n333.6s: trade-off where we are going to perform\n334.919s: a little bit worse on our regression but\n337.8s: um with the benefit of kind of the\n339.6s: things that we're going to talk about in\n340.5s: the next slides a couple two things of\n342.539s: note that I want to point out first is I\n345.18s: tried seeing how affecting the\n346.56s: dimensionality latent space\n348.24s: um affected the test loss and one would\n350.4s: expect that as we have less and less of\n353.759s: a bottleneck the loss goes down so\n355.5s: something like this but it seems to not\n357.66s: really matter and that's going to be\n359.34s: important um and was actually initially\n361.5s: very puzzling but then made sense when\n363.539s: we looked at the actual results\n365.22s: so this is the result of plotting um the\n369.6s: latent space and so what you're seeing\n371.1s: is uh we're learning six-dimensional\n373.02s: representations and we're doing\n375.3s: principal component analysis on those\n376.979s: six dimensions to find the\n378.96s: two-dimensional Subspace of Maximum\n380.639s: variance so that we can actually plot it\n383.1s: and look at things and what you see is\n386.06s: this very strange behavior of kind of\n388.8s: being like linearly uh divided and so\n391.319s: this was one with a much more\n392.96s: regularized thing so this is kind of\n394.74s: like what it should look like and the\n396.36s: two things we want are structure as like\n398.819s: we see here and separation of important\n401.94s: information which we actually see in\n403.44s: both\n404.46s: um and so these are how output variables\n406.38s: might be distributed differently so that\n408.06s: when we sample from the space we can\n410.039s: decode different kinds of\n411.06s: representations\n412.919s: um yes and so now this is a more\n416.4s: detailed analysis of that and so we are\n418.74s: perturbing this first dimension of the\n420.78s: latent space which was kind of the most\n422.4s: regularized and traversing along it to\n425.22s: kind of see\n426.539s: um if we look at one specific Dimension\n428.46s: what does that correspond to and so we\n430.919s: actually see is the principal components\n432.72s: of the latent space are basically the\n434.94s: same as just the zero with Dimension\n436.62s: which helps us explain our bottleneck so\n439.259s: basically we're giving our model Six\n441.539s: Dimensions to learn from but it's really\n443.4s: only using the first one which is a\n445.199s: problem but um which is why the\n447.3s: dimension didn't matter but what we do\n449.22s: see is this Dimension is really well uh\n452.699s: decoded into meaningful information and\n455.699s: so we see that as we Traverse the latent\n457.44s: space this way the precipitation values\n459.599s: follow almost linearly and that kind of\n462.24s: indicates that this Dimension is really\n464.16s: capturing variation precipitation so our\n466.56s: model has learned that I'm gonna instead\n468.72s: of 44 vectors learn 6 and the first one\n471.12s: corresponds very strongly to the\n472.919s: precipitation profile with the\n474.72s: temperature profile still having\n475.919s: structure but not being as separated\n478.259s: because of this symmetry\n481.38s: now the last thing I did which is more\n483.419s: of a proof of concept was initially um I\n485.759s: wanted to do causal representation\n487.02s: learning to try and learn embeddings\n488.819s: that were not just good at decoding but\n491.88s: we're actually causally important for\n494.52s: the\n495.539s: um\n496.139s: for any given label of interest and so\n498.66s: the key uh quantity of Interest here is\n501.539s: this metric called the probability of\n502.979s: sufficiency which is basically really\n504.9s: simple where um if we treat our\n506.94s: variables as light switches if we turn\n509.099s: on a certain embedding value how does\n512.339s: that like intervention change the value\n514.919s: of our output and so it's a pre-force\n517.919s: um maybe like this First Dimension to\n520.14s: adopt a specific value does the\n522.0s: precipitation change which would capture\n523.8s: its causal uh\n525.6s: value so Amanda was talking about kind\n528.0s: of those assumptions of causal\n529.5s: sufficiency and because I was uncertain\n531.36s: whether those held for our encoder\n532.98s: decoder Network I actually had this ad\n535.38s: hoc method of approximating this where I\n539.399s: discretize the variables using the bins\n541.62s: and so I just this is the distribution\n543.54s: of the variable and I just treated it as\n545.58s: taking one of three continuous values by\n548.339s: uh seeing which interval it fell in and\n551.279s: by forcing it to take a value I would\n553.44s: make it jump from one or the other and\n555.36s: then the value I'd make it take was just\n557.459s: uniformly sampled from that interval and\n559.44s: so that's how I approximated like\n560.76s: interventions and instead of trying to\n562.92s: estimate um counter factual quantities\n564.959s: which I was really uncertain about the\n566.7s: accuracy of I just um used K nearest\n569.279s: neighbor search to find the actual data\n571.74s: point that was the most similar to this\n573.42s: forced value and um from the index of\n576.18s: that data point I looked at the ground\n577.8s: truth y variable and so this was\n580.86s: basically to sidestep in a lot of the\n582.72s: literature kind of the complexity of\n584.88s: trying to do Direct Call puzzle analysis\n586.62s: but that would be a really interesting\n588.06s: next step to try to\n589.74s: get through and so\n592.56s: um the results that I did when I read\n593.94s: this were actually on a separate model\n595.26s: than what I've been showing you so I\n596.82s: don't have the table for that but uh it\n599.1s: would be Independence and so yes I think\n602.399s: what this has noticed is that there is\n604.38s: some success for the encoder Network to\n606.6s: capture things that when we decode or\n608.94s: interpret like do give us insight into\n610.98s: the process we see how convection\n612.98s: temperature and precipitation were kind\n615.6s: of distributed\n617.1s: um with a\n618.6s: depending on your preference like\n620.64s: acceptable decline in regression\n622.56s: performance but for my next steps I\n624.6s: would definitely try to balance this\n626.04s: trade off better so try to get a\n628.26s: comparable regression performance but\n629.88s: have a similar regularization so the\n632.16s: living space isn't basically just a line\n633.839s: but it's more of a multi-dimensional\n635.94s: distribution and I'll try to make these\n638.339s: more disentangled so it's kind of not\n639.899s: just relying on one number\n642.24s: um and then there's a lot of tuning I\n643.92s: want to do but then the other thing that\n645.3s: I'd be really excited to do is to\n646.68s: actually try to extend this Beyond this\n649.26s: and\n650.279s: um estimate these causal quantities\n651.959s: without relying on like the existing\n654.24s: data points and trying to estimate the\n655.68s: underlying distribution\n657.779s: um\n658.44s: so yeah uh thank you uh so much I want\n661.8s: to really thank the reu mentors because\n664.079s: I think they really helped me learn a\n665.88s: lot and it was an incredibly valuable\n667.56s: experience and so I'm really glad I got\n669.839s: to learn so much this summer\n671.88s: um and yeah uh\n674.82s: does anyone have any questions\n678.48s: uh yeah I have a question for a lot of\n681.26s: traversal so you were able to I just\n685.14s: wonder do you know like uh the first PC\n688.92s: is most related to which which input\n692.76s: variables do you have an idea of that\n695.1s: yeah\n696.42s: um so that's a that's a great question\n698.16s: to better explain what these red dots\n700.44s: are\n701.339s: um I took the average Vector of the\n704.1s: latent space and I was perturbing solely\n706.74s: the first dimension of the six and so\n709.38s: like kind of traversing this\n711.12s: distribution\n712.68s: um so to your question about which\n714.36s: variables that are the most related to I\n716.76s: actually did not compute this plot for\n719.04s: all of the 43 so I focus managed on\n722.1s: precipitation and temperature due to\n723.72s: time constraint so I can at least see\n725.82s: that it seems to be focusing more on\n727.86s: precipitation than temperature because I\n729.72s: guess it's more um\n731.82s: like given this you can decode this more\n733.86s: easily it's more of a bijective map\n736.2s: um but I did not look at like all 43\n738.42s: inputs to see or outputs to see which\n740.519s: one is most correlated to\n742.079s: but it seems very well correlated\n744.18s: temperature\n746.76s: work\n754.2s: um so my question\n756.86s: but my first part is what what are the Y\n760.079s: labels you're trying to predict again\n761.399s: yeah so my goal is to try to capture\n765.899s: like convective profiles and so ideally\n769.019s: it would kind of be the entire outputs\n771.12s: um but in this case there's a 43\n772.92s: dimensional output of um specific\n775.139s: humidity air temperature\n777.66s: um heat flux of various varieties and\n780.18s: precipitation and so the actual going to\n783.0s: try to capture like everything\n785.7s: um that's going on in the atmosphere\n787.019s: within the embedding\n790.2s: and so\n791.7s: the output\n793.98s: I see there's some variables that are\n796.019s: duplicated between the input and the\n797.459s: output space yeah\n799.44s: um\n800.279s: did you maybe elaborate on that yes\n802.139s: exactly I definitely care and so with\n805.139s: the grid cells essentially what's\n806.579s: happening is we're trying to so we're\n809.04s: tracking temperature and precipitation\n810.66s: let's say in each region of these\n812.519s: columns and what we're trying to do is\n814.2s: figure out how does convection uh change\n817.32s: those and so essentially what you can do\n819.48s: with the these two outputs and inputs\n821.7s: being the same is we're seeing how\n823.44s: temperature has changed as a result of\n825.839s: clouds and so another way you could do\n828.42s: it which is essentially be doing the\n829.74s: same thing is if you have temperature\n831.66s: you're trying to predict like the change\n833.82s: in temperature or like the DT so if it's\n835.92s: like a dynamic system you're trying to\n837.6s: map from like the state to like the\n838.92s: change in state so this is basically\n840.6s: like temperature and then like how did\n843.24s: temperature change because of what the\n844.86s: clouds are doing\n846.839s: okay I guess my last question then is\n849.24s: Could you um elaborate on the purpose of\n852.36s: the Ved architecture instead of just a\n855.48s: regular V vae or just a regular\n857.82s: classification model and\n859.62s: also\n860.94s: um it's a linear model performed better\n863.76s: than the vae does that inform anything\n867.3s: about\n868.86s: I know the distribution of the variables\n871.079s: is something uh yeah those are both\n874.079s: really good questions so the Ved is um\n876.959s: quite similar uh the only difference is\n879.18s: like traditionally when people talk\n880.74s: about VES they're more of an\n882.48s: unsupervised approach that are trying to\n884.36s: recreate data so you have a set of uh\n887.339s: you have a data set of samples and you\n889.139s: want to generate data that looks like\n890.76s: those samples\n892.199s: um I'm trying to\n893.88s: ask more of the model and try to not\n896.82s: just have this uh reconstruction task\n898.74s: but simultaneously force it to a\n900.899s: regression task so I guess it's\n903.06s: basically really similar essentially the\n904.92s: same thing it's just that I'm\n906.42s: concatenating the outputs of both the\n907.92s: input and the output to try to get it to\n910.019s: do unsupervised and supervised learning\n913.199s: um but in terms of the actual like\n914.66s: implementation it's very similar\n918.54s: oh and uh your last question was about\n921.139s: the high performance of the linear model\n924.779s: um actually that was an excellent\n925.98s: question and I was actually quite\n927.48s: surprised at how well\n930.12s: um the linear model did compare to even\n931.92s: like the neural network with\n933.779s: non-linearities\n936.12s: um\n937.32s: yeah actually I\n939.06s: I was also like puzzled by this but I\n941.639s: guess um those baselines were created\n943.62s: very recently so I haven't fully thought\n944.94s: about it\n946.74s: yeah especially when you have a high\n948.959s: correlation maybe plot the scatter plot\n951.72s: of the predicted and True Values of the\n954.779s: some outputs yeah and for your loss\n957.839s: function I think maybe you can add a\n960.12s: weight for The Root construction arrow\n962.579s: and the regression Arrow yeah to because\n966.0s: I feel maybe most of the loss problem\n969.72s: comes from the Reconstruction Era I\n972.12s: don't know but maybe try add some\n974.579s: weights yeah so that also definitely be\n976.38s: a next step of like trying to understand\n978.54s: whether the model does different tasks\n981.839s: like variationally well and if it's\n983.399s: better predicting input variables or\n985.079s: output variables better but then also\n986.519s: like is it better at some like is\n988.86s: precipitation easier than like humidity\n990.839s: for example so yeah definitely would\n992.76s: want to continue that analysis and find\n994.62s: more time\n996.6s: we do have one more question okay\n999.839s: a technical question from Rohan\n1002.42s: folks found online\n1003.62s: L Divergence is an appropriate\n1006.459s: regulatization term\n1009.38s: uh sure Rohan okay so kale Divergence I\n1014.48s: did right here but what it represents is\n1016.459s: for two given probability distributions\n1019.519s: um how different they are and so it's\n1021.139s: actually the expectation of the log of\n1023.3s: one divided by the uh divided by the\n1026.0s: other and so\n1028.339s: um essentially underneath the hood\n1030.74s: conceptually this is all about like this\n1032.66s: uh family of like distribution\n1035.059s: estimation methods called variational\n1036.62s: inference and in those there's a\n1039.079s: trade-off between\n1040.819s: um matching the prior and matching the\n1042.86s: data and so in this we assume like that\n1046.52s: our latent space is distributed with\n1048.559s: like normal gaussian variables maybe\n1050.84s: Suba in a presentation can correct me\n1052.82s: whether that's a good assumption or not\n1054.08s: but um\n1055.76s: um so we are saying when I encode the X\n1058.94s: how similar is it to our prior of just a\n1061.7s: standard gaussian that's like mean\n1062.96s: centered\n1064.1s: um and so the reason it's a good\n1065.419s: regularization parameter is enforcing it\n1067.76s: to try to be similar to a gaussian has\n1070.1s: the properties that\n1072.38s: you want it to look like this\n1073.76s: essentially you want it to be a high\n1075.08s: dimensional gaussian with the things\n1076.7s: clustered together so that if you sample\n1078.799s: from different points of the latent\n1080.059s: space they're all um meaningful because\n1083.12s: for example in this model if you try to\n1085.16s: decode a point here that might just\n1087.14s: decode to Pure gibberish\n1089.12s: um which would be bad right because you\n1090.32s: kind of want the stability of the latent\n1092.12s: space but here kind of\n1094.52s: it is nicer for that reason so I guess\n1097.46s: it's for\n1098.539s: um yeah those reasons\n1104.24s: thank you thank you thank you and Emily\n1106.4s: have our last presenter soba thank you"
    },
    {
        "class": "YouTubeVideo",
        "title": "2024 Summer Education Project 2",
        "videoId": "t8Ad5hleMic",
        "url": "https://www.youtube.com/watch?v=t8Ad5hleMic",
        "publishedAt": "2024-08-03T20:11:03Z",
        "transcript": "4.359s: but um this is Project two I'm Anthony\n7.399s: um my name is Greta and my name is\n10.719s: Laura and we are project two working on\n13.519s: parameterizing turbulent flow and the\n15.44s: planetary boundary\n21.4s: layer um so we have an overarching goal\n24.84s: that we'll use as an outline throughout\n26.199s: our presentation it's to use equation\n28.84s: Discovery methods to develop accurate\n30.4s: and interpretable parameterizations for\n32.599s: vertical turbulent fluxes in the\n34.04s: planetary boundary layer um and we'll\n36.96s: first start off with vertical turbulent\n38.8s: flexes and exploring the planetary\n40.36s: boundary\n42.0s: layer okay so just to provide some\n44.239s: background information before we kind of\n46.199s: dive in um what is the planetary\n48.399s: boundary layer well it's something we're\n50.16s: all really familiar with because it's\n52.039s: basically where we live on earth so the\n54.44s: planetary boundary layer is the lowest\n56.32s: level of the troposphere it's about 1 km\n59.0s: thick um and it's where we live our\n60.68s: day-to-day lives but something important\n62.879s: to note is that it's really influenced\n65.4s: by the Earth the heating and cooling of\n67.36s: the earth kind of influence all the\n69.36s: parameters that are going on in this so\n71.88s: as during the day as the Earth heats up\n74.84s: it makes the air warmer it start they\n77.32s: start to rise have more buoyancy and\n79.119s: such and the planetary boundary layer\n80.88s: actually grows um at night when the\n83.079s: earth is cooler the planetary boundary\n84.88s: layer is then going to shrink fall a\n86.799s: little bit um so it is directly affected\n89.799s: by by our surface Heating and Cooling\n91.6s: but because we are still in this one Kil\n93.96s: kilometer area it's a little bit too\n95.88s: small to be picked up by um climate\n98.439s: models which typically are on scales of\n100.36s: around 100 um kilometers and we're\n102.799s: dealing with like a smaller um area and\n105.079s: just because as the Earth heats up\n107.2s: different areas it creates these small\n109.04s: scale um edies and things that move up\n111.96s: um so this vertical turbulent flux as it\n114.68s: brings up it can transport things in the\n116.64s: air so pollution moisture heat that all\n119.6s: gets kind of moved on up as these air\n121.88s: particles start to rise and work their\n123.68s: way up so this is called a vertical\n125.52s: turbulent Flex so if you're ever on an\n127.439s: airplane at any point you know when the\n128.879s: plan starts to kind of shake before you\n130.56s: land um that's kind of this turbulence\n132.8s: just this movement of air um something\n135.12s: else I just want to mention before we\n136.68s: move on is that the planetary boundary\n138.64s: layer is actually capped a little bit so\n141.239s: we reach this place as we move up we\n143.319s: reach a temperature inversion which we\n145.0s: can kind of see where this capping of\n146.92s: the smog is at that point um it's where\n150.04s: then the actually as we move up then the\n152.16s: temperature does start to increase as we\n154.16s: go up whereas before that as we move up\n156.48s: the temperature starts to decrease and\n158.4s: at this capping inversion um air can get\n160.879s: incorporated into the um planetary\n162.76s: boundary layer and a process through\n164.2s: entrainment but we'll talk about that a\n166.04s: little more\n168.48s: later so if you want to study the pbl\n171.0s: it's good to have a lot of data and if\n172.519s: you want to have a lot of data it is\n174.319s: good to simulate it and so we use large\n177.36s: Eddie simulations as our data we also\n180.159s: want a good amount of variance in our\n181.68s: conditions and so we switch them around\n183.36s: we change the horizontal wind the\n185.12s: surface Heating and the inversion\n186.599s: strength and these will be important\n188.44s: later in the presentation um this this\n191.48s: data captures the evolution of the pbl\n194.28s: at a very high resolution so in the X Y\n196.959s: and Z plane we have a resolution of 24x\n199.64s: 24x 6 M which is a sharp contrast from\n202.519s: today's climate models we're also going\n204.44s: over two hours minute by minute now this\n207.28s: is a really cool picture of what we're\n209.239s: working with here and it is a picture of\n211.56s: Vertical Velocity it's a two-dimensional\n213.36s: slice of the simulation and so these\n215.28s: bright yellow spots are upward and\n217.84s: positive Vertical Velocity and these\n219.599s: dark blue spots are negative so downward\n222.76s: Vertical Velocity but we can't capture\n225.04s: all of this information and it's far too\n226.879s: noisy and diverse for the methods that\n228.84s: we're going to use so in order to deal\n230.84s: with this we core scin our data and we\n232.68s: average it down to a vertical profile\n234.72s: which is that black line right there so\n236.799s: now the dimensions that we're working\n238.12s: with are the height in the planetary\n239.799s: boundary layer and the time Evolution\n242.239s: but we still get a ton of variables and\n243.92s: we get to investigate their higher order\n246.84s: moments in order to achieve our goal we\n249.64s: want to use equation Discovery methods\n251.599s: and the specific method that we use is\n253.84s: called symbolic regression which is\n255.799s: somewhat a cross between absolute magic\n257.919s: and the way that somebody would discover\n260.519s: an equation if they had no idea what was\n262.44s: going on in the field right what it does\n264.52s: at the end of the day is it produces\n265.919s: human interpretable equations a good\n267.72s: example of that is a linear regression\n269.28s: four times humidity might mean something\n271.36s: to a scientist a bad example of that is\n273.44s: a neural net you put inputs into\n276.12s: something it's an absolute blackbox\n277.8s: method it might have really high\n279.0s: predictive power but you have no idea\n280.759s: how it gets to its output so the core of\n284.0s: symbolic regression is essentially a\n285.759s: genetic algorithm inspired by Evolution\n287.88s: and an optimization task it takes in\n290.68s: operators like the plus sign and the\n292.36s: minus sign basic functions like trig\n294.44s: functions and e to the X and\n297.68s: coefficients and it optim izes equations\n300.8s: so what you do is you put in an\n303.72s: input multiple inputs you'll be putting\n306.32s: in your response variable your target\n308.24s: the thing that you want to get and a\n309.88s: number of potential predictor variables\n311.759s: which you believe could constitute some\n313.639s: form of equation for it now what it's\n315.6s: going to do is it's going to create\n317.52s: candidate equations and compare them so\n319.52s: it's going to start with something very\n320.639s: basic say x and then it'll make two\n323.28s: candidates X+ Y and XY and then it'll\n327.16s: staple coefficients onto them optimize\n329.759s: them to see which one fits better to the\n331.36s: data and pick the better one and they'll\n333.319s: continue to evolve off of that kind of\n335.44s: randomly searching through the equation\n337.24s: space until you get something that works\n339.6s: and so your output is going to be a\n341.319s: physical equation that relates the\n342.72s: predictors and the response I've got the\n344.28s: predictors in uh Pink here and the\n346.36s: response in blue here because when we\n348.16s: look at ugly equations later I want them\n349.84s: to be in those colors uh something that\n352.319s: that's very important to mention is that\n354.639s: this algorithm has a lot of Randomness\n357.319s: in it and so when you're optimizing\n359.12s: you're going over over a non-convex loss\n360.919s: function there's absolutely no guarantee\n362.919s: that this going this is going to\n364.16s: converge and in real terms this means\n365.919s: that there's absolutely no guarantee\n367.16s: that we're going to find the right\n371.199s: equation um the next part of our goal is\n373.68s: to use accurate and interpretable\n377.72s: parameterizations so the first thing we\n379.479s: wanted to model in the boundary layer is\n381.479s: inment velocity and that basically\n383.52s: answers the question how does the pbl\n385.24s: grow over time um Greta earlier\n387.479s: mentioned this coping inversion so it's\n389.68s: in this graphic it see in for our case\n392.039s: we use H as the height of the boundary\n393.96s: layer and over time it'll grow and it'll\n395.96s: shrink um with the Earth Heating and\n399.08s: Cooling um and an important thing to\n402.319s: note is that the capping inversion isn't\n403.919s: like a strict lid on the boundary layer\n406.52s: it's a little bit like fluid so air will\n408.759s: rise up when it's heated and it'll\n410.44s: overshoot the boundary layer a little\n412.12s: bit it'll mix in air from the free\n413.599s: troposphere which is this area and then\n415.4s: it'll go back down and that's how the\n417.28s: height of the boundary layer changes um\n420.479s: in our case we represented by dhdt or we\n424.199s: dhdt is just the time evolution of the\n426.96s: boundary layer but it usually includes\n429.16s: more large scale components but in the\n431.08s: case of our Lees we don't have those\n433.08s: large scale components so we just say\n435.4s: that um entrainment velocity is\n439.56s: we um and so the equation that we wanted\n443.12s: to discover or ReDiscover is this top\n445.84s: one over here DH equals a which um based\n449.16s: off of theory is like around 2 and based\n451.44s: off of observational data it's closer to\n453.879s: like0\n455.08s: 443 um times a bunch of this G and this\n458.28s: Theta KN which is a bunch of constants\n460.28s: times this ratio the top the numerator\n463.24s: is the buoyancy flux at the surface and\n465.24s: the bottom is the change in potential\n467.199s: temperature in the inversion layer um to\n470.319s: run our equation Discovery Model we\n472.159s: inputed this um ratio as its own\n475.4s: variable as well as um this ug which is\n478.44s: imposed horizontal win throughout our\n480.479s: simulation surface Heating and the\n482.84s: change in potential temperature in the\n484.84s: free troposphere over time um and we see\n487.36s: that our equation Discovery Model had\n490.039s: this -1.75 one which roughly translates\n493.44s: when we like take the G and the um Thea\n495.759s: not into consideration roughly\n497.199s: translates in a of. 35 um times the con\n500.879s: or times the ratio that we wanted minus\n503.039s: this extra term and this extra term is\n505.919s: um some constant times the imposed\n507.759s: horizontal wind and we um think that\n510.44s: that implies that the horizontal wind\n512.56s: has something to do with mixing in the\n515.039s: boundary layer and that's also something\n516.959s: that modifies the height of the boundary\n518.44s: layer over\n523.88s: time okay so the second equation um we\n526.88s: kind of wanted to look at was in the\n528.68s: inversion layer this Mass flux so as\n531.279s: entainment is kind of happening um how\n533.56s: particles are moving between um the um\n536.519s: boundary layer and then kind of the free\n538.12s: atmosphere um when we kind of wanted to\n539.839s: look at this cuz there are some\n540.8s: discrepancies in the way we can\n542.72s: calculate um entrainment our entrainment\n546.56s: velocity um we some textbooks say that\n549.56s: um this W Theta H minus which is\n552.44s: vertical turbulent Heat at the um top of\n555.519s: the mixed layer is equal to our we or\n558.76s: entrainement velocity times the change\n561.12s: in temperature um in the inversion layer\n563.92s: and so we wanted to use Lura equation as\n566.64s: our new we to see if this still held\n569.92s: true because we are able to calculate\n571.88s: this um W Theta H minus from other\n575.079s: variables in our equation we're able to\n577.6s: pull everything else and calculate it as\n579.68s: a residual and then we were looking to\n581.56s: see if we would get this like plus\n583.04s: overshoot term to see if there was some\n584.959s: other um dependency for this math flux\n588.839s: um however this we did kind of run into\n591.64s: some um maybe um limitations with\n595.2s: equation Discovery here um we kind of\n597.68s: found that equation Discovery does tend\n599.64s: to um struggle to adhere to some of our\n601.88s: laws of physics and while it does have\n604.0s: built-in measures to respecting units um\n606.64s: we were getting some different scales on\n608.64s: our various equations we were um coming\n610.68s: up with so we did choose to not include\n613.2s: the um final equation that we\n615.0s: potentially found just because there\n616.279s: felt like there was too much um\n618.16s: variation if it could actually be\n619.839s: concrete um but there definitely was\n621.959s: some other term in this overshoot so not\n624.519s: entirely sure what it is but that is\n627.0s: what we have\n630.24s: the final equation that we were\n632.2s: interested in rediscovering and\n633.8s: improving upon was something to do with\n635.279s: the heat flux and so we're particularly\n637.04s: interested in the turbulent component of\n639.639s: warm air because it vertically\n641.0s: transports important things like uh\n643.0s: pollution or humidity and so the way\n645.639s: that this is done we want to study this\n647.279s: W Theta right here W is the upwards\n649.48s: component Theta is the heat the bar\n651.279s: above them indicates a co-variance and\n652.92s: that's how we get upwards heat flux so\n655.839s: what we'd like to do is there's this\n658.16s: parametrization for this P term this P\n660.88s: term is a pressure redistribution term\n663.279s: which acts as a source or a sync for\n665.519s: that term so essentially what we're\n667.44s: doing here is we have this equation this\n669.72s: is our response in blue and then we have\n672.56s: some constants multiplied by these four\n675.56s: key pink predictors right here and then\n678.399s: after that we get the resulting\n680.0s: coefficients and plug them into a\n681.88s: parametrization for the heat flux that's\n684.04s: dependent on them now the the simple\n687.04s: goal here is take this ugly equation\n689.04s: take\n689.92s: this response these four predictors\n693.32s: right here a couple others toss them\n695.24s: into the symbolic aggression software\n697.48s: and see if you actually get the same\n699.519s: functional form for p if you get the\n701.76s: same constant times variable plus\n703.36s: constant times variable and so on if we\n705.839s: do actually manage to recover the\n707.2s: functional form we want to compare the\n709.24s: discovered coefficients to theoretical\n710.76s: estimates weirdly enough I mean\n712.32s: coefficients are almost always data\n713.72s: dependent but in a lot of the papers I\n716.16s: looked at they were like these are the\n717.639s: typical values for coefficients which\n719.399s: we're surprised by so we'd like to see\n721.0s: if we have any discrepancy and then\n723.56s: after that we'd like to plug those\n725.04s: resulting coefficients into our\n726.639s: parametrization and see how well it\n729.44s: does so first things first I thought\n731.56s: this was a funny figure to put up here\n733.12s: because the the true vertical profile of\n735.68s: the P term is in Black here and then all\n738.36s: of these other lines are completely\n740.079s: nonsensical over complicated equations\n742.079s: which are really close to what we want\n743.88s: and are essentially one of the negatives\n745.8s: of using symbolic regression now when we\n748.839s: finally do recover the true functional\n751.839s: form it is in the form that we want and\n754.279s: it's this green line right here which is\n756.12s: essentially sitting on top of the black\n757.6s: line and indicates a really really good\n759.639s: fit if you look at the predicted versus\n761.6s: actual plot I don't know if that's too\n763.519s: small to see but we have an R squ of 098\n765.8s: which is so high that sometimes it's\n768.48s: unbelievable but the interesting part\n770.8s: here is that the coefficients that we\n772.44s: get for our functional form differ very\n774.519s: strongly from the theoretical or typical\n776.68s: values in fact if we are to plug in the\n778.8s: theor I or typical values we would get\n781.36s: this blue line right here which is very\n783.32s: far off from the black which is our\n785.6s: ground truth so to speak so that's an\n787.88s: interesting discrepancy now everything\n790.199s: is going well we have the functional\n791.519s: form we have the coefficients let's see\n793.16s: how it does in the actual\n795.079s: parametrization uh and and the short\n797.12s: answer is really poorly um this black\n800.16s: line is once again our truth this green\n802.04s: line is our discovered uh coefficients\n805.399s: plugged into the parametrization and and\n807.12s: luckily we're doing better than Theory\n808.639s: because Theory is in blue but um this\n812.12s: discrepancy is most likely from two\n813.639s: things number one not to get into the\n815.48s: specifics but in our data we calculate a\n817.44s: variable in kind of a funky way and it's\n819.56s: shaped very similarly to the profile of\n822.24s: our lines so we suspect that that might\n824.32s: be messing this up and then secondly we\n826.8s: suspect there are also extra\n828.44s: dependencies on large scale forcings now\n830.839s: I showed you guys that picture with all\n832.079s: of those semi-transparent lines earlier\n833.92s: to show that symbolic regression had a\n835.519s: really difficult time picking up the\n837.36s: original functional form so what we did\n839.68s: is instead of trying to get it to\n842.16s: ReDiscover novel dependencies we just\n845.04s: did it on the coefficients we used the\n847.519s: functional form we took the coefficients\n849.16s: and then we plugged in the coefficients\n850.759s: as a response and large scale forcings\n853.0s: like horizontal wind and surface heating\n855.44s: into their own symbolic aggression and\n857.88s: we get a lot of nonsense but really\n859.44s: really frequently the first coefficient\n861.68s: is dependent on the horizontal wind\n864.8s: now this may be so technical that it's\n867.279s: that it's boring but this first term\n869.959s: right here represents the return to\n871.839s: isotropy term of the equation this means\n874.24s: that eventually everything mixes around\n875.759s: in the pbl and there's a semi-\n877.199s: homogeneous State going on now I know\n879.16s: we're talking about vertical things here\n881.399s: but we suspect that the horizontal wind\n884.519s: likely contributes a lot to the mixing\n886.279s: once again and and so that's a\n887.959s: dependency that actually makes sense and\n889.759s: should be explored\n893.399s: more so just to kind of wrap up just\n896.639s: what we've done with this project we\n898.079s: were able to have basic basically two\n899.56s: successful um rediscovery for equations\n901.92s: our we our entrainment flux and then the\n904.199s: P the pressure term and both of them\n906.32s: really did point to this extra\n907.72s: dependency on um large scale foring\n910.72s: which is our horizontal win additionally\n912.88s: we were able to make a GitHub repository\n915.199s: um so this work can be reproduced um all\n917.56s: of our code is accessible and just by\n919.279s: changing the folder path um people can\n921.44s: potentially Rego in and use this code\n923.32s: and continue it on for further work um\n925.68s: so the future directions potentially in\n927.92s: we'd like to look more into are just\n929.399s: like including more simulations um with\n931.279s: varing initial conditions also um\n933.68s: refining the second stage of symbolic\n935.639s: regression for finding coefficient\n937.44s: dependence on large scale forcings and\n939.839s: just building in more um physical and\n942.279s: consideration of units um one of the big\n945.079s: limitations of equation Discovery is\n947.319s: relying on this local information but\n949.199s: we'd like to probably bring in some\n950.92s: non-locality um\n953.519s: space all right and thank you\n960.04s: okay we have time for two quick\n961.72s: questions I see one in the\n974.519s: back\n982.519s: you\n985.56s: by by people\n990.959s: ands what they do\n993.72s: ISF diens\n997.72s: groups which\n1000.279s: ofits into the equations because you\n1004.319s: want\n1006.48s: right codes are I think available so I\n1009.519s: don't know if you have time this Summer\n1011.319s: that something look unless you already\n1014.319s: looked at it and\n1017.279s: not is one of these paper is the pi Sr\n1021.04s: software because I don't believe I'm\n1022.759s: familiar with\n1025.959s: them we can absolutely\n1030.959s: yeah well I\n1036.64s: think\n1039.48s: in oh I see that's right yeah yeah I'd\n1042.12s: love to look at those\n1047.84s: papers ISR can fix part of the problem\n1050.919s: as well it can reject like candidate\n1052.76s: equations if they don't adhere to\n1054.32s: certain unit constrictions and it can\n1056.16s: also um it it has like a feature for\n1059.679s: respecting the units it's just that the\n1061.08s: feature works really strangely and we\n1062.679s: found it rather unhelpful but in theory\n1065.16s: it should be able to fix part of the\n1066.72s: problem but yes absolutely please slack\n1069.039s: me\n1072.919s: papers I wanted to see if I understand\n1075.44s: is the horizontal wind term is that not\n1078.36s: in the Theory derived parameterization\n1080.6s: but popping up in your equation\n1082.2s: Discovery yes so when we do this\n1084.36s: equation Discovery we put in all of the\n1086.039s: terms that are derived in theory and\n1088.159s: then we toss in a couple extra the\n1090.24s: easiest ones to toss in are the large\n1092.039s: scale forcings because they're simple\n1094.2s: but usually it's physical expert\n1096.32s: knowledge which guides us as to which\n1098.08s: parameters to toss in and large scale\n1100.76s: forcing was just something that we was\n1102.559s: not in there previously would this be an\n1104.72s: easy way to improve the theory derived\n1107.28s: parameterization that's that's the\n1109.12s: suspicion yeah is that a lot of these\n1110.88s: initial conditions aren't being given\n1112.559s: the consideration that they\n1115.2s: should okay thank you so much to all of\n1117.76s: our presenters yeah thank you guys"
    },
    {
        "class": "YouTubeVideo",
        "title": "Automating Discovery: From Cognitive Robotics to Particle Physics with Hod Lipson",
        "videoId": "QU1E1xBFErM",
        "url": "https://www.youtube.com/watch?v=QU1E1xBFErM",
        "publishedAt": "2023-03-03T14:46:55Z",
        "transcript": "5.04s: okay\n6.359s: um\n7.02s: okay guys so really happy to introduce\n12.08s: engineering department uh together at\n14.78s: Columbia University\n17.279s: um he's also director of the creative\n18.48s: machine Labs\n20.039s: um which does really creative work at\n21.539s: building creative machines\n23.34s: um and uh he has um yeah written\n26.519s: multiple books that have\n28.74s: um uh uh you know done very well\n32.64s: um one book is the fact is called\n34.5s: fabricate new world of 3D printing and\n36.66s: another book is driverless intelligent\n38.46s: Cars road ahead\n42.0s: um he's done uh his Ted Talk on AI is\n45.3s: one of the most viewed that talks on AI\n48.42s: um and so yeah hot is just you know\n50.579s: deploy math and has done pretty much a\n52.8s: little bit of air for everything\n54.36s: um and really an expert at where machine\n57.12s: learning hits the physical\n59.399s: World both in terms of part physics but\n61.739s: also in terms of life itself um so\n64.979s: really excited to um give us a talk and\n68.939s: um I'm sure it'll be very enjoyable\n70.2s: thanks so much for coming down\n72.08s: so it's a pleasure to be here I'm not\n74.04s: going to talk about any of these uh\n76.2s: jobless cars or uh uh 3D printing none\n79.86s: of that I'm going to talk about uh\n82.14s: automating discovery which is a little\n83.82s: bit more about how AI can look at\n87.96s: physical phenomena and extract the\n89.88s: physics of these phenomena and I think\n92.22s: it's very relevant to the kind of work\n93.6s: you're doing here\n95.52s: um it's um it's really all about\n99.119s: automating Discovery and I think that uh\n101.9s: you know the the main message I'd like\n104.579s: you to take home in the end is that uh\n108.38s: Pierre and I have argued about their\n110.46s: sermon when the early days of The\n112.2s: Proposal whether the end game is a human\n115.7s: machine collaboration in physics and\n119.159s: discovering the how the world works or\n121.799s: is it purely AI\n123.36s: and we human just collect the data and\n125.52s: feed it in and get predictions so I'm I\n127.979s: think more on the extreme that in the\n129.66s: end the world is too complicated and we\n132.06s: just could have had it over to AI uh we\n134.819s: just got our job is to collect the data\n136.62s: and collect the right data uh and uh he\n139.739s: will do the rest people are all over the\n142.02s: spectrum between the few physics people\n144.42s: want to understand everything all the\n145.92s: way down uh to the AI people want to\n148.86s: hand it over so uh truth is somewhere in\n151.319s: the middle but I want to tell a little\n152.459s: bit of the story\n154.08s: but we're going uh I think the you know\n156.78s: uh I'll start a little bit of my own\n158.94s: story in this area I didn't set out to\n161.7s: understand the world from uh using AI I\n165.0s: set out to build robots this is uh my\n167.22s: goal is it has been since I uh started\n170.76s: my academic careers to make better\n172.62s: robots and the challenge has always been\n175.739s: to make robots\n177.62s: that are adaptive\n180.18s: that's the biggest research in Frontier\n182.76s: in robotics is is robots already fast\n186.18s: and Powerful uh robots can already work\n189.239s: 24 7. it's all solved the biggest\n192.239s: challenge in robotics is making robots\n194.4s: can adapt to unseen situations that can\n196.98s: work and do things they have been\n198.659s: programmed to do work in the\n199.98s: environments they haven't worked in\n201.18s: before uh and in my case work when\n204.36s: they're broken if a bulge falls off of\n207.12s: this robot it's game over can a robot\n209.819s: adapt just like animals can keep on\n211.62s: going when they're broken uh can can\n214.5s: machines repair all these things all\n216.3s: these adaptation all this adaptation\n217.92s: that we see in the real world can robots\n219.9s: also have the same thing so but instead\n223.319s: of uh\n224.76s: uh instead of trying to build robots uh\n228.48s: I thought maybe we can breed robots in\n231.239s: other words we can use Evolution to\n232.86s: generate new kinds of machines uh rather\n236.04s: than sitting at a desk and designing\n237.72s: them as if we know how to design a robot\n239.7s: so my postdoc started at Grinders\n241.98s: university university in Boston uh in\n244.799s: the near MIT whatever that's what uh and\n249.48s: uh it's uh this is the center of complex\n253.08s: systems uh which on a good day looks\n255.48s: like this\n256.5s: and uh in that uh Center I worked with\n260.22s: Jordan Pollock and computer science and\n263.58s: we started to breed robots and the basic\n265.5s: idea was this we built in a big physics\n267.72s: simulation\n268.919s: uh physics simulators uh this was back\n271.5s: in 1999 the previous uh Century\n275.34s: Millennium uh you couldn't just download\n278.1s: the physics simulator you had to code it\n280.919s: from scratch we coded a physics\n282.54s: simulator from scratch\n284.16s: uh and then we threw in robot Parts into\n286.86s: it bars and motors and joints and\n289.86s: control elements like neurons and and uh\n293.58s: wires and things like that and sensors\n295.5s: we threw in all this garbage into this\n297.66s: big physics simulator and we allowed\n299.1s: Evolution to put it together randomly\n301.38s: and see what works\n303.479s: uh and then it's of course nothing\n305.34s: worked so uh some sometimes it\n308.84s: recombined things that worked a little\n311.46s: less badly than other things and uh that\n315.06s: improved a little bit and wanted to see\n317.04s: what would happen so let this thing go\n319.139s: uh we put in on the biggest uh parallel\n322.979s: computer we could find back then this is\n325.62s: the year 2000 already this is the Onyx\n328.1s: silicon Graphics 16 processor\n331.62s: killer machine you know let's get a cell\n334.199s: phone today but that was a state of the\n335.82s: art back then and we hit enter and we\n338.639s: watched what happened\n340.5s: and uh after uh\n343.86s: about a week this is Generations each\n346.02s: dot here is a robot\n348.24s: and you can see the speed of the robot\n350.28s: we evolved breeding robots to run across\n352.68s: the infinite Lane\n354.66s: uh you can see in the first week about\n358.139s: 100 Generations\n360.06s: nothing happened just getting piles of\n362.94s: junk\n363.9s: on the ground nothing's moving didn't\n366.9s: get my postdoc is not going anywhere\n370.139s: uh you know time to think about career\n372.66s: change\n373.74s: I'm about to plug up plug uh unplug the\n377.28s: machine and something you can use to me\n381.36s: but I'll\n382.62s: take a garbage that is vibrating a\n385.86s: little bit\n387.12s: but that vibration is infinitely better\n389.16s: than other pieces of garbage they're not\n390.78s: moving at all and so that vibrating\n393.18s: piece of garbage begins to uh take over\n395.94s: the the world uh and replicates and then\n399.06s: more versions and more versions and\n400.86s: things to get to do with a long story\n402.479s: short about a week later\n404.819s: uh we begin to see if interesting\n407.88s: designs to grow across things from the\n410.52s: plane it's a really really simple\n411.66s: machines\n413.039s: in today's terms\n414.96s: but this was exciting enough that I took\n417.78s: this and combined it with the new\n419.819s: technologies that just came out called\n421.5s: the 3D printing\n423.72s: and here you are with the first ever 3D\n426.18s: printed robot\n427.68s: falling across the floor of the lab and\n430.38s: it was not impressive 3D robot but it\n433.199s: was the first robot to be designed and\n435.539s: manufactured almost automatically\n438.68s: uh so uh so that was it uh that was\n443.46s: enough uh feeling amazing things if you\n446.039s: fast forward 20 years the day we can do\n448.62s: the same thing but we use soft robots\n450.599s: it's already 10 years old today we can\n452.58s: do it even better uh these are evolved\n455.16s: soft robots software wasn't much harder\n456.9s: to simulate uh much more complex to\n459.599s: evolve but still you get lots and lots\n461.46s: of interesting machines when you just\n463.08s: let them evolve and they compete they\n465.18s: almost have a personality right I mean\n467.94s: they're kind of cool and you're\n469.44s: interesting today this is so easy I give\n472.02s: this as homework assignment number one\n474.539s: in my uh evolutionary computation course\n477.12s: and they make amazing things\n479.819s: hold on to your questions to the end so\n482.58s: so uh we are uh so we keep uh we\n486.06s: evolving we evolve these things uh we\n488.94s: also try to figure out how to uh how to\n491.46s: make these things work physically uh by\n494.34s: developing physical actuators that\n496.68s: actually work this is a this is a soft\n499.44s: muscle that we've developed in our lab\n501.44s: uh what I'm not telling you here is this\n504.36s: is accelerated 25 times it's actually\n507.06s: very very slow not enough to make a\n508.56s: robot but still you know what we're\n510.06s: working on it but uh back to the story\n512.7s: this is this is one of the nicest robots\n515.399s: we made at the end of my postdoc uh and\n519.18s: uh it was difficult to publish this but\n522.06s: they did get into the front page of New\n523.74s: York Times which is all you need to get\n526.62s: a faculty position you right and uh uh\n531.24s: the editor of the New York Times it was\n533.399s: below the fall because uh you're\n535.2s: wondering uh the north Terminator uh and\n538.5s: chief told me the only reason they put\n540.36s: it there was because there was nothing\n542.1s: else happening in the world at all that\n544.32s: day\n546.24s: nothing else and they had to put science\n549.959s: I mean it's August 31st which is\n553.459s: yeah there was there was nothing else\n556.32s: happening not even bad stuff depends now\n560.72s: so they put it there and I got my\n563.279s: faculty position at Cornell University\n564.899s: Upstate New York which on a good day\n567.12s: looks like this\n569.06s: uh and of course I uh the big question\n572.04s: for me is can I get uh you know I I knew\n575.339s: that in mechanical engineering I'm not\n577.2s: going to continue on making plastic\n578.519s: robots I couldn't make robots out of\n580.26s: titanium and this is one of our first\n582.54s: robots it's uh uh and I wanted to see if\n585.3s: I can make this robot Gallop in the\n587.58s: fields all right this is uh in 2001\n590.279s: there's no Boston Dynamics yet the field\n593.399s: is wide open all the robots are lame\n596.04s: walking machines that can barely you\n597.899s: know step over uh you know a twig can we\n601.8s: make a robot our job in the field so we\n603.6s: built this amazing robot it has a\n605.58s: paintball canister in the center lots of\n608.16s: you know air valves and amazing power I\n610.98s: can do backflips there's all kinds of\n612.54s: things and the question is can I make it\n614.64s: Gallop gracefully through the fields\n618.24s: so I put it in a big cage\n620.399s: and I ran Evolution with my students on\n623.64s: the controller of this thing to open and\n625.74s: close the valves and it's a big cage\n627.899s: it's a camera at the top the track where\n630.06s: the robot is gives rewards for different\n632.1s: controllers controllers crossbreed with\n634.5s: other boot patrols like a rodeo show and\n637.38s: then the best ones get to ride this\n639.72s: robot and after a while leaving this\n642.12s: overnight we've got some interesting\n643.62s: behaviors here's some of these robots\n645.48s: playing back they don't even have audio\n648.66s: but you can imagine the clicking and\n650.64s: clacking of this machine but it's not\n653.339s: going anywhere okay actually towards the\n656.88s: air they've walked a little bit but\n658.32s: we're not going to take over the world\n659.519s: but this thing and neither was I going\n661.26s: to get changed here this is three years\n662.7s: into the it's a big program a lot of\n666.0s: money but this robot is very little to\n668.519s: show for it right so so Evolution on the\n671.94s: physical robot is not going anywhere so\n673.98s: to summarize to this point I have two\n677.1s: live transcription is great\n680.82s: let me turn this off\n685.16s: do you mind just turning this off so I\n687.6s: got the message\n689.42s: oh wow I have to move it\n696.839s: okay\n711.18s: next\n717.6s: I'm gonna move forward\n727.7s: and click here\n735.3s: okay so uh two projects I showed you the\n739.44s: first one all in simulation\n741.42s: uh we breeded in simulation the best one\n744.24s: gets to go into reality we cross our\n746.7s: fingers and uh it works but it only work\n749.519s: because the robots were really really\n750.54s: simple Dynamics were simple everything\n752.94s: was simple uh the second part said it\n756.36s: wasn't impressive so this only uh works\n760.56s: uh\n763.26s: because the robots were simple and what\n765.66s: we call the simulation reality Gap is\n768.48s: small\n769.5s: right it doesn't work for Real uh\n771.72s: project the second project that I showed\n773.639s: you there was no simulations all\n775.26s: happening on the physical robot it works\n777.54s: really\n778.56s: well it doesn't work simply because it\n781.8s: takes too many physical trials on a\n783.3s: physical robot you can do things on a\n785.459s: physical robot but physical robots are\n787.2s: slow expensive uh they wear out it's\n790.68s: it's complicated to do Evolution on\n793.44s: physical robot so in simulation it works\n796.139s: but doesn't transfer in reality it works\n799.44s: but it's too slow\n800.76s: in other words it doesn't scale either\n802.74s: way so what do we do I have two more\n805.32s: years for my tenure clock I got a fine\n807.959s: alternative solution so I went back and\n810.839s: what we did is a sort of hybrid mix and\n814.2s: this is how it works start off with a\n816.42s: simulator that's bad\n818.339s: all right we don't involve robot in it\n821.399s: and by the way if you're interested in\n823.26s: simulating any pixel systems you can\n825.24s: sort of draw the analogy here between\n827.459s: what we're doing here and what you want\n829.139s: to simulate we start with a crude\n831.72s: simulator we evolve robots we try them\n834.899s: in reality they don't work but we\n836.82s: collect data\n838.32s: and then we use that data to evolve\n840.72s: better simulators and this is sort of\n842.639s: the cycle once we have better simulators\n845.339s: we evolve new robots\n847.68s: and the cycle continuous in other words\n849.3s: we now are optimizing two things at the\n851.82s: same time optimizing the simulators and\n854.82s: the robots so there's two things coin\n857.339s: adapting at the same time uh the in The\n860.7s: evolutionary computation field this is\n862.32s: called co-evolution it happens all the\n864.0s: time Predator prey\n866.12s: symbiosis uh\n868.44s: biology is always co-evolving there's\n871.8s: never anything evolving at the same time\n873.48s: in AI this is called Edward serial order\n876.12s: there's a relationship between these two\n877.98s: things the the robots take advantage of\n881.639s: quirks and the simulator the simulator\n883.699s: uh is tries to explain away observations\n887.519s: uh from Real Robots so they have a it's\n890.699s: not adversarial maybe student uh\n893.16s: Professor kind of relationship it's kind\n894.959s: of mixed but they both lift each other\n897.48s: up and it begins to work here's the last\n899.94s: uh this is the robots on the title page\n903.3s: a four-legged machine uh this robot\n906.06s: needs to learn how to walk\n908.579s: this is our last experiment uh back then\n911.94s: uh it has uh four it has eight mortars\n916.019s: two in each leg one in the foot and one\n917.82s: one of the knee one of the hip it only\n919.98s: has two sensors\n921.72s: which generally if it's tilted left and\n923.339s: right forward and backward and this\n924.779s: robot needs to learn how to walk but\n927.959s: here's the challenge it does not know\n929.82s: what it looks like unlike robots alone\n933.18s: in simulation or robots alone in the\n936.3s: physical world this has no simulation\n938.639s: does not know what it looks like nothing\n941.279s: all it has is these two angles that's\n943.86s: tilted and access to eight Motors but it\n945.899s: doesn't even know if it's a snake a\n947.279s: spider a tree or robotic arm a worm\n950.04s: doesn't know anything about anything\n952.98s: but uh so it's a bit like a brain of a\n956.16s: newborn child maybe that has access to\n958.44s: all kinds of muscles and it needs to\n960.12s: learn how to what it is in order to do\n962.699s: things so the robot the case of making\n964.94s: uh random motions\n967.98s: they're making hypotheses about what it\n970.44s: might be\n972.36s: the hypotheses that are compatible with\n975.42s: data is collecting from its random\n977.459s: motion once it has this uh these models\n981.06s: and this is where it connects to to\n983.04s: automated science it looks for how to\n985.079s: activate these these models\n988.26s: what actuation activity increase the\n990.24s: most disagreement between these models\n992.1s: okay this is like a scientist thinking\n994.199s: about what boundary condition creates\n996.0s: the most disagreement between two\n997.56s: competing models uh between two\n1000.38s: Computing theories and then data from\n1002.0s: the real experiment will refute at least\n1003.86s: one of those theories and then goes and\n1006.139s: back and does that action with future of\n1008.3s: the models look how to make them\n1009.5s: disagree again and goes back in a circle\n1011.66s: at the end when the models cannot be\n1013.519s: made to be secret anymore they converge\n1016.16s: it figures out how to walk in the\n1018.32s: simulation and create it and because it\n1020.42s: matches reality what makes the robot\n1022.459s: move makes in simulation makes it move\n1024.799s: in reality in the same way\n1027.199s: so we started off uh and let's use the\n1030.439s: robot building and simulation of itself\n1032.78s: it's going to move randomly collect data\n1035.24s: and understand what it is at least that\n1037.939s: was the whole you turn it on and Bam it\n1042.38s: unplugs itself\n1044.319s: and that was the end of that robot uh\n1047.959s: and the goal is the message here you\n1050.48s: can't explore too far beyond what you\n1052.7s: know this is this risk exploration where\n1055.4s: you don't want to walk off a cliff to\n1056.78s: find out if you can fly right this is\n1059.679s: there's risk inherent exploration so we\n1062.36s: tame it down a little bit and uh there\n1065.419s: it is uh exploring itself here are some\n1067.82s: models it's creating in the beginning\n1069.2s: they're all wrong this takes about four\n1071.0s: days\n1072.02s: uh this is uh more than a decade ago\n1075.5s: again today I could do it on your cell\n1077.72s: phone but here it is gradually exploring\n1080.12s: itself uh two days into the process it\n1082.7s: figured out that it has four legs but\n1085.22s: doesn't quite know how they're connected\n1087.039s: and this is about four days into the\n1090.02s: process it pretty much figured out what\n1091.76s: it is it's not perfectly accurate but\n1093.98s: this stick figure\n1095.48s: is good enough that you can learn how to\n1098.12s: walk in it's in it's inside its own\n1100.1s: simulation and it's learning a lot it\n1102.62s: takes another day to learn how to walk\n1104.48s: in simulation again it's inside the\n1106.58s: simulation it builds\n1108.32s: of itself and here it is walking around\n1110.9s: I think if we had sound the amazing\n1113.299s: clickety clack sound of the machine\n1115.34s: walking for the first time\n1118.039s: without having done trials in physical\n1119.96s: world without being programmed without\n1122.9s: having a model of itself or not okay to\n1125.36s: test this we did something very cool we\n1127.4s: blocked off a leg\n1128.96s: we watched what happened the robot uh\n1133.76s: of course is doesn't know what happened\n1135.679s: but its Dynamics do not match\n1138.32s: uh its predictions and it goes back into\n1141.2s: the self modeling continues to adapt as\n1143.66s: well and its model also this is the link\n1146.36s: and it's not because you know there was\n1149.0s: a a leg came off and there was a sensor\n1151.16s: that said let came off switch to plan B\n1153.08s: this all happened spontaneously the\n1155.36s: Dynamics change the models changed the\n1157.7s: behavior changed and again we're after\n1160.52s: this Holy Grail of adaptations\n1162.44s: spontaneous adaptation and machines and\n1165.14s: this is the key here is self-modeling\n1167.179s: and this is this uh thing could\n1169.94s: potentially do a lot of interesting\n1171.98s: things here's a\n1173.48s: 30 independent runs standing at the\n1176.48s: origin red dots are where a random\n1178.7s: controller makes the robot move black\n1180.98s: dots are where the robot believes it's\n1183.02s: going to get to using its own simulation\n1185.14s: blue dots are where it actually gets\n1188.24s: into physical reality\n1190.34s: which means that the robot like anything\n1192.679s: else in Academia has an inflated\n1194.539s: self-image\n1196.1s: the leaves it can go twice as far as it\n1198.44s: really can\n1199.76s: however\n1202.52s: even though the model is wrong it still\n1205.039s: allows the robot to learn how to walk\n1207.2s: and this is really interesting because\n1208.64s: you can see that Evolution we Engineers\n1211.16s: are obsessed with accuracy of our\n1213.62s: simulation\n1215.0s: Evolution doesn't care about accuracy as\n1217.28s: long as you're making the right\n1218.299s: decisions with your model you're good\n1221.0s: always time on getting things accurate\n1223.52s: because some things you can't get\n1225.62s: accurate you just need to get the\n1226.94s: gradient right so this is kind of\n1228.38s: interesting for me I give talks about\n1230.419s: this in social science conferences\n1232.76s: because people want to know to what\n1235.16s: degree is our self-image important\n1237.74s: and it's interesting here that that\n1240.62s: inflated self models allow garwa to move\n1242.96s: forward deflated models uh the signal to\n1246.5s: noise ratio is too poor for the robot to\n1248.78s: make any decision this is really really\n1250.34s: interesting from a psychology point of\n1252.62s: view and how we see ourselves and so on\n1254.299s: but\n1255.2s: but let me move on and talk a little bit\n1257.36s: about what happened next uh that was a\n1259.94s: long time ago before deep learning\n1263.419s: deep learning came along and of course\n1265.88s: whatever you did before or you now do\n1268.46s: again with deep drawing so this is what\n1270.38s: we do here this robot is going to move\n1272.72s: in the beginning uh this is completely\n1274.82s: from scratch has no knowledge of physics\n1277.16s: you can see the robot in the background\n1279.08s: does not know what it is and this is\n1280.64s: about after eight hours of training to\n1282.62s: see the shadow is the self model and the\n1285.919s: physical robot in the foreground it's\n1288.02s: not perfect but it's good enough\n1291.2s: but this robot can learn to behave and\n1294.26s: again our human self-image is also not\n1297.679s: accurate if you close your eyes let's do\n1299.78s: this for a second With Me Close Your\n1301.58s: Eyes\n1302.6s: and touch your nose with your eyes pose\n1304.94s: from far away\n1306.74s: okay I can see some of you have missed\n1309.679s: all right\n1310.94s: uh if you got it on okay if you're gonna\n1316.039s: add the dot awesome but most of you have\n1318.02s: missed like I was watching carefully\n1319.52s: each and one of every one of you you got\n1321.799s: it off by about one centimeter all right\n1323.72s: this is the accuracy of a self model\n1326.12s: uh this robot gets it right about\n1329.6s: one age right so it's not as good as\n1331.64s: humans but it's getting there right so\n1335.179s: this robot can see itself\n1337.52s: Envision itself and uh you know again\n1340.1s: the same thing we took a piece of the\n1341.6s: robot we replaced it with the Crooked\n1344.12s: part and we let the robot move and after\n1347.24s: a brief recalibration the robot creates\n1349.7s: a new wall of it so and can keep on\n1351.919s: doing what it did before with this new\n1354.02s: model okay uh this is a really recent\n1358.039s: this is just uh just came out\n1360.98s: uh\n1362.919s: and uh maybe with Carl I'm not sure\n1366.62s: about this one\n1368.72s: maybe uh in science and science robotics\n1373.159s: uh this is a statistical model of the\n1375.5s: robot the robot prances around in front\n1378.02s: of a camera and creates a statistical\n1379.94s: model of itself you can see the physical\n1381.86s: robot in the foreground and this\n1385.88s: this kind of fog behind it that's how it\n1389.419s: sees itself and as it moves on I can use\n1391.28s: that to plan to move forward so these\n1393.799s: self models are getting more and more\n1395.6s: sophisticated uh I want to see how far\n1398.059s: we can push this and and I really\n1399.799s: believe that in the end of the day our\n1403.7s: but self-awareness has to do with being\n1407.299s: able to see yourself in the future and\n1409.58s: that's what these robots are going to do\n1411.08s: all right so we have a self model of\n1413.36s: ourselves and this is what it is\n1415.4s: is some more examples the ground truth\n1417.74s: the self mom so it's getting more and\n1420.44s: more accurate uh these moments are\n1422.419s: learning to see themselves so another\n1424.1s: offshoot of that research that robots\n1425.9s: that model other robots\n1428.12s: not just themselves but looking at other\n1430.039s: robots trying to understand what the\n1431.299s: other robot is like what they can do or\n1433.76s: what is planning uh and so on so we did\n1436.64s: some interesting uh work on hide and\n1440.24s: seek uh where the robots need to put the\n1444.32s: Hydra needs to predict how the seeker\n1446.659s: can see it or not so it has to hide and\n1448.94s: seek is a very sophisticated game where\n1451.34s: you have to see the world from another\n1452.72s: person's point of view in your\n1454.28s: imagination and so it involved a lot of\n1457.22s: this self-modeling other modeling so\n1459.2s: we're trying to create these interesting\n1461.659s: games where that involve machines\n1464.24s: learning to see themselves from their\n1466.28s: own point of view have on the point of\n1468.2s: view of others and I think it's very\n1469.64s: important uh you know to how machines\n1473.0s: will eventually\n1474.559s: integrate in our society all right so\n1477.74s: that's a whole line of research were you\n1479.36s: still working on it but that's not what\n1480.86s: I'll talk about I want to talk a little\n1482.24s: bit about this question of system\n1484.22s: identification which is uh at this point\n1487.7s: I finally got tenure and a new student\n1489.38s: came into the lab and said all you are\n1491.96s: trying to do here is create models of a\n1494.72s: system\n1495.86s: from partial observations where you can\n1498.86s: perturb the inputs\n1500.78s: in order to extract the most information\n1503.0s: from each observation\n1505.7s: so let's try to do it for some other\n1508.22s: systems so so let's take an arbitrary\n1511.4s: experimental system\n1513.679s: uh collect data from it just like you\n1516.32s: connected from the robot\n1517.82s: create models of it but instead of\n1519.86s: models being building blocks mechanical\n1522.14s: building blocks will make models made of\n1524.299s: essentially algebraic building blocks\n1527.059s: same thing instead of experiments being\n1530.539s: how to move the motors we're going to\n1532.76s: change initial conditions and boundary\n1534.679s: conditions on the mouse we can\n1537.799s: assimilate them find out what initial\n1539.48s: conditions and value conditions make\n1541.22s: these walls disagree\n1543.14s: find those apply them in reality get\n1545.9s: more data refute some of the models do\n1548.6s: this again and eventually we'll get a\n1551.36s: model of whatever system we're exploring\n1553.88s: it sounds like a simple thing it's a\n1556.039s: very it's a straightforward adaptation\n1557.96s: what we did before with the exception\n1560.179s: that it's very easy to\n1562.039s: to collect it on a robot the robot can\n1564.679s: do the whole thing with the physical\n1566.0s: experiment it's harder to collect data\n1568.82s: what do you do that so you can have a\n1571.279s: human collecting data for the robot\n1573.44s: which is an interesting turn of the\n1575.299s: Turning of the tables right we always\n1577.039s: thought\n1578.179s: computers will will collect data and we\n1580.82s: will come up with a hypothesis that's\n1582.74s: how most scientists saw the future\n1585.62s: now humans collecting the data computers\n1588.2s: are coming up with hypotheses not\n1589.82s: exactly how we want it to play out but\n1591.98s: we'll take it\n1593.12s: option number two robots also collect\n1595.7s: the data\n1596.779s: for the other robot that's making the\n1598.7s: hypothesis\n1599.84s: option number three is you just collect\n1602.539s: data\n1604.159s: like in atmospheric sciences where you\n1606.26s: can't easily do experiments and then\n1609.679s: you put them in a big database and when\n1611.24s: the robot wants to do an experiment you\n1613.039s: look up the closest thing you have in\n1615.08s: your database and you pull it out and\n1616.4s: said we did the experiment here's here's\n1618.74s: the is the answer and this is kind of a\n1620.419s: little bit realistic this is the way\n1622.279s: most most of these automated science\n1624.2s: ends up being done and you can create\n1626.539s: them all so we try this on a lot of\n1628.039s: things this is uh I was at Cornell at\n1630.08s: the time if you've ever been to Cornell\n1633.14s: anybody here being to Cornell University\n1634.82s: Upstate very far away but\n1638.72s: you know like I think it's uh it's two\n1641.419s: weeks walk from here very far if you get\n1645.5s: there uh it's a beautiful place but it's\n1649.4s: surrounded by Gorges it's very uh\n1653.779s: very difficult to attack this is the\n1656.539s: bridge leading into Cornell I want this\n1659.0s: every morning\n1661.039s: um and it's very wobbly\n1663.559s: and when you walk it you always wonder\n1665.6s: what would happen if we would break at\n1667.4s: least I did and so we uh we did this we\n1670.88s: applied this technique to this uh\n1672.98s: problem we uh attach vibrators to\n1675.74s: different locations of the bridge we\n1677.24s: vibrated we measure vibrations with\n1679.64s: other locations and we try to find out\n1682.039s: create models that explain the\n1683.96s: vibrations and then look to hydro\n1686.299s: vibrate the bridge again to make these\n1688.7s: models disagree and go back and forth\n1690.98s: and we can find out more accurately and\n1694.34s: faster than any civil engineering\n1696.32s: approach how to you know find a broken\n1699.14s: piece in the bridge\n1701.12s: and so you can do is this with\n1702.679s: structural identification this is an\n1704.299s: example of uh just applying this this\n1707.419s: co-evolutionary idea to modeling other\n1709.82s: things it's another example\n1711.679s: analog circuit in a black box I made a\n1714.02s: little bit transparent but I don't think\n1715.46s: you can see it uh how do you activate\n1717.86s: the analog circuit to expose what's\n1721.46s: inside and if we do the forward they can\n1723.799s: find out pretty much what's inside\n1725.779s: and this is a non-linear analog circuit\n1728.539s: very difficult to verse engineer any\n1731.12s: other way you cannot do it using\n1733.159s: conventional methods but you can do it\n1734.539s: using this thing and these patterns are\n1736.64s: generated automatically to maximize\n1739.76s: information coming out so this\n1741.62s: extraction can work so you can see\n1743.9s: almost uh you know scientist\n1746.24s: interrogating a nonlinear system and\n1748.46s: extracting them all okay this is uh\n1751.039s: dudes arguably this is all of science is\n1753.679s: is doing that right so we do it all\n1755.659s: kinds of things so that brings me to\n1757.46s: this\n1758.48s: last example so you can see you can\n1760.399s: apply it to different things it all\n1761.539s: depends on what building block you use\n1763.1s: and so I want to use algebraic music\n1765.5s: blocks and apply it to the most General\n1767.44s: data system which is just a collection\n1769.64s: of data points so that brings me this\n1771.86s: idea called symbolic regression\n1774.74s: uh which uh is all about modeling a\n1778.399s: system\n1779.799s: uh finding out with the equations\n1782.0s: explains data so here I have a couple of\n1784.159s: points enable you know the function that\n1786.98s: creates\n1788.0s: created this point R\n1791.6s: to the Raven of the guests\n1798.52s: okay good that's very close it's uh\n1801.679s: exploding yeah that's pretty close all\n1804.679s: right so if you're trying to do this in\n1806.72s: your head\n1808.34s: you're not doing linear regression\n1811.039s: you were thinking okay there's a sign\n1813.679s: maybe a cosine there's exponent Maybe\n1816.08s: not maybe a linear you're trying to take\n1818.059s: these these building blocks and put them\n1820.399s: together to qualitatively explain what's\n1822.38s: going on\n1823.399s: so uh so we call that symbolic\n1825.799s: regression as opposed to linear\n1827.179s: regression on the nonlinear regression\n1828.86s: we we fine-tune coefficients uh and\n1832.22s: again arguably this is something that\n1833.84s: normally machines don't do right we we\n1836.24s: do that we like to do this part and then\n1838.039s: we let the computer fine tune the\n1839.72s: coefficients but the idea here is we let\n1842.419s: the computer actually search for the\n1844.7s: symbols for the actual uh exponent so uh\n1847.88s: and uh you know since you did it so\n1850.76s: quickly what's this one you can answer\n1852.98s: it then okay I'm kidding it's harder and\n1855.14s: harder the higher Dimensions there are\n1857.72s: this is\n1860.98s: uh this is uh\n1863.779s: um I'll show you what it is tomorrow but\n1866.0s: this is again one dimensional function\n1868.399s: you can do it one of our 20 Dimensions\n1870.799s: you can right so the way we do it is we\n1873.98s: read equations\n1876.34s: represented as trees this is uh you know\n1881.059s: x minus 3 times sine of X plus minus\n1884.24s: seven right so if we breed these\n1885.799s: equations in the beginning they don't\n1887.84s: match the data the error is high we\n1889.76s: cross breed them all these things and\n1891.679s: eventually we get equations\n1893.36s: explain the data so so it's a very\n1895.64s: simple idea uh and uh if we do that we\n1899.72s: might uh it might work so this is the\n1901.399s: idea old idea uh proposed by John coza\n1904.039s: in 1992\n1906.34s: uh who uh\n1909.62s: was it Stanford and then he invented\n1913.46s: uh in the lottery if you if you ever did\n1916.76s: Lottery there's this glue you have to\n1918.679s: scrape off a ticket\n1920.179s: he has a patent on the on the blue all\n1922.94s: right oh you cannot like photograph\n1927.86s: s so uh so uh here's a pattern on the\n1931.22s: glue so he left Stanford and he's a rich\n1935.899s: person but he invented this technique\n1938.48s: but and it's an amazing idea except that\n1940.82s: it doesn't work\n1942.14s: why doesn't it work it's the same reason\n1944.539s: any machine learning algorithm doesn't\n1946.64s: work and that is because it's too slow\n1950.26s: and it tends to overfit the data\n1953.779s: so what we did is a very simple\n1955.76s: adaptation we evolved models to fit the\n1958.34s: data\n1959.6s: except we don't fit it entirely and I\n1962.299s: said no only fit to a few points you see\n1963.919s: these red points\n1965.36s: where are the where do we put these red\n1967.22s: points these red points also involve\n1970.94s: and they move around to defeat these\n1973.82s: models they move around to where these\n1975.919s: models disagree about their predictions\n1977.779s: if all the models can explain this curve\n1980.36s: here that these red dots will move away\n1982.58s: from this Red Dot from this area so it's\n1985.7s: a Predator prey again adversarial\n1989.0s: learning a model that models that try to\n1991.82s: model data and data the price to\n1993.799s: escaping modeled they go back and forth\n1996.44s: they chase each other around but over\n1998.899s: time it works in incredible way because\n2001.24s: one of our first applications\n2003.36s: Windows uh 2000 or whatever\n2006.899s: points jumping around the same data I\n2009.7s: said I gave you still low resolution to\n2012.039s: C but very quickly models it and it goes\n2014.799s: back with X exponent of x times sine of\n2018.46s: absolute value of x right\n2021.399s: perfect\n2022.539s: so uh you can see the points jumping\n2025.0s: around\n2026.32s: uh so if we ran this uh and we found\n2029.44s: these interesting things if you model if\n2031.299s: you use an entire data set it kind of\n2033.159s: gets better over time random sub\n2035.32s: sampling Dynamic sub sampling but if you\n2038.74s: use uh just the co-evolution you get the\n2042.779s: solution that's more accurate and you\n2045.1s: get it sooner\n2046.36s: and this is counter-intuitive you would\n2048.159s: think that using the entire data set is\n2050.139s: always the best thing\n2051.58s: why would you throw away data well here\n2054.399s: it says no if you use a subset of the\n2056.74s: data but a subset that has been involved\n2058.78s: to defeat the models you get better\n2060.52s: answers so so it's sort of active\n2062.74s: learning query by committee all kinds of\n2065.379s: uh ideas baked in here two things\n2069.22s: co-adapting at the same time and you get\n2071.2s: better not only you get it better but if\n2073.599s: you use the entire list and you get\n2074.98s: models that are more complex than if you\n2077.2s: use Clear evolve data sets where you get\n2079.359s: similar models\n2080.98s: the same\n2082.419s: accuracy\n2084.22s: so if it's simpler and just as accurate\n2086.8s: it's closer to the truth Occam's razor\n2088.899s: and I think this is what is happening\n2090.82s: here\n2091.96s: so what do we do with this\n2093.82s: of course we uh try to predict the stock\n2096.52s: market\n2097.599s: why not New York\n2100.0s: uh of course that didn't work I'm still\n2101.92s: here so uh so uh you know we try to do\n2106.0s: something else so we uh try to predict\n2108.46s: the prime numbers another cool little\n2111.7s: project that didn't work either we did\n2113.619s: find\n2114.7s: known relationships between prime\n2116.8s: numbers but nothing no formula all right\n2119.68s: not gonna be rich or famous so we wrote\n2123.64s: some papers\n2125.2s: how to do this and we got an email from\n2128.2s: the school concern who said um\n2131.92s: uh we have this uh challenge it's called\n2135.04s: The Binding energy of atomic nuclei I\n2137.079s: don't understand what it is exactly but\n2139.48s: they have the data they sent over the\n2140.98s: data they said if you can model it\n2144.16s: uh let us know\n2145.72s: just want the equation\n2147.4s: we ran this thing we got a beautiful\n2149.44s: equation this is what we got exclaims\n2152.56s: the relationship to three digits\n2155.74s: amazing I emailed the guy and sir and\n2160.24s: emailed me back it says we already know\n2163.24s: about this for me\n2164.859s: it's called White Cycles formula and our\n2167.2s: formula is good to four digits\n2169.78s: so he was disappointed but I was\n2172.18s: actually very excited\n2173.619s: we can find named formulas\n2176.44s: from there\n2177.94s: uh who else you know who knows what else\n2180.4s: we can find right I mean it's an\n2182.02s: incredible thing so to take it up a\n2184.24s: notch we said let's not just moral\n2185.859s: static data that's model Dynamics so we\n2188.44s: take time series data we compute the\n2190.72s: derivatives now we have derivatives of\n2193.06s: the data easily easier said than done\n2195.94s: but let's say you can do it uh and now\n2198.28s: we model the data to the derivative so\n2200.92s: we get differential equations and we\n2202.48s: tried it out on glycolysis a daylight\n2205.42s: cycle of the cell and we get back all\n2209.859s: seven nonlinear differential equations\n2211.66s: of the model that the causes cycle again\n2214.66s: I don't know what that means exactly but\n2216.52s: there's a lot of data about this and we\n2218.02s: can type the equations from scratch\n2220.66s: amazing\n2222.579s: uh and before we move on\n2226.359s: uh you know at the time\n2228.96s: uh as Carl mentioned earlier we did a\n2232.0s: lot of work on 3D printing we still do\n2233.98s: we made this robot that slaps its wings\n2237.16s: and flies like a mosquito that's another\n2239.92s: project that somebody's working on uh\n2242.74s: and the question was how much lift does\n2245.26s: a flapping Wing create and this is a\n2247.24s: very complicated aerodynamic uh elasto\n2250.54s: uh\n2252.22s: durable and you know all the bad things\n2254.5s: combined okay and then how do we uh\n2257.98s: measure the lift of this we so we've\n2259.839s: dealt a lot of experiments connected\n2261.4s: data so let's see quick weight and\n2263.56s: equation a formula for the lift for an\n2266.14s: air elastic Wing okay very complicated\n2268.18s: thing uh and I don't want to show you\n2270.28s: the answer it's not interesting uh for\n2272.38s: this talk and I want to compare it to\n2274.72s: the state-of-the-art equations this is\n2276.64s: where it gets interesting and I want to\n2278.619s: compare it on two axes\n2280.78s: uh and we can you can use that for all\n2283.18s: of signs\n2284.92s: accuracy and complexity\n2287.68s: you have models that are simple but not\n2291.099s: very accurate every equal remains\n2293.859s: actually it's pretty accurate uh you\n2296.2s: have models that are uh you know they're\n2298.42s: good enough right\n2300.4s: very accurate\n2302.14s: to complex or they're complex and use\n2303.94s: them in some situations but they're very\n2305.74s: accurate now of course we all want to be\n2308.44s: here right this is a Nobel Prize but\n2310.54s: this is where most of us end up right\n2313.54s: it's the whole Space of scientific\n2316.599s: thinking so where do the models coming\n2318.82s: out of this process stand up so we did a\n2321.4s: large literature review here are all the\n2323.74s: models at the time for air elastic lift\n2327.099s: different uh degrees of accuracy and\n2330.94s: different degrees of complexity we\n2334.119s: measure it complexity by the amount of\n2335.74s: ink taken to write down the model\n2337.92s: equation the true measure but that's\n2341.02s: what we have and here are the models\n2343.06s: created by our system and the important\n2345.16s: thing is that they are these models are\n2347.38s: simpler and more accurate than the\n2349.119s: models created\n2350.38s: people\n2351.339s: so this is not a neural network that has\n2354.76s: a billion parameters that can make\n2356.44s: accurate predictions this isn't simpler\n2359.5s: than models published by experts in this\n2362.38s: area this is where we're going these are\n2364.42s: polynomial fits from the same data and\n2366.82s: we are sort of on the right side of the\n2368.44s: tracks\n2369.94s: okay uh lots of examples this another\n2373.18s: student came in wanted to model Road\n2375.88s: tire interaction\n2378.76s: I thought it's a noble cause it's for uh\n2383.2s: you know so making cars safer\n2386.14s: he said no uh I said uh is it uh\n2391.48s: um for making cars more efficient he\n2393.76s: said no so it's okay why are you trying\n2395.32s: to do this he said for video games\n2397.42s: making video against better all right\n2399.4s: whatever the reason you model this and\n2402.22s: you got balls are better and more\n2403.96s: accurate than state-of-the-art models by\n2406.3s: the automotive industry\n2408.64s: so again you get models that are\n2411.7s: interesting they're understandable and\n2413.56s: so on so I I started giving talks just\n2415.72s: like this at the end of this point\n2417.82s: that would say give me your data I'll\n2419.68s: give you a loan let's collaborate you\n2422.32s: have data I have this hammer and we're\n2424.42s: going to take the nails and the hammer\n2426.16s: and we're gonna create lots of\n2428.2s: interesting things so so uh usually\n2431.14s: people don't want to share the data this\n2433.06s: is this is always being a problem\n2436.2s: uh but uh this guy grows Sewell came to\n2439.78s: me at the end of the talking I said I\n2441.4s: have the perfect data set I'm doing\n2442.78s: these experiments with with some\n2446.44s: uh some bacteria that I can't pronounce\n2449.579s: and uh I have these Dynamics collected\n2453.82s: from Individual cells I can give you all\n2457.24s: these Dynamics and maybe you can create\n2459.4s: them all that explains it for all the\n2461.38s: cells and he gave me 60 cells\n2464.99s: [Music]\n2468.72s: they give me the cell I ran it and um\n2473.8s: uh after about a week we get these two\n2475.9s: bottles\n2477.04s: and it'll look like great these two\n2479.32s: differential equations explain the\n2480.88s: entire data set and I email Google and\n2483.88s: and I say here we have the walls and he\n2485.619s: says\n2486.579s: this is total garbage\n2489.099s: it's not related to biology it's uh\n2491.92s: second order there's no second order in\n2493.78s: biology this is not relevant\n2497.44s: complete guard so what do we do so we\n2500.02s: went back and we figured that we're\n2501.46s: using the wrong building blocks\n2504.339s: we're using sine and cosine for example\n2506.859s: which are irrelevant to biology biology\n2508.72s: doesn't have sine and cosine algae has\n2511.24s: different building blocks that we're not\n2512.44s: putting in so we scratched our heads and\n2514.54s: rubbed our chin\n2516.22s: and found and thought that maybe we need\n2519.7s: a new building block called time delays\n2521.74s: the biology there's a lot of time delays\n2523.96s: nothing happens exactly between the time\n2526.06s: delays and down we get this beautiful\n2528.4s: wall that explains everything and evil\n2530.98s: girl they say I have them all for you\n2533.14s: and he says we have a problem\n2535.119s: use the models I published\n2538.06s: and your models are more accurate and\n2541.359s: simple\n2543.94s: but there's one challenge\n2546.28s: we have no clue what the speeds\n2549.7s: he wrote his paper and he can explain\n2551.619s: every little comma in this thing and we\n2554.56s: have no we start copying the whole world\n2556.18s: and so on\n2557.56s: and you can submit it but you don't know\n2559.359s: how you got there and you can't explain\n2561.339s: anything and this is exactly where we\n2564.099s: are we cannot explain what we have and\n2568.18s: it works on new data sets and unseen\n2571.66s: data sets and all kinds of things but we\n2574.3s: can't explain how we don't understand\n2576.16s: the physics\n2577.72s: you have the answer we don't understand\n2579.099s: the physics we can't publish this\n2581.079s: reviewers don't say you can't publish it\n2583.06s: if you don't understand what it means\n2585.64s: you still have God published it the\n2587.14s: students just graduated moved on\n2589.48s: what do we do with this\n2591.7s: put it on archiving\n2594.04s: so it brings me to the last topic which\n2596.2s: is the search for meaning\n2597.88s: not this kind but the actual meaning of\n2601.359s: equations because as AI moves forward we\n2604.18s: get answers without rationale and this\n2606.88s: is always going to be an increasing\n2609.4s: challenge for these automated systems\n2612.099s: correlations are not enough\n2614.56s: this is a classic example people analyze\n2617.619s: data and Supermarket found out that\n2619.359s: people that buy diapers on Thursdays\n2622.42s: also buy beer\n2624.24s: it's true and if you run a supermarket\n2627.28s: you don't care why you move the beer\n2628.96s: next to the diapers and you said well\n2630.72s: but if you are a scientist you always\n2634.359s: want to know why what is driving it\n2636.64s: what's the causality Behind these things\n2638.38s: what's driving everything and so it\n2640.42s: brings me to this next\n2642.88s: challenge which was okay let's take a\n2646.18s: system like a pendulum\n2648.22s: and let's say you can measure angular\n2650.02s: and angular velocity\n2651.579s: of this pendulum and I ask you\n2654.579s: not to predict what's going to happen\n2656.319s: next ask you what is not changing about\n2658.599s: angular angle velocity is there some\n2661.18s: constant\n2663.04s: is the ratio constant what is the\n2665.68s: invariant\n2667.119s: of angular angle and angular velocity\n2669.819s: anybody know\n2672.579s: okay the answer is\n2674.74s: the total energy\n2676.96s: okay total energy of the pendulum is\n2679.54s: invariant\n2680.859s: it's constant\n2682.66s: kinetic energy plus potential energy\n2684.64s: assuming friction is go goes away but\n2687.28s: generally speaking is more or less\n2689.16s: constant and if you so that's called the\n2691.54s: hamiltonian of the of the pendulum and\n2694.3s: if you figure out the hamiltonian of the\n2695.92s: pedal mean or everything there is\n2698.319s: it's the answer for a pedal so the\n2701.98s: question is\n2703.9s: can we use a system not on the model\n2706.42s: Dynamics but defining variants and again\n2708.88s: there are papers from the 18th century\n2711.7s: seeing how all of science is the search\n2714.099s: for invariance\n2715.72s: all the constituent laws everything that\n2719.26s: we look for are invariants F equal and M\n2721.9s: A is an invariant we're looking for\n2724.0s: invariance laws of nature are nothing\n2726.579s: but interference symmetries they're all\n2729.04s: in variant so we're looking for\n2730.9s: invariants\n2732.099s: so uh we said okay this is really simple\n2734.68s: we just need to search for things that\n2736.66s: don't change\n2737.92s: took the data this is from a double\n2740.079s: pendulum\n2741.7s: and we search for an equation not an\n2743.56s: equation that models the Dynamics\n2745.72s: but an equation a formula that remains\n2749.619s: roughly constant across the entire data\n2752.56s: set\n2753.4s: in other words we try to minimize the\n2755.619s: variance of the equation\n2758.98s: across entire data\n2761.319s: right so we put it in hit enter and we\n2764.2s: wait\n2765.22s: we wait for a week and finally the build\n2769.48s: wings and we get the answer and the\n2771.4s: answer comes out as\n2774.339s: constant\n2776.5s: and it's true a constant\n2779.619s: is invariant across in Titus this is a\n2782.74s: Formula that is invariant but it's\n2785.5s: useless\n2786.819s: of course a concept is constant\n2789.88s: so how do you reward a system for\n2793.54s: finding a formula that is constant\n2796.72s: then you get constants so we said okay\n2799.42s: let's force it to have the variables in\n2802.72s: you can't just put a constant to put a\n2804.76s: formula that uses the variables in the\n2807.099s: data set and is constant so we force it\n2810.099s: and it comes back with this\n2812.5s: yeah\n2815.2s: it's constant\n2817.359s: you know but it's okay so\n2819.16s: okay so eliminate symbolic and and it\n2821.68s: comes back with this which is almost\n2823.3s: constant and it's just like arguing with\n2825.04s: a teenager we're not getting anywhere\n2827.2s: and it's just giving us garbage so it's\n2829.9s: a really difficult thing if you think\n2832.599s: about it searching for invariance is\n2835.48s: really tricky because there's lots of\n2837.22s: invariance but they're useless so how do\n2839.319s: you find B invariant\n2842.38s: uh so we we tried this uh for a long\n2845.98s: time and eventually I gave it as\n2848.079s: homework assignment in my course this is\n2851.14s: what I do and I can't uh solve it I I\n2855.04s: really did this of course Evolution\n2856.72s: algorithms I said here are three data\n2859.119s: sets finally invariance you know\n2861.18s: assignments the three question three a\n2864.339s: what is the fitness criteria for an\n2867.579s: invariant as if I know the answer all\n2870.52s: right uh nobody could do it except one\n2873.76s: student\n2874.72s: who said yeah it's easy this is what it\n2877.18s: is blah and name solve the three things\n2880.42s: right so I called into my office\n2883.96s: I said okay explain he said this is how\n2886.839s: I did it you take the you computer you\n2890.56s: have a candidate function f\n2892.9s: you can compute the FDX and the FDI\n2896.14s: symbolically and the ratio between them\n2898.9s: gives you the xdy you take the data\n2902.38s: you can compute the derivatives you\n2904.3s: compute the xdy\n2906.04s: and you compare the two and it cannot\n2908.14s: cheat it has to work\n2910.06s: I said excellent I knew this\n2913.42s: uh and uh let's try it out on a few more\n2916.06s: things so we try to add a few more\n2917.56s: things\n2918.48s: uh and uh this example of uh\n2922.78s: you know physics 101 uh oscillator uh\n2926.14s: collect data from it blah blah blah very\n2928.839s: easy with a webcam and after it works\n2931.839s: for a while it comes back to the\n2933.579s: hamatora and lagrangian about your added\n2935.98s: you get the two of the system\n2939.64s: and we run it again on the pendulum and\n2942.819s: we get the habitorian lagrangian of the\n2944.859s: pendulum we ran on a double oscillator\n2947.619s: this is already quite difficult\n2950.92s: double oscillator what's what's not\n2952.839s: changing about the the red and the green\n2954.7s: curve I mean kind of looks like random\n2957.579s: like you ask me it's yeah it's a sine\n2959.2s: wave\n2960.04s: maybe with some offset\n2962.14s: no this is what it is and it's perfect\n2965.68s: it's exactly the hamiltonian of a double\n2967.839s: oscillator purely from the data right\n2970.359s: and again this is the uh Steve schwargax\n2973.619s: uh king of double pendulums he is with a\n2977.44s: double pendulum uh we collected the data\n2980.8s: this is the data I showed you earlier\n2982.78s: we collected it by tracking uh LED in a\n2985.78s: dark beautiful\n2987.52s: you know Modern Art\n2990.4s: and you collected he said what's\n2993.22s: invariant about this\n2995.38s: so it runs for about a day\n2998.619s: we're eating all kinds of models\n3000.48s: remember looking at data that defeats\n3003.0s: the models and after a while\n3006.66s: it comes back with this and it says\n3010.02s: this is not changing this is this is the\n3012.359s: hamiltonian of a double pendulum\n3014.9s: conservation of energy F equal and a all\n3017.7s: kinds of things\n3018.72s: all found in the double panel\n3021.619s: uh and\n3024.24s: with this of course we went back to our\n3026.339s: bacteria that we didn't know what was\n3028.38s: not changing there\n3029.7s: and we found that the invariant of the\n3032.46s: bacteria which happens to be the\n3034.079s: competence level of the bacteria\n3036.3s: competence is how much the bacteria\n3038.88s: wants to exchange genetic material with\n3040.8s: other bacteria very important for\n3043.02s: material survival\n3044.88s: that's what's driving them\n3048.359s: that's what the equations represent so\n3050.819s: we've got the meaning out of it but I\n3053.88s: still haven't published it because the\n3055.079s: students has left and you know when the\n3056.52s: student leaves paper dies\n3059.22s: so I showed you examples in physics and\n3061.26s: biology uh\n3063.359s: but since then uh you could do a lot of\n3066.3s: things you can add noises the building\n3067.859s: blocks you can call stochastic mechanics\n3070.14s: you can change your building blocks to\n3072.599s: be reactions uh and then you get\n3075.48s: reaction models or ecological and\n3078.48s: chemical systems hybrid systems that\n3081.24s: switch Dynamics in the middle I mean you\n3083.16s: can play around with the building blocks\n3085.02s: you get different things but there's one\n3087.0s: last thing I want to talk about which\n3088.38s: kind of bothered me the whole time\n3091.44s: and that is that you remember I showed\n3094.079s: you this example I told you create a\n3096.48s: model with Anglo and angular velocity\n3099.24s: how did I know that angle and angular\n3101.52s: velocity are the things to measure\n3104.579s: like this is just a panel how do they\n3107.16s: even know about angular velocity that's\n3109.74s: a deep concept\n3112.2s: if you went back a thousand years and\n3116.04s: talked to\n3117.66s: whoever\n3119.28s: big great the Leonardo da Vinci I don't\n3121.98s: know who lived there then and you say\n3124.5s: talk about angular velocity do you think\n3126.599s: they didn't know what you're talking\n3127.38s: about\n3128.099s: It's A New Concept\n3130.14s: how do we come up with these variables\n3133.14s: and arguably finding the variables is\n3135.66s: harder than finding hamiltonian\n3138.72s: once you know what the right variables\n3140.579s: are finding the model with these\n3142.8s: variables is easy how do we find the\n3144.24s: variables so arguably be automated in\n3147.119s: this we automated\n3148.859s: uh this step of going from the variables\n3153.72s: to the equation\n3155.94s: but how do we go from the observations\n3158.46s: to the variables this is arguably even\n3161.46s: harder than creating a model on the\n3164.22s: variables\n3165.42s: uh so step two is hard but Step One is a\n3169.619s: lot harder than step two\n3171.66s: uh how can we automate this\n3174.3s: uh so\n3176.52s: uh\n3178.26s: so that's what we did in this project\n3180.54s: I'll just show you some brief results\n3183.599s: we look at the Double panel it's a real\n3185.819s: double pendulum and we first all we do\n3189.0s: is we just do um\n3191.339s: video prediction we just say Okay\n3193.38s: predict the next frames of the double\n3195.72s: pendulum uh and we can predict it fly a\n3199.079s: few frames into the future and I align\n3201.42s: them so you can see the predictions are\n3203.04s: pretty close to reality amazing can\n3205.74s: predict the Dynamics of double panel if\n3208.02s: you can do that it clearly knows about\n3209.94s: the hamiltonian\n3211.38s: deep inside now we just have to extract\n3214.74s: that it knows something about the\n3216.839s: physical extract it out of the deep\n3219.0s: Network this is the Deep Network the\n3221.16s: gazillion parameters\n3222.839s: it knows the answer and I'm going to\n3224.819s: extract it from the neural network all\n3226.92s: right so we let it model uh and we first\n3229.619s: we ask okay how many variables\n3232.26s: do you need to make that video\n3235.619s: from frame to frame how many feet how\n3237.9s: many variables do you need to pass\n3239.099s: forward a thousand nine hundred\n3242.9s: 850 coming so we uh the way we do it\n3247.079s: this is the corner decoder deep network\n3248.819s: but we quench\n3251.28s: this we throttle this latent space as\n3254.64s: tight as we can there's a lot of clever\n3256.92s: math I don't understand behind how to\n3258.96s: quench it you don't just quench it\n3260.52s: because it doesn't work you have to do\n3261.54s: it in in gradually and all kinds of\n3264.359s: Tricks but in the end when you do it\n3267.42s: you get the answer that there are 4.7\n3270.48s: variables going from here to the next\n3272.28s: one\n3273.18s: which we know is true there are four\n3274.859s: variables driving a double pendulum the\n3277.079s: AI said 4.7 so it's pretty close\n3280.319s: from this 50 000 pixels going from here\n3284.22s: to here there's only 4.7 numbers than\n3286.8s: that\n3288.3s: that's magic to me because it's the\n3290.579s: beginning of telling me there's only\n3292.38s: four variables in this thing in fact the\n3295.26s: 0.7 probably has to do with the fact\n3296.88s: that this pixelation and maybe this kind\n3300.0s: of vibrated uh out of plane and maybe\n3304.079s: somebody opened the door in the middle\n3305.579s: and all kinds of things like that all\n3306.96s: right so uh we did it for other things\n3310.26s: what are the number of variables\n3312.18s: required to explain this fireplace uh\n3315.72s: Christmas movie Christmas Loop\n3318.54s: okay the answer is first of all it makes\n3320.94s: the predictions which to me is\n3322.74s: astonishing that you predict how the\n3325.14s: fire is gonna lay out uh and it tells me\n3328.98s: there are 24 variables\n3331.079s: that's it with 24 variables you can\n3333.72s: explain all this time here\n3335.88s: uh and we did it for lots of different\n3338.7s: systems and uh real and simulated some\n3342.839s: we know the answer some we don't and it\n3345.3s: gives us answers that are pretty much\n3347.16s: close to the ground truth when we know\n3348.839s: the graph\n3350.46s: uh of course the big question is okay so\n3353.28s: what are the variables\n3355.38s: now here it gets uh this is where I lose\n3358.2s: the track of this story\n3360.9s: every time you run it you get different\n3362.64s: variables and the variables don't mean\n3364.44s: anything to us normals all right this is\n3366.9s: the real variables versus the variables\n3369.48s: come can come up and come up with a\n3371.819s: system not correlated not related not\n3374.76s: linear combination it's not energy it's\n3376.74s: not angles it's not angle velocity it's\n3379.079s: something this is for a single pendulum\n3381.48s: I thought this would be trivial it's not\n3383.46s: trivial it's coming up these crazy\n3385.74s: things uh but we have just found a way\n3388.859s: to put all kinds of additional\n3390.78s: constraints on the system to force the\n3393.359s: system the variables to be smooth when\n3396.119s: you force the variables to be smooth\n3397.98s: they become get closer and closer to to\n3401.52s: variables that we humans\n3403.8s: we physicists choose to have to uh\n3407.24s: describe it so these are the variables\n3409.8s: function of time\n3411.66s: very romantic uh picture uh very\n3415.2s: philosophically meaningful but the\n3418.079s: reality is we still don't know what the\n3419.76s: variables mean this is for a single\n3421.2s: panel either what the variables mean uh\n3424.319s: we can plot beautiful plots but we know\n3426.42s: what they mean so again I want to end\n3428.94s: with this big Quest that I think if you\n3431.76s: look historically on great physicists\n3434.819s: the the greatness I think is not in\n3437.4s: finding the equation which we usually\n3439.26s: name after them it's in finding the\n3441.54s: variables\n3443.46s: students great accomplishment in my mind\n3445.98s: is not writing every poem a it's coming\n3448.74s: out with the concept of acceleration\n3451.92s: before Newton nobody talked about\n3454.26s: acceleration\n3455.819s: you had speed and you had going faster\n3459.059s: but the idea of acceleration as a\n3461.22s: quantity that you can then use in\n3463.14s: physics nobody ever did it once you know\n3466.14s: about acceleration this is a really easy\n3468.66s: equation to find\n3470.52s: so finding the variables is by far\n3473.4s: harder than finding the models and this\n3476.16s: is this is my conclusion here uh New\n3478.74s: York Times said about our work uh\n3480.96s: theoretical physicists on audio absolute\n3482.88s: the scientists have stick and steps was\n3484.619s: thinking itself and that is exactly not\n3487.8s: true because the key is assigning\n3490.44s: meaning and finding the variables uh up\n3494.28s: from which to build the models because\n3496.02s: building the models is easy the AI can\n3499.02s: do that but finally the equation and\n3501.18s: defining the variables to begin with\n3502.74s: that's the next big Challenge and that's\n3505.14s: I think where if we can Master we'll do\n3507.599s: great things thank you\n3511.319s: foreign\n3517.64s: we also have some online\n3521.04s: any questions in the room here the\n3523.14s: millions of viewers\n3525.72s: yes sir\n3528.839s: thanks so much very interesting\n3531.119s: um so I was wondering about the state\n3532.68s: variables that you were showing so do we\n3535.799s: need to observe the whole system like\n3537.66s: for example the image that you have for\n3539.099s: double pendant if I crop that image and\n3541.26s: pass on behalf of that great question\n3543.42s: hidden variables uh can we spot that's a\n3546.599s: great question uh we should try that\n3549.24s: hopefully the answer is no\n3552.059s: uh we don't need to watch the entire\n3553.98s: system right because that's a already a\n3556.02s: big question is uh what to include and\n3559.44s: that's always a struggle right should I\n3561.299s: include this extra variable or can I\n3563.099s: ignore it\n3564.059s: that's a great question you should try\n3565.559s: that\n3568.38s: any other questions just just to follow\n3572.04s: up imagine you actually have a a white\n3575.22s: at the end of the second one that is out\n3578.04s: of the frame and I would expect the\n3580.859s: degree freedom of your latent space with\n3583.14s: the increase from 4.7 to another if the\n3586.079s: weight is constant no but if the way\n3588.059s: this part is is variable\n3590.54s: I mean arguably this gravity\n3593.339s: affecting the pedal but you can't see it\n3595.2s: so so as long as it's models the\n3598.26s: Dynamics and yeah that's a bar almost\n3601.799s: only spring or something well so if yeah\n3605.339s: so we so if so what happens if the ball\n3607.74s: is not visible I think as long as it\n3610.319s: affects the Dynamics and then the\n3612.599s: changing Dynamics are visible I think it\n3616.02s: can be found but you know I'm just\n3618.0s: saying that your pump 4.7 degree Freedom\n3620.579s: then you know that's the I think the\n3622.74s: point seven yeah the 4.7 may increase to\n3625.319s: suggest yeah right all right to tell you\n3627.299s: that there's more uh that's that's right\n3630.359s: okay so so maybe the answer is you'll\n3633.0s: find out that there are more available\n3634.799s: but you all find out what they are\n3638.22s: also but this is a really good question\n3642.54s: any other questions yeah me too yeah\n3649.2s: thank you for the talk it was very nice\n3651.54s: uh so I just have one question so you\n3654.72s: showed that when you don't know\n3656.7s: something Evolution starts from a simple\n3659.099s: model and then it moves on to the right\n3662.52s: direction accuracy doesn't matter so and\n3665.46s: then you show the double pendulum so I'm\n3667.68s: thinking\n3668.819s: if you started with a very simple model\n3671.4s: there\n3673.14s: like with you know that ideally you need\n3675.839s: five variable but if you started to\n3678.72s: somehow start with one variable\n3681.599s: right so I think I so it's okay A very\n3684.78s: very deep question there\n3686.94s: um so the difference between the first\n3688.619s: part of the talk is that the robot needs\n3690.839s: to learn to walk so it's not modeling\n3693.18s: itself as a scientist because it wants\n3695.339s: to know what it is it's modeling itself\n3697.38s: because it needs to walk so the model is\n3700.02s: not important the walking is important\n3702.059s: so we call this modeling for control so\n3704.52s: if you model something in order to\n3705.9s: control it you don't care about the\n3707.4s: model as long as the control works\n3709.079s: you're good\n3710.28s: a scientist we sometimes create a model\n3712.98s: because we want the model\n3714.78s: not because we're doing it for control\n3716.579s: and if you're doing the models for the\n3719.099s: sake of modeling then you really want it\n3721.44s: to be accurate if you're doing the model\n3722.7s: for the sake of control you're willing\n3724.92s: to sell for approximations so you can do\n3727.74s: one variable approximation is fine yeah\n3730.619s: yeah but that what I meant is that the\n3733.74s: if you will start from one variable and\n3736.68s: then add oh gradually uh well so we\n3739.74s: don't tell the AI how many variables to\n3741.9s: use we just say first of all make the\n3744.299s: video predictions and it uses 50 000\n3747.359s: variables because it's a deep neural\n3749.88s: network and then we trim it down and see\n3752.16s: how far it goes so we start from the\n3753.48s: thought okay and we see how far we can\n3755.76s: go yeah the evolution goes from the\n3758.579s: bottom you're right the evolution starts\n3760.44s: low and goes up deep learning starts\n3762.72s: from everything and then Narrows down so\n3770.839s: any more questions\n3774.0s: I'm not sure online so we don't have any\n3776.64s: questions so thanks again very\n3778.619s: interesting talk yeah thanks so much\n3781.5s: foreign"
    },
    {
        "class": "YouTubeVideo",
        "title": "Tiny Ocean: Physically Meaningful Dimensionality Reduction for pCO2 Reconstruction",
        "videoId": "Iwxl_fulfQ4",
        "url": "https://www.youtube.com/watch?v=Iwxl_fulfQ4",
        "publishedAt": "2025-01-27T17:01:43Z",
        "transcript": "3.919s: okay great so for our second uh talk\n6.359s: today we'll have Viviana aquaviva vivana\n10.04s: is Professor in the physics department\n11.92s: at the cuni NYC College of Technology\n15.36s: and at the cuni Graduate Center an\n17.56s: adjunct senior research scientist at\n19.08s: Columbia University and the lont DH\n21.32s: Earth Observatory and a visiting\n23.599s: professor at the SSA Institute for data\n27.64s: science and at the flat iron Institute\n30.32s: after many happy years as an\n31.679s: astrophysicist she is now working at the\n33.68s: intersection of climate science and data\n36.48s: science thank you thank you Katie for\n38.6s: the introduction hi everyone it's nice\n40.96s: to be back here uh so I'm GNA talk about\n44.36s: uh a project that we started recently\n46.28s: called tiny ocean physically meaningful\n48.879s: dimensionality reduction for pco2\n50.92s: reconstruction and I promise I'll tell\n52.719s: what every one of those words uh mean uh\n55.879s: but I want to sort of like zoom out\n58.239s: for well\n60.76s: I want to do something okay I want to\n62.68s: zoom out for a second just to put this\n64.36s: in context and so you know this just to\n67.56s: give you uh a bit of a bigger uh picture\n70.84s: idea of the different things I'm working\n73.04s: on so I have two main research\n75.04s: directions now that I'm you know sort of\n77.119s: solidifying this transition to climate\n78.92s: science uh one project is uh about\n82.28s: assessing similarity in the output of\n84.2s: climate models you have heard about this\n86.439s: and this project is led by Gabriella SAR\n88.64s: is also a part participating in this and\n91.04s: I think you'll be hearing about this on\n93.2s: March 7 which is why I decided to focus\n95.479s: on something a little different here and\n97.68s: then the other thing that has occupied a\n99.759s: lot of time uh of myself recently is\n104.079s: this follow-up proposal to the pivot\n106.119s: Fellowship that I had that I finally\n108.84s: completed and it's called from sparse\n110.759s: data to full spatial temporal Fields\n113.439s: surface ocean caribon and Beyond and\n116.159s: this hopefully is setting the foundation\n118.24s: for a long-term collaboration with uh\n120.439s: some people here in particular in\n122.399s: galin's research group like we have Abby\n124.56s: and T and Amanda who is online and Tian\n128.44s: uh as well as some people from my old\n130.44s: world so Roberto is an astrophys in data\n133.08s: sciencea which is the place where I did\n135.08s: my PhD in triesta Italy and Alexandro\n138.239s: and Romina who are there they are\n140.12s: researchers in statistical physics who\n142.16s: are participating with um you know more\n144.599s: of the um sort of techniques uh aspect\n148.16s: of this so I'm excited about that and\n150.4s: this is where tiny ocean uh lives so to\n154.16s: tell you a bit more about this uh the\n157.2s: problem that we are trying to solve uh\n160.04s: when I say surface ocean carbon that's a\n163.0s: lot of words so you know we usually\n164.36s: write this as pco2 the partial pressure\n167.28s: of CO2 in the surface ocean and so uh\n170.56s: the issue that we have is that the\n172.44s: observations of this variable that are\n174.84s: available are very sparse both in space\n178.04s: and time so this is actually not all the\n180.68s: ones that we have I believe this is from\n182.4s: a one year interval but you can see that\n185.04s: they're limited to certain trajectories\n187.04s: they are very uh there are many more of\n189.36s: them in the northern hemisphere compared\n191.159s: to the Southern Hemisphere and if you\n193.159s: were to be able to represent this in\n195.44s: time you would also see that you know\n197.84s: there is like a strong seasonality\n199.64s: effect and you know overall if we were\n202.2s: to Greed all the observation that we\n204.12s: have and put them on a grid of a one by\n206.12s: one degree and on a man Cadence we will\n208.64s: find that only less than 2% of uh degre\n212.76s: cells are filled this is something Abby\n214.68s: Anda also described earlier in the year\n217.76s: so what we want to do is a process\n219.36s: called reconstruction which is turning\n222.2s: from this parse and bias observation to\n225.04s: a dense field in space and time and this\n228.56s: is somewhat challenging but it's also\n230.959s: important why do we want to do it and\n233.519s: the reason for this is that uh this uh\n237.599s: pco2 that we talk about uh participates\n241.28s: in understanding what is the\n242.68s: contribution of the ocean to the carbon\n246.159s: cycle and the ocean plays an important\n249.159s: role there with absorbing about 40% of\n252.159s: the emission uh from Earth and there're\n255.76s: still like a lot of uncertainty in the\n258.32s: role of the ocean here we have about a\n260.28s: 15% uncertainty in the most recent\n263.52s: Evolution from like the global carbon\n265.479s: budget but this 15% is actually limited\n268.36s: to when we consider the annual mean\n271.44s: right and so when we look at things like\n273.12s: seasonality or like dehle variability\n276.0s: the uncertainties are higher and the um\n279.68s: this number comes from combining our\n283.639s: estimates of uh the um contribution of\n288.199s: you know basically like of the flux of\n290.759s: carbon between ocean and atmospheres\n293.0s: which is determined two ways one is from\n295.479s: Global ocean biochemistry models uh and\n298.44s: the other one is from the so-called CO2\n301.72s: products and this is the process that we\n303.88s: are referring to here and so this is\n306.8s: what we're trying to do we are trying to\n308.68s: reduce the uncertainties on this\n310.639s: estimate so that we can make better\n313.039s: plans for mitigation adaptation to\n315.0s: climate change and the way we are trying\n317.16s: to do this is improving the\n318.88s: reconstructions basically trying to\n320.6s: obtain smaller uncertainty in the\n323.28s: Reconstruction\n325.36s: process so this is sort of like a a a\n328.72s: big picture map of my\n331.12s: proposal um we try to do different\n333.919s: things and uh you know the reason I'm\n335.88s: putting it here is that you know I would\n337.6s: love to talk more uh with you know any\n340.24s: of you if there are something where you\n341.88s: feel like okay I'm interested in this I\n343.56s: have something to say I have a\n344.68s: suggestion I just want to hear more so\n346.919s: one part is to improve the machine\n348.919s: learning modeling uh this is a process\n351.639s: that involves machine learning and so we\n353.52s: can do something on that side uh one\n357.28s: part which is an important part is to\n359.44s: Val validate the Reconstruction process\n361.919s: so uh whenever you use machine learning\n364.84s: to uh go from uh a SP and biased domain\n368.919s: to a domain that is bigger has different\n371.199s: distribution there are a lot of risks in\n374.68s: uh you know the you know whether this\n376.479s: procedure is safe whether you can trust\n378.44s: it whether the results that you obtain\n379.96s: are reliable and so this is something\n382.52s: that we need to validate using air\n384.479s: system models and so this is you know a\n386.919s: big part of this effort and then another\n389.639s: thing that we are looking at is how can\n391.599s: we plan future observation to be\n394.84s: efficient and useful and so this is an\n397.759s: ongoing project that we have with some\n399.84s: of the people here called Data valuation\n403.0s: understanding what is the value of\n404.36s: different data points that we already\n406.08s: have in participating in this sort of\n408.639s: like determination of the PC2 field uh\n411.84s: and um what I'm proposing is to turn\n415.68s: this into a constraint optimization this\n418.68s: should read actually problem not model\n421.28s: this is maybe this is me wishful\n422.8s: thinking you know I have a problem and I\n424.479s: want a model so I already did this in my\n427.24s: head uh so the idea is that if we can\n430.199s: describe observation as a parameterized\n432.8s: system then you know to find Optimal\n434.56s: observation we can actually do parameter\n437.319s: estimation uh but in general the\n440.68s: umbrella that uh is comprehensive of all\n443.84s: of these is tiny ocean which is the idea\n446.84s: of finding\n448.16s: representations uh that are agile\n450.599s: meaning small robust and interpretable\n453.639s: so we can do clustering and\n455.44s: dimensionality reduction so in general I\n457.639s: feel like this Pro you know one of the\n459.759s: reason why we started from this project\n461.639s: and why I'm also passionate about it is\n463.44s: that uh it uh it can help everything\n466.599s: else by at the very minimum at the very\n469.68s: minimum making things less\n471.639s: computationally expensive but also\n474.0s: helping with efficience and so\n477.159s: on um so I know that you guys know this\n480.8s: but I like this slide so if you have\n482.159s: seen it very recently for example agu\n484.36s: please do not intervene uh\n487.28s: but you know I'm talking about\n489.68s: representation so I want to give a very\n491.8s: practical idea of what representation is\n495.0s: so let's say that this is a supervised\n496.759s: machine learning problem which means\n499.08s: that I have to give you a learning Set\n501.879s: uh where both the input and the output\n503.96s: is known and then I ask you to learn the\n506.199s: rule that is behind this and I'm giving\n508.639s: you a learning set composed of five\n511.4s: objects there is only one feature which\n513.32s: mean one piece of information for each\n515.399s: object and so for input one the output\n518.32s: is three for input two the output is\n520.12s: three for three is five for four is four\n522.32s: and for five is four and then I'm going\n524.039s: to ask you to predict um the output for\n528.92s: number six actually I'm going to ask you\n531.32s: if you can find the\n532.92s: rule I'm going to give you exactly 10\n535.56s: seconds 9 8 7 six no anxiety five four 3\n542.32s: two one okay too bad okay now I'm going\n544.72s: to give you a better representation it's\n547.04s: the same\n548.399s: thing and now I'm going to ask again if\n550.839s: somebody can figure out what's the rule\n552.72s: and what the prediction for six should\n555.68s: be yes three very good and\n560.12s: why it's a number of letters excellent\n563.2s: that's one of the fastest that I have\n565.56s: seen very congratulations and so here\n568.8s: you can see that you know I have added\n570.48s: no information right all I did is like I\n573.519s: rewrote this data in a way that was more\n577.04s: useful so this is what we're looking for\n580.12s: here can we get an improved\n582.04s: representation of ocean features so that\n584.56s: overall the process of uh reconstructing\n588.279s: the pco2 field can also be improved so\n592.36s: I'm talking about ocean features I\n594.519s: haven't told you what these features are\n596.64s: so I want to open up the process of\n598.959s: Recon raction for a second to tell you\n601.079s: that it's less uh linear than I made it\n605.8s: so you know like from this pictures it\n607.68s: look like oh I have this and then magic\n611.16s: interpolation and then disappears in\n613.839s: reality unfortunately this is something\n615.48s: we cannot do with data that are dispar\n618.48s: so instead we have to go through an\n620.2s: intermediate process which is where the\n621.959s: machine learning enters uh the picture\n625.2s: which is we also have some features uh\n629.8s: in machine learning parland in practice\n631.76s: it means input variables or just in\n633.68s: general information that we have about\n636.6s: the state of the ocean so from a\n638.72s: physical perspective these are things\n640.44s: like temperature Solarity chlorophyll\n642.88s: mixed layer that and also the CO2 amount\n646.16s: in the atmosphere this is basically our\n648.68s: you know the only variable that takes\n651.2s: account of the passing of time and then\n653.72s: also we have some spatial temporal\n656.36s: features that tells us uh what is the\n659.0s: time of the year right because there is\n661.12s: a strong seasonality effect and then we\n663.399s: also have some geographic features which\n665.24s: tells us where we are on the sphere and\n668.2s: so these are the physical features that\n669.88s: we can use to Aid the data where the\n673.6s: observation are spars so what we can do\n676.44s: is to build a machine learning model\n679.32s: that learns the connections between\n681.44s: these physical features and the\n684.0s: pco2 and we can do it using as a\n687.079s: learning set the places where obser\n689.48s: ations are available now once we have\n692.12s: this we can then use the machine\n694.12s: learning model to fill the gaps because\n696.639s: the physical feature are available\n699.16s: densely these are something that we can\n701.92s: usually uh Avail ourself of uh in space\n706.68s: and time so really what we're trying to\n709.24s: do here is to build a representation\n711.76s: from those\n713.04s: variables that improves the\n715.2s: Reconstruction\n717.68s: process how can we do do this well what\n720.519s: you know there are uh many ways but I\n723.519s: think you know maybe the first step is\n725.76s: to say okay when I say improve the\n727.76s: representation what am I looking for\n729.839s: what are the things that matter to\n731.68s: me so again you know you can answer this\n735.68s: in many ways according to what is\n738.24s: important to you right for example you\n741.16s: know this uh you know you can see that\n745.72s: powerful uh is not necessarily something\n748.279s: I have put here have put physical which\n751.079s: means that I don't want to stray away\n753.32s: from the space of physical variables and\n756.199s: this is just because we decided that for\n758.56s: this project interpretability was uh\n762.44s: ranked very high in our priority list\n765.639s: there are a lot of encoding methods that\n767.44s: you can use to get something that is\n769.6s: problem Weare and very\n771.88s: small but then you sort of like lose\n774.8s: track of what the variables are so for\n777.6s: something where you know that you want\n779.36s: to use to communicate for example for\n781.36s: others to be like more Universal for us\n783.8s: staying in the space of physical\n785.24s: variables was\n786.88s: important problem aware uh again you\n790.0s: know there are many dimensionality\n791.639s: reduction representation learning\n793.519s: methods that are General you never look\n795.839s: at your Target and what you're trying to\n797.72s: do you just look at what your variables\n800.24s: are and you ask how can I re represent\n802.88s: this for us uh this doesn't work too\n806.0s: well so what we're looking for here is a\n808.56s: represent St that is aware of the Target\n811.12s: that we're trying to\n812.36s: reconstruct and is sensitive to that\n815.279s: which also limits in a way what this\n817.56s: representation can do if you were to\n819.44s: solve another problem or reconstruct a\n821.399s: different field then you would have to\n823.0s: pick a different representation uh but\n826.12s: you know for our idea of improving the\n828.68s: skill of machine learning model that\n830.639s: predict that field and the\n832.32s: generalization properties which means\n834.24s: when I go outside of domain in my\n836.199s: reconstruction can I trust uh what I\n839.199s: learn this is quite important and\n842.24s: finally we want the representation that\n844.079s: is small possibly tiny that's where tiny\n846.399s: ocean comes from and uh you can do\n850.36s: dimensionality reductions in different\n852.399s: direction right if you have a data set\n854.079s: that has a bunch of rules these are your\n855.759s: objects and then a bunch of columns that\n857.48s: typically your features we often talk\n859.839s: about dimensionality reduction in the\n861.48s: feature Dimensions like okay can I\n863.959s: represent my data with fewer variables\n866.199s: and that's nice and one of the things\n867.839s: that we want to do but we can also do\n869.839s: dimensionality reduction along the\n871.519s: dimension of data points and this is\n873.72s: sometime you know you can think about it\n875.56s: as a clustering data that are very close\n878.56s: to each other and so we want to explore\n881.519s: both uh one reason is it makes uh\n885.399s: problems more tractable from a\n887.24s: computational perspective another reason\n890.04s: which is related to the feature\n891.959s: Dimension is that if you can get to a\n895.44s: final dimensionality in feature space or\n898.04s: four or five now you start to be able to\n900.639s: visualize things you know like three\n902.279s: dimensional you can plot to a color you\n904.04s: can add perhaps you know you can figure\n906.639s: out a shape or something for your\n908.279s: markers which means that you know four\n910.48s: is really the magical number but even\n912.399s: when five you can start to work and now\n915.36s: you can physically interpret what your\n917.519s: data are you're not anymore in a space\n919.8s: that has like 10 12 15 Dimensions which\n922.04s: is the starting Dimension idea where\n923.8s: physical space uh you can actually you\n926.8s: know look for Trends and this is really\n929.199s: helpful when you want to um you know\n931.92s: interpret the relationships that you\n934.88s: find I might\n936.959s: do okay so there are two uh sort of uh\n942.0s: ingredients of the tool that we have\n944.759s: used uh the first one is when we talk\n948.6s: about representation so we're looking\n951.04s: for I think I wrote it here you know I'm\n954.0s: not very good at keeping notation\n955.6s: consistent so you know when I talk about\n957.839s: representation you will see me talking\n959.48s: about a metric or a distance or a\n961.399s: combination of feature variables this is\n963.24s: what it means just bear with me I wa\n965.72s: iner language uh so one of the things\n968.839s: that we ask is how do we evaluate the\n972.759s: information content the different\n974.44s: representations or metric have and so\n977.92s: this is a very simple idea let's say\n979.6s: that you know I'm just comparing two\n982.12s: variables or metrics this is you know\n984.24s: basically onedimensional representation\n986.519s: that's why there is only one variable it\n988.48s: could be bigger but then again we be\n990.519s: able to plot and so we want to compare\n994.079s: the content of information in X and\n997.759s: Y we start from Y and so something you\n1000.56s: can note is that if points are close to\n1004.16s: each other along the Y AIS you can see\n1007.0s: that they're also fairly close to each\n1008.68s: other on the x\n1010.199s: axis just an\n1012.8s: observation however if points are close\n1015.72s: to each other along the x axis as you\n1018.399s: can see this doesn't mean that they are\n1020.56s: close to each other on the Y AIS so in\n1023.72s: terms of information content of these\n1025.64s: two metrics the way we can interpret\n1027.6s: this is that Y is more informative than\n1031.199s: x because vicinity in y is productive of\n1034.52s: vicinity in X but the vice versa is not\n1037.959s: true right so this is one ingredient\n1040.559s: this is one way we can think about how\n1043.12s: informative different metrics are\n1044.959s: compared to each other this gives us a\n1047.16s: way of comparing them\n1049.52s: uh the other ingredient for this is\n1052.919s: interpreting distances as neighbor ranks\n1056.52s: and so the idea here is that if you have\n1058.64s: different distances or metrics you can\n1060.799s: calculate what is the closest neighbor\n1062.88s: according to the metric for each point\n1064.919s: that you have uh and this may vary so\n1068.52s: this is you know you can see here we\n1070.039s: have point I and point J according to\n1073.0s: space a that weighs some directions\n1076.08s: differently uh J is the first neighbor\n1079.08s: of I but according to another metric J\n1081.799s: may be the third neighbor so of course\n1084.24s: you know the neighbor rank will depend\n1087.12s: on what distance metric you use but what\n1089.48s: is nice about this is that this is a\n1092.28s: type of distance that is insensitive to\n1095.72s: um the physical scale of your variables\n1098.799s: and so in a problem like I ours where we\n1101.36s: are mixing physical features we're\n1103.36s: mixing things like latitude and\n1105.0s: longitude we're mixing things like Time\n1107.039s: of the Year this is really nice to have\n1109.28s: it's a very nice\n1111.44s: property so putting them together we can\n1114.28s: define something called information\n1116.76s: imbalance and this is basically tells\n1119.039s: you what is the information loss when\n1121.28s: you move from one metric space to\n1123.24s: another and the idea is that you\n1125.84s: calculate uh the ranks which means like\n1130.24s: you know for each point uh what is the\n1133.64s: neighbor rank of all the other points in\n1135.64s: the data set and then you calculate the\n1138.88s: average of the ranks according to\n1140.76s: distance B of all the first neighbors\n1143.84s: according to distance\n1146.559s: a and this you call the information\n1149.12s: imbalance between A and B so let's think\n1153.08s: about this let's say that you know we\n1154.4s: are going from space a to space b now I\n1159.24s: look at the neighbor ranks of all the\n1163.72s: points according to metric B they were\n1166.32s: first neighbors according to metric a so\n1169.28s: if these two metrics are aligned then\n1172.12s: the first neighbor according to distance\n1174.919s: B according to distance a would also be\n1177.96s: the first or maybe second or third but a\n1180.159s: very small number according to distance\n1182.919s: b instead if we are in a situation where\n1186.159s: distance B is not contained at all in\n1188.72s: distance a which means that you lose a\n1191.2s: lot of information when you move from\n1192.96s: one to the other you will find that the\n1195.64s: neighbors is Distributing may be uniform\n1198.84s: and so you end up with an average which\n1200.799s: is not close to zero it's bounded by one\n1203.88s: but it's certainly not close to zero and\n1206.88s: so you can build this representation\n1210.159s: this tells you the information loss\n1211.88s: going from A to B this tells you the\n1214.159s: information loss going from B to a of\n1216.52s: course they're not symmetric like in the\n1218.24s: example that we had before one metric\n1220.44s: was more informative than the other\n1222.32s: which means that we're not going to be\n1223.64s: at this corner or this corner we're\n1225.44s: going to be here or here like one of\n1227.88s: them is contained in the other but this\n1229.96s: gives you a way of representing the\n1231.88s: information\n1234.559s: loss and now we can use this to generate\n1237.919s: our improved representation how do we do\n1240.2s: it well we have our Target metric this\n1242.84s: is the information we want to have which\n1245.0s: is the proximity in PC2 space so we can\n1248.32s: calculate that neighbor rank then for\n1250.84s: any candidate metric that we can build\n1253.36s: which means let's take our feature space\n1255.52s: and just build all the possible\n1256.96s: combination of distances we can do it\n1259.64s: without weights or we can do it with\n1262.44s: weights which makes it more General now\n1265.28s: we can calculate the information\n1266.76s: imbalances between our Target metric and\n1269.799s: any possible candidate that you can\n1271.48s: build and the goal is to find something\n1274.36s: with the smallest information in Balance\n1276.76s: versus your target which is the PC2 you\n1279.32s: don't need to find something equivalent\n1281.72s: you just need to find something that\n1283.64s: contains the information about PC2 which\n1286.48s: means that if this is uh the symmetry\n1289.12s: going from your physical variable to PC2\n1291.919s: you want to stay in the bottom part of\n1294.799s: this\n1296.52s: plot so this is what we did and the nice\n1300.559s: thing sorry that I forgot to mention is\n1302.6s: that you can do this as the a function\n1305.12s: of the number of Dimensions so that you\n1306.84s: can find your optimal representation for\n1309.76s: every dimensionality that you want to\n1313.76s: explore so finally I'm showing this an\n1316.2s: actual scientific result after all this\n1318.08s: talk so this is what we did we started\n1321.52s: with a subspaces of 11 features which\n1324.24s: were the physical variables that I\n1325.919s: presented and then usually three are\n1328.52s: used to have lat and Loan on the sphere\n1330.64s: we need an extra one to have periodic\n1333.559s: condition excuse me and two are used for\n1336.88s: Time of the Year again to impose\n1338.799s: periodic conditions you add another one\n1341.679s: and so what we found is that this is\n1343.88s: idea symmetry of information you never\n1346.44s: go to zero okay at think like the lowest\n1349.44s: that we had was around\n1351.159s: 0.4 however you can also see that as you\n1353.84s: go from like two features to 11 you have\n1356.96s: a point of Maximum return and for n\n1360.64s: equal 5 I mean arguably this is n equal\n1363.279s: 6 but six was too much for me so I I\n1365.88s: chose five I feel like you know five is\n1367.96s: probably where the elbow of these curves\n1370.52s: is and these are where the points go and\n1373.72s: so what this is telling me is that if I\n1375.76s: only use two variables my information\n1378.799s: imbalance is very high with three\n1381.4s: variables it goes a little further down\n1383.52s: with four variables a little further\n1385.12s: down and then here this is where it\n1387.24s: starts to converge and so with five\n1391.2s: variables which is this point here I\n1394.279s: have a reasonably small information in\n1397.32s: balance and with six I can do a tiny\n1399.48s: little bit\n1402.24s: better um what can we do with this\n1405.4s: improved\n1406.679s: representation well we can do different\n1408.799s: things uh you know as we mentioned we\n1411.2s: want to use it for visualization for\n1413.559s: interpreting data points um we can also\n1416.799s: use this new distance metric for\n1418.64s: clustering right clustering will be more\n1420.88s: effective because all of most of the\n1422.4s: clustering M are based on distance if\n1424.24s: you have a distance and knows what Pro\n1426.72s: what points you want to put together\n1428.2s: this is good um however you know one of\n1431.4s: the things that we can also do is to go\n1434.76s: back to our machine learning modeling\n1436.919s: perhaps the simplest thing and and see\n1439.0s: now that I have a better distance can\n1441.6s: very simple methods for example K and\n1443.559s: and Ker's neor become more powerful this\n1446.44s: what I want to\n1447.72s: show I have okay two\n1452.76s: minutes so again I'm trying to build the\n1456.159s: model so that from the physical features\n1458.48s: I learn the\n1460.64s: PC2 uh the state of the art uh to for\n1464.84s: doing this in data is an algorithm\n1466.44s: called XG boost you can also use an\n1468.6s: network but this is essentially tabular\n1470.48s: data so you don't use to they are\n1472.279s: essentially the same XT boost is a model\n1475.88s: very nice model uh it's built on\n1478.52s: decision trees they're sort of like the\n1480.679s: basic estimator so you build decision\n1482.919s: trees it tells you ask binary question\n1484.919s: about your features make a predictions\n1487.52s: and then you refine them basically at\n1489.32s: each stage instead of predicting your\n1491.6s: target variable you try to predict the\n1493.84s: residuals of the previous stage model so\n1496.72s: you make a correction and this works\n1499.08s: because in practice the residuals are\n1501.52s: the derivative of the Min square error\n1503.08s: loss which means that in practice you\n1504.84s: are taking gradient descent step along\n1507.24s: the Lost function that's a reason why it\n1509.559s: works and we're going to compare it to\n1512.72s: uh a very simple method called Ker's\n1514.84s: neighbor which you don't even need to do\n1516.84s: training if you have to make a\n1518.96s: prediction for new object for example\n1521.08s: this one you just say okay I'm going to\n1523.24s: look at the K closest examples in the\n1525.72s: training set and then for a\n1527.52s: classification problem you just output\n1530.2s: the average of the class and for a\n1532.24s: regression problem you output the\n1534.48s: average of the target property for those\n1537.559s: points so this's an example in which for\n1539.52s: example for this point um if I chosen k\n1542.36s: equal 5 I just look for five examples in\n1545.84s: my training set and then I said okay for\n1548.44s: this you know let's say that I want to\n1550.039s: Output the pco2 for this point it's just\n1552.08s: going to be the average of those you can\n1554.6s: weigh according to distance but it\n1557.24s: doesn't matter\n1558.96s: so we start with 11\n1561.279s: features and we um buil the model using\n1566.039s: KNN and XG boost XG boost is here and\n1569.919s: here is KNN and you can see that 11\n1572.76s: features they perform quite similarly I\n1575.559s: mean this is just a visual thing and\n1576.919s: plotting median absolute error at each\n1579.36s: point and then we reduce the\n1581.6s: dimensionality in actually the way you\n1583.679s: reduce dimensionality is that you do a\n1585.44s: feature ranking and you start\n1587.2s: eliminating less important features in K\n1591.08s: in K&N you're using this best distance\n1593.48s: that I told you about to do your\n1594.96s: dimensionality reduction you can see\n1597.559s: that with five features this is\n1599.559s: essentially\n1601.32s: stable but this is quite a bit worse\n1604.84s: which tells you that yes you know at the\n1606.76s: beginning they're equivalent but to go\n1609.44s: to a smaller dimensionality this\n1611.799s: distance is really powerful and you know\n1614.559s: you can look at other measures to model\n1616.919s: skills for example this is is like the\n1618.96s: median absolute errors and then in one\n1621.44s: case is stable and then it goes up this\n1623.96s: is the R2 score which is a measure of\n1626.2s: model skills so higher is better and has\n1629.039s: the same\n1630.88s: behavior so I'll conclude saying we are\n1633.88s: excited about this information imbalance\n1637.039s: uh well I am very excited about it uh as\n1639.84s: a way of building optimal representation\n1643.44s: for fixed dimensionalities uh you can\n1645.88s: use it for many things and the other\n1648.399s: things that I'm particularly excited\n1650.279s: about this is that I know that there is\n1652.559s: a potential for further Improvement\n1655.2s: because using five\n1657.52s: dimension space and time for something\n1660.2s: that physically has only three you know\n1662.72s: we know it's something that we could do\n1664.32s: better on and so if we were to get to D\n1667.64s: equal 4 in particular this would be very\n1670.08s: uh exciting for our data evaluation\n1672.44s: process and but in general it's a very\n1675.039s: general Pipeline and so if you have\n1676.84s: similar properties in know similar\n1678.76s: problems where you have a physical\n1680.12s: problem you want to go to reduce them\n1681.519s: and shiny space I love to talk to you\n1683.559s: about it thank\n1690.519s: you thank you so much vivana for a great\n1693.24s: talk um any questions from anybody in\n1695.84s: the\n1703.72s: room hi very nice talk thank you I have\n1706.72s: a question on the slide that you have\n1708.88s: with nice 2D plot that shows the\n1710.48s: informativeness of your um now go\n1717.0s: back this yeah this one so if you pick a\n1720.039s: different set of two for example if you\n1722.039s: pick right at the beginning X CO2 and\n1724.679s: for example SS would you get like a\n1726.88s: larger drop right at the beginning like\n1728.679s: is it sensitive to the pair that you\n1730.32s: pick at the beginning yeah actually this\n1733.039s: is uh not picked at the beginning it\n1735.08s: goes from 11 to\n1736.88s: two okay but for every D actually no I\n1739.88s: take it back it's done independently in\n1742.84s: every Dimension so it's not a stagewise\n1746.64s: process I say okay you know so I only\n1749.08s: fix the number of dimensions and then it\n1751.2s: does a search for the\n1753.559s: weights and uh we do it with L1\n1756.039s: regularization so it encourages\n1758.72s: sparcity um so in a way each Dimension\n1761.76s: is independent but basically yes there\n1764.72s: is is not a specific order okay but I\n1768.36s: think for a fixed dimensionality the\n1769.96s: pair is always the same thank you thanks\n1773.519s: for the presentation uh regarding\n1776.279s: information imbalance M um does it\n1779.519s: compare to information Theory measures\n1783.44s: that are well grounded uh theoretically\n1786.039s: but hard to compute in practice such as\n1788.36s: the mutual information for example so I\n1791.279s: I'm not an expert on this I read the\n1792.96s: papers but I think I should really\n1794.6s: reread the papers to tell you but from\n1796.32s: what I understand yes my understanding\n1798.48s: is that this is sort of like a um how\n1801.399s: what is it call like a heuristic\n1802.84s: estimator of the actual\n1806.0s: um Mutual information content so it's\n1808.72s: it's expected to approximate or converge\n1811.48s: to in some limits to the mutual\n1813.559s: information I think so at least this is\n1815.399s: my understanding of it okay thanks\n1820.6s: you're okay thank you so much vivana for\n1823.799s: a great talk and we hope everybody will\n1825.64s: stay and enjoy uh light lunch in the\n1827.559s: kitchen"
    },
    {
        "class": "YouTubeVideo",
        "title": "2024 Summer Education Project 5",
        "videoId": "6M-b2uydK6A",
        "url": "https://www.youtube.com/watch?v=6M-b2uydK6A",
        "publishedAt": "2024-08-03T20:09:54Z",
        "transcript": "5.799s: okay hi I'm fry the title of my project\n10.16s: that also relates to Jack and Tony's\n11.799s: project was modeling the impact of small\n14.2s: scale surface heterogeneity on airc\n16.16s: fluxes so this Talk's going to be split\n18.16s: into two parts part one's going to be me\n20.039s: just providing some general background\n21.68s: information about climate models and how\n23.8s: processes can happen across a variety of\n25.76s: skills um that's relevant to all of our\n27.84s: research and then part two will be me\n29.32s: talking about my research well and then\n31.119s: I guess part part three is I'm talking\n32.719s: about their\n35.879s: research okay part one a reef\n38.16s: introduction to climate modeling across\n39.879s: different\n41.44s: scales okay so the Earth system has\n44.68s: scales that happen has processes that\n46.719s: happen at a variety of different scales\n48.52s: and all these scales can kind of\n49.84s: interact with each other and these\n51.199s: scales can be as large as like 10 to the\n53.719s: E meters in space um and as small as\n56.199s: just a couple millimeters we want our\n58.6s: climate models to be at as\n60.44s: representative of the earth system as\n62.039s: possible but the problem is we have\n63.96s: limited computing power so these climate\n65.92s: models typically end up having a maximum\n68.439s: resolution and struggle to capture some\n70.64s: of these really small skills so this is\n73.64s: actually an image of a bunch of\n75.479s: different processes that happen often in\n77.72s: the ocean at a variety of different\n79.439s: spatial scales and the ones that climate\n81.32s: models really struggle to pick up on are\n82.84s: typically some of these sub mesoscope\n84.4s: processes the smaller ones and molecular\n86.84s: processes so when we have processes that\n89.72s: are are smaller than the climate model's\n91.479s: maximum resolution we call those\n93.759s: processes subgrid scale processes so if\n95.759s: you look at this little image of edies\n98.159s: here um the larger the Eddie or\n102.159s: hypothetical process the easier it is\n103.84s: for the climate model to actually pick\n105.24s: up on um and then at a certain point you\n107.88s: know as the process gets smaller and\n109.68s: smaller on spatial scale it's harder and\n111.2s: harder to pick up and at a certain point\n113.079s: it gets so small that we call it the\n114.64s: subgrid scale because the climate model\n116.079s: is not going to pick it up on its\n118.079s: own so how do we account for these\n120.2s: processes there are a lot of ways we can\n122.079s: do this but our research group used a\n124.439s: variety of ml based methods to do it\n126.36s: this summer so what I've actually done\n128.879s: is I'm using a neural network to kind of\n131.64s: predict how sub scale processes might\n134.36s: impact larger scale processes whereas\n136.8s: Tony and Jack are actually looking at a\n138.68s: low resolution map or image that only\n141.519s: contains these larger scale processes\n142.92s: and figuring out where exactly on the\n144.72s: map these subgrid scale processes might\n146.48s: occur so two different methods to kind\n148.319s: of do somewhat a similar task um so I've\n152.64s: got a couple figures up here uh this is\n155.12s: just relevant to me I have like this\n157.76s: little graph here um where okay the\n160.879s: biggest the larger edies are what I'm\n162.76s: going to pick up by with the climate\n164.319s: model which I'll get to later and the\n166.0s: smallest one the subgrid skill one\n167.56s: that's what's picked up by the neural\n168.84s: network or like whatever machine\n170.4s: learning algorithm we're going to use so\n172.36s: same as trueth for Tony and Jack this\n174.879s: comes from the climate model just the\n176.4s: sub grid scale stuff comes from the\n178.159s: machine learning that they're doing um\n180.12s: I've also just included this picture\n181.56s: here to kind of point out like or to\n183.519s: kind of give you a general idea of like\n185.4s: how large of a scale is picked up by a\n187.799s: high resolution simulation so this is\n189.76s: just the Velocity in the merional\n192.36s: direction um and as you can see like\n194.64s: this is like thousands of kilometers in\n197.92s: length for some of these like fronts\n199.4s: that are being picked up or not fronts\n200.64s: but like figure features that are being\n202.599s: picked up um whereas if something was\n204.799s: like on the scale of just a couple\n206.519s: meters or even millimeters it would be\n208.2s: really hard to see in this large graph\n209.84s: here even maybe even on a regional\n212.319s: map okay part two my research U modeling\n215.76s: the impact of small scale surface\n218.0s: heterogen and air SE fluxes so I want to\n220.56s: start by just defining the problem which\n223.879s: you probably have kind of figured out\n225.319s: from the title already the problem is\n227.2s: that airc fluxes occur at a variety of\n229.28s: different scales and they impact\n231.08s: processes at Scales both larger and\n233.319s: smaller than them climate models\n235.879s: obviously can't capture all the scales\n238.36s: at which airc fluxes occur at so they\n240.4s: don't end up capturing the subgrid scale\n242.48s: air fluxes those sub grid scale air\n244.599s: fluxes do impact larger scale boundary\n246.84s: layer processes near the atmosphere\n249.04s: ocean interface which is why in order to\n252.12s: account for that and make our climate\n253.239s: models more accurate I'm developing a\n255.48s: neural network or training one right now\n258.479s: that is meant to find the effect of\n260.479s: these subgrid scale airc fluxes on\n262.52s: larger scale processes in the boundary\n264.759s: layer region the idea is to eventually\n266.68s: integrate the senstive climate model\n268.0s: we're far from that right now\n270.28s: so this is just for those who don't know\n272.44s: a basic definition of Airy fluxes an air\n274.4s: SE flux is any transfer of energy\n276.6s: momentum chemical compounds across the\n278.44s: atmosphere ocean interface the three\n280.68s: types of heat fluxes I'm looking at or\n282.32s: sorry air seat fluxes I'm looking at are\n283.88s: the heat momentum and freshwater flux so\n286.199s: heat flux can kind of be thought of as a\n287.96s: transfer of thermal energy across this\n289.479s: interface momentum flux I think a good\n291.8s: example of that would be maybe how the\n293.96s: wind forces currents in the ocean and\n296.759s: vice versa and freshwater flux mostly\n299.16s: has to do with the evaporation and\n300.32s: precipitation of fresh water\n303.0s: um okay so now I'm just these are just a\n305.919s: couple maps of the fluxes that I've been\n308.12s: talking about and I've included these\n310.039s: these here just so you can kind of get\n311.52s: an idea of what the global patterns look\n314.24s: like with these fluxes so for example\n317.16s: with the momentum flux um the areas\n319.319s: where you'll have I guess the highest\n321.08s: momentum flux are the areas where\n323.0s: typically there is like the most Z the\n325.08s: strongest zonal wind components so\n326.84s: that's like in these areas from what I\n329.479s: understand s i could be wrong um then we\n331.919s: have the heat flux over here and the\n333.919s: magnitude of the heat flux is much\n335.36s: larger um in lower parts of the ocean\n338.319s: then up here in the Arctic and then the\n340.28s: freshwater flux um yeah I guess like the\n344.44s: transfer between evaporation and\n345.68s: precipitation that happens a lot more\n347.4s: significantly in areas where there is\n349.639s: not that much sea ice covering the\n352.319s: Earth and now to methodology this is a\n355.479s: wonderful graph thank you Julius so um\n359.039s: this is what was my first step in the\n360.479s: research I was doing so step one was to\n362.24s: really figure out if these subgrid skill\n363.68s: fluxes that I wanted to like\n366.199s: parameterize for were even computable so\n369.12s: step one what I did this is a\n370.84s: complicated figure so bear with me I\n372.72s: took some very high resolution global\n374.479s: climate data um and counted that as my\n377.4s: ground truth um on this top row what\n380.72s: I've done is I compute the airc fluxes\n383.4s: um based off that highres data and I\n386.4s: just spatially filter to get rid of any\n388.039s: nonlinearities and now I have a\n390.16s: flux that accounts for both large and\n391.84s: small scale um processes and then on the\n396.199s: bottom I have done the same thing but\n398.88s: I've first the the only difference is\n400.639s: the first step is to sort of decrease\n402.28s: the resolution that I'm looking at so\n404.039s: this is my low resolution flux so I have\n406.28s: two fluxes one that accounts for high\n408.08s: and low resolution and one that accounts\n409.759s: for only wait sorry one that accounts\n411.56s: for large and small scale processes and\n413.4s: one that only accounts for large scale\n414.84s: processes so when you take the\n415.919s: difference you get the subgrid scale\n417.12s: flux which is this qar so This was done\n419.319s: for all three types of\n421.44s: fluxes here's kind of what the map looks\n423.72s: like the only reason I've really\n424.919s: included this is just so you can kind of\n426.96s: see like how sharp some of the\n428.96s: differences are between various features\n431.12s: on these Maps like if you looked\n432.639s: remember the high resolution graphs we\n434.68s: looked at before that captured more\n436.24s: large scale processes the I guess if you\n439.08s: went from one feature to another it\n440.4s: looked a lot more smooth than this so\n443.28s: it's just meant to kind of capture the\n444.599s: variability that can occur on the\n446.039s: subgrid\n447.039s: scale okay and then The Next Step I did\n450.44s: which is like kind of the most\n451.759s: significant step this summer is like\n453.319s: extensive amount of testing to just\n455.24s: check if the fluxus I calculated were\n458.479s: anywhere close to the fluxes that were\n460.96s: calculated in this very high resolution\n462.919s: run so this like ground truth run um it\n465.72s: turns out that yes for the heat flux I\n468.28s: and momentum and freshwater flux I'm off\n470.56s: by just a little bit every single time\n473.0s: um and this is actually building upon\n474.44s: what Julius has done previously he\n476.24s: presented this as a poster at the when\n478.52s: at the NSF site visit\n480.36s: um and so my fluxus did match julius's\n482.52s: here which gave me a lot of confidence\n484.36s: um but aside from that there was like a\n486.52s: lot of testing I'm still trying to\n487.759s: figure out why this Gap is there I'm\n489.199s: also trying to figure out whether it's\n490.759s: like useful to like create an ice mask\n492.759s: which kind of excludes the parts of the\n496.0s: I guess ocean that might be covered by\n497.599s: ice so I don't end up I'm only\n498.84s: calculating air sea fluxes not like sea\n500.879s: ice air fluxes and so this is just a\n503.599s: summary of all those tests that I'm\n504.84s: happy to go into more detail about later\n506.599s: on if you have more questions um but yes\n509.639s: the sanity check was clear enough that\n511.599s: it like cleared me to at least try the\n513.039s: neural network training so for the\n514.24s: neural network training I haven't gotten\n515.56s: too far yet um but the way I I'm have\n519.24s: set it up so far is I'm inputting the\n521.24s: low resolution heat momentum freshwater\n523.88s: flux whatever I'm looking for um and\n525.92s: then various uh low resolution input\n528.519s: parameters such as the wind speed C\n529.88s: surface temperature and the idea is that\n531.64s: I output a parameterization for um each\n534.48s: of these airc fluxes and so this\n537.04s: parameterization is meant to account for\n538.68s: how the subgrid scale Airy fluxes\n541.399s: account will impact largest scale\n543.44s: processes at the boundary layer okay\n546.399s: that's me and now I'm G to give oh wait\n550.079s: sorry that's an epic e slide this is for\n552.0s: Jack and\n556.64s: Tony so hi my name is Tony Manriquez I'm\n559.6s: an undergrad at MSU Denver studying\n561.36s: meteorology and physics and this summer\n563.64s: I worked with Jack alandre Yu Wang Jing\n566.2s: Wang Liu and RPI through wda with our\n570.76s: project well super resolution of SE\n573.959s: surface height using machine learning so\n576.079s: as pry mentioned in their slides airc\n578.079s: interactions are a really complicated\n579.6s: system that involves Dynamics\n581.12s: thermodynamics and\n582.6s: biogeochemistry but it's a really useful\n584.64s: tool to understand uh and build climate\n586.6s: models uh given my background in\n588.64s: meteorology this project was really\n590.36s: helpful in actually making the\n591.44s: connection between the ocean and the\n593.44s: atmosphere especially as an\n594.88s: undergraduate we currently use satellite\n597.2s: imagery to kind of understand what these\n598.959s: air SE interactions are doing so the\n602.36s: resolution isn't the best to actually\n604.04s: know what's going on in really great\n605.6s: detail as you can see from this figure\n607.6s: on the left is a low resolution image\n610.48s: from a satellite compared to the one on\n612.48s: the right and for our project we wanted\n614.44s: to see if we could build a machine\n615.959s: learning model that will take that low\n617.399s: resolution image and then create a high\n619.6s: resolution image so to start we used a\n622.76s: high resolution ocean model from MIT\n625.079s: called LL c4320 what this allowed us to\n628.24s: do is pick a specific spefic region in\n630.12s: the ocean and then build a high\n631.72s: resolution image data set uh we focused\n634.48s: on C Surface height for our\n636.639s: project so after building the high\n638.959s: resolution image data set we then can\n640.92s: filter it out to create a low resolution\n642.76s: image data set and from building that\n644.519s: low resolution data set we then are\n646.72s: training a machine learning model that\n648.2s: will take that reconstruct it and build\n650.24s: a high resolution image data set so this\n652.44s: is just kind of a big picture of what it\n654.2s: looks like and as you can see from the\n656.44s: high resolution image it's a bit more\n658.32s: Jagged hopefully\n659.76s: than the smooth image from the low\n661.44s: resolution and to help explain how we\n663.72s: built that data set I'm going to pass it\n665.16s: to\n666.68s: Jack thanks\n673.36s: um so essentially in order to do this we\n676.48s: had to start out by creating uh two data\n679.8s: sets in order to train the machine\n682.32s: learning model so um one of the data\n685.519s: sets the first one you can see is this\n688.68s: one is\n690.519s: essentially uh one region in the\n693.56s: ocean that\n695.36s: was uh\n697.839s: 1,280 by 1,280 pixels and in that region\n704.04s: there are 76 different uh different\n707.519s: times at which uh each image was\n711.76s: recorded So we essentially divided that\n716.48s: uh 1280 by 1280 size into 100 smaller\n720.72s: 128 by 128\n723.399s: images and we compiled those into a data\n727.72s: array an xarray object which had 100\n731.48s: different locations each one of those\n734.519s: locations with 76 different times and\n738.959s: then each of those times corresponding\n741.12s: to a 128 by8 pixel image and our other\n748.0s: data set um as you can see right here is\n752.72s: was uh in the same was basically we took\n757.279s: our uh unfilter data set that we got\n760.16s: directly from the high resolution image\n762.519s: and we used uh this downscaling method\n766.16s: to\n766.959s: essentially um turn the original image\n771.12s: into a lower resolution more grainy\n774.92s: image that we saw earlier in Tony's\n778.079s: slides\n779.88s: and these images were each 16 by 16\n783.48s: pixels but with the same amount of the\n787.44s: same\n788.839s: locations in a yeah the same locations\n792.44s: as our unfiltered data set as you can\n794.519s: see 100 different locations and each one\n796.639s: with 76 different times that they were\n799.04s: recorded at so that each low resolution\n801.92s: image had a corresponding high\n803.72s: resolution image and from there once we\n807.199s: had our data sets in order to to convert\n809.92s: them to tensor objects in order to feed\n813.199s: them to our machine learning model uh we\n815.16s: use the following code right over here\n817.88s: which basically took our times and the\n823.12s: 100 different locations and multiply\n825.839s: them to get them together in one\n828.32s: dimension so that way our the shape of\n831.639s: our tensor our tensors uh only had one\n835.32s: channel which is the second dimension\n837.519s: and was able to function better in the\n839.92s: model and then we essentially yeah we\n843.279s: converted those to data arrays and then\n845.36s: converted those to tensors which we were\n847.8s: ready to use in the model so our next\n850.759s: step was using a unet model which is uh\n854.48s: a type of convolutional neural\n856.8s: network and we designed it to take the\n860.399s: low resolution 16 by6 images and scale\n863.519s: them up to high resolution 128x 128\n867.48s: images so essentially the process should\n870.72s: look something like this this is uh a 16\n873.519s: X6 low resolution image scaled up and\n876.72s: this is its corresponding high\n878.759s: resolution image um these are both\n882.16s: corresponding uh images in our data set\n885.199s: so this isn't a uh this one isn't a\n888.24s: model generated one a model generated\n891.079s: image but essentially um we ended up\n895.399s: using the model and we weren't we were\n898.68s: still working on it by the end um but\n902.199s: this is just a little graph of the\n906.079s: training loss and validation loss over\n908.079s: time as you can see they're both pretty\n910.16s: large but um and only only uh only\n915.88s: decreasing a little bit over the 25\n918.44s: Epoch that we tested so the model hasn't\n922.24s: been perfected um there's still a lot of\n924.759s: work to do with it but the overall idea\n929.519s: and the overall goal that we're getting\n931.199s: at is certainly we're certainly U we\n933.8s: were certainly moving towards there\n935.72s: before as uh you know the model just\n939.279s: needs some tweaking and by then uh we\n943.44s: will be able to have a data set of older\n949.079s: satellite images that we could get\n952.319s: higher resolution data\n957.199s: from these are our\n963.199s: citation okay questions\n989.16s: or are you\n993.56s: just mypic that very that scaling up\n1014.04s: ising um so you're asking like is there\n1017.0s: like a normalization factor before okay\n1020.24s: um yeah so well what we were doing right\n1023.92s: now is essentially just the the exact\n1027.319s: code to downscale it I believe just\n1030.559s: takes an average over uh over a certain\n1034.24s: amount of pixels and just combines those\n1039.52s: into one so like in the 16 by 16 each\n1042.679s: pixel would be an average of a group of\n1045.6s: pixels in the high resolution image so\n1048.36s: that way\n1049.6s: um it's scaling up like it already has\n1052.52s: all the data from the high resolution\n1054.24s: images so that way it's scaling up\n1057.72s: to it's not really introducing any\n1061.08s: artifacts I don't believe that would uh\n1063.84s: not be accounted\n1065.16s: for um it's basically kind of just not\n1070.24s: like Den noising it but just adding more\n1073.48s: detail that uh the training image was\n1078.32s: created from if\n1081.76s: that what are the values of each pixel\n1084.24s: on that training like are they between\n1086.08s: zero and one or are they you know zero\n1088.4s: to\n1089.799s: thousand\n1091.36s: um each P uh yeah so on the little color\n1094.799s: bar it ranges from negative 1.8 to -2.5\n1098.799s: just in this example and each of those\n1102.0s: um corresponds to different C Surface\n1106.76s: Heights uh above or below zero so in\n1109.679s: this case all of these different pixels\n1113.84s: would represent like say if it's uh\n1116.76s: negative\n1117.76s: 1.8 m below CA level to -2.5 meters\n1123.32s: below sea level so this is kind of just\n1125.2s: like you know a color map for the height\n1128.88s: and and so you feed in that negative 1.8\n1131.039s: to that positive 2.5 yeah okay got you\n1134.12s: got you thank you\n1140.039s: any other question\n1144.12s: yes it's B like a comment uh so the low\n1148.0s: resolution to higher resolution is from\n1149.96s: a 16 by 16 to 128 by 28 so comment is if\n1155.039s: if you scale up like a uh\n1158.84s: directly uh uh maybe the performance is\n1161.72s: not that good but the uh possibility is\n1164.64s: to scale from 16 by 16 to 60 x 60 first\n1168.88s: and then you go from 60 by 60 to 12 128\n1172.64s: and by 28 it's like there's a\n1175.4s: hierarchical uh modeling maybe the\n1178.159s: performance uh can get better"
    },
    {
        "class": "YouTubeVideo",
        "title": "Hops, Skips, and Jumps: Development Activities Around CAM7",
        "videoId": "qfRrGGaR5QY",
        "url": "https://www.youtube.com/watch?v=qfRrGGaR5QY",
        "publishedAt": "2024-10-29T18:54:48Z",
        "transcript": "4.52s: all right so while some people are\n7.6s: making their way in hi\n9.759s: everyone Welcome to our next uh our next\n14.4s: um talk here for the fall and we have uh\n17.439s: Brian mados visiting from the national\n19.72s: well visiting virtually from the\n22.56s: national Center for atmospheric research\n25.119s: and Brian is a project scientist there\n27.88s: at enar he's been there for 15 years\n30.72s: um Brian got his bachelor's degree in\n32.96s: physics uh from UC Berkeley in 2000 then\n36.16s: he went on to do his graduate work at\n38.04s: UCLA and got his PhD in 2007 um and\n41.719s: Brian is really interested in um clouds\n44.96s: and their interactions um with global\n47.84s: circulation and uh their role in the\n50.16s: climate system and in climate in in\n52.039s: cloud feedbacks and he's a a key member\n54.76s: on the uh so enar runs the community\n58.16s: Earth System model and uh Brian is a key\n61.359s: key developer in the atmospheric\n63.359s: component of that model known as cam or\n65.239s: the community atmosphere model uh and\n67.4s: Brian is a key developer of of that um I\n70.84s: met Brian actually Brian I don't know if\n72.96s: you remember when so this is a an NSF\n75.84s: Science and Technology Center right as\n77.84s: we all mostly know um there was another\n80.36s: one at at Colorado State University\n82.2s: called cmap and I was a graduate student\n85.04s: in cmap and Brian was I think a visiting\n88.079s: postto um and and we were regularly\n91.119s: around the cat meetings and we had a lot\n92.64s: of a lot of coffee and some some\n94.479s: discussions many years ago and then I\n96.28s: hadn't seen them for a long time and now\n97.439s: I get to see him again being part of\n98.72s: leap so that's kind of that's a fun\n100.119s: little uh that's been a fun Evolution so\n103.36s: anyway so Brian today is going to be\n104.56s: talking about um development activities\n107.079s: um in the newest version of cam um and\n110.0s: uh we look forward to hearing this so\n111.399s: Brian with that take it away thanks\n114.04s: Craig uh yeah\n116.64s: so so uh this was I was was going to try\n120.28s: to do an extended metaphor um to connect\n122.399s: with leap and do hops skips and jumps on\n124.399s: our way to developing cam 7 I thought\n126.759s: that was especially cute because the\n128.119s: buses in Boulder are called hop skip and\n130.039s: jump but I won't I won't it turns out\n132.48s: that's going to be harder to do than I\n133.68s: wanted so I'm not going to try to\n134.76s: belabor that metaphor but I will try to\n136.519s: mention th hops skips and jumps in our\n139.04s: development um what we're going to talk\n140.959s: about today is uh an overview of cesm\n144.2s: and development activities around cam\n146.4s: the community atmosphere model and what\n148.959s: what we've been doing going from cam six\n151.04s: to cam s in terms of the actual changes\n153.68s: to the model and how we make changes to\n155.959s: the model and then some of associated\n158.04s: things um around evaluation of the model\n160.68s: and then a little bit about future work\n163.64s: with it with development so um most of\n166.599s: this work that I'm going to show is not\n167.84s: mine so I want to acknowledge the entire\n169.8s: cam 7 development team which isn't a\n172.2s: huge number of people it's a maybe a\n174.319s: dozen people or so maybe a little bit\n176.68s: more than that if you include all the\n178.12s: software engineers\n180.04s: but especially Julio Cecil and Peter who\n182.8s: are the um previous co-chair the AMW the\n186.08s: aison and the current co-chair of the\n188.12s: AMW and they do a lot of the\n190.4s: coordination of model development\n192.48s: activities and I'll mention a few other\n194.48s: specific names as we go along so uh leap\n198.519s: and CM are pretty closely tied together\n202.519s: and I think we want to bring them even\n203.92s: closer together going forward uh with\n206.0s: leaps activities in phase two um and so\n210.56s: I think many of you will know a lot of\n212.239s: the structure of CSM but I I wanted to\n214.36s: just review it really quickly to make\n216.439s: sure everyone's on the same page so CSM\n218.68s: is a large Earth System model has a lot\n220.519s: of components that are coupled together\n222.68s: CSM 2 is the current version of the\n224.36s: model it was released in\n227.28s: 2018 um the next version is csm3 it is\n231.08s: going to be released sometime in late\n233.879s: this year or early next year I'm not\n235.599s: exactly sure uh when that will really\n238.56s: happen um I mentioned to somebody who\n241.0s: works at Nvidia recently that our our\n244.76s: development cycle is about five or six\n246.76s: years and they literally laughed at me\n249.239s: but that's how we work in science so\n252.4s: cesm is this big coupled model and it\n255.28s: has a couple of layers of\n257.72s: um of organization one is the code\n261.359s: itself so there's these different\n262.68s: components so seam is the coupler that\n264.759s: sits in the middle and connects all the\n266.639s: different component models which are\n267.919s: shown by these rectangles by changing\n270.12s: fluxes so it takes fluxes from the\n271.8s: atmosphere and send sends them to the\n273.32s: ocean of the land takes fluxes from them\n275.36s: and brings them back to the\n276.919s: atmosphere and then each component model\n279.6s: sort of takes care of its own Realm of\n281.56s: the climate system so the atmosphere the\n283.52s: land land ice which are um ice sheets uh\n287.52s: sea ice and ocean and then associated\n290.68s: with uh some of these models are sort of\n293.479s: models that are more tightly coupled to\n295.96s: one particular component model so for\n297.84s: example biogeochemistry in the ocean is\n299.759s: really run as part of the ocean model\n302.28s: and the uh river is really tightly\n304.08s: coupled to the land the river runoff\n305.84s: model Mozart is really tightly coupled\n307.68s: to land model uh and there's probably\n310.36s: other ones especially around land but I\n312.08s: just wanted to simplify things for this\n314.12s: for this um and then there's a couple of\n316.28s: different configurations that you can\n317.639s: run for different component models so in\n319.96s: the atmosphere we normally are running\n321.72s: cam six uh which I'll talk more about in\n324.28s: a moment but there are other flavors of\n327.16s: Cam which are which have different names\n329.36s: so Wacom and Wacom X are the whole whole\n332.4s: atmosphere model and so they much have a\n334.52s: much higher model top so for studying\n338.28s: the stratosphere and the middle\n339.8s: atmosphere cam Kim is the configuration\n342.479s: that's run with much more sophisticated\n344.759s: chemistry with M many more um chemical\n347.199s: mechanisms involved so they and these\n349.52s: have their own working groups so these\n351.12s: wgs all around the figure are the\n353.44s: working groups and they those are sort\n355.039s: of communities of people who work on um\n358.479s: developing the models or you Andor using\n361.039s: the model so the atmospheric model\n362.919s: working group is responsible for\n364.24s: developing cam making decisions about\n366.08s: how development proceeds and there's\n368.319s: working groups associated with pretty\n369.84s: much all of the component models and\n372.12s: then there are a couple of additional\n373.24s: working groups the climate variability\n374.919s: and change working group the Earth\n376.319s: system prediction working group and to\n378.52s: some extent the Polar climate working\n379.919s: group which are kind of a step away from\n381.599s: development and a little bit more um on\n383.8s: the application side they do a lot of\n385.52s: community projects running a lot of\n387.08s: production simulations and then around\n389.44s: the whole thing are the um kind of\n391.56s: governance of of cesm so there's an\n393.759s: Advisory Board and a steering\n395.759s: committee so the for the rest of the\n397.72s: talk I just want to focused in on this\n399.319s: little piece of cesm which is Cam which\n401.52s: is an important piece but in this\n403.28s: picture it looks\n404.68s: small and so cam 6 which was released\n407.88s: with csm2 in 2018 looks sort of like\n410.759s: this in kind of a simplified view so\n412.639s: what we do is we solve the equations of\n415.0s: motion in the atmosphere using the\n416.68s: dynamical core that uses a finite volume\n419.36s: uh method on a nominal one degree\n423.0s: latitude longitude grid that's fed into\n425.8s: the physics which is represented by all\n427.479s: these um symbols on the right side and\n429.96s: they basically feeds through to the Deep\n432.039s: convection then this iteration between\n434.599s: club which is a unified um turbulence\n438.72s: shallow convection and Cloud\n440.84s: macrophysics scheme and the aerosol and\n443.199s: Cloud microphysics this goes around\n444.84s: three times to iterate so basically a\n447.28s: smaller time step within the model's\n449.16s: physics time step that's fed into the\n451.52s: radiation scheme and then the then the\n454.0s: fluxes are sent to the surface model so\n455.8s: this is a coupling step where we send\n457.479s: all the information to the surface\n458.96s: models and get information back when we\n461.08s: get back the fluxes from the surface\n463.159s: models we do aerosol emissions chemistry\n466.759s: um diffusion that's separate from the\n469.0s: boundary layer turbulence in club dry\n471.479s: deposition basically particles falling\n473.479s: out of the atmosphere and various forms\n475.68s: of drag so gravity wave\n477.12s: parameterizations and and surface drag\n480.56s: and then this is this goes back around\n482.24s: to the Dynamics for the next time step\n485.159s: so a couple of things about this um is\n487.84s: that first this is a slightly simplified\n489.56s: picture but it has most of the major\n491.479s: components second is that we use a Time\n493.759s: splitting technique uh so what that\n495.8s: means is that each scheme in this\n498.199s: picture gets the state that's that was\n500.479s: produced by the last scheme so um and\n504.12s: and you can think about that is the\n505.36s: physics is basically working on the\n506.919s: state uh that the Dynamics produces um\n509.96s: and that was um you can think of that\n512.44s: about that as a s being a temperature or\n514.76s: water vapor or whatever at time T the\n516.959s: Dynamics works on it and then the\n518.479s: physics works on that to produce the the\n520.68s: predicted quantity at time t+\n523.12s: one this matters um for a number of\n525.839s: reasons but one of them is because that\n527.68s: means that the uh you can think of each\n530.0s: of the parameterizations as being an\n531.88s: essentially an operator so the radiation\n534.36s: might be called R and the the boundary\n536.36s: layer um uh physics might be called B\n538.959s: and the deep convection might be called\n540.64s: Z each of those in themselves are\n543.44s: nonlinear which means that the order of\n545.44s: operations matters so when we expand\n547.92s: this to uh to show you what the\n551.24s: evolution of s looks like for time t\n553.24s: plus one it's really the radiation\n555.12s: working on the state produced by the\n556.959s: boundary layers physics produced that\n559.279s: was produced by the Deep convection\n561.56s: which got its state from the\n563.959s: Dynamics and if we change the order of\n566.519s: operations we're going to change the\n568.399s: prediction of size and we're going to\n570.079s: come back to this in a in a few minutes\n572.72s: because it does it does matter and it\n574.959s: also matters for future cam development\n577.12s: that I'll talk about at the\n579.839s: end so now I wanted to start thinking\n582.56s: about how we're going to change from\n584.2s: this\n585.0s: structure H from this structure to\n588.16s: update things for cam s so the first\n590.44s: thing is our fir is a jump so we're\n593.16s: jumping from um solving the equations of\n596.16s: motion using a finite volume approach to\n598.6s: a spectral element approach and this is\n601.92s: visually represented here by the the\n603.76s: different grids so the finite volume\n605.959s: Dynamics works on this regular latitude\n608.0s: longitude grid that just looks like map\n610.12s: um grid lines of latitude and longitude\n612.88s: and we're changing to uh the spectral\n614.68s: element which works on in on\n617.04s: quadrilaterals on this cubed sphere mesh\n619.32s: and you can kind of see the curvature of\n621.279s: the mesh shown here there's there are a\n624.0s: number of reasons for making this change\n626.16s: um one of them is highly practical which\n627.839s: is that the finite volume Dynamic that\n630.68s: we've been using for the last 15 years\n632.48s: or so is no longer developed or\n634.92s: supported so we want to move to\n636.72s: something that has a little bit more um\n640.0s: uh support behind it interest in it and\n644.079s: and along with that comes some\n646.0s: additional things including one is that\n648.72s: uh a deficiency or a drawback of using a\n651.48s: regular latitude longitude grid is that\n653.639s: the the lines of longitude converge so\n656.279s: the meridians converge at the poles you\n657.92s: can see that at the top of this picture\n660.8s: and that means that the grid spacing\n662.24s: gets very very small which is not good\n664.12s: for numerical stability so in order to\n665.8s: take the long time steps we want to take\n667.959s: in the model um Dynamics we have to do\n671.16s: filtering to avoid numerical\n672.88s: instabilities near the pole um that's\n676.44s: not not a desirable numerical approach\n678.6s: so we would like to get away from that\n680.48s: it also introduces other problems that I\n682.399s: that I won't bother talking about um\n684.839s: that goes away when we go to the spec\n686.6s: the cube sphere mesh you can see that\n688.279s: the the grid space here is much more uh\n691.56s: homogeneous around this the\n694.399s: globe uh another thing is uh the scaling\n698.32s: of the of the numerics of the Dynamics\n700.8s: here so the spectral element dor uh can\n703.76s: scale out to many thousands of\n705.399s: processors um pretty well um it's\n707.72s: becomes very efficient so the the bang\n709.8s: for your computational buck goes farther\n712.279s: with spectral element with than finite\n713.959s: volume um there is a trade-off there\n716.24s: though because on small numbers of\n717.959s: processors the finite volume core is\n720.24s: actually cheaper than spectral element\n721.639s: so there's a crossover point which\n723.16s: probably varies depending on what kind\n724.56s: of machine you're\n726.519s: using um and the other thing that I\n728.76s: wanted to mention about the spectral\n729.92s: element dor is that it allows a new a\n732.68s: new capability in cam which is using\n735.079s: regionally refined meshes so you you\n737.199s: might have a this kind of very coar\n739.04s: resolution mesh for most of the globe\n741.639s: but then refine it down to a very high\n743.92s: resolution mesh in a particular region\n745.76s: of interest and that's permitted um in\n749.24s: the spectral element dor because of the\n750.88s: way it's constructed but it it's it's\n753.399s: not possible really with the finite\n754.88s: volume dor uh so this reduces the new\n757.639s: capability so this is going to be the\n759.44s: new Dynamics and the grid and horizontal\n761.8s: grid for the for cam going into Cam 7\n765.079s: but we're also changing the vertical\n766.839s: levels so cam for for cam 6 we had a\n771.12s: model top around 40\n772.959s: kilometers and and the entire atmosphere\n775.48s: was represented by 32 vertical levels\n777.839s: which are the nominal pressure are shown\n780.16s: here and now what we're doing is we're\n783.0s: moving to two different vertical grids\n785.04s: with Pam 7 one is a 58 level vertical\n788.12s: grid that has its top also around 40\n790.0s: kilometers and another which we're\n792.0s: hoping to run for all of our CIP like\n794.16s: production runs which is l93 so 93\n796.839s: vertical levels and its top is around 80\n798.76s: kilometers or so and you can see that\n801.279s: there's um many even approximately\n804.639s: evenly spaced levels in the\n806.24s: midtroposphere and into the stratosphere\n808.72s: with the l93 grid and that's in order to\n812.279s: um better resolve the stratosphere with\n814.16s: a a version of Cam that's not Wacom so\n817.24s: um Wacom has an even higher top and more\n820.16s: vertical levels but we we do want to\n822.88s: represent vertically propagating waves\n824.839s: and I'll show you why in just a moment\n826.92s: we're this is just a zoom in on the far\n829.0s: right um showing that we're also down\n831.32s: here in the boundary layer in the lower\n832.56s: troposphere we're adding 10 additional\n834.24s: boundary layer levels in the lowest\n836.279s: three kilometers or so and we're\n838.079s: lowering the bottom model level from\n840.6s: about 50 m to 17 M so this is a big\n845.0s: change and I'll talk about that again in\n846.72s: a couple of\n847.839s: slides so first I want to talk about\n850.12s: these this midtropospheric vertical\n852.24s: spacing which is 500 meters the main\n855.12s: reason uh we're trying to increase the\n857.88s: free tropospheric vertical resolution is\n860.6s: to resolve vertically propagating waves\n864.12s: for example equatorial waves that\n866.279s: propagate into the stratosphere and\n868.279s: provide momentum forcing for the Quasi\n870.72s: banial oscillation the Qbo which is a\n873.44s: source of predictability um in the\n875.519s: climate system and so this is just a\n877.759s: picture of that um this is\n881.279s: ra5 um showing a a composite of the Qbo\n884.56s: so the the Westerly phase um shown in in\n888.24s: warm colors and the easterly phase shown\n890.04s: in blue colors and you can see that it\n892.079s: forms and it and it propagates downward\n894.36s: toward the troposphere um and gets\n896.72s: pretty low to almost 100\n899.68s: uh hectopascal or\n901.48s: so this was not um possible to represent\n905.44s: in cam with the 32 levels with the low\n908.68s: low top so we raised the top and then\n910.72s: we've done a number of experiments to\n912.399s: look at the sensitivity of the Qbo to\n914.279s: the vertical um resolution so this is a\n918.0s: a a series of simulations with a, 900\n921.839s: 800 so on um grid um meter grid spacing\n925.199s: in the free troposphere and what we're\n926.959s: settling on is 500 and we've argued\n929.199s: about whether we should go to 6 or 700\n930.92s: or go down to 400 so we compromised and\n933.44s: we're going to 500 meter vertical grid\n935.44s: spacing in order to capture the\n937.88s: amplitude and the um phase of the Qbo\n941.16s: and you can see it comes down much lower\n943.36s: when we go to 500 meters uh grid spacing\n945.88s: than a\n947.8s: th so that's that's the free chopa\n950.68s: sphere and then there's also the\n952.04s: boundary layer part which we we wanted\n954.399s: to increase the vertical resolution in\n955.88s: the boundary there for a number of\n957.079s: reasons um one of them is capture thin\n959.92s: Cloud layers over the ocean so Strat\n961.959s: cumulus and Tradewind cumulus which can\n964.199s: have um fairly fine vertical um\n966.72s: structure in the in the real world and\n968.92s: we think that these clouds are important\n970.24s: for cloud feedbacks um as the climate\n972.92s: warms so we'd like to represent them\n974.399s: better but another reason is to better\n977.16s: capture um temperature extremes\n978.88s: especially cold extremes over land and\n981.319s: and Ice uh where the the surface can get\n984.199s: very cold and that and that leads to a\n987.0s: surface-based inversion and a very thin\n989.399s: boundary layer and with a 60 or 50 layer\n992.759s: lowest model level and very coarse um\n996.44s: very coarse vertical resolution in the\n998.04s: boundary layer in previous versions of\n999.839s: Cam we really could not capture stable\n1002.079s: boundary layers at all we're hoping that\n1004.12s: going to this um much higher resolution\n1007.04s: boundary layer with grid spacings of of\n1009.72s: a few tens of meters stretching up to\n1011.8s: about 200 meters at 700 hectopascal that\n1014.72s: will be able to capture um stable\n1016.88s: boundary layers and surface-based\n1018.279s: inversions much better but once we\n1020.759s: introduced this new grid we found that\n1023.279s: it the tropical deep convection was\n1025.799s: behaving extremely badly there was\n1028.28s: pathological Behavior where we just it\n1030.839s: destroyed the\n1032.199s: climate uh looking into it what it seems\n1034.72s: to be the main culprit is that the Deep\n1037.959s: convection parameterization which is\n1039.559s: called it's based on Jen McFarland it's\n1041.72s: a mass Flex scheme and it it relies on U\n1044.88s: consuming Cape that's determined by\n1046.919s: raising a parcel um from from a layer in\n1050.48s: the boundary layer upward to to\n1052.44s: determine how much pocy that parcel has\n1055.12s: um and how much Cape can be consumed and\n1057.6s: the properties of that parcel were\n1059.039s: always um previously coming from the\n1061.12s: level in the boundary layer with the\n1062.6s: maximum moist static energy and when we\n1065.0s: went into this new vertical structure\n1068.2s: that level was often one of the very\n1070.039s: lowest model levels which are these\n1071.679s: really thin layers so we would lift the\n1073.88s: parcel in the calculation and it really\n1076.039s: wouldn't have much Cape so it couldn't\n1078.36s: it the convection was essentially being\n1080.679s: impeded by not be by not having enough\n1083.32s: energy available to to to uh to actually\n1087.799s: stabilize the the atmosphere which led\n1090.559s: to um bizarre um knock on effects once\n1094.24s: you start once you start impeding that\n1095.96s: kind of um instability removal so what\n1099.4s: Rich Neil has done as a modification is\n1102.08s: instead of launching the parcel from the\n1103.919s: level with the maximum moistc energy\n1105.679s: which tends to be near the surface we're\n1108.0s: now launching that test parcel from a\n1111.4s: from a hypothetical level in the top\n1113.52s: part of the boundary layer the subcloud\n1115.24s: layer using the vertically integrated\n1118.12s: moist static energy of a few levels in\n1120.679s: the boundary layer so if you're running\n1122.2s: with course resolution that's probably\n1123.4s: going to be one or two levels but if\n1124.799s: you're running with this finer vertical\n1126.48s: resolution it'll be several levels being\n1128.48s: averaged together to determine the\n1130.12s: parcel properties which I think is\n1132.28s: consistent with the uh philosophy that\n1134.2s: goes along with this Mass F scheme doing\n1137.4s: this is uh the main\n1139.84s: basically re uh got us back to the\n1142.4s: previous behavior of deep convection so\n1144.0s: the climate the climatology looked\n1146.6s: fairly reasonable and and there are some\n1148.84s: other changes in the Deep convection um\n1151.0s: that are less important I think for our\n1152.48s: purposes\n1153.48s: here and then also for cam s we have a a\n1157.72s: whole bunch of other updates um which\n1160.76s: are mostly Hops and skips to go back to\n1162.76s: our metaphor um so the turbulence scheme\n1166.08s: Club has been updated it's developed at\n1168.6s: the the University of Wisconsin\n1169.919s: Milwaukee by Vince Larsson and his group\n1172.48s: and so they're continuously updating um\n1175.12s: the scheme and and cam tries to keep up\n1177.2s: with it and we have a couple of\n1178.799s: collaborative projects that that develop\n1181.28s: that scheme along with them and so they\n1184.48s: it it's pulled in as an external code\n1186.72s: repository when you build\n1188.84s: cam microphysics is similar so we've\n1192.159s: been using Morrison getlan version 2\n1194.52s: microphysics that's being updated to\n1196.6s: Pumas this is a for a while was called\n1199.0s: Morrison Gan version 3 but they changed\n1200.64s: the name to Pumas but this is an updated\n1202.88s: version of that of that microphysics it\n1205.76s: has a number of improvements including\n1207.64s: um improved ice fall speed uh fixed\n1211.12s: number limiter that we'll come back to\n1212.4s: in a second and a few other things it is\n1214.4s: also now living in its own separate code\n1216.36s: repository that gets sucked into cam um\n1219.32s: when you build it radiation is another\n1222.2s: update uh so we're we're transitioning\n1224.32s: from\n1225.44s: rrtmg to RR tmgp which is a more modern\n1228.88s: code design it has updated spectroscopy\n1231.36s: under the hood which provides a more\n1233.679s: accurate answer in the radi of transfer\n1235.72s: calculation it is also pulled in as an\n1238.12s: external\n1239.6s: repository aerosols are have a slight\n1242.12s: update from m m four to M five that's\n1244.24s: not a version number that's actually the\n1245.679s: number of modes that are being\n1247.32s: represented um there's also updates to\n1250.0s: emissions including a major update to\n1252.039s: dust emissions that's just coming into\n1253.48s: the model right now and optionally you\n1256.36s: can use hco emissions but I don't think\n1258.08s: that's going to be the default I don't\n1259.64s: remember for sure and then gravity waves\n1262.159s: have been um updated slightly um and\n1264.96s: service flexes are are being updated\n1266.919s: slightly as well so a whole bunch of\n1269.28s: smaller changes and I just wanted to go\n1271.44s: through a few of the of these as\n1273.24s: examples um starting with this um ice\n1276.08s: number limiter which got kind of a lot\n1278.159s: of attention in some Circles of the\n1279.799s: community so csm2 um is a very high\n1284.159s: climate sensitivity model so if you\n1286.24s: double carbon dioxide and run the\n1288.679s: coupled system you get more than a 5\n1290.48s: degree warming uh and that's that's\n1293.32s: outside the likely range of climate\n1295.2s: sensitivity and it's been described as\n1296.799s: one of the hot models in SE\n1299.08s: 6 and one of one of the uh culprits for\n1303.24s: that seems to be a change in the\n1305.0s: Southern Ocean clouds in particular in\n1308.4s: in cesm1 which had a climate to be\n1310.52s: around four degrees or\n1312.52s: so the the Southern Ocean clouds were\n1315.4s: basically completely ice clouds and so\n1317.52s: when you warm the climate the ice\n1319.159s: transitions to liquid that acts as a\n1321.279s: negative feedback on the climate slows\n1323.32s: down the warming reduces the climate\n1325.08s: sensitivity in csm2 a lot of work went\n1327.72s: into um producing more realistic\n1330.279s: Southern Ocean clouds that are that are\n1332.48s: a mixture of ice and liquids and that\n1334.919s: that was successful um and so there's\n1338.159s: less ice to transition to liquid in the\n1341.159s: base state of the csm2 climate so when\n1343.679s: you go to warm it there's um less\n1346.44s: negative feedback which means that the\n1348.159s: positive feedbacks are more exposed and\n1349.84s: you get more warming and a higher\n1351.0s: climate\n1352.84s: sensitivity um but we got a lot of we\n1355.2s: got a lot of warming and and people have\n1357.72s: looked at this Southern Ocean as being a\n1359.799s: main culprit for our increased climate\n1362.159s: sensitivity and and when we ran when\n1365.44s: jeang XU in particular ran um paleo\n1368.0s: climate simulations he found that the\n1369.84s: the sensitivity going the other\n1371.039s: direction toward Cooling in the last\n1372.48s: glacial maximum was also too large way\n1374.96s: outside of the bounds of um paleoclimate\n1377.559s: proxy records\n1379.44s: so in as part of the fixing as part of\n1382.76s: tuning retuning the model to capture the\n1385.039s: last glacial maximum better they\n1387.159s: discovered that there was an ice number\n1388.6s: limiter in the code that hadn't been\n1390.679s: correctly changed going from Morrison\n1393.2s: Gman microphysics version one to version\n1395.559s: two essentially what the the idea is to\n1398.76s: limit the production of ice particles by\n1402.6s: making sure you don't you you don't\n1404.2s: produce more ice partic ice crystals\n1406.24s: than you have ice nucleating particles\n1408.799s: if you if you if the tendency of uh ice\n1411.52s: particles is too large and you're going\n1413.2s: to use up all your ice nucleating\n1414.64s: particles then it would it would cut off\n1417.039s: the production of\n1418.919s: Ice uh in the transition from mg1 to mg2\n1422.88s: that wasn't that limiter wasn't adjusted\n1424.919s: correctly to account for a new process\n1426.84s: and so the the limiter was being set way\n1430.159s: too low um which basically cut the um\n1434.6s: amount of Ice uh down in some\n1437.24s: circumstances that's been corrected in\n1439.24s: Pumas um which is the the update and now\n1441.96s: we have a much simpler limiter that\n1443.72s: happens at the end of the ice at the ice\n1446.0s: physics um basically says if you if the\n1449.039s: ice number is outside the bounds of\n1450.72s: reality then just limit it to um to a\n1454.799s: particular fixed upper\n1457.919s: bound but this this limiter has gotten a\n1460.52s: lot of attention because people have\n1461.76s: pointed at it as a major flaw in cesm 2\n1464.88s: that leads to a really high climate\n1466.32s: sensitivity we've been recently doing\n1468.559s: work to investigate this and quantify\n1471.159s: exactly how much it matters this is work\n1473.2s: by Margaret Duffy that's in prep turns\n1475.399s: out that if that whether you use it with\n1477.52s: use csm2 with the ice limiter um being\n1481.679s: incorrect or or correct it um csm2 still\n1485.679s: looks like csm2 in transit climate um\n1488.36s: runs and this is a this is a bit of an\n1490.559s: aside to everything but if you look at\n1493.0s: if you look at these colored lines and\n1494.559s: these graphs for uh an SSP simulation\n1499.44s: 1% CO2 increase simulation for 150 years\n1502.919s: and an Abrupt four time CO2 simulation\n1505.08s: for 150 years the colored lines don't\n1508.2s: look as different from each other as\n1510.08s: they look from the from the gray lines\n1512.2s: in the background those are the seip 6\n1514.36s: models so with with or without this ice\n1516.76s: number limiter we have a very uh similar\n1520.64s: transient climate response although a\n1523.08s: different a different equilibrium\n1525.159s: climate sensitivity but we're still the\n1527.799s: CSM 2 model still looks like the csm2\n1530.279s: model and is is well within the range of\n1532.919s: C6 models so as an aside but we've spent\n1536.12s: a lot of time thinking about it so I\n1537.36s: wanted to make sure to say\n1538.84s: it um coming back to cam 7 physics\n1542.24s: updates so I wanted to return to this\n1544.76s: time Loop really quickly so remember we\n1547.0s: went from Dynamics into the physics and\n1548.679s: we went through all these\n1550.0s: processes after csm2 was released um it\n1553.76s: was a a a weird oscillation was detected\n1558.559s: um and you can see an example of that\n1560.12s: down here from Adam Harrington so this\n1561.64s: is the uh V component of the wind and\n1564.08s: you can see these oscillations in the\n1565.72s: solution this is a single column model\n1568.159s: run with different numbers of levels and\n1569.96s: that that doesn't matter but you see\n1571.52s: these weird\n1573.159s: oscillations um tracing this into the\n1575.72s: code it turns out there was an\n1577.08s: inconsistency in the uh in the near\n1579.64s: surface uh physics which which turns out\n1582.72s: to be because of a an offset between\n1584.84s: where the wind stress is calculated and\n1587.32s: where it's applied so the surface stress\n1591.0s: is essentially calculated at the surface\n1592.919s: coupling um step in the physics so you\n1595.76s: can think of that is happening at time T\n1598.36s: but that surface stress then doesn't get\n1600.039s: used until you come all the way around\n1601.64s: the physics Loop go through the Dynamics\n1603.919s: come back and it gets used in club in\n1606.6s: the in the boundary layer physics and\n1608.6s: that's basically at time t plus one so\n1610.2s: there's an offset in time between when\n1612.559s: the surface stress is calculated and\n1613.96s: when it gets applied and that caused\n1615.96s: this kind of like pushpull kind of\n1617.679s: oscillation in the physics which doesn't\n1620.36s: look great when you when you start to\n1621.72s: look at individual time steps so this\n1623.96s: has been corrected you can see evidence\n1625.559s: of that here um the the correction is\n1628.12s: essentially to move this surface\n1629.76s: coupling up in the time step to right\n1632.0s: after the Deep convection and so that's\n1633.48s: been a Adam Adam Harrington applied this\n1636.52s: um for cam seven and it took a\n1638.48s: tremendous amount of work because if you\n1640.08s: remember when I showed you the the uh\n1644.32s: the time splitting approach where each\n1646.679s: parameterization gets the state from the\n1648.52s: previous um Pro\n1651.64s: parameterization that's that can really\n1653.679s: affect the solution so and the whole\n1656.0s: code is set up\n1657.48s: to run in a\n1659.72s: particular um series of processes and so\n1663.24s: moving things around was a tedious\n1665.519s: process and and Port atom had to do it\n1667.799s: and now this is what the time Loop looks\n1669.36s: like for cam 7 so we the dynamic you go\n1672.399s: from the Dynamics which just changed now\n1674.32s: to the spectral element dynamical core\n1676.36s: and you go into the deep convection\n1677.679s: which is now um modified to use the new\n1680.2s: vertical grid and then we couple with\n1682.159s: the surface fluxes we come out of that\n1684.399s: and and we do our new aerosol emissions\n1687.64s: and come into this same kind of\n1689.559s: iteration between the the boundary layer\n1691.72s: scheme and the microphysics we still\n1694.36s: iterate that three times these these\n1696.519s: schemes have all been updated into the\n1698.919s: new radiation scheme r r tmgp into the\n1701.84s: updated um chem aerosol chemistry scheme\n1704.519s: M five and then into the diffusion drve\n1707.2s: deposition and the modified drag which\n1709.36s: is U still being still being modified\n1711.799s: which is why I put it at hashed so you\n1713.679s: can see that from going from cam 6 to\n1715.6s: cam 7 we have quite a few changes\n1718.519s: including the structure of the physics\n1720.88s: and many updates to individual\n1724.799s: packages so I wanted to now spend a\n1727.84s: couple minutes talking about how we've\n1730.72s: gotten to that um not just in terms of\n1732.76s: the actual physics of it but how we do\n1734.76s: it as a process so this is kind of a\n1736.84s: different time Loop\n1738.679s: which starts on Tuesday mornings and\n1740.6s: goes around to Friday mornings and then\n1742.76s: repeats so on Tuesday Mornings the cam\n1746.08s: scientists and cam software engineers\n1747.88s: get together to go through all of the um\n1750.08s: software engineering tasks for the week\n1752.32s: I'll show you an example of that in a\n1754.08s: minute and then there's an additional\n1756.6s: cesm project meeting where thing where\n1758.88s: the we talk about the development of the\n1760.559s: coupled system so the cam scientists get\n1763.12s: together with the scientists the\n1764.679s: developers from the other component\n1766.399s: models uh at the same time time the cam\n1768.88s: software engineering team has a separate\n1770.399s: meeting to talk about um the software\n1772.08s: engineering details and tasks for the\n1774.279s: week and then things go around on Friday\n1776.799s: morning um the cam science team\n1779.64s: development team gets together to talk\n1781.32s: about what simulations are looking like\n1783.6s: and what needs to be done uh next and\n1786.679s: then simulations are run basically over\n1788.559s: the weekend and we start the cycle again\n1791.2s: during this um as changes come in um\n1794.039s: changes need to be proposed uh as a\n1796.64s: GitHub issue so github's at the the\n1798.159s: center of this whole thing and there's\n1799.799s: lots of uh interactions around the\n1802.279s: loop uh so discussions happen there\n1805.08s: about what particular changes are going\n1807.36s: to mean a pool request needs to be\n1809.679s: issued and that triggers a series of\n1812.76s: detailed code reviews by the cam\n1814.6s: software developers or software\n1816.96s: Engineers um sometimes and especially if\n1819.559s: the if the pull request is coming from\n1821.519s: an external group um cam the cam\n1824.24s: scientists will be pulled in to also\n1825.76s: review the code um once the pr is\n1828.799s: accepted once the pull request is\n1830.679s: accepted and the and the code is brought\n1832.44s: into Cam it means it's there a new cam\n1835.559s: tag is issued so a new cam version if\n1838.6s: you will but that doesn't mean it's part\n1840.84s: of Cam yet because it still needs to be\n1842.519s: evaluated for um for its effects on\n1845.76s: climate um and it still probably is\n1848.399s: subject to additional modification and\n1849.88s: tuning as part of the um release\n1853.96s: process so that Tuesday morning meeting\n1856.72s: between the cam scientists and software\n1859.039s: Engineers looks kind of like going\n1860.6s: through this so this is the cam\n1862.36s: development board we talk about all the\n1864.72s: cam tags that have been made in the last\n1866.44s: week cam tags that are coming up this\n1868.84s: week and then go through um what's\n1871.159s: happening in terms of like what pool\n1873.24s: what pool requests are are basically\n1875.12s: ready to go in and become become new cam\n1877.6s: tags or going through review um what PRS\n1881.039s: have just started a review and what what\n1882.919s: pull requests are um not yet started and\n1886.44s: anything that's coming up so uh and then\n1889.76s: we talk about a few other um software\n1891.559s: engineering related tasks um as\n1894.24s: needed this the Friday morning meeting\n1897.12s: is is pretty different because it's a\n1898.88s: lot of um talking about individual\n1900.519s: processes and how they actually uh\n1903.44s: manifest in simulations so this is a lot\n1905.639s: of informal presentations of of work in\n1908.08s: progress and these are just pictur uh\n1910.32s: figures that have been shown in recent\n1911.96s: meetings over the last few months I\n1913.2s: pulled out of the slide deck that we\n1914.96s: that we show every week this there's a\n1917.32s: lot of up on the status of simulations\n1919.559s: discussion and\n1920.76s: planning and these are so these are\n1922.919s: examples of what of issues that we've\n1924.799s: been talking about lately so we have an\n1926.6s: East Pacific precipitation bias we've\n1928.88s: been going back and forth with the\n1929.919s: oceanographers to determine whether it's\n1931.919s: an ocean issue or an atmosphere issue\n1934.08s: turns out it's both we often are talking\n1936.679s: about the labrador SE um freezing in\n1939.08s: pre-industrial coupled RS and that's\n1941.44s: shown down here um you can see this red\n1944.12s: line popping up this is an issue that\n1946.2s: comes up often we had the same issue\n1948.159s: with C with development of csm1 and csm2\n1951.639s: where the labrador sea would suddenly\n1953.279s: free spontaneously freeze and that\n1954.96s: becomes an issue because it doesn't\n1956.639s: unfreeze um in in most cases in a\n1959.36s: pre-industrial run we also have been\n1962.559s: talking about a stratospheric water\n1964.0s: vapor um bias in cam especially with the\n1967.679s: the new l93 level uh the 93 level\n1971.039s: version of the model we we want the\n1973.2s: stratosphere to look pretty good so we\n1974.76s: want the water vapor to be right this\n1976.36s: also ties into those changes in the deep\n1978.08s: convection scheme which is essentially\n1979.84s: the source of water for this for the\n1981.48s: lower Stratosphere and then in the last\n1983.84s: couple of weeks um we've been we've been\n1985.799s: looking at the 20th century simulations\n1987.88s: in the coupled system and they're too\n1989.76s: warm and I just wanted to show you a\n1991.12s: couple pictures of this this is\n1992.24s: literally from last week and this week\n1994.48s: this is the time series of global mean\n1996.639s: surface temperature through the 20th\n1999.08s: century and these colored lines that are\n2001.919s: too high are the uh surface temperature\n2004.88s: anomalies in recent versions of SE of C\n2007.919s: sm3 or prototype csm3 and you can see\n2010.76s: that they all warm too much in the mid\n2012.519s: 20th century um and this the gray\n2015.799s: shading is the csm2 large Ensemble and\n2018.279s: the black line is a observational\n2020.76s: estimate we think that this has to do\n2022.919s: with aerosol Cloud interactions so this\n2024.919s: is the the cloud shortwave Cloud rate of\n2027.159s: effect you can see it's not the colored\n2029.12s: lines aren't falling off in the mid mid\n2031.559s: 20th century the same way that we see in\n2034.679s: csm2 um but we so we've been trying to\n2037.12s: dig into the uh Cloud aerosol\n2039.32s: microphysics and try to figure out\n2040.799s: what's going on so we've been looking at\n2042.08s: Cloud number um uh Cloud drop number\n2046.0s: concentrations which are can be high or\n2048.56s: low so we kind of think just this week\n2051.399s: we've been deciding that maybe Cloud\n2053.76s: drop number distributions are red\n2055.159s: herring so we don't really know what's\n2057.24s: happening here but we're and it's a\n2058.879s: problem that we're like desperately\n2060.72s: trying to solve right now we'll be\n2062.48s: talking about it tomorrow at the at that\n2064.32s: Friday morning\n2066.44s: meeting uh so so we saw here in the in\n2069.52s: the development meeting we we see a lot\n2071.56s: of individual plots from Individual um\n2073.76s: people doing investigations but we also\n2076.0s: have an automated model evaluation\n2078.28s: system that we're developing um so the\n2081.2s: in the soft on the software side we have\n2082.72s: regression tests but in terms of\n2084.76s: evaluating the climate we're we're\n2086.44s: developing this AMW Diagnostics\n2088.599s: framework or ADF it's a python based\n2091.119s: package um that makes just basically\n2093.0s: makes a bunch of plots and splits them\n2095.2s: out into a a website a static website\n2097.72s: that looks like this when you land when\n2099.24s: you open the the homepage and you can\n2101.28s: click around and browse through a whole\n2102.76s: bunch of figures this is run by uh\n2105.24s: basically a user modifying a yaml file\n2107.359s: to tell that tell the package what\n2110.359s: variables to plot and um what kinds of\n2112.72s: plots to make we can have maps and polar\n2115.4s: plots and zonal means and this is a Qbo\n2118.04s: plot and and tailor diagrams and and\n2120.04s: there's several others in the\n2122.48s: package and so this is the first line of\n2124.92s: evaluation so we run these we run these\n2127.04s: development um simulations we run the\n2130.4s: the ADF um to produce these plots we\n2132.72s: click around and look at at what's going\n2134.48s: on to make a first level evaluation the\n2137.839s: ADF can optionally also run the climate\n2140.079s: variability Diagnostics package the cbdp\n2142.44s: that's developed by Adam Phillips so\n2144.44s: those are those are useful when we want\n2145.88s: to start to look at modes of variability\n2148.56s: and we've recently Incorporated um\n2150.72s: thanks to um Danny Colman at incar the\n2154.119s: Noah mdtf package so we can this is\n2156.359s: mostly looking at process Orient\n2157.64s: oriented Diagnostics so things related\n2159.599s: to the mjl or blocking or other\n2163.24s: extremes and and in addition to the\n2166.28s: atmospheric side of things we're\n2168.44s: developing a new package at incar called\n2170.28s: Cupid which is a framework for running\n2172.56s: sets of Diagnostics so the ADF will be\n2174.92s: one of those and hopefully uh when we\n2177.319s: run um coupled simulations we'll be able\n2180.76s: to run Cupid it'll run ADF for the\n2182.96s: atmosphere and then it'll run other\n2184.24s: packages for the other components and so\n2186.0s: we'll have one unified place to run all\n2188.2s: of the kind of routine\n2190.68s: Diagnostics U which which we've been\n2192.8s: lacking up until\n2195.119s: now so what we're doing in the current\n2198.16s: process and you saw a little bit of that\n2199.88s: with the with that 20th century run was\n2202.319s: model tuning and this is just an example\n2204.8s: of a of a of how we do this tuning so we\n2208.2s: actually we literally are doing runs\n2209.96s: that are incremented in number yes it\n2212.44s: did start at one uh and and we go\n2215.72s: through we do these evaluations some of\n2217.8s: them are ad hoc some of them are are are\n2219.92s: routine like running the ADF just to\n2221.76s: make sure everything looks normal um and\n2223.92s: then when we when we spot when we have\n2225.599s: something that we want to uh make\n2227.16s: adjustments to we'll do a new run and\n2229.8s: 104 here is an example where it was the\n2232.839s: same as run 103 but the club C8\n2235.16s: parameter has been adjusted from 4.25 to\n2237.96s: 4.95 and it's the description of this is\n2240.72s: tuning so this is a very manual process\n2243.64s: and it's it's slow and expensive and so\n2246.96s: this is one place where I think we uh\n2249.28s: work in leap can make make a a direct\n2252.04s: impact on cam\n2254.72s: development and one idea for this is\n2257.2s: through perturb parameter Ensemble so\n2259.88s: systematically adjust varying par the\n2262.2s: free parameters in a model to try to\n2263.72s: find Optimal parameter\n2265.56s: settings we've had we have some\n2267.44s: experience with this with Cam 6 so this\n2269.28s: is an example from chudah ID heimer's\n2271.04s: paper um looking at a whole bunch of\n2273.76s: parameters and a bunch of global fields\n2275.839s: and how the par parameters affect the\n2278.4s: sensitivity of the the or affect those\n2280.64s: fields so the colors show the\n2282.44s: sensitivity so immediately these kinds\n2284.56s: of per parameter ensembles can provide\n2286.88s: some useful information by quantifying\n2289.52s: the parametric sensitivity and informing\n2291.68s: parameter ranges and indicating which\n2294.4s: parameters are really useful for tuning\n2296.839s: which have high sensitivities or low\n2298.44s: sensitivities and for which Fields I\n2301.48s: think that there's a an opportunity here\n2303.44s: to apply machine learning approaches\n2305.64s: doing emulation to optimize parameters\n2308.079s: in a more automated way Yang um has and\n2312.04s: Greg have already been doing this um to\n2314.079s: some extent with both the the incar\n2316.599s: model and the NASA model but there's a\n2319.4s: challenge also which is uh we don't know\n2321.72s: what to optimize and if you optimize one\n2323.8s: thing you might be degrading something\n2326.119s: else and different you get different\n2327.599s: answers for what parameters are best if\n2330.16s: depending on what Target you have so\n2332.24s: that's a challenge um and another\n2333.96s: challenge is being able to do this\n2335.4s: really fast because you saw that this is\n2337.24s: basic basically we have a weekly time\n2338.76s: Loop where we want to change the model\n2340.88s: run it and evaluate it and so we need to\n2342.839s: be able to do a a parameter optimization\n2346.56s: as fast as possible otherwise we're\n2349.0s: going to Resort back to the same thing\n2350.44s: that we've been we're doing now which is\n2351.72s: hand tuning which is which is again slow\n2355.04s: and and expensive so we have a leap\n2358.4s: project and adisu and yang are going to\n2360.319s: be starting on this in October and one\n2361.88s: of the things I think we can do is to\n2364.2s: try to develop some workflows to\n2366.319s: accelerate this model tuning\n2369.96s: process uh I just wanted to spend a\n2371.96s: couple minutes at the end and I know\n2373.72s: we're running out of time probably um\n2376.119s: talking about what happens when we're\n2377.64s: done with csm3 and cam\n2380.48s: 7 so we're we're at the point now um\n2384.24s: where the scientific part of Cam 7 and\n2387.28s: csm3 are about to be finalized so\n2390.0s: there's a Code freeze coming um this\n2393.599s: month or maybe early next month where no\n2396.0s: additional science capabilities going to\n2397.599s: be added to the model that doesn't mean\n2399.56s: the model's done because there's a\n2401.359s: there's still a bunch of software\n2402.44s: engineering and model tuning that needs\n2404.359s: to happen over the next few months\n2405.8s: before we we release the model once it\n2409.119s: is released though we basically jump\n2411.16s: into CIP 7 and so these are some\n2413.16s: pictures from the CIP 7 website and you\n2415.68s: can see that um if you look at the\n2418.359s: Timeline here AR7 FastTrack runs are are\n2422.4s: slated to start in early\n2424.76s: 2025 that's essentially when we're think\n2427.359s: we're going to be done with CSM\n2429.4s: 3 uh and so we might be late we might be\n2432.44s: late starting our FasTrack and deck runs\n2435.88s: uh compared to this timeline but I'm I'm\n2438.079s: sure other modeling groups will too but\n2440.319s: then once we do get started there these\n2442.24s: are dozens of simulations thousands of\n2444.16s: simulated years tons of output to deal\n2446.8s: with and a substantial amount of\n2448.359s: post-processing to turn to change the um\n2451.56s: Cam and CSM native outputs to the CIP\n2454.2s: compliant output so that's this is a\n2456.24s: huge undertaking\n2458.2s: um that we're still um organizing now\n2461.96s: and as soon as we're and also as soon as\n2463.92s: we're done with csm3 there will be\n2465.96s: additional Community projects that\n2467.44s: people will want to do including a new\n2469.4s: large Ensemble single forcing ensembles\n2472.359s: and there's a big push um to move more\n2475.24s: strongly into Earth system prediction\n2476.839s: doing subseasonal to seasonal prediction\n2479.04s: and decal prediction um which it which\n2481.56s: requires additional model development\n2483.599s: and and workflow\n2485.92s: development and development itself\n2488.04s: doesn't really change doesn't really\n2489.72s: stop once we have a final version of Cam\n2491.8s: 7 and csm3 because we want to there are\n2494.88s: plans already to bring in additional\n2496.48s: capabilities um including um developing\n2499.16s: and tuning a high resolution version of\n2501.24s: the model that would be like a 25 km\n2503.079s: atmosphere so that's going to be a large\n2505.56s: large amount of work just to move to a\n2507.28s: 25 kmet version of the atmosphere and if\n2509.4s: we want to couple it to a 10 a 10\n2512.119s: kilometer version of the ocean um that's\n2515.119s: that's an additional tuning exercise\n2517.079s: that that needs to be tackled there's\n2519.44s: also plans to incorporate machine\n2521.04s: learning based parameterizations coming\n2522.56s: from leap and also in squared lines and\n2524.4s: other projects into cesm this work is\n2527.52s: already started with the warm rain\n2529.4s: microphysics um that we've heard about\n2531.4s: in leap\n2532.8s: already and then there's also\n2534.56s: collaborations to produce ultra high\n2536.44s: resolution versions of CSM at least Cam\n2539.68s: and so Earthworks and storm speed are\n2541.359s: two of those that are looking to produce\n2543.64s: different versions of a an approximately\n2545.76s: 3 kilometer global version of cam um\n2549.2s: using different dynamical cores for\n2551.119s: example and this is an example of one of\n2552.96s: those um looking at a 60 keter version\n2555.68s: of Cam and then a refi a regionally\n2558.119s: refined version like I mentioned earlier\n2560.079s: where we refine from 60 kilometers down\n2562.079s: to 3 kilometers in this Maritime\n2564.68s: continent region and the plot is showing\n2567.48s: the the phase of and amplitude of the\n2569.76s: dial cycle of precipitation and you can\n2572.119s: see how and the observations are on the\n2574.52s: bottom you can see even without tuning\n2576.72s: just going in much higher resolution\n2578.72s: produces a much better representation of\n2580.8s: the diagonal cycle of convection over\n2583.119s: these islands and and around them so\n2586.52s: that's a Hu that's also a huge\n2588.079s: undertaking computationally in and in\n2590.359s: terms of software\n2593.119s: engineering and we can't we can't just\n2596.16s: be uh thinking about cam 7 and what to\n2599.359s: do with it because there's already um\n2602.64s: the beginnings of plans for what to do\n2605.079s: after cam 7 so we already have to be\n2606.92s: thinking thinking about the workflow and\n2609.16s: the development cycle toward CAM 8 um\n2612.079s: which uh yeah uh it's overwhelming um\n2616.52s: but we know we have a few things to do\n2618.119s: including deep convection needs to\n2619.8s: change in CAM 8 if we're going to have\n2622.68s: the capabilities to go to these um\n2624.359s: convection permitting resolutions we\n2626.44s: need a scale aware parameterization so\n2628.52s: one project is is looking at um evolving\n2631.88s: toward a a any diffusivity Mass flux\n2634.92s: appro approach so that's a mass flux\n2638.4s: approx a mass flux scheme to club uh we\n2642.16s: also need improved and more physically\n2644.28s: consistent coupling with the ocean and\n2646.24s: in particular there's a new ocean model\n2647.839s: in csm3 I haven't even mentioned that\n2649.559s: but we're moving from pop two to Mom six\n2652.68s: mom 6 expects to get an enthalpy flux\n2655.28s: from the atmosphere so that requires a\n2657.559s: detailed accounting of the\n2658.72s: thermodynamics of the atmospheric\n2660.24s: physics so Peter lson has been working\n2662.599s: on\n2663.92s: on um developing code to consistently\n2669.079s: get an inaly flux that matches what's\n2671.16s: happening in the atmosphere and pass it\n2672.76s: to the\n2673.92s: ocean there we are also looking to\n2676.16s: improve the treatment of sub grid scale\n2678.0s: heterogenity as part of the class\n2679.96s: project essentially coupling Club to the\n2683.0s: um heterogenity that's in the in the\n2685.28s: land surface model there's going to be\n2687.8s: changes in the club parameterization\n2689.319s: moving from a length scale formulation\n2690.8s: to a time scale formulation likely at\n2692.96s: least and then at incar there's this\n2695.2s: SEMA project which is trying to bring\n2697.96s: some of the uh some of the different\n2700.599s: atmospheric modeling efforts uh that\n2702.88s: have been happening at different parts\n2704.2s: of the organization together uh and one\n2706.839s: of those one of project within that is\n2709.24s: converting all of Cam physics to the\n2711.68s: ccpp compliant that's a major\n2714.52s: infrastructure change um for how\n2716.88s: parameterizations in cam uh work\n2720.079s: essentially takes out\n2721.68s: the interface between Cam and the and\n2725.079s: the parameterization scheme and replaces\n2727.559s: it by um automatically generating that\n2730.28s: interface code by reading metadata\n2732.68s: associated with each\n2734.0s: parameterization that and then we this\n2736.92s: enables a few things including much\n2739.319s: being able to reorder the time Loop much\n2741.76s: more easily so going through the work\n2743.359s: that Adam did won hopefully won't be as\n2745.92s: onerous in the future because the entire\n2748.599s: parameterization Suite can be reordered\n2750.4s: by changing what's called a a a\n2753.0s: parameterization suite file which is an\n2754.92s: XML file which the ccpp infrastructure\n2757.8s: reads and then builds that that\n2760.4s: parameterization Suite on the\n2762.72s: Fly another part of SEMA is integrating\n2765.52s: impass into cesm so that's the model for\n2767.64s: prediction across scales that's a\n2769.359s: basically a non-hydrostatic dynamical\n2771.2s: core on a hexagonal grid that's shown\n2774.2s: over here into into C into Cam as a as\n2778.68s: another option for dynamical core the\n2781.04s: major thing here is um it's it's\n2783.28s: non-hydrostatic which means it can it\n2785.16s: can go to these convection resolving\n2786.559s: scales we want to do for ultra high\n2788.599s: resolution and in fact this example from\n2790.92s: shinging Wang was one was using cam\n2794.359s: impass so that will continue and then\n2796.839s: I'm sure there's a zillion other things\n2798.68s: sh by these\n2800.2s: dots so hopefully that wasn't too much\n2803.44s: and too boring thank you very much and\n2805.839s: I'll I can talk about any questions or\n2808.68s: or take any comments you have\n2817.359s: thank you Brian um okay so we'll do some\n2819.72s: we'll uh do questions now we'll start\n2821.359s: with some of the early career scientists\n2822.88s: in the\n2824.8s: room Sam you had your you had your hand\n2827.16s: up did you want to ask here let use the\n2828.96s: mic so they can hear online uh thanks um\n2832.4s: was extremely interested in the\n2835.24s: Diagnostics uh tool you mentioned um you\n2839.319s: know as a software person getting\n2842.04s: getting started on uh making changes to\n2844.92s: these models I imagine that's very\n2847.68s: useful to be able to double check um so\n2852.599s: it generates a lot of bots right now\n2854.559s: which I think is is useful but I'm\n2856.64s: curious if there's any actual automated\n2859.839s: testing to like direct your attention to\n2862.24s: things which are specifically wrong or\n2865.76s: you just have to like know what the\n2867.4s: plots should look like and Eyeball\n2869.559s: them yeah so the the automated testing\n2873.52s: is all done on the software side um\n2876.119s: basically to check check that the model\n2877.52s: is running correctly but then yeah once\n2881.24s: we get to the\n2882.24s: Diagnostics um we it's really expert\n2885.24s: assessment so you have to know what to\n2886.92s: look for uh it would be amazing to\n2889.8s: actually have\n2891.2s: um something to at least direct\n2893.92s: attention toward what some particular\n2896.079s: thing and we've talked about that in\n2897.359s: terms of there are metrics that we could\n2899.839s: incorporate and maybe produce some kind\n2901.76s: of like scorecard that would show if\n2904.8s: something got much worse or much better\n2907.76s: and in fact the land model has a a uses\n2911.24s: a package that's developed by um by Doe\n2915.0s: called ilam which produces a scorecard\n2917.839s: which you basically see I think like red\n2920.4s: and green on the um in a grid for each\n2924.4s: variable or something and if it's very\n2927.24s: red then you need to go look at it\n2928.599s: because you got worse so something like\n2930.92s: that would be useful but we don't we\n2932.28s: haven't had a chance to develop that for\n2933.839s: the atmosphere diagn Diagnostics yet\n2936.52s: yeah cuz cuz it has these like baselines\n2939.119s: versus the the new code so it seems like\n2942.559s: you would be able to save a lot of time\n2944.359s: if you didn't have to eyeball every\n2946.28s: single one yeah that's absolutely\n2948.559s: correct and we do have the capability of\n2951.24s: uh comparing against observations so if\n2953.359s: you and doing multi multiple cases so\n2955.76s: there we we sort of have the\n2957.64s: infrastructure almost in place to do it\n2959.64s: but we have nobody's actually tackle the\n2961.72s: problem of producing uh something like\n2965.2s: that cool\n2968.96s: thanks okay other other\n2975.559s: questions if anyone has questions online\n2978.359s: feel free to use the raiseed hand\n2980.119s: function so we can unmute\n2987.4s: you hi Brian this is Marcus um hey\n2990.44s: Marcus so when uh when you're going over\n2992.28s: like those issues um you know this looks\n2994.96s: wrong this is bad other notion whatever\n2997.76s: um like how much of those things would\n2999.92s: you say are definitely like structural\n3002.88s: issues with code or like bugs and how\n3005.64s: many of them are like oh we need to\n3007.2s: tweak these parameters so I guess I I\n3009.28s: guess what I'm getting at is how many of\n3010.68s: these things would sort of be addressed\n3013.319s: by uh the kind of tuning exercise that\n3016.64s: might be happening through leap\n3020.799s: anyway I that's a good question and it's\n3023.76s: hard to quantify because we don't keep\n3027.359s: ra uh in any formal way so\n3031.839s: just spitballing it I would say we have\n3036.4s: like maybe a maybe a fourth of the\n3040.68s: things we find or maybe less at this\n3043.2s: point like and it this changes as\n3045.119s: through the development cycle but maybe\n3046.96s: a fourth of the things we find or or\n3048.64s: less are bugs that are detected and we\n3052.16s: and we Trace them and we're like oh well\n3054.44s: we we just did this wrong and so we have\n3056.04s: to fix it\n3057.48s: structurally uh a lot of what we see now\n3062.48s: is um I would say associated with the\n3065.96s: tuning process so setting parameter\n3068.92s: values and and modifying process rates\n3071.28s: and interactions between processes to\n3073.64s: try to optimize the\n3075.24s: climate and\n3077.839s: that and that we know from the pp work\n3082.04s: uh is ambiguous I mean there are\n3085.68s: different you could get to the same\n3087.24s: answer different ways and so this is\n3089.799s: another another place where like work\n3092.0s: from leap could really inform the\n3093.76s: process because we basically tune the\n3096.359s: knob one way if it goes the right way\n3098.28s: then that we're we keep\n3100.16s: going but we know that if we tune a\n3102.2s: different knob maybe we should have\n3103.72s: turned the changed the other parameter\n3106.2s: the the opposite direction\n3109.079s: even thanks\n3111.68s: Brian thanks everyone"
    },
    {
        "class": "YouTubeVideo",
        "title": "TikTok, Cheese Sticks, &amp; Our Future: How Educators Perceive Students&#39; Engagement with Climate Change",
        "videoId": "jRe9gS7vey4",
        "url": "https://www.youtube.com/watch?v=jRe9gS7vey4",
        "publishedAt": "2024-03-02T04:36:50Z",
        "transcript": "4.2s: starting with the teach of college team\n6.16s: so we have no back she has a great\n8.96s: experience cofounded um a company\n12.759s: looking at especially at climate\n15.36s: advocacy and and climate impact uh she\n18.199s: was nominated as one of the forbs 30\n20.92s: under 30 in 2020 uh and now she's a\n24.32s: graduate student at Teachers College and\n26.64s: we have Christina Torres also like very\n29.48s: U experience in the past was also part\n31.759s: of a startup back then she's a PhD\n34.32s: student at Teachers College and uh\n37.64s: together they are also collaborating\n38.96s: with d p Levy who happens to be in\n41.68s: Israel right now not canot join and was\n44.2s: an associate professor at Teachers\n45.84s: College and they've been really looking\n47.48s: at the impact of uh educ\n51.52s: Educators perception on climate change\n53.8s: and how we can have more of an impact in\n55.359s: terms of providing climate data\n57.559s: information to a boad r job stakeholders\n60.12s: especially on the education very much\n61.84s: looking forward to your thank you so\n63.92s: much I\n65.72s: see I'm going to turn\n76.84s: around you all hear me okay great uh\n80.96s: well okay good afternoon everyone and\n82.439s: thank you so much for having us like\n84.119s: Pier said uh this is research that's\n86.079s: being done in Te college but we're\n88.28s: probably partnering with Le think about\n90.36s: these bigger questions of diversity in\n92.84s: climate movement and what does that mean\n95.2s: specifically for our knowledge\n96.64s: transformation here at Le you'll notice\n99.2s: our Title Here is a little bit different\n100.84s: than the one that you saw adverti Tik\n103.0s: Tock cheese sticks in our future how\n105.399s: educators perceive students engagement\n107.52s: with climate change we're more than\n109.439s: happy to talk more about the beginning\n111.56s: of that title in uh Q&A and uh we had a\n115.28s: great Fortune to talk with teachers and\n117.52s: ask them to use metaphors in focus\n119.479s: groups to explain how they perceive\n121.719s: their students engagement with climate\n123.24s: change and they used a lot of really uh\n125.479s: great metaphors to explain that\n127.2s: engagement uh we're also proud to see\n129.44s: that this work is uh has been accepted\n132.04s: at a and CIS so a is the American\n136.239s: educational Research Foundation annual\n138.4s: conference and C is the comparative\n141.12s: International Education societies annual\n145.68s: confence so the our foundational\n148.239s: motivation for this work has the global\n150.92s: climate movement which you all are\n152.44s: probably already aware of uh the\n154.72s: Resurgence stared with thumber work\n157.36s: protesting every Friday on the steps of\n159.319s: Swedish Parliament not going to school\n161.519s: to urge governments and adults to do\n163.599s: work uh related to climate action this\n166.72s: uh sprung in entire organization called\n169.44s: Friday for future where kids all over\n171.76s: the world do not go to school every\n173.64s: single Friday to protest for climate\n176.12s: change this came to a huge surgent back\n179.48s: in 2019 you can see that huge\n182.04s: participation uh Spike uh where over 1\n185.319s: million people globally uh specifically\n187.72s: youth March in the climate we did see a\n190.2s: sharp decline due to the pandemic but\n192.48s: we're now seeing a Resurgence of kids\n195.4s: marching in the streets um and over the\n199.28s: years since the climate movement has\n201.319s: been going on what has come into\n202.959s: question is the diver of this movement\n206.2s: uh it is largely while it is largely\n208.519s: being flooded is also largely fight uh\n211.799s: and while age and gender of the youth\n214.92s: climate movement has been studied a lot\n216.799s: in literature the race and ethnic\n219.239s: demographics of this movement has not\n222.56s: for this work we're specifically\n224.08s: focusing on New York City as a case why\n226.599s: New York City is special it has the\n228.72s: largest public school district in the\n231.56s: country um and we also have\n234.0s: institutionalized sustainability\n235.64s: education it has to do with a\n237.12s: Chancellor's regulation a85 Zer um and\n241.4s: we're specifically part of that\n243.159s: legislation zeroing in on one part of it\n245.599s: called the sustainability coordinator\n247.68s: mandate so every school in the New York\n250.519s: City public school system has a person\n253.36s: called a sustainability coordinator that\n255.439s: coordinator doesn't need to be a teacher\n257.84s: uh they can be an assistant principal\n259.84s: they can be support staff but their goal\n262.479s: is to create these Partnerships and\n264.44s: resources related to sustainability for\n266.68s: students and\n268.6s: staff a lot of what we know related to\n272.32s: uh race and ethnicity and engagement and\n274.16s: climate comes from these large public\n276.44s: opinion surveys that are done you might\n278.199s: be familiar with the Yale public opinion\n280.8s: maps that are quite famous that people\n282.639s: use what we're showing right here is a\n284.72s: figure uh from the Yale CL uh public\n287.919s: opinion maps and what we know is that\n292.08s: we're looking at the two middle roads\n294.44s: here for Black and Hispanic of concern\n298.12s: for climate change we know Bop\n300.32s: individuals tend to be more concerned\n302.919s: about climate change than white\n304.4s: individuals they also from our other\n307.24s: work in public opinion not shown here\n309.44s: that we do with the center for\n310.52s: sustainable Futures know that they also\n312.8s: tend to uh Advocate more for climate\n315.32s: change\n316.28s: education but even though they're\n318.319s: advocating for education and have this\n320.199s: concern there's a gap between the\n322.319s: diversity that we see in these spaces\n325.6s: and then who's actually marching in the\n327.319s: streets for climate change what you're\n329.28s: see on the left here is the ethnic\n332.08s: makeup of New York City public schools\n334.319s: in the middle you're seeing the makeup\n336.24s: of our own research who showing up to\n338.68s: the global climate protest in 2021 and\n341.919s: 2022 and you can see if we're looking at\n344.24s: the gray bar in the middle for latinx\n346.24s: individuals 41% of near City public\n349.68s: school students are latinx but in 2021\n352.8s: only 10% of the people who came to the\n355.4s: climate March were latx so we're seeing\n358.56s: this disconnect between worry and\n361.24s: concern for the movement motivation for\n363.56s: the movement but then who's actually\n365.479s: showing up to do the action uh which was\n369.039s: the our thinking around our initial\n371.16s: framework for approaching This research\n373.4s: project the reason we're focusing on the\n376.8s: educator here and specifically the\n378.759s: sustainability coordinator is that\n381.039s: educators are the social agents that\n383.68s: interact with youth on a daily basis and\n386.96s: through interacting with youth they can\n388.96s: form differing opinions of their\n391.759s: engagement with climate change education\n394.12s: and with those differing opinions they\n396.36s: that might influence the learning\n398.08s: opportunities that they create for their\n400.12s: students and then finally that could\n402.8s: influence uh which students are\n405.0s: participating in climate action and\n406.8s: which students are\n408.44s: not the two research questions at the\n411.12s: center of this work is how do these\n412.88s: sustainability coordinators and New York\n414.84s: City Public Schools perceive their\n416.879s: students engagement with climate change\n419.16s: and to what extent do these perceptions\n421.479s: vary by the teachers individual\n424.039s: characteristics and the school level\n427.96s: demographics we are lucky enough to have\n430.199s: a research practice partnership with the\n432.4s: New York City Department of Education\n434.28s: specifically with the office of energy\n436.319s: and sustainability uh where we work with\n438.96s: them to create these annual surveys uh\n441.879s: to look at these questions with\n444.0s: sustainability coordinators this is a\n446.28s: sequential mix method study so we use\n449.72s: this survey data and then did\n451.28s: quantitative analysis on it and from our\n454.8s: understandings from that quantitative\n456.36s: work then did qualitative based uh\n459.4s: research to to try to understand better\n462.44s: and dig into the Quant\n466.0s: work uh from for these surveys that\n469.08s: we're working with uh we're working with\n471.199s: the sustainability survey from 2021 and\n474.24s: 2022 we're also looking at another piece\n477.44s: of administrative data from the\n479.599s: Department of Education which are the\n481.159s: school demographics and\n484.36s: characteristics for our qualitative\n486.599s: piece we did seven focus groups with 39\n489.319s: sustainability coordinators from\n491.199s: November 2022 to February 2023 and in\n494.919s: these we proved further about how they\n497.44s: engage their students with climate\n499.0s: change how they perceive their students\n501.4s: interest in climate change uh and we\n503.72s: also asked them to interpretate to\n506.44s: interpret our quantitative results we\n508.879s: put shared our zoom and we shared what\n511.759s: Noah was going to explain the different\n513.68s: results that we found in our\n514.959s: quantitative work and asked them if our\n517.399s: patterns made\n519.68s: sense for our analytical strategy we\n523.08s: dids or ordinary Le squares and logistic\n525.88s: regression models we controlled for the\n528.88s: co coordinator socio demographics their\n531.399s: role in the school motivation years of\n534.0s: experience and the actual size of the\n535.72s: school so we can really understand what\n538.36s: we think of key predictors which is\n540.36s: climate concern the grade level of the\n542.76s: students the burrow that they're\n544.68s: situated in we from our previous\n546.76s: research really different engagement in\n549.32s: the movement with Staten Island versus\n551.32s: Manhattan and the differents of New York\n553.04s: City and then the socio demographic\n555.399s: composition of the body of the student\n557.2s: body and then for our qualitative\n559.519s: analysis with the transcripts of what we\n561.48s: learn from the teachers in the focus\n562.8s: groups we did thematic\n567.959s: analysis okay okay um so this is we're\n572.279s: getting into the findings portion of the\n575.6s: presentation\n577.24s: um let me just Orient you here on what\n579.72s: we see so we said the coordinators go\n582.32s: through these surveys t a year this is\n585.279s: showing results of responses by almost,\n588.64s: 1400 coordinators um on the survey the\n592.48s: question that we asked was\n595.399s: um what they think sorry how many\n598.279s: students in your school have the\n599.48s: following Char characteristics we were\n601.279s: asking about these different domains of\n604.399s: Engagement so at the top you see um\n607.24s: about students curiosity about climate\n609.88s: change and we go in this like scale all\n612.68s: the way up to engage with people who\n615.399s: were already engaged with climate action\n618.0s: and activism and the percentage um\n622.2s: represents the share of Ed of\n625.92s: coordinators who responded for example\n629.12s: 6% said that many of their students um\n633.68s: are curious or want to Le about so um\n639.079s: two things to no just on this we see\n642.16s: certainly that there is Big sh change of\n645.6s: a trend from the let's say lower levels\n648.8s: of Engagement curiosity and knowledge\n652.079s: going up to climate action right so 36\n655.279s: and 6% let's say 42 are so that many\n659.04s: many or all of their students have the\n661.92s: Curiosity to learn about C change and\n664.2s: then when you go up the scale of\n665.959s: engagements um the numbers\n669.76s: become smaller and\n675.24s: smaller dates R this is 1,400 Educators\n680.88s: coordinators from all grade levels all\n683.0s: BOS this doesn't show us\n686.44s: any sorry yes\n692.079s: um and then as Christina mentioned he\n694.519s: showed this the results to our teacher\n698.56s: talked with um 39 sustainability\n702.2s: coordinators and asked them to make\n704.68s: sense of\n706.279s: those results for and generally speaking\n711.279s: they Echo the analysis they said yes\n714.24s: there is some awareness but the\n716.72s: engagement is really not that high or\n719.76s: large when it comes to being already\n722.0s: active in the movement um the\n724.72s: overarching reason for that that they\n727.12s: gave of this life of Interest was that\n728.639s: the youth didn't have any close contact\n732.519s: with uh climate change or its effects so\n735.959s: this is why there less understanding of\n738.56s: it or maybe just less interested in\n741.16s: understanding it you can see a little\n742.279s: bit of um some quotes and some ideas\n745.12s: from those um focus groups you know\n749.199s: certainly many teachers spoke of the um\n753.04s: stress that they have to face with\n755.279s: standardized testing and the focus that\n757.36s: they have to spend in class you know how\n759.839s: do we how educators and students have\n763.36s: any space\n764.92s: time to talk about Lang um time too big\n769.199s: too complicated so those are some\n771.68s: examples of the rationalization\n775.04s: explanation that we got on on those\n777.839s: results then what we did is um we looked\n782.279s: at the\n783.639s: correlation between the what\n785.72s: coordinators think so the perceptions of\n788.12s: again this is all we're not really\n790.12s: talking about the students engag but\n792.04s: about Educators perceptions of the\n794.88s: engagments and how that correlates with\n797.36s: the type of students that the schools\n799.72s: serve so X AIS shows the um the share of\n805.48s: students living in poverty so the left\n808.12s: side\n809.399s: means more\n810.72s: ACS um y AIS shows us the percentage of\n816.04s: uh responses\n817.6s: so the the 60% at the top is the 60% of\n821.8s: those teachers said that their students\n823.24s: are engaged okay many or\n826.56s: all and we have all the domains of\n829.8s: Engagement that we showed in the\n831.04s: previous\n832.12s: slide for each of those lines and we see\n835.6s: we saw that for all domains of\n837.839s: Engagement even though\n839.32s: a little bit different in the slope\n841.92s: there is a negative Trend so the more um\n846.56s: when coordinators work in schools that\n849.16s: serve more marginalized students by side\n852.32s: the coordinators tend to view the\n853.959s: students as less engaged across all\n857.92s: domains that's the main idea behind this\n861.759s: this gra\n862.88s: here and then then we took that and we\n865.48s: also showed this to the educators suain\n869.8s: coordinators ask to expl explain that\n872.399s: for us\n874.0s: and again here generally most\n876.88s: participants rationalized the pattern\n879.8s: saying that for their students the\n883.32s: hierarchy of needs or where the students\n885.56s: meet the idea of change it's just not\n888.36s: you know many students uh live in\n890.959s: temporary housings many students have\n893.12s: other concerns such as food insecurity\n896.279s: and this um uh\n899.24s: the concern or or definitely engagement\n901.6s: with activism with climate change just\n903.6s: goes down to this um some other\n906.32s: explanations were around opportunities\n909.279s: so less exposure to to travel and to see\n912.56s: other places and the effects of climate\n914.24s: change or just the um less possibility\n919.519s: to spend the money on sustainable\n923.68s: practices less less accessible less\n925.92s: available for those students small\n929.279s: minority of of the participants did\n931.72s: mention B and I I want to just read out\n934.88s: um some of these quotes someone said\n937.319s: it's important to name institutional\n938.839s: racism and our biases about what people\n941.16s: care don't care about we can't assume\n944.04s: these assumptions this is about our\n945.88s: perceptions regarding low in kids not\n948.079s: about their actual engagement clents\n951.0s: cents live hands to mouth does not does\n953.0s: that mean that they don't care or think\n954.839s: about the stuff there could be an\n956.639s: interest if they were presented with\n958.72s: maybe we don't\n960.759s: ask\n965.12s: um some additional findings outside of\n968.68s: those main concerns that we uh looked at\n971.92s: respondents who are more concerned about\n974.759s: this from the qu Parts respondents who\n977.319s: are more concerned about climate change\n979.399s: also perceive more of their students the\n982.16s: topic uh respondents working in Middle\n984.56s: Schools or high schools perceive more\n986.319s: students to be engaged with climate\n987.839s: change answers the question about the\n990.24s: age\n991.079s: groups and compared to their\n993.04s: counterparts in manhatton the most\n994.72s: affluent and probably the most\n996.16s: Progressive City respondents from Queens\n998.56s: and Island receive fewer students to be\n1001.04s: engaged\n1004.959s: with so of course if we see um Educators\n1010.36s: as socialization agents and we know that\n1013.279s: these patterns could inform the way they\n1015.12s: teach and what they bring into the\n1016.279s: classrooms we might see that schools\n1019.16s: with higher concentrations of or\n1021.399s: students will have fewer teaching\n1024.12s: opportunities on the topic and what we\n1026.679s: are trying to do at the center for\n1029.039s: suable futures um we try to think of\n1032.0s: ways to translate those findings into\n1034.24s: interventions so the two things that I'd\n1036.4s: like to mention here today one um um\n1040.559s: targets the youth and the other one\n1042.439s: targets the the Educators Youth of the\n1044.919s: center is a initiative that tries to to\n1048.64s: bridge use interest in climate with the\n1051.36s: resources that we have here at do um our\n1054.96s: current project is our workshops\n1057.48s: storytelling workshops where students\n1059.76s: kids around the city write their climate\n1062.2s: stories and we upload them to a very\n1065.559s: repository um our current project with\n1069.6s: them and then the summer Institute that\n1071.799s: was of course hosted here the summer and\n1074.44s: is a part of a fiveyear\n1077.2s: grant that that uh aims\n1080.12s: to teach and train uh New York City\n1084.0s: public school teachers on climate change\n1087.679s: education um next five year plan will\n1091.08s: the first year this summer for\n1094.559s: more and I guess um we're gonna end with\n1098.12s: these remaining questions and of course\n1099.6s: we're happy to take any questions\n1102.76s: um we'd love to hear what is what do you\n1105.88s: think is are the implications of this\n1107.88s: word for our knowledge transformation\n1110.0s: year um at least how can we better\n1112.559s: engage formal C 12 education with our\n1115.08s: climate data science\n1116.559s: research and more specifically the same\n1119.0s: question but of course through the lens\n1121.08s: of equity and inclusion which we see is\n1125.4s: just very\n1127.559s: evident our results so thank you very\n1137.32s: much here I can put him up with you\n1167.24s: guys\n1169.88s: this about resour right so school have\n1173.0s: few resources also can provide you\n1177.159s: knows IDE just opportun\n1191.76s: Imago so I don't know is there are\n1195.0s: opportun here to not just like activi\n1206.24s: climate change\n1210.159s: education\n1212.159s: have something that you\n1219.559s: are you have anything to say not I'll\n1221.76s: jump\n1223.4s: in so the uh the off energy\n1227.159s: sustainability thinking a lot about this\n1229.919s: um there's actually a a sustainability\n1232.32s: grant that teachers could apply for um\n1234.96s: something that we didn't talk about in\n1236.64s: these uh in this presentation that now\n1239.24s: the mayor there are four Mand climate\n1241.4s: action days that every year\n1244.64s: school each day has a different climate\n1247.84s: change problem is is that the\n1250.96s: sustainability coordinators and the\n1253.08s: schools that tend to have you know the\n1255.84s: resources and support have the progam\n1259.6s: related\n1267.159s: toate so say it's definitely a dream and\n1270.159s: I think that's a dream of the summer\n1271.799s: Institute right how do we take these 40\n1274.24s: teachers that we uh talked to last\n1276.6s: summer and how do we turn that to 200\n1279.279s: how do we not just get teachers in a\n1280.799s: room how do we get administrators in a\n1282.88s: room right something that we literally\n1284.6s: talked to our teachers last night and\n1286.6s: we're hearing we got to school it's\n1289.279s: September we have all of these amazing\n1291.159s: resources from the summer Institute new\n1293.559s: mandated curriculum you can't teach\n1295.679s: anything that's not in the workbook we\n1297.76s: have an administrator that doesn't even\n1299.32s: believe in climate change what do I do\n1302.44s: um so I think there are a lot of uphill\n1305.08s: battles in a school that are tied to\n1307.24s: funding but some aren't even related to\n1309.08s: funding it's a huge multivariant problem\n1311.76s: but we hope through the summer Institute\n1313.44s: through youth at the center that we\n1315.2s: actually hit all of these touch points\n1317.24s: especially in the schools that don't get\n1319.24s: the Le that\n1320.64s: they I'll add that so the policy aspect\n1324.52s: is of course a big part of the night and\n1326.64s: while we have a lot to say about\n1328.84s: standardized and mandated curriculum the\n1332.32s: city is you know sooner rather than\n1335.2s: later probably is going to adopt a\n1337.96s: climate change curriculum that will be\n1339.76s: mandated happen in other states and what\n1341.559s: happen here D probably pretty soon so\n1345.84s: that will you that will bring change\n1349.36s: school all\n1350.96s: schol different\n1355.279s: problems for the whole question the full\n1358.48s: question was about resources and if we\n1360.159s: see those disparities um resources at\n1364.12s: home of course we also see it as in\n1366.279s: schools and what kind of interventions\n1368.44s: or and yeah and just like you know the\n1371.32s: office of sust stainability like these\n1372.88s: climate action days exist there are\n1374.48s: these things that exist but it isn't\n1376.08s: necessarily fixing the inequality\n1388.72s: I thank you for the talk um that was\n1390.24s: really interesting I'm curious if uh you\n1392.559s: found other partners in informal\n1395.039s: education in museums or NOS or other\n1397.96s: organizations that are additionally\n1399.48s: providing resources and education to\n1401.36s: young people or are you finding that the\n1403.76s: primary mechanism that young people hear\n1405.76s: about and learn about climate change is\n1407.64s: School\n1410.039s: there are hundreds of organizations um\n1412.679s: working in the New York City area I\n1415.32s: would\n1416.88s: say there is access to organ outs\n1422.039s: School between schools and those\n1424.039s: organization so they bring a lot of the\n1426.08s: funding and the resources not just money\n1430.32s: it's workshops and you know the garden\n1434.72s: that someone needs to attend which is a\n1437.48s: big thing\n1438.44s: school um School organizations come into\n1441.52s: the schools and and this that\n1443.919s: way it get um exposed those too I think\n1450.08s: manys spend so many hours a day SCH yeah\n1454.72s: and I would just highlight that you know\n1457.2s: um with our leap summer Institute that\n1460.159s: we had this past summer we partnered\n1462.36s: with subject to climate uh which is a\n1465.84s: open source uh curriculum materials\n1469.24s: website um where uh teachers can go on\n1472.24s: and find standard align materials K\n1475.0s: through 12 what's really cool about\n1477.039s: their website um that is a a similar\n1480.08s: principle that we took in our summer\n1481.279s: Institute is that it's trans\n1482.64s: disciplinary let's say you are fourth\n1484.96s: grade teacher and you want and you're\n1486.84s: trying to hit an English Standard and\n1489.279s: you want to teach something related to\n1490.6s: climate change you could find something\n1492.799s: um so we worked with them and we're um\n1495.84s: these are teachers from the summer are\n1498.6s: writing their lessons based on the\n1500.52s: subject to climate template so there are\n1502.64s: like curricular resources for teachers\n1505.64s: uh there are also things that are more\n1507.36s: student facing um I would say definitely\n1511.08s: challenges are that Trend sary aspect is\n1514.84s: you'll find a lot for science uh you'll\n1517.44s: find a lot for high school science uh\n1519.72s: there's a reason this summer we started\n1521.44s: with Elementary School teachers uh it's\n1523.799s: the where the largest need is um and Al\n1528.08s: for not just the curricular needs but\n1530.039s: these programming like again the the\n1532.279s: schools that tend to have the most\n1533.84s: resources are the ones that get to go to\n1536.6s: A&H and see the climate wall right\n1538.96s: they're they're the ones who get to go\n1540.44s: hang out with billian oyster project and\n1542.84s: you know go to the F so um there's\n1546.0s: definitely disparities there the with\n1548.0s: the actual like Museum institutions\n1556.679s: that\n1558.799s: Molly is it possible for me to say\n1562.96s: something can everybody hear me\n1565.72s: or um okay hi everybody um thank you so\n1570.6s: much for attending uh the question about\n1572.64s: the NGS and the community based\n1574.76s: organizations is a really good one\n1577.279s: because we've been uh identifying that\n1579.559s: that sector is really underst studied we\n1582.279s: got a grant last year and we are mapping\n1584.6s: now all the Nos and cbos that are provid\n1587.679s: F in climate change education\n1589.799s: worldwide we identified already around\n1592.2s: 4,000 of them we send them a survey we\n1595.039s: are mapping their needs and seems to be\n1597.159s: that they have even greater needs than\n1599.0s: the teachers in New York City uh\n1601.279s: especially around access to knowledge\n1604.08s: around climate and how to visualize it\n1606.279s: how to present it and we hope that that\n1608.64s: will be another piece of our uh\n1610.52s: partnership with leap moving forward how\n1612.559s: to address their needs because many\n1614.72s: education systems are relying on this\n1617.279s: sector to actually do the work so the\n1620.72s: the the question is great and we are on\n1622.559s: it um I hope that we'll be able to share\n1625.0s: some findings next\n1646.52s: year"
    },
    {
        "class": "YouTubeVideo",
        "title": "LEAP ML Journal Club: Sara Shamekh &amp; Kara Lamb",
        "videoId": "AxKEmE5wXZo",
        "url": "https://www.youtube.com/watch?v=AxKEmE5wXZo",
        "publishedAt": "2023-02-02T15:47:54Z",
        "transcript": "3.84s: okay it's a presenter mode or okay\n9.36s: so I'm going to talk a little bit about\n10.86s: uh the motivation then I'm gonna go\n12.78s: through neural network and data and then\n14.4s: at the end I'm gonna uh present the\n16.32s: results on parameterizing precipitation\n19.98s: so here the plot that I'm showing uh\n22.5s: Compares\n24.08s: yeah Compares uh precipitation from\n27.539s: observation that's this solid line with\n31.14s: uh one climate model that's this dashed\n33.78s: line and we have frequency of occurrence\n36.3s: on the y-axis and the brain rate on the\n40.32s: x-axis so what we observe here is that\n43.079s: the dashed line like the the model\n46.2s: precipitation\n48.42s: um\n49.379s: tend to wear drizzle so it's in the\n51.96s: model predict a large amount of small\n54.78s: rain and then underestimate the strong\n57.239s: rain so to give a more accurate number\n59.34s: number of the rain event less than 1.5\n61.8s: millimeter per hour or as much as like\n63.84s: five times more frequent and then\n66.0s: precipitations larger than uh two\n68.7s: millimeter per hour is underestimated uh\n71.82s: by as much as an order of magnitude now\n74.58s: these numbers are specific to this model\n76.439s: but this issue exists in many other uh\n79.5s: climate models\n83.04s: okay so then uh climate models they\n85.799s: Reign usually they rain too often and\n87.78s: too little and they have a bias toward\n89.759s: uh light rain and they have a very\n93.119s: smaller variance compared to what we\n94.92s: observe in uh in real world so it's\n97.74s: somehow like it's very deterministic and\n99.84s: then the new and the more recent\n101.7s: approach is to add some stochasticity in\n104.7s: order to increase the variance in uh in\n107.34s: predicted precipitation\n109.46s: now all these problems\n112.2s: um can be rooted in the Vader\n114.6s: precipitation is modeled so we know that\n117.78s: in climate models\n120.18s: we do not resolve any scale smaller than\n123.0s: the grid size of the model or the timing\n125.34s: step of the of the model so that's like\n127.619s: 100 kilometer or 15 minutes for GCM and\n131.34s: then the model has to rely on\n132.599s: parameterization for the processes that\n134.7s: are not resolved\n137.16s: and then\n138.42s: um the parametization then we can Define\n139.92s: it as a representation of physical\n141.54s: processes that are not resolved by the\n143.52s: model and the assumption is that these\n145.68s: unresolved processes can be approximated\n147.84s: using the result variables\n151.26s: so what I'm showing here is two examples\n153.3s: for the parameterization of\n154.86s: precipitation on let on on the left so\n157.56s: this is from Benson Miller one of the\n159.3s: first commercialization of precipitation\n161.04s: that they model P precipitation as a\n164.04s: function of w so w is the total amount\n167.4s: of moisture in a column of the\n169.2s: atmosphere so they predicted as a linear\n171.66s: function of uh W and then WC which\n174.959s: itself is a critical value of w\n176.879s: depending only on temperature so they\n179.58s: assume that if the uh if the column of\n181.739s: atmosphere get moisture than a threshold\n183.84s: that moisture is going to collapse to uh\n186.66s: to form rain\n188.099s: and his age is simply\n190.26s: um a heavy side function and then the\n193.14s: one on the right is a more popular one\n196.14s: um that predicts a cloud condensate so\n199.14s: that each grid size the model has a\n201.599s: prognostic equation for total specific\n204.54s: humidity that's my QT here and then the\n207.48s: model also implements a prognostic or\n209.64s: sometimes the diagnostic equation for a\n211.56s: standard deviation of that specific\n213.18s: humidity and then it's assign a PDF so\n216.3s: that could be like a gaussian or\n217.68s: sometimes a beta distribution\n220.62s: um to specific humidity and part of this\n223.14s: distribution that has a value larger\n225.18s: than the saturated specific humidity is\n228.06s: assumed to go into uh condensate and\n230.76s: form clouds\n232.68s: now this parametrization they do not\n234.84s: represent any information about\n236.94s: sub-related scale structure so it\n238.799s: doesn't matter like if I have uh clouds\n241.26s: that are staying very close or if I have\n243.18s: a very randomly distributed uh cloud and\n246.299s: structured\n247.86s: why from observation we see that cloud\n249.84s: can get many different forms some of\n252.36s: them they haven't happened to they\n254.22s: adhere very frequent that they have been\n256.019s: given a specific name so like flower\n258.06s: fish so these are the cases from uh for\n261.419s: shallow clouds but we also know that we\n263.52s: can have different degrees of\n265.199s: organization or many different Cloud\n268.44s: structure for deep convection and that\n271.139s: is way more important for precipitation\n272.94s: because uh another part of precipitation\n276.18s: comes from Deep convective\n278.28s: transportation\n279.9s: now my GCM does not represent this\n282.12s: upgrade scaled structure because it\n283.919s: takes only the mean value to predict or\n286.199s: to approximate the unresolved unresolved\n289.62s: processes right from\n292.199s: um Cloud resolving simulation we know\n294.78s: that this structure is important so from\n297.72s: cloud resolving simulation we know that\n299.58s: convection can be randomly distributed\n301.68s: as the one on the top so these are the\n304.08s: same 3D outputs of through simulation\n306.479s: the gray color shows the clouds and then\n309.54s: the color on the like the shading on the\n311.94s: surface shows the near surface\n313.68s: temperature\n315.3s: so the one on the top is randomly\n317.46s: distributed in convection that's one of\n319.919s: the situation in uh idealized simulation\n322.62s: but convection can also can clamp\n325.44s: together and form this very strong\n327.66s: structure that is very moist and\n330.06s: precipitation is happening now only in\n331.979s: this small region and the rest of the\n333.66s: domain is very dry and this can have a\n336.18s: large impact on the atmospheric profile\n338.52s: uh for example relative humidity I'm\n340.8s: showing here these are average over\n342.66s: these two domains\n344.58s: we see that the case that is very\n346.5s: organized has a very smaller average\n349.639s: relative humidity compared to the very\n352.139s: random case so based on our bed some\n354.78s: other prediction then the one on the top\n357.0s: has to have a larger precipitation and\n358.979s: the one on the bottom is probably not\n360.6s: precipitating at all based on their uh\n363.0s: based on their threshold based on their\n364.919s: simple model but we know that it's the\n367.32s: opposite the one on the bottom has a\n369.12s: larger amount of precipitation\n371.16s: so we know that um organization is\n374.16s: important for precipitation uh one in\n377.1s: one because uh at one point because uh\n379.259s: it changes the rain evaporation so now\n382.02s: in the case on the bottom precipitation\n384.36s: is happening only in this moist region\n386.34s: that means that when it's precipitation\n388.319s: travels through a form of atmosphere it\n390.539s: evaporates less because\n392.759s: um\n393.6s: um because the atmosphere is more humid\n395.58s: and that increases the precipitation\n397.319s: efficiency\n398.819s: and that means that the rain rate at the\n400.68s: surface is larger becomes larger when we\n402.9s: have organization we can we could also\n405.419s: have inner Cloud interaction so that's\n407.88s: uh uh caused by Focus when we have two\n410.639s: clouds uh the downdraft that reaches the\n413.34s: Surface starts propagating out and then\n415.86s: if they\n417.36s: um Collide and they're going to trigger\n419.46s: deep convection and it has been shown\n421.139s: that deep convection that form because\n422.819s: of uh corporate interaction is more\n425.94s: likely to develop to extreme\n428.34s: precipitation and then we also know that\n430.38s: this structure can survive over time and\n432.6s: that means that the accumulated\n433.919s: precipitation is larger when we have uh\n436.68s: organization\n438.6s: now if we are a GCM we are somewhere\n441.9s: between these two cases\n444.18s: um like organization can have any degree\n447.12s: from strongly organized very randomly\n450.18s: distributed why the parametrization of\n453.06s: uh convection they usually assume an\n455.94s: ensemble of randomly distributed\n457.919s: convections so they do not include any\n459.96s: interaction between clouds we also know\n462.84s: that organization can matter for\n464.94s: outgoing long wave radiation because if\n467.22s: we get organization the atmosphere is\n469.38s: overly drier and that lets more um\n472.199s: outgoing long wave radiation and that\n474.539s: can affect climate sensitivity\n477.72s: but in our GCM we didn't have any\n480.12s: interaction or any degree of\n481.8s: organization and we also saw that we\n484.38s: have some shortcomings\n486.599s: um shortcomings and prediction\n487.68s: precipitation so what we want to know\n489.84s: here is uh uh to like to investigate if\n493.86s: you need to input some information about\n495.599s: subgraded scaled structure in\n497.28s: parameterizing precipitation and if\n499.44s: maybe that is the information that is\n501.72s: missing in our parametrization\n504.539s: so before getting to uh the methodology\n506.819s: I want to also share this plots from\n508.62s: needine that they look at precipitation\n510.24s: from observation so what they do they\n512.64s: condition precipitation on Autumn water\n515.459s: vapor and future with spray temperature\n517.08s: so they basically they've been the\n518.94s: economy water vapor and the average\n520.38s: precipitation over beans and they show\n522.899s: that\n523.979s: um meat precipitation has a simple power\n526.64s: dependency on water vapor and it\n529.44s: increases it as a threshold it increases\n532.2s: rapidly\n533.7s: so now we want to use this as a\n535.5s: benchmark to evaluate our prediction of\n538.2s: precipitation but before that I wanted\n540.36s: to see if the data that I'm using can\n542.399s: reproduce this critical Behavior\n545.399s: um so this dashed line is then supposed\n548.04s: to have similar Behavior as the one on\n550.92s: the left it sort of sort of has has the\n553.26s: same tendency so we have this strong\n555.24s: increase although the data is pretty\n557.339s: much different so this and Diamond data\n559.62s: that I'm going to talk about in a if you\n562.019s: slide it uh simulates only 40 days so it\n566.279s: has a very short period while the one on\n568.98s: the left is data from 18 18 years so the\n572.7s: uh the feature space on the left is very\n574.8s: larger\n577.5s: um so beside this critical Behavior we\n579.6s: also see like kind of strong spread in\n581.64s: precipitation for a given column water\n583.68s: vapor and Peter perspective temperature\n585.2s: precipitation can be everywhere like any\n587.82s: verb so we want to also see if this\n590.519s: spread is only due to stochasticity or\n592.92s: if we can somehow inform our model and\n594.959s: predict our code of this spread\n598.56s: um any question\n602.76s: okay\n604.56s: so I'm gonna continue there\n607.44s: um\n608.519s: so then we have to your objective we\n610.26s: want to see how much we can predict\n612.48s: precipitation using only result variable\n614.76s: could be uh reproduce this overall\n617.22s: behavior of precipitation that we saw\n619.26s: the critical Behavior versus\n620.82s: precipitable water and then how much of\n623.64s: the spread that we see we can uh we can\n625.74s: predict then the second part we want to\n628.44s: see if including software scale\n630.06s: structure can improve the prediction\n632.899s: okay so the for the first uh question\n636.66s: I'm going to use a simple neural network\n638.459s: it's a fully connected feed forward\n640.2s: neural network that takes larger scale\n642.18s: variables as input and predict\n643.8s: precipitation and the loss function is a\n646.32s: mean square error I'm talking I'm going\n648.36s: to talk about larger scale variable in a\n651.24s: few slides but so here is my\n653.3s: parameterization again and now what I'm\n655.32s: going to do I'm going to replace this F\n657.06s: with my neural network\n658.92s: the data that I'm using or from Diamond\n661.079s: simulation so these are Global storm\n663.3s: resolving simulations that have been\n665.579s: drawn for like 40 days\n668.519s: and the resolution of the original data\n671.64s: is\n672.54s: um four kilometers and the time step of\n674.76s: the outputs the 2D outputs that we use\n677.16s: is 15 minutes\n678.54s: from this data I'm gonna ignore the\n680.64s: first 10 days as they're considered as\n682.74s: the spin up of the model and then I from\n684.779s: the 30 days that remains I'm going to\n686.64s: randomly select 10 days\n689.22s: and we're going to concentrate only on\n691.019s: the tropical ocean\n693.18s: and then to produce the data we're going\n695.22s: to just uh course the range to GCM size\n697.44s: grids and pass that as the input so the\n699.899s: size of my input now is only four\n701.88s: dimension I have\n703.44s: um column border Vapor that's my PW\n705.36s: surface temperature temperature and a\n707.82s: specific humidity at 2 meters so there's\n709.74s: two major variables I use them to inform\n711.959s: the model as a funding model about the\n714.54s: boundary layer structure\n718.5s: okay so the result for the Baseline if I\n721.74s: if I pass as input only column border\n724.2s: vapor and a specific Cube and surface\n726.18s: temperature this is my result so what\n728.279s: I'm showing is precipitation on y-axis\n730.92s: and uh specific sorry converter vapor in\n734.04s: x-axis so the dashed line is the uh\n737.399s: predict is the true value and the solid\n739.74s: line is the predicted one so I'm what\n741.899s: I'm doing I'm building again the cotton\n744.3s: water vapor and I'm\n746.22s: um showing the spread or the\n748.019s: precipitation average over that column\n750.42s: bottom that spin of column bottom and\n753.3s: then this shading is showing your spread\n755.1s: so we see that the model captures this\n757.079s: critical Behavior to some extent but it\n759.54s: doesn't capture the spread in the data\n761.64s: if I include two other variables as the\n764.339s: input the model better now predict the\n767.639s: uh\n768.36s: in a critical behavior and it also\n770.519s: captures a little bit of a spread but\n772.8s: its own square is still low so that\n774.779s: overall R square is about 1.45 and then\n778.8s: the R square computed for each bin of PW\n781.74s: is about\n783.6s: um is and the maximum is about 4.5\n787.2s: and if we look at the uh\n789.839s: if you look at the distribution the\n792.3s: probability distribution of these two\n794.459s: production so in the green as the one on\n796.98s: the left the oranges and the one on the\n798.72s: middle and then the blue is my 3D or you\n801.06s: see that the model overpredicts the uh\n804.06s: um\n805.079s: the precipitation with a small intensity\n807.66s: and then underestimate or does not\n809.94s: predict at all the extreme precipitation\n814.26s: okay so we know now the first uh on the\n816.839s: answer to first question we can\n818.279s: reproduce the critical behavior of this\n820.079s: mutation but we cannot uh predict the\n822.42s: spread in this mutation\n824.339s: so now we want to go to the second part\n826.38s: is there any question\n832.139s: yeah a question on how you're dealing\n833.94s: with time\n835.079s: um you may have explained this I just\n836.519s: missed it but each day the times that\n839.339s: you're working on is daily\n840.839s: that's 15 minutes timer 15 minutes okay\n844.079s: so then how are you incorporating the\n847.019s: like lag time or the history of known\n851.1s: not I haven't included anything about\n853.32s: history yet but I'm gonna get to that\n855.12s: that's the last one yeah thank you\n864.42s: okay so um then we want to include\n867.06s: information about some weird scaling\n869.399s: structure\n871.74s: um so to do that we have to quantify the\n874.26s: subcutaneous structure or organization\n876.42s: over the last couple of decades let's\n878.94s: say there has been more than like 50 25\n881.399s: metrics that has been developed to\n883.62s: measure the degree of organization that\n885.6s: they look at different aspects of\n887.82s: organization like some of them they look\n889.62s: at the statistical properties for\n891.42s: example the variance of precipitable\n892.98s: water or they might look at the um some\n896.04s: of the uh let's say cloud size or Cloud\n898.86s: distribution\n900.959s: oh they might look at the also the uh\n903.72s: the scale decomposition\n906.6s: so what we did we took these 25 metrics\n909.36s: and we applied them to our data and then\n911.639s: we make a Time series and then we\n913.32s: compute the correlation between these\n914.82s: time series so the idea was to somehow\n917.339s: find out which of these metrics you can\n919.62s: use to inform our neural network about\n922.199s: software escalated structure but the\n924.18s: pattern doesn't doesn't give like a\n927.0s: result or a hint of which of them we can\n929.579s: use it's pretty much a spread\n932.279s: but then there's also two other issue\n934.38s: issues with these two with these metrics\n936.54s: the one is that they're designed for\n938.339s: large domains so uh the domain like\n940.92s: launched them by large domain I mean a\n942.6s: domain of like 500 in 500 kilometers\n945.24s: Square so if I apply them to GCM size\n947.94s: domain they may not capture any relevant\n950.399s: information and then the second issue is\n952.86s: that they target the specific aspect of\n955.8s: um of organization right when I want to\n958.26s: predict precipitation we don't really\n959.579s: know which aspect of organization might\n961.74s: be important\n963.42s: so then to overcome this issue we\n966.12s: thought that we can implicitly learn\n967.74s: organization using another reporter so\n970.019s: another encoder is\n971.76s: um let's say an non-linear\n974.04s: dimensionality reduction technique that\n976.019s: has two networks an encoder that takes a\n978.6s: high resolution fields and Maps it to a\n980.94s: very low Dimension representation that\n983.339s: we call it latent representation and\n985.86s: then the decoder takes that low\n987.839s: representation and Maps it back to high\n990.42s: high dimension space\n993.54s: now we don't know what this all captures\n995.699s: this ZL sorry but we know that it has to\n999.36s: capture enough information that can be\n1001.279s: used to reconstruct the original field\n1003.139s: so what I'm doing here I'm passing high\n1005.6s: resolution column of water vapor as\n1007.88s: input and I compress it to a dimension\n1011.0s: of 2 power 2. so I'm going from 2 power\n1013.88s: 10 to 2 power 2 and I want to use this\n1016.04s: that L as uh\n1018.44s: um to inform my network about\n1019.88s: organization\n1021.62s: so here is then the structure of my new\n1025.1s: network what would be called organ n it\n1027.439s: has two blocks on the right I have my\n1029.419s: simple feed forward neural network that\n1031.1s: I had before it inputs our larger scale\n1034.1s: variables but I add also work that I\n1037.64s: extract from my own encoder so this org\n1041.0s: then goes as input to my\n1043.339s: um simple feed forward Network it gives\n1045.98s: some information about precipitation and\n1048.62s: then it gets it gets feedback from um\n1052.16s: um it gets feedback through bad\n1053.84s: propagation and and then goes back to\n1056.48s: encoder so that means that my work is\n1059.24s: forced now to get relevant information\n1061.7s: related to crispy tension\n1064.4s: and I trained these two blocks together\n1067.52s: um so the loss that I have now is the\n1069.679s: mean square error of this reconstruction\n1071.66s: that I have here the mean square error\n1074.059s: of precipitation and we add a third term\n1076.52s: that is the rotation invariant\n1078.919s: so basically if you know that if you\n1080.72s: have an organization metric it shouldn't\n1082.52s: be sensitive to the orientation of this\n1084.679s: image right so the in we add this\n1087.86s: constraint we rotate any input that we\n1090.38s: have randomly so it should be only 90\n1092.84s: degrees and then we pass both of them so\n1095.66s: that in the encoder and we force uh the\n1098.299s: org of those two to be closed\n1100.82s: so we add that to our um onto our loss\n1104.9s: function\n1107.78s: um so some results these are again from\n1109.7s: the Baseline\n1111.02s: and these are for my organ and and we\n1113.78s: see that now the model capture the right\n1115.94s: uh the right spread that we have in the\n1118.34s: data so if you look at this green line\n1121.22s: it's almost 0.8 for all bins of uh we\n1125.6s: will call them water vapor and then if\n1127.4s: you look at the probability distribution\n1129.26s: the model captures this tale of\n1131.24s: precipitation like precipitation extreme\n1133.1s: that was the challenge for our simple\n1135.679s: Baseline model\n1137.179s: then we can also look at the R square\n1139.64s: computed for time series of each grid so\n1142.52s: now for each latitude longitude I have\n1144.86s: several time and step and I compute R\n1147.14s: square for predicted entry precipitation\n1149.36s: and this is then the result we see that\n1152.059s: it does a good job almost everywhere\n1154.94s: over the operator tropic\n1159.32s: um and then this result is robust to the\n1161.84s: choice of uh resolution and then\n1165.62s: the dimension of work so we tried the\n1168.02s: dimension four and two and we see that\n1169.82s: it does a good job even with only two uh\n1173.0s: our variables\n1175.82s: any question\n1183.38s: okay\n1184.52s: um so now if we we know that if we have\n1187.1s: org we can improve the prediction of\n1189.2s: precipitation but we also know that in a\n1191.539s: GCM we don't have access to high\n1193.16s: resolution Fields so then how you can\n1195.5s: predict our work\n1198.559s: um one solution is that maybe we can\n1200.48s: predict all from result variables using\n1203.179s: a neural network\n1205.22s: so I take a neural network and I passed\n1208.58s: my uh predictors my larger scale\n1210.62s: variable as input and I try to predict\n1212.539s: my work so what I'm showing here in\n1215.059s: order by old T I mean the work that I\n1217.4s: extracted from uh encoder and or p is\n1221.059s: the one that I'm predicting using larger\n1222.799s: scale value\n1224.66s: um so what we see is that it's not that\n1226.46s: much predictable so except for or one\n1229.039s: that is that has an R square of 0.13 the\n1232.34s: rest of them has an R square of 0.1 one\n1234.799s: that is very small but this is not\n1236.84s: surprising because if we could learn or\n1239.6s: from larger scale variables we didn't\n1241.76s: need to go through encoder we could have\n1245.0s: a better prediction even from our\n1246.679s: Baseline model\n1249.98s: um but this is a bad news because that\n1251.78s: means that I cannot have access to my\n1254.419s: org but we can maybe improve that so\n1257.24s: what we do now we want to see if we can\n1259.82s: use the historical information from\n1262.22s: larger scale like let's say larger\n1264.559s: scales of previous timeline steps to\n1266.78s: predict all of this time that means that\n1269.84s: we are assuming that maybe part of this\n1272.419s: structure persists over time and has and\n1275.66s: has a signature on larger scale so that\n1278.96s: including larger scale of previous\n1280.76s: timers that maybe can improve its\n1282.74s: prediction\n1283.94s: so here I'm including a large scales\n1287.419s: from current time and for previous time\n1289.94s: steps like one hour of memory\n1292.28s: it does improve the the prediction but\n1294.98s: not that much like for um first org I\n1298.1s: have now or a square of\n1299.98s: 4.4 for the rest of them is R square of\n1302.9s: 2.2\n1306.44s: um one other thing that we can do is to\n1308.419s: include org history as well so we know\n1311.36s: that if we have any structure at this\n1313.52s: time it's not totally different from\n1315.74s: what I would have 15 minutes later or 15\n1318.14s: minutes before so that means that we can\n1320.6s: use work history as well\n1323.659s: um to um to predict work of current time\n1326.059s: and steps so that's what I'm gonna do\n1328.039s: now so now I'm including previous\n1330.62s: climate step of work and two of uh\n1333.62s: previous time this step of larger scale\n1335.6s: and that significantly increase the the\n1339.02s: prediction of my old variables so all of\n1341.48s: my R square now are larger than 0.95 so\n1345.74s: that means that my org is actually\n1347.299s: capturing some information about subgrid\n1349.58s: Escape structure that cannot be captured\n1352.1s: from larger scale but they persist over\n1354.679s: time so there is a correlation a\n1356.659s: temporal correlation between the work\n1358.7s: variables that I have\n1360.799s: so we did a little bit more of\n1363.02s: Investigation on the uh how many timer\n1365.48s: steps we need to include so this is like\n1367.88s: what I'm showing here is rsquare for\n1370.159s: different tests that we did so n of Ls\n1373.4s: means how many previous larger scale\n1375.799s: timers that I'm including and enough\n1377.659s: work means how many previous work kind\n1380.299s: of steps on farming's reading\n1383.78s: um so when I include work of\n1386.12s: um sorry previous time a step of work I\n1388.46s: always have a very uh very high R square\n1391.659s: but the very interesting case is uh the\n1395.12s: purple one that I include only one\n1397.28s: previous time step of work but no\n1399.98s: information from larger scale and we see\n1402.559s: that R square is larger than 0.95 that\n1406.1s: means that we can use a simple\n1407.62s: autoregressive model to predict org of\n1410.659s: time of world of time T based on August\n1413.14s: time T minus delta T\n1416.44s: Annette has a lot of advantages for\n1419.24s: implementing in GCM because then we we\n1421.64s: don't need to carry around a lot of uh a\n1424.52s: lot of data\n1428.419s: um any question\n1431.179s: I have a quick question and maybe you're\n1432.679s: going to get to this later but did you\n1434.24s: look at the latent space of org at all\n1436.58s: to see like what's being represented\n1438.34s: specifically yeah so that's the next\n1441.08s: part okay\n1443.299s: any other question\n1452.179s: okay so I'm gonna pass it to Kara for\n1454.88s: for the part on what work learns\n1457.82s: thanks so much\n1460.64s: I will hopefully do the same thing\n1464.96s: okay can you guys see that\n1468.5s: uh or do you see my yes okay and great\n1471.799s: title\n1472.82s: okay yes so this is that is uh the part\n1475.28s: I'm gonna talk about is what does orc\n1476.539s: mean\n1477.679s: um so the basic idea is that we're going\n1479.96s: to use\n1480.679s: you to train decoder to map out the\n1482.72s: latent representation\n1485.12s: um but we need to know kind of what to\n1487.1s: put in uh for like org to be able to do\n1490.34s: this so first we need to know how org is\n1492.74s: distributed across the the set of\n1494.72s: observations in the diamond simulations\n1496.7s: and so that's something that I'm going\n1498.559s: to get from the encoder and just like\n1500.48s: feeding it in like\n1502.28s: um the 10 days of simulations\n1504.799s: um to get these distributions of org one\n1507.38s: so I guess I'm just going to start with\n1509.179s: talking about\n1510.44s: um a latent space of just two uh for the\n1513.62s: org and then I'll get to the four\n1514.88s: dimensional case in the second\n1517.22s: so this is for this 2D latent space and\n1521.179s: so you can see that the distribution of\n1525.26s: um org one and org2 so this is the joint\n1527.9s: distribution and then on top you see the\n1529.76s: distribution for each of the parameters\n1532.7s: um so like they're pretty highly\n1534.44s: correlated with one another and they're\n1536.72s: also not particularly gaussian they have\n1539.24s: some pretty long tails\n1541.7s: um but um I can so in order to kind of\n1545.059s: take care of the fact that they are not\n1546.559s: gaussian I'm going to sample um deciles\n1549.62s: um from those distributions and then\n1552.86s: feed those values back into the decoder\n1555.08s: and so that gives us this kind of\n1556.58s: mapping across org one and org2\n1560.0s: um and so from this you can kind of see\n1562.159s: that probably up here things are more\n1564.32s: organized and like more aggregated and\n1567.26s: then down here things seem to be less\n1569.419s: aggregated and more uh just like random\n1572.12s: randomly distributed but it's sort of\n1574.4s: hard to interpret like what exactly is\n1576.14s: happening along the diagonal and like\n1578.539s: how exactly this is uh you know how\n1580.82s: exactly to interpret this\n1582.74s: so one thing that I've just tried\n1586.22s: actually is to apply a principal\n1589.46s: component analysis to org one and org2\n1592.34s: and then here I'm plotting the\n1595.22s: distributions of the first two principal\n1596.9s: components of the latent variables so\n1598.88s: now you can see um at least for org2\n1601.159s: it's much more gaussian org one still\n1603.08s: has like kind of a long tail\n1605.32s: but now if I basically oh and I could\n1608.72s: look at also the explained variance\n1610.159s: ratio so actually the majority of the\n1612.08s: variance is explained by like the org\n1614.84s: one what I'm calling org One Prime so\n1616.94s: that is the first principal component\n1618.559s: from the PCA analysis\n1620.539s: and I can do the same thing of mapping\n1623.72s: out the the deciles of the distributions\n1626.059s: now for org One Prime and org two Prime\n1628.22s: and so I think in this case it's much\n1630.559s: clearer to see that as you go uh towards\n1633.62s: the right for org One Prime it's much\n1635.6s: more aggregated and uh significantly\n1638.24s: less aggregated like on the other side\n1642.38s: um and then it's a little bit less clear\n1644.779s: exactly what order two prime is but as\n1647.539s: I've said it's like the majority of the\n1648.919s: variance is actually explained by Oregon\n1650.24s: Prime\n1651.5s: oh and then I should say for this I'm um\n1654.44s: scaling this relative so each box is or\n1657.74s: like each high resolution field is like\n1660.02s: scaled relative to the maximum value in\n1661.82s: the field\n1663.08s: um but I can also look at the absolute\n1665.24s: scaling\n1666.44s: um to like so now it's scaled relative\n1669.44s: to the maximum value in the data set so\n1671.72s: this suggests that it's not just\n1674.14s: learning something about the you know\n1677.0s: the column water vapor but it's actually\n1678.5s: something about organization\n1680.96s: um or the aggregation\n1683.48s: um the subgrid scale aggregation\n1686.0s: um so I'm now going to do the same thing\n1687.919s: for the four-dimensional case and again\n1689.9s: if you just take the values directly\n1692.24s: learned by the encoder they're actually\n1695.299s: again very highly correlated with one\n1697.159s: another\n1698.48s: um\n1699.32s: so again I do like a principal component\n1701.659s: analysis\n1703.159s: um and find again that the first\n1705.86s: principle component actually explains\n1707.659s: like the majority of the variants in our\n1710.419s: data set\n1712.1s: um and so again I'm going to do the same\n1714.2s: thing now for orc1 Prime and org two\n1716.419s: prime for the four dimensional case and\n1718.22s: you can see it like looks quite similar\n1720.38s: to what was learned for the\n1722.12s: two-dimensional case and like to\n1723.86s: convince you of that I'm going to put\n1725.48s: them I'm putting them side by side so\n1726.98s: this is what we learned\n1728.539s: um for the first two principal\n1729.799s: components for the four-dimensional\n1731.48s: latent space and then this is the same\n1733.279s: for the two-dimensional latent space so\n1735.5s: it seems so that you know it's not\n1736.88s: exactly the same if you look at the\n1738.98s: details but like the the main variants\n1742.64s: being explained by this like increasing\n1744.5s: aggregation\n1746.179s: um it seems to hold true for both cases\n1748.34s: and that that's the problem we're\n1749.72s: learning so you can also look at some of\n1751.82s: the other modes of variability that we\n1753.44s: learned for the other uh like org One\n1756.26s: Prime and org three or four Prime and\n1758.539s: org one but it's I think it's a little I\n1760.88s: I find these a little harder to\n1762.2s: interpret but at least we see some\n1764.24s: differences in like terms of like what\n1766.1s: the the fields look like\n1768.62s: um so yeah I guess maybe the conclusions\n1770.779s: I think from this are that the the\n1772.52s: greatest variability in the org\n1773.779s: parameter seems to be related to how\n1775.159s: aggregated that subgrid scale um PW\n1777.98s: field is and this is very consistent\n1779.84s: between\n1781.159s: um across different sizes of latent\n1783.08s: spaces\n1784.58s: um and this basically implies that we\n1786.44s: might only need just a single parameter\n1788.299s: to parametrize that subgrid scale\n1790.34s: organization because that's explaining\n1791.899s: the majority of the the variability\n1795.559s: um\n1796.34s: cool\n1798.02s: that's all I had did you have more Sarah\n1804.44s: yeah itself on my side as I say any\n1807.02s: question\n1810.74s: um can I ask a question\n1815.12s: sure\n1816.38s: um I'm curious if you looked at how the\n1819.14s: latent space like metric of organization\n1821.96s: correlates with other more\n1823.82s: well-established metrics of organization\n1827.12s: I started to do that but one of the\n1829.039s: challenges is that like as Sarah said\n1831.98s: there a lot of the organization\n1833.419s: parameters are actually designed for\n1835.159s: much larger\n1836.48s: Fields so they like don't\n1839.779s: uh give values that are very um like\n1843.559s: yeah they don't necessarily get values\n1845.48s: that are very um interesting but I think\n1847.399s: that is like something that could be\n1848.539s: explored in more detail\n1850.94s: um and like should probably be explored\n1852.919s: in more detail but\n1856.82s: I also did a test related to that so I\n1859.58s: replaced the work that we learned with\n1861.559s: uh simply the standard deviation of 2D\n1863.899s: field and the result was that like it\n1866.659s: improves the prediction\n1868.76s: um let's say if my order Square without\n1870.26s: any work is 0.5 including standard\n1873.2s: deviation would increase at 2.6 but it\n1876.32s: wouldn't improve that much the\n1877.64s: prediction of extremes\n1893.84s: foreign\n1897.2s: I have a quick question um\n1903.44s: do you plan to or have you think of\n1905.779s: strategy about\n1908.24s: um how to incorporate this to the the\n1910.279s: current GPM parameterizations\n1918.32s: um\n1919.12s: yeah so one thing that is nice is that\n1922.52s: we we find that we can use an auto\n1924.98s: regressive model to project a work so\n1927.919s: that means that it's it's not that it's\n1929.899s: not that complicated to implement it in\n1932.0s: a GCM we only need to let's say sample\n1935.659s: from our latent space to have the first\n1938.24s: hold of like let's say first time next\n1940.159s: step and then we can go forward using\n1942.02s: our Auto regressive model to predict the\n1944.0s: future uh the future org but for\n1947.179s: implementing in a GCM we need to train\n1950.48s: probably our Network on the whole group\n1952.58s: so for the moment it's only tropical\n1954.559s: ocean we don't have land and we don't\n1956.36s: have the extra Tropics so probably that\n1959.539s: would be the the next step if you want\n1961.279s: to go forward with implementation\n1964.36s: thank you\n1972.919s: but if I may uh I think one thing I find\n1976.399s: really cool here is that it means that\n1978.62s: potentially you don't need a stochastic\n1980.48s: parametrization\n1983.12s: so that's a that's a huge thing I feel\n1985.159s: because I mean you never know how to\n1987.38s: actually parametrize them anyways you\n1989.539s: know it's very empirical so and you\n1992.0s: don't know how to add back that in space\n1993.38s: and time so I think it's very clear\n1995.779s: metric you know if that can be\n1998.24s: implemented of course you know but that\n2000.279s: that would be great in that case\n2005.2s: is that why you chose to use an\n2007.84s: autoencoder instead of a variational\n2009.72s: autoencoder to try to stay away from\n2011.86s: stochasticity\n2016.72s: um not really so I didn't want to use\n2018.94s: the variational order encoder because I\n2020.679s: didn't want to impose the distribution\n2022.48s: of the of the world variables\n2025.84s: yeah that was the main reason although\n2027.46s: we talked about trying trying if we can\n2029.799s: find out the uh\n2031.779s: if you can if you can uh if a\n2035.32s: variational audio encoder works as well\n2037.0s: but then it's interesting because if we\n2039.039s: don't impose\n2040.84s: um the rotation invariant the work\n2043.36s: variables are sort of like very\n2045.039s: independent\n2047.019s: so they are let's say I don't have this\n2049.419s: I don't have the uh the generative part\n2052.24s: of my uh variational encoder but I have\n2054.7s: the disentanglement between the equal\n2056.56s: variables\n2064.26s: sorry uh sorry\n2067.179s: um so Sandra there was also the the\n2069.82s: point that early on you know the target\n2072.28s: target was actually a probabilistic loss\n2075.04s: like a stochastic loss so targeting the\n2077.74s: mean of precipitation and the variance\n2079.54s: together because the Hope was to try and\n2082.839s: and learn the stochastic parametrization\n2085.0s: so as a mean and a variance let's say so\n2088.0s: you could think you're targeting not\n2089.56s: just the mean value with the neural net\n2091.599s: but you're targeting uh basically\n2093.28s: parameterized distribution\n2094.839s: but then in the end it seems that uh the\n2098.44s: organization it just happens to be that\n2099.94s: the organization explains all of the\n2101.56s: variants pretty much so there's really\n2102.88s: no need to that you know so in the end\n2104.92s: in fact in the revised paper like uh\n2107.859s: that got removed you know so now the\n2110.14s: target is just a regular mean square\n2111.579s: error so basically you don't need even\n2113.02s: like this all together which is kind of\n2115.48s: interesting\n2117.82s: so there was more complexity before and\n2120.04s: unless sometimes it's nice when you have\n2121.9s: less impact\n2126.64s: I was going to say also like just\n2129.94s: um I I found like that training of Vie\n2133.24s: is significantly more challenging than\n2135.7s: training an auto encoder\n2138.22s: um like because you have those two\n2140.8s: different loss terms that are trading\n2142.24s: trading off and there's like you know\n2143.68s: these different methods to deal with\n2145.66s: that like sort of cyclical annealing and\n2147.52s: things like that but I I personally\n2149.32s: haven't had like a lot of success with\n2151.06s: that for some of the problems that I've\n2152.56s: tried applying like via used to versus\n2154.359s: like Auto encoders but\n2183.28s: and the other question this is actually\n2186.04s: kind of uh\n2188.14s: so so there's a talk in the ai2es some\n2192.88s: of our Series yesterday about uh from\n2194.98s: day\n2197.14s: um on some of the rich y'all may be\n2199.72s: aware of uh on on some of the work he's\n2202.48s: doing with uh\n2205.06s: um kind of forward prediction of uh of\n2209.4s: what I guess the digital twin type\n2211.72s: models and one of the things he was\n2214.48s: discussing pretty heavily is this issue\n2216.22s: of spectral bias were the mob the model\n2218.92s: predicts the like the large\n2222.04s: I basically a storage wave number or\n2225.579s: sorry large scale modes but but\n2228.339s: puts too much energy in a small scale\n2230.26s: and thus the model blows up if you\n2232.42s: integrated forward\n2233.74s: the\n2235.359s: I'm wondering how much of a connection\n2236.8s: there is between some of the stuff he's\n2238.18s: seeing with that and his solution was to\n2240.339s: do a I don't like basically a spectral\n2242.44s: regularizer to force the model to try to\n2245.26s: recover these small modes I\n2247.42s: I wonder if what kind of connections\n2249.46s: there might be between some like this\n2251.38s: kind of approach and the trying to model\n2253.48s: the organization which is again\n2256.839s: but like\n2258.579s: like a like a smaller scale features and\n2262.48s: kind of trying to organize them and\n2264.22s: force the model to to actually account\n2265.839s: for them more explicitly"
    },
    {
        "class": "YouTubeVideo",
        "title": "Interpretable Meta Learning for Physical Systems",
        "videoId": "46giEUZqZfo",
        "url": "https://www.youtube.com/watch?v=46giEUZqZfo",
        "publishedAt": "2025-03-03T22:35:19Z",
        "transcript": "4.48s: hi everyone for our second Talk of the\n7.279s: day we'll have matu blong who is a post\n11.16s: doctorial associate at NYU kurant\n13.559s: Institute working with Sher schmeck on\n16.52s: deep learning for parameterization and\n18.24s: climate models and he received his PhD\n20.72s: from E normal Superior ens in\n25.96s: Paris thank you thank you for being here\n29.119s: so I'm mature and uh I'm going to\n32.119s: present a work called interpretable\n34.0s: metal learning of physical\n35.96s: systems uh which we did with my PhD\n38.84s: adviser Mar lar during my PhD so it's\n43.36s: mostly on the machine learning Sid but\n47.0s: with targeted applications on physical\n49.0s: systems and so the topic here is going\n51.399s: to\n52.52s: be uh building adaptive models that that\n57.0s: can handle um multi environment data\n60.92s: from physical systems so the general\n63.559s: topic is machine learning for physical\n65.72s: systems so as you all know uh machine\n68.479s: learning is very promising for many\n70.759s: applications in physics including\n73.28s: climate and weather forecast so here you\n75.32s: can see some applications in weather\n78.84s: Coast weather forecast and\n81.64s: oceanography and um the topic that we\n85.159s: are going to talk about is one issue one\n89.24s: challenge of\n90.6s: that we have to face when we uh learn\n92.799s: physical systems that is the variability\n95.52s: of physical\n97.24s: systems so uh physical systems are not\n101.36s: fixed but they vary over time or over\n104.92s: experiments here you have for example um\n108.04s: data from the era 5 reanalysis data set\n111.96s: showing that of course the climate\n113.56s: changes over years and so if you to\n116.56s: learn um a machine learning model it has\n119.92s: in some sense to adapt to the\n122.28s: variability of the system right and so\n124.6s: for a physical system this is hard\n127.0s: because data is typically very rare to\n129.84s: acquire so it will it's difficult to\n132.319s: have a data set covering the whole\n134.319s: variability of your\n136.48s: system and so another challenge is that\n140.319s: uh when you do deep learning deep\n142.44s: learning models tend to be uh\n144.48s: uninterpretable because they are just\n146.28s: blackbox models and when we are learning\n149.04s: physical systems with like to have some\n150.519s: interpretability in terms of physical\n152.16s: parameters for\n153.84s: example so here's an illustrative uh\n158.319s: drawing or of what's what the problem is\n161.72s: for dynamical systems that vary over\n164.12s: time we have a trajectory of U dynamical\n168.319s: System with some data here in the past\n170.72s: on which we've trained say some machine\n172.64s: learning model which forecasts this blue\n175.8s: trajectory here now if our physical\n178.76s: system is very varying over time what's\n181.68s: likely to happen is that in the future\n185.12s: uh the new observations that you you're\n187.08s: going to have have will follow some\n190.12s: shifted distribution with respect to the\n191.92s: past and so your train model on the past\n194.68s: will not be\n196.08s: accurate and so what we would like to\n198.68s: have is a way of adapting your trained\n201.599s: model to fit those new observation at a\n204.44s: cheap cost without retraining the whole\n206.48s: model from scratch so have some sort of\n209.36s: adaptive\n210.879s: model so now let's see a mathematical\n214.799s: framework for that on a simple example\n217.56s: here I have a very simple physical\n219.2s: system uh that is the the temperature\n221.92s: field into D between two bars so\n224.799s: satisfying here the leas\n226.84s: equation and so what an example of a\n231.0s: variable physical system here is that\n235.319s: okay so sorry first when we try to do\n237.76s: machine learning we want to learn a\n239.799s: predictor of the state of the system\n241.68s: which is here the temperature y of X as\n244.0s: a function of space and we want to learn\n246.76s: it from a data set D that you have uh\n249.439s: from system so now the system is\n252.72s: variable so what's likely to happen is\n254.439s: to have some physical parameter fi which\n257.72s: is here the displacement of the of the\n259.639s: bars that will vary from one experiment\n261.959s: to another and\n264.04s: so you want your machine learning model\n267.12s: model to be robers to that otherwise\n269.0s: you're not going to to be to learn um\n272.199s: effectively so let's see what happens if\n274.56s: you do a Nave machine learning\n277.759s: model uh train on those multi-\n281.0s: experiment data set that is a data set\n283.639s: made of the data collecting during the\n285.919s: different experiments with the diff\n287.919s: different physical\n289.16s: parameters so assume that we have data\n292.6s: from two experiments with some\n294.32s: variability between the experiments and\n296.759s: you train some sort of machine learning\n298.96s: model by regression here on the\n300.919s: collection of these two data sets now if\n303.8s: you have uh at prediction time some\n307.52s: observations of your new system so it's\n310.36s: the same system but with a slightly\n312.72s: different physical parameter leading to\n314.44s: a slightly different distribution what\n316.639s: you could do is just tune this uh the\n319.44s: parameter of your model but if we did\n322.639s: only that what we would learn is just a\n326.24s: blurry prediction of the the collection\n329.08s: of all the data that we had precisely\n331.199s: because we have not modeled the\n332.759s: variability of our data set we have not\n334.96s: Incorporated in the model some parameter\n338.16s: indicating that the the the data\n341.0s: distribution will be slightly different\n342.52s: from an exper one experiment to another\n345.52s: and this is where meta learning can uh\n347.84s: come into play to uh help us handle\n352.759s: those multitask uh data\n355.8s: scenario so I'm going to talk about that\n358.84s: so metal learning is a a paradigm that's\n362.56s: gain much interest in the machine\n363.84s: learning community and especially in the\n365.72s: Deep learning\n367.599s: community and here's how we can it can\n370.8s: be useful so we have this multitask uh\n374.039s: problem where our dat data set is made\n376.16s: of several data sets with several each\n380.24s: data set T the DT here is collected from\n383.919s: one instance of our physical system with\n386.12s: a different physical parameter so here\n388.599s: task is going to be an a synonym for for\n392.0s: physical parameter or\n394.0s: environment and so instead of modeling\n397.199s: the X toy relationship with a classical\n400.84s: regression model f ofx Theta metal\n404.0s: learning adds another parameter W here\n408.759s: that models precisely that extra degree\n411.12s: of freedom of variability between the\n413.56s: tasks or uh\n416.199s: environments and so here again with\n419.12s: these new parameter we can train the\n421.319s: model to minimize the regression error\n424.52s: here but with this new uh parameter dou\n427.84s: that is adapted from task to task at\n430.44s: each\n431.4s: task and so now if we have this new sort\n434.879s: of model at prediction time we can just\n436.72s: tune the task specific parameter that is\n440.28s: w and keeping Theta fixed okay so Theta\n444.52s: is the parameters of say a deep neural\n446.28s: network it's fixed after training and at\n448.879s: prediction time we just adjust W to fit\n452.44s: the observation of our new\n454.52s: environment so on our example here\n458.0s: here's how it would go so we have the\n461.4s: multitask um data set and yet another\n464.919s: environmental prediction time and here\n467.919s: as before you train Theta to minimize\n470.039s: the prediction error on your data set\n472.12s: but you have Al you have also a\n474.599s: parameter W that is adjusted at each uh\n478.52s: task for each task ask to take into\n481.199s: account the variability of each specific\n483.479s: experiment and now at prediction time\n485.44s: you just tune the W parameter to fit\n488.479s: those new observations and now that you\n490.68s: have modeled this variability you can\n492.44s: hope to have some good generalization on\n494.919s: this new experiment at prediction time\n498.159s: so that's basically the the concept of\n500.84s: multitask metal learning now all the\n503.199s: question is the how to compute this\n507.479s: WT uh for each different experiment\n510.599s: right because I haven't specified\n513.719s: that um and\n516.76s: so when we're doing uh when we are doing\n520.24s: deep\n521.0s: learning uh the the parametric model is\n523.36s: a deep neural network and a popular\n526.16s: approach uh for modeling the task\n528.32s: variability has been the mamal algorithm\n530.24s: that is now pretty famous in the Deep\n531.88s: learning community and so what maml does\n534.72s: is that it says that the the variability\n538.2s: of each task can be encoded in the\n540.56s: parameter space of the neural network by\n543.12s: an additive correction so f of x Theta W\n546.8s: is just your neural network F ofx Theta\n549.44s: corrected additively in the parameter\n551.519s: Space by some\n553.44s: W and so this kind of algorithm of of\n557.279s: architecture has known many successes in\n561.0s: reinforcement learning classification\n563.2s: many fields and even recently in\n565.279s: physical systems with the Cod\n568.12s: architecture uh\n570.079s: from a group in in Paris so the paper\n573.959s: from kme and\n575.88s: collaborators but the drawback with such\n578.0s: an architecture so there are a few first\n580.56s: it's very computationally challenging to\n583.2s: train and to adapt because the parameter\n586.6s: space of a neural network is of course\n588.72s: of a huge size second uh even when the\n593.48s: neural network is trained adapting the\n595.16s: neural network is very costly for the\n596.839s: same reason and third this method is not\n599.72s: interpretable because the parameter\n601.2s: space of your network that you here\n603.32s: adapt is not\n605.079s: interpretable so with these\n606.959s: considerations in\n608.6s: mind uh we've tried to do something more\n611.12s: interpretable and faster based on the\n613.32s: following\n614.519s: observations so with mammal since we are\n618.0s: learning an additive correction in the\n619.64s: parameter space of a neural network well\n622.0s: by extending this reasoning we could\n624.16s: just try to linearize the neural network\n627.0s: with respect to the parameter and if we\n629.36s: we do that we observe that the the term\n633.0s: that is um specific to each task is just\n636.6s: a linear or a fine contribution in this\n639.88s: equation also in physical systems the\n643.16s: physical parameters that vary from an\n644.839s: experiment to another can also often be\n648.079s: found to be linear just as in the\n651.68s: equation above so there's often a linear\n654.88s: dependence it's of always not it's not\n658.32s: always true of course\n659.88s: but what we can hope for is to have a\n662.519s: locally linear uh dependen in the task\n665.2s: parameter because um since we're dealing\n668.72s: with a multitask learning problem all\n670.92s: the tasks have some similarity so we\n673.12s: could argue that the physical parameters\n674.68s: only slightly value vary around some\n677.12s: Central value here 5 Z so those two\n681.56s: equations suggest that one good way to\n684.12s: learn cheaply a\n685.88s: multitask uh problem would be to\n688.8s: postulate\n690.2s: uh a naine or linear\n692.839s: dependence of the statistical model with\n695.16s: respect to this task parameter and this\n696.8s: is what we did with our the architecture\n700.04s: that we proposed called camel for\n703.24s: context ofine multienvironment\n705.8s: learning uh we propos to model the\n708.72s: output as a neural network that is Task\n712.56s: agnostic times a linear or aine task\n716.279s: specific contribution W So based on the\n719.76s: the previous observations and so by\n722.279s: doing that we have uh speeds because the\n726.079s: linear structure allows us to make all\n728.2s: the computations much faster both at\n730.639s: training and at prediction\n732.92s: time uh in fact at adaptation time so\n736.399s: when you want to tune W it's just an\n738.399s: ordinary least Square regression that\n740.04s: you want to solve so you can do that in\n741.36s: close form as opposed to gradient based\n744.24s: methods to optimize W and finally it's\n747.32s: more interpretable actually we have a\n749.92s: result showing that when the physical uh\n752.959s: system has the same structure of linear\n755.0s: dependence with respect to the task\n756.639s: parameter the physical parameter you can\n759.0s: actually learn a mapping between the\n761.399s: physical parameter and your uh learning\n763.8s: parameter W this is what you show in the\n765.92s: paper I'm not going to do to go into the\n768.12s: details but this result shows that this\n771.68s: architecture is\n774.12s: interpretable um so now let's see some\n776.639s: applications on physical systems\n780.04s: um first on our uh simple 2D example\n783.959s: from uh\n786.16s: thermodynamics here we have the the\n788.839s: error cures for train\n792.399s: architectures um as a function of the\n794.639s: number of um adaptation shots which are\n798.48s: the number of data points that you\n800.16s: provide the model to adapt to a new\n802.88s: task and so as you can\n805.32s: see uh when the physical system here\n808.639s: does exist bit some uh linear structure\n811.8s: with respect to the physical parameters\n814.24s: because uh camel mimics this dependence\n818.36s: in the learning model adaptation can\n820.68s: occur at a much faster um rate and with\n825.04s: lower error and you can see in the on\n827.48s: the bottom The computational Times They\n830.199s: Are much lower for this simpler uh\n834.04s: linear structure of camel compared to\n837.24s: the blackbox approaches that I present\n839.639s: before and so here's the here you can\n842.88s: see an illustration\n845.079s: of uh in the bottom row no in the center\n848.68s: row you can see the reconstructed\n850.959s: physical system by camel uh learned from\n854.199s: so adapted from 50\n856.6s: shots uh so with increasing\n864.72s: perturbation the estimation of the\n866.72s: actual physical parameters in terms of\n868.68s: the learning parameters of the learning\n870.8s: model and as you can see when the\n872.44s: perturbation of the of the of the bars\n877.079s: on the left is is small that means that\n879.68s: the physics is linear in the in the\n882.079s: physical parameter and you can see in\n884.72s: the bottom row that the identification\n887.88s: error is very low for Camel so camel is\n891.279s: able to identify the physical parameters\n893.759s: from the learning parameters so showing\n896.199s: the interpretability of the model\n898.24s: whereas the other approaches are not\n900.0s: able to do that so now let's see an\n903.0s: illustration that I made in the last\n905.16s: days to illustrate this model from a a\n909.399s: climate climate Dynamics learning\n911.639s: perspective so in this example we use a\n915.0s: neural network to learn parameterization\n917.199s: of the burgers equations so a very\n919.24s: simple uh pte for which there are some\n922.519s: small scale phenomena and so\n924.12s: parametrization is necessary if you want\n926.079s: to simulate this PG at at small\n930.44s: resolution and so here on the animation\n933.639s: you have in red no in Black rather the\n935.839s: high resolution simulation in blue the\n938.519s: small resol the sorry the the low\n941.519s: resolation simulation and in red is what\n943.68s: the neural network corrects the the blue\n946.24s: simulation so the parameterization and\n949.0s: at the dash line here the the physical\n952.44s: parameters of the Dynamics abruptly\n954.48s: change okay so we have a Time varying\n957.399s: Dynamics with some varying physical\n959.199s: parameters on the left the neural\n961.279s: network is not trained on uh does not\n964.68s: model this variability in the physical\n967.12s: parameters and so cannot adapt to change\n969.959s: of physical parameters so as you can see\n972.319s: in the beginning it manages to somehow\n974.48s: parameterize and resolve the the subgrid\n977.48s: phenomena but once the physical\n979.199s: parameters changes the neural network\n981.56s: completely loses track of the Dynamics\n984.12s: which you can see on the energy uh value\n987.16s: being far from the the true energy now\n990.8s: the a metal learning approach will model\n994.639s: for example with camel here I\n995.959s: implemented camel uh so models the\n998.44s: variability of the physical parameter\n1000.199s: and in real time adapts the model to fit\n1004.48s: uh the physical parameters on the new\n1006.8s: observations and so it's able to track\n1008.839s: the Dynamics even if the physical\n1010.519s: parameters vary abruptly that's a kind\n1013.12s: of a small illustration of the of the\n1016.079s: model on a dynamical system on the\n1018.36s: typical let's say a typical uh climate\n1021.88s: uh forecasting problem of\n1024.039s: parameterization so another field where\n1027.24s: we've experimented but less relevant is\n1029.439s: robotics but actually there are a lot of\n1031.319s: interesting connections between Robotics\n1033.12s: and control and climate science here you\n1036.88s: have the goal is to learn the Dynamics\n1039.0s: of a robot so here is a robot arm and\n1041.679s: you want to use this learn model to\n1044.28s: track a trajectory uh a desired\n1047.199s: trajectory of the arm which is in black\n1050.48s: here uh and so here in Gray is an\n1054.12s: analytic model that does not know\n1056.6s: exactly the Dynamics because the\n1058.08s: Dynamics here has friction and the\n1060.08s: analytic model ignores friction so it's\n1063.16s: enabled to to track the robot and\n1066.08s: abruptly here there's a new Mass on the\n1068.08s: robot arm making the analytic model\n1070.88s: completely losing track of the Dynamics\n1073.44s: whereas if you train your network to\n1075.32s: learn friction and the full Dynamics in\n1077.84s: an Adaptive way\n1079.679s: the control is going to be able to track\n1081.28s: the trajectory even if at some point you\n1083.679s: you change the physical\n1086.0s: parameters\n1087.52s: so of course another benefit is um\n1091.88s: interpretability which can be\n1093.559s: Illustrated and not going to go into the\n1095.72s: details here but you have tracking\n1097.28s: curves and at the bottom you have\n1099.44s: parameter identification curves showing\n1101.64s: that because the our learning model\n1104.08s: camel here in red is interpretable we're\n1106.6s: able not only to track the trajectory\n1108.52s: but to estimate the physical parameters\n1111.32s: that vary across time whereas it's not\n1113.76s: possible with the other\n1116.48s: approaches uh so we've made some\n1119.44s: experiments on the simulator of one\n1120.919s: robot that we had in in Ria but here\n1123.24s: again it's robotics but you can think of\n1126.36s: the same techniques being applicable to\n1127.88s: to climate potentially with some\n1130.08s: trajectory tracking and thanks to the\n1132.0s: interpretability of the method parameter\n1135.6s: estimation so to summarize what we did\n1138.4s: here we started from\n1140.52s: a a complex blackbox vision of multitask\n1144.159s: learning\n1145.24s: model uh and we said that well we can\n1148.0s: linearize this complicated expression\n1150.36s: that is postulated on blackbox papers to\n1153.28s: the first order the the zero order term\n1156.919s: would be ignoring the task variability\n1158.64s: but the first order term we show is uh\n1162.0s: easy and cheap to learn so it's kind of\n1165.12s: a can be thought as a as an easy first\n1167.6s: step when you want to learn\n1169.36s: um a variable system and if this first\n1172.32s: step doesn't succeed of course you can\n1173.919s: go to higher orders or to the full\n1176.24s: blackbox model but our point is that you\n1179.4s: can learn efficiently with this cheap\n1182.88s: and simple first order\n1186.72s: approximation um of course when the data\n1190.24s: distribution deviates from a linearly\n1192.88s: parameterized physics this is expected\n1195.64s: to to work um worse so as a conclusion\n1200.4s: what we've proposed is a multitask\n1202.28s: learning model for physical for physical\n1205.88s: systems and thanks to the linear\n1209.52s: structure of the problem we're able to\n1211.72s: design a simpler architecture that\n1213.679s: leverages the structure and by\n1215.76s: leveraging it makes the learning and the\n1218.159s: inter interpretability of the of the\n1220.88s: model\n1222.4s: better uh so it's computationally more\n1225.84s: uh efficient which can be very important\n1228.48s: in applications where you need to do the\n1230.799s: computations often such as dynamical\n1234.559s: systems and yes so it's very well suited\n1237.72s: for real-time applications because uh as\n1241.24s: I said ordinarily squares can be\n1243.08s: computed in Clos form and online meaning\n1246.48s: that uh it's basically inexpensive to\n1249.2s: adapt the model as time goes um at for\n1253.12s: each time step and so that's it if there\n1256.52s: are any questions I'd be happy to try to\n1258.36s: answer\n1260.4s: sir thank you very good presentation a\n1263.32s: whole question it's uh the prayer\n1265.44s: request for use of this method is I\n1267.88s: should know the physical equation right\n1271.679s: so it's not a requirement you can use\n1274.4s: this method on any on any system but the\n1277.44s: point is\n1279.36s: when when you know that the system\n1282.84s: exhibits this structure at least\n1285.24s: approximately you expect this method\n1288.32s: that exhibits the same structure to work\n1291.159s: better and that and in an interpretable\n1294.32s: way in the sense that you can estimate\n1295.799s: the physical parameters in terms of the\n1297.4s: learning parameters but it's not a\n1299.4s: requirement you can in fact in the in\n1303.32s: the example here when the two bars are\n1307.039s: are separated are separated by a large\n1310.76s: uh space with a a large angle the\n1314.12s: physics is not like the the perturbation\n1316.6s: of the system is large with respect to\n1318.679s: the normal position and so the the\n1321.279s: physical parameters is expected to be uh\n1324.76s: to intervene nonlinearly but yet the the\n1328.08s: Reconstruction is still\n1336.279s: accurate sorry\n1338.36s: sorry this method is um can solve those\n1342.72s: a nonlinear problem right yes but it's\n1346.08s: specifically designed to work well when\n1348.32s: you know or where you expect the the the\n1351.48s: physics to be linear in some physical\n1353.559s: parameter that varies okay thank you\n1357.32s: yeah thank you so much for your talk\n1358.64s: Matthew um I just had it out of\n1362.36s: curiosity because maybe I didn't\n1364.24s: understand 100% the method why is the\n1366.2s: inference time here so much higher for\n1369.039s: mamal Koda than camel because it sounded\n1371.44s: to me as if in the end you're also just\n1373.76s: an inference time evaluating a neur\n1376.2s: network no no oh okay sorry there's a\n1379.679s: maybe I should have called that another\n1381.159s: name so inference so it's at inference\n1383.52s: time but it's not the time you you\n1385.039s: employ to evaluate the neural network\n1387.279s: it's the time you employ to adjust the\n1389.6s: task specific parameter okay so for the\n1391.96s: first two methods here you do that by\n1394.08s: some uh gradient descent so you adjust\n1397.12s: the weights by doing gradient descent\n1400.039s: which is not guaranteed to converge so\n1402.88s: Mak make it might take time whereas here\n1405.88s: it's just well\n1408.559s: question yeah okay cool thanks and can I\n1412.12s: small followup um not followup but um in\n1415.039s: the light now of your talk I was\n1416.64s: wondering if your question for the\n1418.44s: previous talk was actually thinking if\n1420.76s: there's a way to do symbolic regression\n1422.279s: in a similar way yes to what you did\n1424.159s: here I think I saw a paper trying to do\n1426.76s: that so they PR train a neural network\n1428.32s: to learn some physical\n1430.0s: system and you know specific way to they\n1434.0s: want to design the neural network so\n1435.48s: that um systems on same instances of the\n1438.84s: system but with different physical\n1440.159s: parameters the the weights of the\n1442.279s: symbolic regression can be tuned so\n1444.76s: basically metal learning but in symbolic\n1446.96s: agression way so that the previous talk\n1449.88s: made me think about that and I was\n1451.52s: wondering if you can combine cleverly\n1453.72s: the a neural network and a symboling\n1455.24s: progression that might make sense but I\n1457.559s: don't know much about that okay cool\n1460.039s: thanks\n1462.279s: thanks yeah thanks\n1464.88s: for thanks for the presentation I\n1467.72s: actually wanted to ask for a bit more\n1469.799s: details on the\n1471.32s: linearization cuz I guess I mean the way\n1473.559s: you show it locally linear it made me\n1476.399s: think about Tor expansions but I would\n1479.039s: think in that case you have to worry\n1480.679s: about convergence radius if not if\n1482.96s: you're talking about like linearization\n1485.52s: of operators I think of\n1488.039s: equipment uh operators but in that case\n1490.72s: you have to worry about truncating the\n1492.96s: dimensions right so I guess just I'm\n1495.72s: curious a bit more details of the\n1497.399s: linearization here the linearization\n1499.799s: happens with respect to the physical\n1501.32s: parameter not to the state so it's not\n1503.84s: as in equipment operator where you\n1506.039s: assume that the Dynamics is linear with\n1508.52s: with respect to the state here it's the\n1510.48s: given function with respect to some\n1512.679s: physical parameter and so as I've\n1515.08s: mentioned before the you don't assume\n1519.64s: the physical system to have this\n1521.12s: structure but you expect that if it does\n1523.52s: have a structure or a similar structure\n1525.64s: that is some approximate linearity then\n1528.2s: this this method is going to fit well\n1529.96s: because the learing model has exactly\n1532.24s: the same\n1533.52s: structure and what if it what if the\n1537.399s: true Dynamics models doesn't actually\n1540.32s: exhibit this linear structure then then\n1543.279s: well you expect some uh lower\n1545.32s: performance and you might have to try\n1547.039s: some uh more expensive methods but the\n1549.64s: point here is that if it does that's a\n1552.039s: very cheap method to to leverage that oh\n1556.279s: okay thank you much cheaper than m I\n1558.6s: don't know if you you've already worked\n1560.399s: with mammal but it involves second order\n1562.44s: gradients so it's very very\n1564.36s: computationally expensive to train and\n1566.559s: also to adapt okay thank you thank you"
    },
    {
        "class": "YouTubeVideo",
        "title": "LEAP Annual Meeting: Day 2",
        "videoId": "GCP9P6-uQRQ",
        "url": "https://www.youtube.com/watch?v=GCP9P6-uQRQ",
        "publishedAt": "2023-02-01T14:39:24Z",
        "transcript": "4.319s: okay let's get started to make sure we\n6.54s: are on time uh so welcome back yeah from\n10.38s: day two it was exciting Thursday so\n12.36s: really great to see everything starting\n14.34s: to glue together from research education\n17.1s: now it's transfer really really a great\n18.48s: moment uh so today we're gonna get\n21.06s: started with a summary of the focus\n22.98s: group so we had three different sessions\n24.779s: and then we that would be followed by a\n27.06s: Dei presentation by Courtney okay thanks\n30.06s: welcome dear\n37.32s: oh uh I'm Drew again uh I led the focus\n42.0s: group for prioritization and uh to\n45.12s: summarize the problems\n47.52s: final problem uh we have subject scales\n50.34s: and we need to find a way to create\n53.219s: shortcuts for those processes that are\n55.26s: in those skills uh typically require a\n57.719s: lot of compute power but we can get good\n60.719s: approximations of the treatment\n61.8s: potentially\n65.22s: um and we also have staff\n66.42s: prioritizations for\n67.979s: processes that we don't have governing\n70.08s: laws for in which case uh more\n72.479s: computational power won't help at all\n76.26s: so some of the problems we'll address\n77.939s: besides the main problem is minimizing\n80.759s: time minimizing amount of time it takes\n83.04s: equated with jargon so we have a lot of\n85.74s: people going with different backgrounds\n86.88s: from math engineering and physics and\n90.84s: they all need to be onboarded to the\n92.28s: same type of domain and minimizing that\n94.86s: onboarding time is critical\n98.34s: second is expanding X High resonance\n100.439s: from process data sets\n102.479s: um Jessica starter do you need to have a\n104.88s: toy problem to work with and making sure\n107.04s: the spin-ups that play problem is uh\n109.56s: minimize this rate\n113.46s: um if you want a foster collaboration\n114.84s: then stuff like two i2c Pangea is is\n118.259s: awesome gets an essential skill as well\n123.54s: um and uh particularly one of the\n126.659s: biggest problems associated\n127.5s: prioritization is making sure any\n129.66s: Improvement in offline skill translates\n131.34s: to online skill\n133.02s: um\n134.099s: because that tends to be an intractable\n136.68s: problem if you're not plugging into\n138.06s: problems looking into prioritizations\n140.22s: online\n142.92s: uh on that note\n145.14s: um to go from offline to online\n146.64s: typically you need to go from a python\n148.7s: model to something that works in Fortran\n152.16s: and\n154.62s: um there there are let's do this with\n156.959s: the Fortran Keras Bridge or high torch\n159.9s: uh binding but they have the\n162.42s: shortcomings and finding a way to\n163.8s: improve them it would speed things\n165.42s: considerably\n169.26s: um lastly on shared problems uh we have\n172.62s: we have separate focus groups we all\n174.84s: have slow problems and finding ways to\n176.819s: identify the shared problems so we are\n178.86s: siled is uh an important step\n183.84s: so IT addresses problems what kind of\n185.099s: trend you want to see\n186.72s: um\n186.82s: [Music]\n188.099s: for Tran training I'm biased towards\n189.9s: this I definitely would benefit from uh\n192.72s: much more transforming I don't think\n194.879s: this is taught in any undergrad courses\n197.22s: that I'm aware of and I sort of it's\n199.44s: sort of a thing you just teach yourself\n200.34s: uh even though it's like quite adequated\n202.62s: and there's not a lot of documentation\n203.7s: online so having a sort of formal setup\n206.64s: for this would be very helpful\n210.019s: Advanced get training this is something\n212.459s: that people learn themselves a lot\n214.739s: especially if they're doing like\n216.18s: professional software engineering\n217.44s: internships\n219.06s: um but if we want to collaborate\n220.98s: professionally across campuses and you\n223.799s: know not to send code back and forth uh\n226.2s: making sure we can collaborate on git in\n227.76s: a really efficient way is really helpful\n232.379s: um\n233.159s: a similar note making sure we can\n236.879s: um\n237.959s: communicate with code in a way that\n240.54s: doesn't break when we're transferring uh\n242.4s: we're working different systems or\n244.319s: different packages uh is really helpful\n247.379s: and do that we would probably want to\n249.299s: have container training uh particularly\n251.939s: with Docker or similarity\n255.9s: um and glcr2c we had some of this at\n258.06s: Labor Ready and more of that will be\n259.859s: useful\n262.38s: um lastly have soft skills which are\n264.9s: also not quite caught these are women\n266.52s: herself\n267.54s: project management communication and\n269.52s: reverse skills\n271.38s: um\n272.759s: and if you yourself have a topic that\n275.699s: you think you've taken well outside of\n277.8s: Master and you can help for others then\n280.08s: the volunteers has a workshop would be\n282.0s: very much appreciated\n285.36s: so what lessons we learned from our\n286.979s: discussion\n288.36s: um so uh the traditional Academia is to\n292.74s: really publish your successes in the\n294.06s: form of papers and uh show like I guess\n297.18s: the end result of a lot of Trials and\n299.759s: failure but if we want to I guess help\n303.0s: each other out then being open and\n304.86s: transparent about failures is critical\n306.72s: because that means that a lot of people\n308.759s: don't have to stop the same failure to\n309.96s: get to the point that you are at\n312.3s: um\n313.86s: on a similar note if you have an\n316.919s: interaction that's positive uh it's\n319.62s: important taking time to reflect and try\n321.24s: to emulate for yourself and that doesn't\n323.639s: have to be a form of like say a\n325.68s: one-to-one interaction that can be a\n327.6s: presentation or a paper or just some\n329.82s: writing you found very concise and easy\n332.94s: to understand\n336.12s: uh the question another part of this is\n338.88s: to not be afraid of dumb questions\n341.639s: um everyone has some questions starting\n343.139s: out and sometimes people at the\n344.699s: questions later in their career and it\n348.3s: always takes more time to figure that\n350.52s: out yourself and just ask them so uh\n353.46s: yeah just ask and to get it over with\n359.699s: um lastly for Lessons Learned\n362.88s: um we're all learning new tools but\n364.86s: these tools aren't Immortal uh\n367.02s: eventually there will be another program\n368.46s: language or another set of tools you\n370.62s: need to learn so don't uh commit and\n372.96s: pretend that's going to be the end-all\n374.1s: be-all uh you will have to be told many\n376.56s: people pre-chooled multiple times so be\n378.9s: comfortable with the Core Concepts and\n380.4s: be willing to reinvent yourself to learn\n382.62s: what you need to learn\n385.5s: next steps\n387.0s: um so for meeting next steps we want a\n389.699s: third data set that cloud scientists and\n391.08s: computer scientists can Cloud around\n392.1s: freely uh with the least friction\n394.199s: possible that means something that is a\n396.96s: very pre-process uh has a lot of\n398.88s: documentation comments and whatnot uh\n402.12s: roughly using GitHub and having data on\n404.1s: cloud\n406.86s: um we want more defined roles than the\n408.66s: focus group so that people feel more\n411.419s: involved especially if they're not at\n412.979s: Columbia it's hard to\n415.199s: feel like they're I guess\n418.199s: really involved if you're not physically\n419.759s: on campus so that'd be very helpful\n425.34s: shared GitHub we've seen my workflows a\n427.5s: few things you've nailed down a certain\n429.18s: workload and it's impeccable than\n432.539s: sharing with others to be useful and we\n434.52s: could have it could help that\n435.36s: centralizes all these uh workflows\n439.68s: and lastly this is a bit ambitious but\n441.78s: maybe having a tackle style competition\n443.46s: where uh there's a fair data set and a\n447.479s: hidden test set and everyone submits\n449.699s: their models for ranking\n453.78s: and that's it thank you\n461.34s: good morning everyone this is Young I'm\n463.979s: a leap postdoc so uh we are doing the\n467.52s: parameter estimation group\n469.74s: so the goals is to you know introduce\n472.199s: and discuss different uh like a\n474.24s: parameter estimation methods to promote\n476.72s: collaborations and uh like in the long\n480.36s: term and also I think learn from each\n482.4s: other so the focus of our previous\n484.62s: discussions are about like like more\n487.919s: about methods less like a collaboration\n491.22s: uh related so it's about things that you\n494.52s: don't get to see on the papers for\n497.039s: example like the limitation of implement\n500.22s: or difficulty of implementing certain\n502.5s: methods and like your personal views and\n506.039s: experience uh or feeling about certain\n508.379s: methods so we have 24 groups uh three\n511.44s: discussions in the last three months and\n514.38s: normally the attendees range from 7 to\n518.159s: 12. so here are the topics uh Bayesian\n522.3s: statistics and Ensemble common filter\n527.22s: so just to give you an example of what\n530.339s: we have discussed so we go so like we\n533.519s: want to see the things you don't see uh\n535.68s: like I said earlier so we go with the\n538.32s: simplest uh scenario simplest method\n540.959s: which is common filter and then we uh\n544.5s: introduce Ensemble common filter and\n547.019s: then how it is adapted in a paper so you\n551.16s: can see a example slide here so we try\n554.7s: to Mark the connection which is the\n557.399s: thing that you know sometimes they use\n559.56s: just one sentence in the paper and the\n562.2s: discussion points we have had includes\n565.019s: like sometimes the details in the paper\n567.44s: sometimes like a clarification of a\n570.839s: concept and Etc\n572.94s: uh so for the discussion from yesterday\n575.58s: it seems like there's a common uh\n577.98s: challenge that we all face which is to\n581.279s: build the emulator so what it does so\n584.16s: the emulator basically predicts the\n586.98s: output of a complicated numerical models\n590.72s: based on a relatively small data sets so\n594.42s: it's not really a big big data problem\n598.26s: but it's I think it's critical because\n600.36s: we need to deal with uncertainty and\n604.5s: Etc so that seems to be a common problem\n607.2s: and also uh like more specifically it's\n611.16s: like how do we sample the parameters to\n614.76s: run the models such that we could have\n617.04s: more valuable input and output for\n619.8s: training the emulator and it seems It's\n622.32s: like kind of universal and that Gap\n625.56s: perhaps we can fill in is that so to you\n629.04s: know uh strengthen the collaboration\n631.5s: between different communities seems like\n634.74s: we need to describe a problem or\n637.68s: Challenge in a format that is you know\n640.459s: understandable to different communities\n643.38s: or sometimes you we should kind of\n646.14s: simplify the context and all that and\n649.2s: also uh also the data set that can be\n653.22s: shared are like it's actually very\n655.86s: doable and can be done fairly soon we\n658.92s: can have synthesized the data sets from\n661.079s: different kinds of models with different\n662.959s: levels of complexity so the the other\n666.899s: challenges are listed here as well so\n669.839s: the focus group for this year so we want\n672.779s: to have more discussion for sure build\n675.24s: collaborations uh but also we don't want\n678.48s: to burden the uh the participants too\n681.3s: much and uh fortnite wise we have done\n684.6s: black method introduction and discussion\n687.779s: perhaps we can try to focus on\n690.74s: discussing the challenges that have been\n694.019s: listed in the previous slide and\n696.54s: definitely want to have more students\n698.459s: participating like take some more\n701.0s: responsibilities and that's a good\n703.62s: training process I think and also our\n706.74s: discussion and last year is kind of\n709.68s: sometimes goes from like very detailed\n712.92s: stuff to like very broad thingy but I\n716.82s: think both of them are like very\n718.86s: beneficial to to us researchers and\n722.339s: another important point for me is to\n725.279s: better record and track the things we\n727.86s: have been discussed and that's it we'll\n731.22s: work you're welcome to join yeah thanks\n740.399s: if you don't know me I'm Taya hamdau I'm\n742.92s: a poster at\n745.8s: I'm in Germany\n748.2s: so I have been so lucky that I've gotten\n750.959s: to organize the map focus group this\n753.6s: Paul and I want to tell you a little bit\n755.399s: about who we are and what we've been up\n757.019s: to\n759.06s: okay so officially we're 16 members and\n762.72s: we meet every three weeks about once a\n765.36s: month and we have hybrid meetings so\n767.22s: both on zoom and for those who want to\n769.32s: they can meet up in person at the to\n771.779s: leave space\n772.98s: we have a broad range of backgrounds in\n775.62s: our group in terms of career stages and\n779.16s: our research Focus we have PhD students\n782.1s: postdocs and professors and I was\n784.8s: looking up yesterday all of our research\n787.579s: interests it's very broad it ranges from\n791.519s: everything from clouds precipitation\n793.2s: organ or ocean carbon cycle ecosystem by\n796.8s: geochemistry vegetation Dynamics ice\n799.44s: physics land atmospheric interactions\n801.42s: and this makes this into a really\n803.22s: interesting group but it can also make\n805.139s: it challenging to find common goals\n809.76s: so during our first focus group meeting\n812.579s: I asked everyone what are your\n814.44s: expectations what do we want to get out\n816.06s: of this group and these were overall\n818.88s: people's answers so to build a community\n820.62s: and network within leads to share code\n823.26s: and workflows that can cut across\n825.36s: disciplines\n826.44s: to have interactive conversations to\n829.079s: have a place where it's safe to ask\n831.18s: questions and learn to improve\n833.82s: communication between the observation\n835.86s: and modeling communities\n837.72s: and also to evaluate evaluate models\n840.06s: observations and uncertainties and\n842.16s: hopefully in the future we will be able\n844.139s: to address all of this\n847.8s: so what have we done so far and most\n850.32s: importantly we have gotten to know each\n851.88s: other\n852.6s: uh our group meetings don't have a set\n857.1s: format so our group meetings have been\n859.62s: quite different from time to time and we\n862.2s: have all had individual presentations of\n864.779s: our projects\n865.98s: to show what we're working on what kind\n868.019s: of problems we're facing and what our\n870.06s: goals are and we have also had a session\n872.88s: where we had a discussion on a topic\n875.399s: that we selected and in this case it was\n877.5s: uncertainties\n878.579s: and most importantly we have come up\n880.74s: with a lot of questions\n884.519s: uh so future plans and we have been\n888.0s: thinking about trying to identify\n890.04s: specific research challenges\n893.279s: um that for all of us that are working\n895.26s: on different things and to see do any of\n897.72s: these challenges overlap and if they do\n900.3s: would it be possible perhaps to Define\n902.639s: some sort of templates maybe a jupyter\n904.68s: notebook and how to solve this specific\n906.72s: problem and then everyone can have\n908.1s: access to this notebook just an idea we\n910.5s: have and in order maybe to do so we were\n912.899s: thinking about maybe trying to\n913.92s: collaborate with more data scientists we\n916.139s: don't have so many aluminar group\n918.36s: we've also briefly discussed maybe the\n921.06s: possibility of can you write a review\n922.56s: paper together as a group\n926.639s: so going forward we have many questions\n930.42s: um how do you define uncertainties\n932.82s: how do you evaluate your machine\n934.26s: learning models\n935.94s: how do you measure model improvements\n938.459s: how do you choose the right metrics if\n940.92s: you have multiple data sets or\n942.3s: observations how do you know which one\n943.92s: to choose\n944.94s: and what do you what do we do if the\n947.04s: observational errors are poor or unknown\n950.579s: and if you have an answer to any of\n953.04s: these questions please join our group\n956.279s: thank you\n963.12s: yeah I think there's a there seems to be\n964.92s: a lot of shared feeling around the value\n966.12s: of these these problems and I feel like\n967.56s: we had laid plans for hackathons and a\n969.779s: bottleneck is just getting them ready\n971.339s: and like I find the idea of like for a\n974.82s: quarter having the focus groups like\n976.98s: work together on getting them ready\n978.66s: really interesting there's like at least\n980.16s: three data sets that I'm aware of that\n981.959s: on the microphysics side that are ready\n983.82s: to upload on the Supreme transition side\n986.459s: and on the parameter inversion for the\n989.22s: uh for the NASA guess tuning that are\n991.98s: that are ready to go but the metrics are\n994.079s: clear but um it's a lot of work and it\n996.779s: could be fun to distribute and also\n998.339s: serve a training need to spend a month\n1001.1s: or two doing that work together through\n1002.72s: the focus groups\n1004.88s: maybe so does they continue to respond\n1007.459s: to that having said in most of the focus\n1009.139s: groups I mean I think that's what\n1010.279s: everyone wanted to do I mean to your\n1011.839s: point Robert I mean I think that the\n1013.759s: question is very much like what Tian\n1015.38s: said is what do we Define it as a toy\n1017.54s: problem you know and uh actually a few\n1020.42s: weeks back you know we had the Stefan\n1022.279s: rice actually presenting in the journal\n1023.839s: club and he said I think he made a very\n1026.12s: good case which is that it should be\n1028.66s: something that would be useful down the\n1031.04s: road right so if it's too simple that's\n1033.5s: great to get some understanding would\n1035.48s: that be used for in terms of the\n1036.679s: algorithmic development potentially not\n1038.36s: right so it has to be to strike the\n1039.98s: right balance right and I think that's\n1042.079s: potentially\n1045.62s: foreign\n1052.22s: exactly you're right education yeah\n1059.48s: it's like walking those two are not\n1061.58s: competing in a way right so so you want\n1064.52s: to get this thing to be useful for the\n1066.5s: research but if you don't train people\n1068.6s: to get familiar with machine learning\n1070.4s: you know what I found is that I cannot\n1072.44s: Define those type of songs I don't know\n1074.12s: the science enough to Define it but but\n1076.22s: I need to work with someone who have a\n1078.32s: domain knowledge to collaborate a\n1080.78s: confined Master student to help cleaning\n1083.059s: data you know getting started already\n1084.86s: but somebody need to tell them what is\n1086.72s: good and what is bad but I can clap with\n1089.72s: with Bob but he said I don't know\n1091.46s: machine learning enough to tell you\n1092.6s: whether it's good or bad or not like so\n1094.16s: so we need to do the education one which\n1096.5s: is that's what's up a forward and then\n1100.16s: then eventually the research goes like\n1102.32s: so so nothing is I think nothing is too\n1105.32s: simple to get started with and if it's\n1107.66s: so easy that would get it done very\n1109.52s: quickly and we're ready to move to the\n1111.08s: next one so that's that's why I said\n1113.84s: so I feel the Swiss part of a school\n1116.9s: example is is a moving Target and and\n1121.28s: and we may never be able to Define it\n1123.799s: and so to get started and to to and then\n1126.62s: get back to the first one is I've allow\n1128.72s: some of our effort to fail uh it's also\n1132.26s: a good good experience\n1135.559s: yeah um I just wanted to mention that um\n1138.62s: in past workshops actually a few\n1140.78s: participants here went to the Aspen\n1142.82s: Global change Institute Workshop over\n1145.34s: Summer and the toy model problem came up\n1147.679s: as well so this is like even Beyond leap\n1150.919s: it seems to be a really big Community\n1152.36s: need but I really want to emphasize that\n1154.16s: it seems like there could be a use case\n1156.679s: for data sets but then the toy model\n1158.36s: from a physics standpoint is different\n1160.64s: right because we can train some sort of\n1162.919s: parameterization\n1165.08s: um emulator offline and then when we put\n1167.78s: that back into a model that's where some\n1169.76s: issues can arise and so my thinking at\n1172.039s: least something that I would love to\n1173.48s: have to play with is some simpler sort\n1175.94s: of physical model that I can train\n1178.64s: parameterizations or other processes\n1180.5s: offline and then test to see whether\n1182.419s: they remain Stable online or or in\n1185.6s: further development so if that makes\n1187.4s: sense right so it just seems like\n1188.66s: there's a difference between a data set\n1190.16s: toy problem and then a physical model\n1192.799s: toy problem\n1194.179s: and if I may just to what has been\n1196.58s: satisfaction and Robert I mean to some\n1198.799s: extent it's not too far from what we are\n1200.6s: seeing also in the climate Community\n1201.74s: this idea of modeling up here right I\n1204.38s: mean that's pretty much how we would\n1205.52s: want to apologize something that's\n1206.72s: approachable so that we could actually\n1208.1s: understand things actually get in and\n1209.96s: you have a class you know actually on\n1211.88s: you know so that would be a very nice\n1213.5s: entry point as well like on simpler\n1215.299s: model to understand the physics you know\n1216.86s: things like that I'll be really quick\n1218.36s: just to reply to Maria\n1220.1s: big plus one on the toy models in the M\n1222.919s: squared lines project we've had a lot of\n1225.02s: success with qg models quite traffic\n1227.78s: reduce order but still turbulent\n1229.52s: simulations we have a nice python code\n1231.32s: called Pi Fuji you can just run on your\n1233.12s: laptop and it allows you to play with\n1234.98s: things like you know putting the\n1236.78s: parameterization online is it still\n1238.16s: stable like these questions so that that\n1239.9s: can be important part of that we're very\n1241.22s: happy to collaborate with people on that\n1243.679s: um on the data point just responding to\n1245.539s: what Mike said uh especially as we're\n1247.76s: figuring out how to do this there is a\n1249.26s: lot of work involved in creating a good\n1251.78s: Benchmark data set and sharing it in a\n1253.58s: way that's accessible to people\n1254.72s: hopefully that'll get easier over time\n1256.58s: but you know I I want to note something\n1259.22s: that Rob said yesterday this is a\n1260.9s: question about incentives like what we\n1262.22s: hear often is well we we'd like to make\n1266.0s: a benchmark data set but my postdoc\n1267.559s: really needs to focus on getting their\n1268.94s: next paper out like they don't have a\n1270.38s: few months to spend really fine-tuning\n1272.66s: this data set and Publishing it\n1274.76s: um\n1275.36s: and you know as a center I think we need\n1277.64s: to find ways to resist that culture and\n1281.059s: if that's really on the pis to\n1282.679s: prioritize this work and\n1284.72s: um give people the space to work on\n1286.16s: those things but also we have you know\n1288.86s: budget for this like you know Julius and\n1291.14s: I are focused on this problem so if you\n1293.78s: have a data set that you think will be\n1295.28s: useful you don't have the time or the\n1297.02s: expertise to really make it accessible\n1299.0s: reach out to us and we will help you\n1300.5s: we'll get it online Stefan Ross had a\n1302.78s: huge impact by doing all that you know\n1304.64s: climate bench stuff and\n1306.5s: um we can do things like that so yeah\n1308.419s: yeah that's a great one in fact we also\n1310.64s: have additional resources if it's a\n1312.14s: matter of like improving your data\n1314.059s: improving your model so it can actually\n1315.799s: make it it could make it more widely\n1318.26s: available and useful so we can actually\n1320.48s: leverage and support that as well from\n1322.28s: additional resources as well so please\n1324.32s: reach out in that case thanks everyone\n1326.0s: great discussion so we went a little bit\n1327.74s: overtime sorry for me yeah we have just\n1331.039s: a little faster in ml building data sets\n1333.919s: is valued a lot and so that's a great\n1336.62s: way to get citation and be known it's\n1338.84s: just building those data sets yeah\n1341.299s: that's a great thing\n1348.74s: hi everyone uh and I'm joined by Dr\n1351.5s: Christian branyan who will come up as\n1353.6s: well\n1354.44s: we'll get started\n1357.2s: is this what\n1369.32s: foreign\n1376.22s: okay so to introduce myself many of you\n1378.62s: already know me but just to give you\n1379.94s: some background I describe myself as a\n1382.88s: transdisciplinary social scientist and\n1384.799s: in part because I have been trained in\n1387.44s: and work across multiple areas and\n1390.02s: disciplines including uh psychology\n1392.9s: social work and population Health as\n1395.659s: well as computational social science my\n1398.299s: work focuses on the characterization and\n1400.4s: measurement of racism and I also think\n1403.22s: about the ways in which racism affects\n1405.38s: health and contributes to racial\n1406.88s: inequities and health I do work in\n1408.86s: virtual reality other emerging\n1410.48s: Technologies and think about social\n1412.1s: justice very broadly as well as\n1414.32s: curriculum and pedagogy\n1416.72s: um I also work in corporate Dei and\n1419.72s: anti-racist practice particularly with\n1421.58s: senior leaders so all of that comes to\n1424.4s: bear on my work and this role uh helping\n1427.22s: to lead Dei here at leap and I also uh\n1431.419s: lead the EI at our data Science\n1433.22s: Institute at Columbia as well I'll turn\n1435.679s: it over to Christian to introduce\n1437.36s: himself\n1438.32s: hey good morning\n1440.12s: um I may I think I know some of you\n1441.98s: folks here my name is Christian branion\n1444.559s: I'm a climate scientist and a civil\n1446.84s: engineer so both a researcher and a\n1449.84s: practitioner my training is in\n1452.12s: environmental fluid mechanics and\n1454.1s: hydrology\n1455.2s: and after that training I went on and\n1457.7s: worked for civil engineering firm doing\n1459.44s: Water Resources planning and a lot of\n1461.24s: resource engineering I spent five years\n1463.82s: at Nasa guess in the climate impacts\n1466.039s: group doing research with satellite data\n1469.1s: and with global climate model outputs\n1471.4s: helping folks around the world use those\n1473.9s: data sets for climate adaptation and now\n1477.5s: I still do work in climate impacts\n1479.419s: adaptation resilience but also doing\n1482.0s: work around carbon management as well so\n1484.039s: really please to be here yeah so we just\n1487.28s: wanted to give you a sense of what\n1488.72s: informs our work and what informs our\n1491.24s: remarks and comments today\n1493.179s: as I indicated in the the title for this\n1496.94s: session the goal is to provide some\n1500.059s: context to\n1502.46s: um from my perspective uh push and may\n1505.1s: disrupt the way that you think about\n1506.48s: issues related to to Dei this is not a\n1509.72s: training session we're not going to do\n1511.159s: anything related to unconscious bias\n1512.98s: I'll explain why that would not be\n1515.539s: useful in just a moment\n1517.34s: um and then we will turn to a Christian\n1521.12s: who will share some of the ways in which\n1523.84s: Dei anti-racism has intersected with his\n1527.36s: work in climate over the course of his\n1530.12s: career using a few examples to make it\n1532.4s: more concrete this is all leading up to\n1535.58s: a session in part two where we'll do\n1538.58s: strategic planning so we'll have you\n1541.039s: work in very concrete ways around what\n1543.679s: your commitments goals and actions are\n1546.26s: are related to Dei and anti-racism in\n1550.52s: particular\n1551.5s: so I appreciate your attention as we've\n1554.6s: all agreed to not look at our computers\n1556.58s: while we're engaged in this session and\n1559.4s: uh look forward to the discussion\n1561.86s: so like I said we'll I'll first give an\n1563.9s: overview of Dei and leap offer some food\n1567.38s: for thought and critical Reflections\n1569.179s: I'll turn it over to Christian uh so I\n1571.82s: forgot that I'll also give you some\n1573.14s: brief uh breath best practices\n1576.32s: um and then we'll open it up for\n1577.58s: discussion to help set us up for the\n1580.039s: strategic planning session we'll also do\n1582.14s: an exercise where we're thinking\n1583.94s: together what our specific spheres of\n1586.4s: influence are so given the roles that\n1588.14s: you occupy professionally in different\n1590.659s: organizations having you reflect on your\n1593.299s: different spheres of influence and then\n1595.279s: we'll go into part two after the break\n1598.22s: so I don't want to spend a lot of time\n1600.26s: on this I think we're all familiar I'm\n1601.76s: not here to convince you that Dei\n1603.62s: matters for climate science and climate\n1606.02s: adaptation most of us know that there\n1609.2s: are particular groups of people who are\n1611.299s: suffering more harms at the hands of\n1613.88s: climate change that are deeply rooted in\n1616.22s: structural racism and other structural\n1618.74s: inequities so living in communities with\n1621.74s: more concrete as opposed to more trees\n1623.919s: where are pollutants dumped where our\n1626.84s: buses parked Etc and how that gets\n1631.22s: organized around race and socioeconomic\n1634.039s: status that makes particular communities\n1636.679s: more vulnerable to the effects of\n1638.36s: climate change in addition to the\n1640.64s: resources to respond to those threats\n1644.36s: so we're in the broadening participation\n1647.799s: knowledge transfer space as I indicated\n1650.299s: in my remarks about knowledge transfer\n1652.279s: knowledge transfer education and Dei all\n1655.34s: intersect\n1656.659s: um we're really thinking about Dei as\n1658.88s: being integrated throughout the work of\n1660.919s: leak not as a separate entity that does\n1663.26s: Dei stuff on the side\n1666.44s: so it's really important for us to think\n1668.299s: about leap's vision and um related to\n1670.88s: the Eis related recruitment research\n1672.559s: education and knowledge transfer we're\n1675.32s: focused on increasing representation of\n1677.299s: underrepresented minorities in this\n1679.7s: burgeoning discipline and we also are\n1682.4s: committed to assessing reviewing and\n1684.08s: revising our activities related to this\n1686.72s: explicitly through a Dei lens\n1690.02s: so we're thinking about Dei and\n1692.36s: everything so uh knowledge transfer\n1694.82s: education everything that was talked\n1697.159s: about related to those activities are\n1699.5s: filtered through a lens of Dei we our\n1702.38s: executive committee has a shared\n1704.36s: commitment to moving the needle on these\n1707.299s: issues um and so we have been having our\n1709.58s: own discussions leading up to this event\n1711.62s: and are continuing to engage uh even the\n1714.98s: ethos of open science and\n1716.679s: transdisciplinarity is also connected to\n1719.059s: broadening participation in Dei those\n1721.64s: things are related to the concepts that\n1723.74s: we talk about in Dei as well of course\n1726.26s: we think about it as it relates to our\n1727.88s: Recruitment and hiring as well as our\n1729.62s: retention efforts but we're also really\n1732.26s: trying to integrate it as I said into\n1734.059s: our Center and lab cultures and climate\n1736.88s: so not seeing the Dei acronym doesn't\n1739.76s: mean that it's not being implemented\n1741.32s: it's in everything and that should be\n1743.36s: the assumption\n1745.46s: so what are we focused on we're focused\n1747.559s: on Dei as a holistic lens in practice uh\n1751.039s: we're thinking about Dei that's\n1752.48s: anti-racist and anti-oppressive I'll\n1755.059s: explain what I mean by that in just a\n1756.559s: moment\n1757.82s: um supporting integration of Dei into\n1759.74s: your science and research uh developing\n1762.98s: yourself and social competency how do\n1765.14s: you understand yourself as a person\n1767.059s: engaged in science as a person engaged\n1769.64s: in social impact as a person engaged in\n1772.46s: Dei work as well as your understanding\n1775.46s: of how these issues manifest in society\n1777.799s: in ways that are just generally uh\n1780.559s: implicated and the things that we think\n1781.88s: about in terms of social inequalities\n1783.98s: but also in ways that have implications\n1786.08s: for both climate adaptation and your\n1787.64s: work\n1788.899s: um we will focus on strategic planning\n1791.0s: development implementation and\n1792.559s: accountability and also thinking about\n1794.84s: ways to offer ongoing support for your\n1797.419s: decision-making problem solving and\n1800.24s: strategy building and then thinking\n1802.82s: about how we have influence beyond what\n1805.039s: we're doing here at least so committed\n1806.899s: to documenting and disseminating what\n1809.659s: we're learning here so that other people\n1811.64s: can benefit from from what we're doing\n1814.46s: I just wanted to highlight sometimes\n1816.44s: people use this acronym of Jedi we've\n1818.6s: used it on occasion as well Justice\n1820.94s: Equity diversity and inclusion just to\n1823.34s: make a distinction about what those\n1824.899s: different components mean they're not\n1826.94s: the same thing so Justice would think\n1829.1s: about repairing past harms Equity would\n1831.919s: think about systems outputs that prevent\n1834.26s: future harm\n1835.539s: diversity is really about Recruitment\n1837.919s: and representation and inclusion we're\n1839.96s: thinking about culture climate\n1842.84s: Etc\n1844.34s: so what do I mean by anti-racism uh\n1847.159s: thinking about anticipating and prevent\n1849.26s: preemptively avoiding racial inequities\n1851.299s: and systems and in our behaviors and\n1853.94s: what I mean by racial inequities is that\n1856.039s: anytime we observe a pattern by race\n1857.96s: we're dealing with the racial inequity\n1860.179s: right we're observing a pattern uh at a\n1862.94s: population level or that's repeating\n1864.799s: over periods of time we would think that\n1867.44s: that's not due to the group itself\n1869.36s: there's probably something else\n1870.74s: underlying that and would frame that as\n1872.72s: an inequity\n1874.24s: anti-oppression is just a broader frame\n1876.5s: thinking about anticipating and\n1878.299s: responding to social cultural and\n1880.159s: interpersonal barriers to access based\n1882.799s: on social positionality\n1885.5s: so why are we do we have this emphasis\n1888.08s: on Race so one there's a general lack of\n1890.659s: competence and a resistance to having\n1893.779s: that incompetence corrected uh related\n1896.48s: to issues of race and racism there's a\n1898.34s: pretty broad psychological literature\n1900.08s: that documents people in the United\n1902.24s: States in particular\n1904.24s: underestimate racial inequities across a\n1907.34s: number of social metrics and resist data\n1910.46s: that attempts to correct their\n1911.6s: misunderstandings and so given that\n1914.24s: there's a need to emphasize and dissect\n1916.46s: race and racism specifically also when\n1919.039s: we're thinking about Earth sciences and\n1920.659s: geosciences we know that you have over\n1922.76s: four Decades of data indicating a severe\n1925.7s: lack of representation along the lines\n1927.679s: of race and retention and uh you know no\n1932.84s: progress whatsoever on on that\n1935.24s: particular indicator for about 40 years\n1937.88s: and so given the data suggesting that\n1940.82s: this is a sticking point in the\n1942.679s: disciplines that intersect with leap it\n1945.2s: make sense to think about this as a\n1947.659s: specific challenge that we need to\n1949.1s: address we also know that colorblind and\n1951.98s: race neutral Dei approaches are not\n1954.38s: effective when you know that when we\n1956.419s: think about Dei as a generic undertaking\n1959.419s: we tend to see more progress for women\n1961.399s: white women in particular and we're less\n1964.039s: successful with other groups when we're\n1965.779s: not thinking about them specifically in\n1967.64s: our efforts and in the landscape of\n1970.58s: social inequity and oppression racism is\n1972.62s: an anchor that intersects with and\n1974.419s: exacerbates all other inequities anytime\n1977.12s: you introduce race into a model that's\n1979.58s: trying to document social inequity the\n1981.919s: worst outcomes are for groups that\n1984.2s: represent particular\n1986.14s: racial positionalities and so we know\n1989.0s: that that changes uh the likelihood of\n1992.24s: progress the likelihood of access Etc\n1994.279s: significantly so it's important for us\n1996.5s: to think about it as a distinct\n1997.7s: phenomena\n1998.84s: what we're not focused on is training uh\n2001.539s: we're not focused on unconscious bias\n2003.279s: and we're not focused on convincing you\n2005.26s: that Dei matters you're a part of leap\n2007.299s: and it's assumed that you're on board\n2008.86s: with this as being Central to the work\n2010.899s: of understanding climate adaptation and\n2013.419s: addressing the climate crisis\n2016.36s: so I wanted you to to know that there\n2018.64s: are several resources I'll share these\n2021.22s: slides in the slack channel so that you\n2023.919s: have all the links we've been developing\n2025.899s: a list of resources reading ways in\n2028.84s: which you can engage on your own around\n2030.88s: best practices related to recruitment\n2032.98s: lab cultures and climate Etc I encourage\n2036.82s: you to take it upon yourself and and\n2039.519s: have some agency\n2041.679s: um in in Consulting these resources in\n2044.799s: addition to General kind of uh empirical\n2048.22s: um and think pieces related to these\n2050.679s: issues specifically related to climate\n2053.619s: um uh we'll engage in the strategic\n2056.02s: planning and development process in part\n2058.0s: two and we also have Dei office hours\n2060.82s: which are on Thursday I'll send all of\n2062.8s: this information out and remind you but\n2065.2s: the way that I would suggest you use\n2066.879s: this is are how people have used it in\n2069.099s: the past is you have a question about\n2071.679s: recruiting where should you go to try\n2073.78s: and diversify your pool of candidates\n2076.3s: how might you write your job description\n2078.82s: differently to try and maximize\n2082.2s: attention from a more diverse pool of\n2085.599s: candidates there might be particular\n2087.7s: issues that are coming up in your work\n2089.5s: uh even in terms of your service that's\n2092.619s: happening at the University that I might\n2095.139s: be able to support and I'm happy to do\n2097.119s: that\n2098.38s: um we're also in the process of\n2099.88s: developing a code of conduct and as\n2102.16s: Pierre mentioned on day one issues\n2105.099s: related to conduct and ethics issues\n2107.68s: that might be coming up in your lab\n2108.94s: things that you would like to discuss\n2110.44s: related to climate in your lab I am\n2112.839s: definitely your point of contact for\n2114.4s: having those conversations and happy to\n2116.859s: support you there as well based on your\n2119.26s: initial serving input thank you to those\n2121.42s: of you who completed that who were\n2123.28s: basically wrangled into completing it on\n2125.8s: the bus a small group discussions and\n2128.68s: speaker series also seem to be of\n2130.119s: interest and I'll talk about that in\n2131.44s: just a moment as well\n2133.839s: um so just an overview of your initial\n2135.46s: responses we have a 21 responses uh as\n2139.18s: of uh um Sunday uh was it Monday I'm\n2143.5s: sorry I'm losing track of days\n2145.18s: yeah so you talked about I asked you to\n2147.52s: think about representation by race and\n2149.56s: gender and your disciplines\n2151.599s: um most of you identify that your\n2153.099s: disciplines are predominantly white and\n2154.72s: or Asian there are multiple references\n2157.3s: by you that there are zero or very few\n2159.64s: black people in your areas of study\n2163.02s: there seem to be more gender parity but\n2165.88s: it's clearly still an issue that\n2167.859s: representation but in particular the\n2169.9s: experiences that women are having once\n2172.359s: they're in these spaces are not always\n2175.06s: great and some of you have an\n2177.28s: understanding of why we would we're\n2178.72s: observing those patterns and some of you\n2180.28s: do not you self-identified yourselves as\n2183.7s: having pretty strong competencies and\n2185.56s: racism sexism and Dei and Society\n2188.079s: generally your self-identified growth\n2191.02s: points were around ableism and\n2193.18s: integrating Dei into your research\n2197.92s: so how are ways that you can engage so\n2200.32s: we're again starting off with what\n2201.7s: what's happening at leap in general uh\n2203.98s: consult this digital resource that we've\n2205.9s: been developing come to Dei office hours\n2208.48s: and seek support\n2210.28s: um though our futurist science group who\n2212.2s: presented this is a concrete way for you\n2215.02s: to engage in social impact that\n2217.42s: intersects with both Dei and knowledge\n2219.52s: transfer I know with some of you there's\n2221.92s: a struggle at times to really understand\n2224.44s: how your work on ice particles and\n2228.16s: clouds has implications for social\n2230.02s: impact and it does and I look forward to\n2232.66s: having those conversations more but this\n2235.0s: is an immediate way for you to engage\n2236.74s: and have impact if you say this is\n2238.3s: important to you and is it valuable to\n2239.92s: you here's a way through leap to to stay\n2242.2s: engaged\n2243.4s: um some of the themes that I'm thinking\n2244.599s: about related to small group discussions\n2246.579s: are ways in which you can connect the EI\n2249.04s: and anti-racism and social impact to\n2251.2s: your research ethical Community\n2252.64s: engagement further development around\n2255.16s: your strategic planning and thinking\n2257.079s: about your identity in positionality as\n2259.72s: it relates to your science so who you\n2262.42s: are and how you think about yourself as\n2264.7s: a person but also how you walk through\n2266.44s: the world your positionality and how\n2268.54s: that has implications for the work that\n2269.92s: you do\n2271.48s: um and then also for this again so\n2272.98s: further support to help you complete and\n2274.54s: Implement your strategic plan\n2277.96s: so hamster will I'd like us to get off\n2281.02s: of it we are stuck in this space of not\n2284.56s: seeing progress related to Dei\n2286.96s: especially around race and other markers\n2289.3s: and so what do we have to do why is it\n2292.48s: so hard to be diverse and Equitable and\n2295.359s: inclusive why does that require so much\n2296.92s: time resources and money why is that not\n2299.079s: naturally occurring and I think this is\n2301.24s: an important point for us to consider as\n2304.3s: a shortcut before I offer some food for\n2306.64s: thought I will assume that you don't\n2308.92s: believe that we have a Dei problem\n2310.48s: because some social groups by race or\n2312.64s: gender or what have you are just\n2314.32s: inherently smarter work harder than\n2316.48s: other social groups\n2318.22s: um that would be pretty racist for that\n2320.14s: to be the assumption that you're making\n2322.359s: so if that's not true if there are\n2324.28s: inherent differences in particular\n2326.38s: groups of people women black people Etc\n2329.2s: what else is going on that's producing\n2331.839s: these patterns that we're observing in\n2333.7s: our in our disciplines and in stem what\n2336.099s: is getting in the way of increase\n2337.98s: representation I'll also assume that\n2340.599s: you're aware that stem disciplines in\n2342.16s: general and Geo art Sciences in\n2343.66s: particular have a clear and stagnant\n2345.28s: race problem in particular that you\n2347.98s: believe Dei matters in society and\n2350.2s: Science and at leap and that you'd also\n2352.48s: like to get off of this hamster will\n2354.04s: that you'd like to see some progress if\n2357.16s: those these assumptions are inconsistent\n2359.26s: with your beliefs I'd love to have a\n2361.3s: chat with you\n2363.28s: so food for thought things for you to\n2365.44s: think about we won't discuss these\n2367.06s: things necessarily directly but we'll\n2368.98s: come to a discussion at the end\n2370.359s: following uh Christian's remarks so we\n2373.66s: have to first believe that change is\n2375.76s: possible\n2377.32s: you can't fix or meaningfully engage\n2379.96s: problems you don't understand that you\n2382.0s: aren't willing to name Define or defend\n2386.38s: implicit bias is not particularly useful\n2389.02s: as a point of intervention so uh a green\n2392.619s: Walt who was one of the three creators\n2394.24s: of the implicit attitudes task which is\n2396.16s: many of you may have taken you indicated\n2397.9s: on the survey that you've taken as it\n2399.4s: tells you how biased you are\n2400.839s: unconsciously\n2402.82s: um based on the millions of data points\n2405.4s: at this point that we have related to\n2407.14s: IAT data we know that implicit bias is\n2409.66s: pervasive we know that it shapes\n2411.46s: behavior and decision making but there's\n2413.5s: not any convincing empirical evidence\n2415.66s: that being aware of your bias actually\n2417.579s: shifts your behavior or that we can\n2419.56s: meaningfully reduce your bias over time\n2421.839s: it's not the place to invest our time\n2424.18s: and resources it's a bit of a sisyphean\n2426.28s: task pushing a boulder up a hill when\n2428.32s: it's rolling back down what creates the\n2430.78s: bodies and the first place what under\n2432.16s: what are the beliefs that underlie those\n2433.78s: biases are a more important thing for us\n2435.76s: to consider and think about Greenwall\n2438.04s: said I see most implicit bias training\n2440.32s: as window dressing that looks good both\n2442.18s: internally to an organization and\n2444.46s: externally as if you're concerned in\n2446.92s: trying to do something but it can be\n2448.96s: deployed without achieving anything\n2451.66s: which makes which makes it in fact\n2453.7s: counterproductive after 10 years of\n2456.04s: doing this stuff and nobody reporting\n2458.02s: data I think the logical conclusion is\n2460.359s: that if it was working we would have\n2461.859s: heard about it it's not we're not\n2464.68s: reducing bias in meaningful ways that\n2466.48s: last over time in spite of our spending\n2468.94s: millions of dollars uh related to\n2471.28s: implicit bias change training\n2474.579s: um another thing that gets in the way is\n2477.16s: uh system justification so there's a\n2479.619s: tendency to uphold the status quo\n2481.48s: because it's more comfortable the\n2483.46s: prioritization of comfort order and\n2485.68s: stability influences resistance of\n2488.32s: change and Alternatives especially if\n2490.119s: you're a member of the group that's not\n2491.98s: experiencing the brunt of Oppression and\n2494.26s: threat when we realize change is hard\n2496.96s: particularly but not exclusively those\n2499.0s: in dominant positions we're likely to\n2501.099s: frame the status quo as good enough\n2502.859s: legitimate and even desirable we have\n2505.96s: enough women we're good we have enough\n2507.76s: black people that's fine or we really\n2509.56s: tried we haven't seen any progress we\n2512.2s: might as well just keep focusing on our\n2513.76s: work and not dedicating any more time to\n2515.74s: that we're clearly not going to move the\n2517.54s: needle\n2518.74s: so what do we know that does work so\n2521.5s: discrimination elimination this gets a\n2523.54s: little tricky when we're outside of a\n2524.98s: corporate setting and we're moving into\n2526.3s: an academic context where we have things\n2528.22s: like academic freedom but once you've\n2530.74s: identified a problem that has to be\n2532.72s: solved it's up to administrators to\n2534.64s: figure out why how and where the\n2537.099s: problems are occurring expect because\n2539.5s: the data are clear here particularly\n2541.359s: regarding implicit bias that decisions\n2543.22s: that require subjective judgment will\n2545.32s: result in unintended disparities\n2547.42s: removing or limiting discretion with\n2549.579s: predetermined objective meaningful and\n2551.68s: rigorously applied criteria are less\n2553.9s: likely to produce disparities we know\n2556.119s: the places where if we are saying that\n2558.579s: implicit bias is pervasive everyone has\n2561.4s: bias this is asking us to anticipate\n2564.46s: that that is going to be true and try to\n2566.98s: create systems that counteract those\n2569.26s: biases rather than trying to remove the\n2571.72s: bias itself which is a much more\n2574.18s: difficult task but anticipating that\n2576.22s: when we have subjective power over or\n2579.22s: who we're choosing why we're choosing\n2581.079s: Etc this is where it becomes problematic\n2583.42s: so what I would like to do is help us\n2585.52s: think about more policies and systems\n2587.56s: that help standardize the ways that we\n2589.24s: engage this is why we remove names from\n2591.64s: resumes this is why we remove schools\n2593.56s: from resumes this is why we ask a\n2597.099s: standard set of questions to candidates\n2598.839s: when we're interviewing them so our bias\n2600.7s: is not entering in the ways that it\n2603.16s: could if we were just sort of winging it\n2604.96s: and going by the seat of our pants\n2607.66s: so questions for critical reflection are\n2610.3s: my beliefs about an understanding of\n2612.52s: racism rooted in emotion and gut\n2614.68s: instinct are thoughtful and critical\n2616.96s: reflection in education have you really\n2619.24s: read and thought carefully about this\n2620.8s: are you really just kind of going with\n2622.42s: what you've picked up along the way\n2625.0s: am I racially competent do I understand\n2627.76s: how racism functions in society I\n2631.119s: mentioned this not as some far-fetched\n2633.28s: uh you know group of people who are\n2635.98s: rallying uh and and claiming white\n2638.68s: supremacy I'm talking about it as a\n2640.599s: system that has created the lack of\n2642.819s: representation in geosciences and Earth\n2644.8s: Sciences do you understand that and how\n2647.38s: it has implications for you and your\n2649.0s: work\n2649.839s: if you believe racism exists and is bad\n2652.599s: who was responsible for doing something\n2654.46s: about it or simply believing if it's bad\n2657.4s: sufficient\n2659.68s: are my actions aligned with my beliefs\n2664.3s: do I value being perceived as a good\n2666.64s: person or not racist or not biased more\n2669.7s: than engaging the realities of racism am\n2672.22s: I more invested as being seen as someone\n2674.26s: who cares about these issues or am I\n2676.599s: more invested in actually doing\n2677.8s: something about it\n2679.78s: does my engagement of racism primarily\n2682.0s: take the form of intellectual exercise\n2683.619s: and symbolic gestures\n2687.04s: am I more comfortable talking thinking\n2689.319s: and casually disagreeing with racism or\n2691.359s: other social inequities then I am taking\n2693.579s: action against it\n2696.88s: what do I not understand where are my\n2699.4s: points of tension and resistance in my\n2701.68s: thinking about racism and about Dei\n2704.14s: generally\n2706.54s: at your institution lab and in your\n2708.64s: disciplines Etc where have you seen the\n2710.859s: most meaningful progress what has\n2712.72s: contributed to these successes what are\n2714.88s: have been effective strategies has there\n2717.339s: been more progress for some issues more\n2719.5s: than others some people more than others\n2721.72s: and why\n2724.0s: again at your institution lab and in\n2725.98s: your discipline what factors are\n2727.9s: impeding progress\n2730.78s: Beyond representation how does my\n2733.54s: specific area of research intersect with\n2735.52s: Dei social and racial equity and Justice\n2738.099s: and social impact\n2740.02s: it does for all of us and ultimately\n2741.94s: we're engaging the Earth in humans and\n2744.22s: trying to save the world there's a\n2746.02s: there's a there's a link between what\n2747.76s: you do and how things are working in\n2750.64s: society\n2752.68s: you have five minutes and five dollars\n2754.96s: where would you place your bet of\n2757.06s: limited time and resources for achieving\n2759.04s: your organizations or your personal Dei\n2761.68s: goals where would you start so when I\n2763.9s: talk about centering race I'm not saying\n2766.54s: that other issues aren't important or\n2768.099s: that we're completely ignoring gender\n2769.9s: and every other issue what I'm saying is\n2772.119s: that the data indicates we are doing the\n2775.06s: worst on that particular indicator in\n2777.819s: limited time and resources would suggest\n2779.98s: we may want to think about trying to\n2781.839s: move that specific needle not up to the\n2784.54s: exclusion of everything else but\n2786.099s: thinking about its significance in the\n2788.02s: work that we're trying to do\n2791.14s: I will share these slides again this was\n2793.3s: just meant for food for thought I'll\n2794.8s: share these as well as the best\n2796.42s: practices are part of this deck as well\n2798.16s: so you'll be able to reference those but\n2800.319s: I'd like to turn it over to Christian\n2801.76s: who has been engaged in this work for\n2804.7s: more than a decade now\n2807.28s: um yeah it has a lot to say about how\n2810.4s: this actually translates in his\n2812.44s: experiences as a climate scientist and\n2814.48s: engineer thanks for being here Christian\n2816.16s: thank you should I take the clicker\n2822.76s: powerful\n2825.46s: um\n2826.0s: yeah so thank you all uh for being here\n2829.359s: today and inviting me to speak I should\n2831.64s: have noted my experience is somewhat\n2833.5s: unique in that\n2835.9s: um I attended a liberal arts college uh\n2838.599s: Morehouse College where Martin Luther\n2840.28s: King attended as well as Georgia Tech\n2843.099s: so historically black college and a\n2845.14s: predominantly white Institution\n2847.24s: and when I was at Morehouse I actually\n2848.56s: studied abroad in Japan\n2850.319s: twice uh kind of minored in Japanese and\n2855.04s: did research in a Japanese research lab\n2857.56s: one summer so I've worked in different\n2859.839s: contexts\n2861.22s: and for sure the biggest difference for\n2864.16s: my experience at Morehouse to Georgia\n2865.54s: Tech is that the faculty looked at me\n2867.7s: like I could be their son you know\n2869.26s: whereas that uh Georgia Tech was very\n2871.78s: clear there was not this cultural\n2874.119s: connection uh they were surprised I was\n2876.76s: there you know things like that so it\n2878.92s: was very distinct so I just want to\n2880.66s: clarify for you if you if you think that\n2882.4s: there isn't a difference in the\n2883.72s: experience a black suit is just distinct\n2885.819s: I actually felt more welcomed in the\n2889.119s: Japanese environment than an American\n2891.52s: environment uh and a predominantly white\n2893.74s: institution you know for context\n2897.04s: um but I want to give you some clear\n2898.72s: examples so\n2900.16s: um\n2900.76s: I was fortunate enough to go to Durban\n2902.68s: South Africa in 2019 and\n2905.319s: I went for\n2908.56s: um\n2909.22s: a climate adaptation workshop and what\n2911.619s: was interesting about it is I had a\n2913.839s: colleague joined me from America and\n2916.0s: Italy and I was the only black person in\n2920.079s: this delegation but we're going to this\n2921.579s: you know this this country full of black\n2923.74s: folks\n2925.18s: um and so we're super excited we're\n2926.619s: gearing up for the workshop I'm\n2927.94s: analyzing like outputs from GCM models\n2931.18s: you know we're trying to give them a\n2932.319s: sense for sea level rise and extreme\n2933.94s: heat conditions and my colleagues are\n2936.94s: mostly Architects that do work that\n2939.64s: intersects with micro climate and they\n2941.5s: want to tell them how can they you know\n2943.48s: change how their cities are designed and\n2945.579s: and make design interventions right\n2948.339s: so you know this just for this\n2950.8s: discussion I'm going to focus on\n2951.88s: procedural Equity um you know how much\n2953.859s: are we involving the public how much are\n2955.78s: we engaging\n2956.98s: folks in the adaptation process but\n2959.26s: anyway we gear up for this Workshop\n2961.359s: um we go to Durbin in February\n2964.3s: and we actually have briefings\n2968.8s: um uh with City staff and then we meet\n2972.28s: with Community leaders well I want to\n2974.68s: but I want to tell you this this part\n2976.78s: before I get into the Department of\n2977.92s: Community leaders\n2979.3s: um\n2980.02s: a fascinating thing happened where every\n2982.42s: meeting we had\n2984.339s: uh with the city staff this is the city\n2987.099s: of Darwin staff started with explaining\n2989.56s: apartheid\n2990.819s: and at the first meeting you know I'm\n2992.92s: looking and I can kind of see my white\n2994.48s: colleagues Fringe when they say like\n2996.579s: apartheid you know and it was like I\n2999.22s: could have had some popcorn I was just I\n3000.78s: was like oh this is delicious like and I\n3003.48s: was just I was like wow this is\n3004.619s: interesting you know thinking about them\n3006.66s: being in this environment where they're\n3007.859s: the minority and where people aren't\n3009.96s: uncomfortable talking about racism\n3012.18s: so then the second session the second\n3014.22s: briefing again this is a climate\n3016.44s: adaptation Workshop\n3017.88s: guys we just want to start off and talk\n3019.74s: to you about apartheid and how we're\n3021.3s: trying to undo apartheid\n3023.52s: and by the end every single session\n3025.68s: whether it was a black South Africa and\n3027.66s: a white South African they always\n3028.98s: started talking about apartheid and how\n3031.26s: they're trying to undo apartheid\n3033.54s: by then it was clear\n3035.4s: they also trusted me the blacks office\n3037.5s: actually trusted me more and would talk\n3039.119s: to me more than they would my colleagues\n3041.46s: from Italy and America and what I\n3043.74s: realized by the end was that they were\n3044.88s: like oh we want to make it clear we're\n3046.26s: serious about undoing our part High we\n3048.72s: know you're not serious in America about\n3051.059s: undoing your apartheid you know I mean\n3052.619s: that was really the message they were\n3053.88s: kind of sending in the end like we know\n3055.8s: you're not serious about addressing\n3057.48s: racism but we're really serious about it\n3060.0s: and the context in South Africa is that\n3062.88s: they actually invested resources and\n3064.8s: infrastructure in communities where\n3067.079s: folks that identified as white lives as\n3068.94s: opposed to other communities but you can\n3070.619s: also imagine you're investing in people\n3072.0s: and who gets education and those things\n3074.579s: as well and that that's reflects in our\n3076.26s: society so anyway I just wanted to get\n3077.64s: that caveat that\n3079.74s: um that we could actually be in a\n3082.079s: society and folks are doing work in this\n3084.3s: space and they do talk about racism and\n3086.46s: they and they prioritize it in the very\n3087.9s: beginning you could think of that as\n3089.28s: being anti-racist\n3091.26s: um in their approach\n3093.0s: when one thing that came up though was\n3095.16s: that\n3096.18s: um in this part of Durban there was a\n3098.46s: Transit camp and in South Africa if\n3102.24s: you're not familiar everyone's\n3103.68s: guaranteed access to housing and so when\n3106.559s: the World Cup happened there some folks\n3108.54s: were displaced all those folks were\n3111.359s: basically in an informal settlement and\n3113.88s: they're still waiting to get their\n3115.319s: housing and they were upset about it and\n3117.18s: so as we're gearing up to come to Durbin\n3120.66s: the city officials are telling us hey\n3122.579s: you know there might be some protesters\n3124.079s: there there's folks that live in this\n3125.94s: Transit Camp we'll have to watch out for\n3128.64s: them and what I said was hey let's\n3131.16s: invite them to the workshop uh and they\n3134.099s: were like no they've been burning tires\n3135.9s: and blocking roads you know they're just\n3137.76s: really kind of troublemakers\n3139.619s: and I was like no like we need their\n3141.66s: opinion and their voice at the workshop\n3143.339s: so I made sure they came to the workshop\n3145.02s: okay so this is and that's actually some\n3148.319s: of the folks in that Transit pepper\n3149.579s: actually on the right in that front\n3150.96s: table I sat at that table and we made\n3153.359s: sure their inputs and their ideas kind\n3156.0s: of drove our work\n3158.28s: um what we did is if you click on this\n3160.38s: list we asked everyone in the room which\n3162.54s: included the folks in the transit Camp a\n3164.52s: business owners City officials you know\n3166.859s: what are what are the challenges for the\n3168.78s: city of Durban\n3170.16s: are this this District in Durban called\n3172.26s: isipingo and what are opportunities and\n3175.68s: then we match those challenges and\n3178.26s: opportunities you know this is just high\n3179.64s: level this has nothing to do with\n3180.839s: climate science two ways we two\n3183.96s: different um approaches we have for\n3186.24s: changing the built environment to\n3188.28s: address extreme heat and flooding right\n3190.559s: so those are the deficiency of the urban\n3192.42s: system the form and layout\n3195.0s: uh using heat resistant construction\n3197.04s: materials using vegetation cover and we\n3198.9s: basically took things from the left and\n3200.28s: moved them to the right and tried to\n3201.359s: figure out where there was alignment\n3203.16s: and this is where we should focus our\n3204.78s: research and our work okay so so just\n3206.76s: wanted to give you this concrete example\n3208.44s: of one The Learning Experience for my\n3211.079s: colleagues uh and and really kind of the\n3214.319s: learning about about how you could\n3216.0s: actually Center racial equity and racism\n3218.46s: anti-racism in your work and then also\n3220.14s: just how we brought in the community\n3221.339s: perspective\n3223.26s: um to some extent much to the Chagrin of\n3226.38s: the city staff although it went better\n3227.64s: than the city said I thought and things\n3229.319s: went smooth and I think we had a better\n3230.7s: outcome\n3231.78s: as a result so just giving this this\n3234.78s: example from beverage I love this\n3236.22s: example from Darwin\n3237.839s: um because it just yeah why not just\n3240.18s: have all these great memories\n3242.579s: um of the stories about apartheid but\n3245.46s: also just just love that we were able to\n3247.859s: bring in like the most marginalized\n3249.3s: group in this it's a Pingo District into\n3251.4s: this world\n3254.16s: the second example I want to give you\n3255.66s: now is bring it home to New York City\n3257.04s: and again we're talking about procedural\n3258.42s: Equity this is this is an image using\n3260.52s: NASA landsat data to map land surface\n3263.819s: temperature uh in New York City this is\n3266.099s: using landsat 8.\n3268.2s: um and so\n3270.18s: uh you know recently NOAA has a\n3273.059s: initiative where they get community\n3275.819s: members to actually map the urban heat\n3277.74s: island in their cities you may have\n3279.0s: heard of this so you go around with\n3280.859s: temperature and humidity sensors uh you\n3283.74s: attach them to your cars or your bike or\n3285.78s: you walk and I was interested in doing\n3289.079s: this in New York but I wanted to make\n3291.3s: sure we actually and you know involved\n3294.74s: involve Community organizations from the\n3296.88s: beginning\n3297.559s: and so what I did is I said let me find\n3300.839s: a community group this is true I'm gonna\n3303.059s: give you this is this is with Columbia\n3304.2s: so I'm going to give you just a real\n3305.4s: example here\n3307.079s: um I at least after we act because we\n3309.24s: Act is interested in extreme heat\n3311.16s: they're they're based in Northern\n3312.72s: Manhattan it's an environmental justice\n3314.22s: Focus organization\n3315.599s: a new couple leaders there\n3319.5s: um they they engaged me a little bit but\n3321.119s: said they they were moving on and they\n3322.74s: were focused on other things\n3324.42s: and so I actually was ready to give up I\n3327.059s: reached out to a colleague Liv Yoon who\n3329.339s: was a postdoc now faculty at University\n3331.859s: of British Columbia and she had a\n3334.14s: relationship with organization called\n3335.4s: South rocks unite which actually focuses\n3337.319s: on air quality and so because she\n3339.54s: already already had that relationship\n3342.059s: um we we started talking to them about\n3343.68s: what the project could look like so\n3345.54s: again we we before we before we submit\n3348.599s: the proposal before we sculpt the\n3350.04s: project we found a community partner so\n3352.14s: this is important to remember usually\n3353.52s: academics faculty you design the entire\n3355.68s: initiative the work that God responding\n3357.9s: to the proposal you're like oh let me\n3359.22s: get a letter of support from a from a\n3361.14s: community-based organization you know\n3363.24s: now what we did is at the very beginning\n3364.619s: as we're designing the project we\n3366.9s: engaged South Carolina Street night and\n3368.339s: I think it was even if we can't get them\n3371.04s: involved with this particular NOAA um\n3374.4s: solicitation we'll get them involved in\n3376.26s: the future we're starting the\n3377.28s: relationship we're starting a\n3378.48s: partnership\n3380.4s: um what happened is they actually helped\n3382.079s: us design the study because they said\n3383.94s: they actually told us hey you should go\n3385.559s: down these streets as opposed to these\n3387.18s: streets as you collect data for these\n3389.64s: reasons\n3390.78s: um I could talk about those reasons\n3391.859s: later but what's interesting they\n3394.14s: actually helped us make the study better\n3396.0s: by Design\n3397.619s: and one thing I did and I and I one\n3400.02s: thing I often do because I don't work\n3401.64s: for Columbia I just kind of work with\n3403.8s: Folks at Columbia as I tried to find\n3406.26s: fundings we could pay committee members\n3407.88s: for the time whereas most of the north\n3410.22s: campaigns the community members are\n3411.66s: volunteering their time right and that\n3413.099s: makes sense right because the folks at\n3414.48s: NOAA they get paid to do this you guys\n3416.28s: faculty post-docs students actually get\n3419.339s: paid in a way to do these studies and\n3420.96s: these work\n3422.339s: um so I actually found money at Columbia\n3423.78s: to pay community members\n3425.94s: that helped us recruit uh more community\n3428.52s: members when we when we went out in the\n3430.079s: field to collect the data and what I\n3432.359s: should notice there was another campaign\n3434.04s: plan in Brooklyn\n3436.319s: um that campaign failed because they\n3437.76s: didn't get enough Community Support they\n3439.02s: didn't have enough volunteers to go out\n3440.7s: with them they used they and I actually\n3442.92s: talked to the leader of that campaign\n3444.42s: I'll show a picture of her later she\n3446.16s: acknowledged us because they didn't do\n3447.42s: enough media engagement\n3449.64s: um so we went we go out in the field\n3452.16s: and and we trained folks beforehand and\n3454.68s: they put the potassium sensors to their\n3456.359s: cars\n3457.26s: um if you're not familiar with this this\n3458.7s: is this effort uh involves Vivek\n3461.04s: shaundice at Portland State University\n3462.8s: basically they use sentinel data land\n3465.599s: cover data\n3468.059s: um as well as the day we collect in the\n3469.619s: ground and some different machine\n3472.02s: learning techniques to basically map the\n3474.3s: urban heat island\n3475.68s: and on the left you can see the\n3477.359s: different uh the different routes we\n3479.76s: took from three to four pm that day this\n3482.88s: is the modeling of of how\n3486.3s: heat is distributed\n3488.28s: what's interesting about this is the\n3490.079s: community partner suggests that we not\n3491.94s: just focus on the south rocks but\n3493.5s: compare it with Northern with the area\n3495.839s: around Central Park compared with the\n3497.22s: area around Columbia and this was where\n3499.92s: social equity and social justice came in\n3502.079s: come came to play because really the\n3504.48s: question is not necessary with the\n3506.64s: absolute air temperature humidity is but\n3508.26s: the question is what's the disparity you\n3510.42s: know who's getting different exposure\n3513.839s: um and why are they getting different\n3514.92s: exposures because of trees because is it\n3516.839s: because of the design so in this way\n3518.88s: they actually improved that improve the\n3520.68s: routes we chose but also improved the\n3522.599s: study overall this is worth by working\n3524.579s: with this community these Community\n3525.839s: Partners\n3527.46s: um what I once want to note for the\n3528.9s: faculty in particular because this may\n3531.299s: not you may be wondering like this\n3532.859s: helped me get tenure and help me advance\n3534.119s: it's got lots of press people think I'm\n3536.76s: faculty at Columbia because of this\n3538.38s: project actually you know I'm not\n3540.72s: faculty at Columbia people think I am\n3542.4s: because of this project uh because of\n3544.68s: all the Press got Soledad O'Brien CNN\n3548.16s: all these folks because of what it\n3550.559s: revealed but also\n3552.18s: um the buy-in we have from the community\n3553.68s: as we did it and I would obviously say\n3556.02s: all the growth that the faculty and\n3557.64s: students involved receive by being part\n3559.98s: of this process\n3561.0s: um and this is being published this work\n3563.76s: is part of work I'm doing for New York\n3565.14s: City depend on climate change that will\n3566.579s: be Pub that's will be published this\n3568.26s: year\n3569.52s: um in New York Academy of Sciences this\n3572.04s: inspired me to do work on redlining and\n3575.04s: how redlining intersects with land\n3577.38s: surface temperature many of you guys may\n3578.76s: be familiar with redlining it's just\n3580.859s: practice in the 1930s where people\n3583.14s: received federally backed home mortgages\n3586.68s: um when you uh when you look at the data\n3588.24s: closely you actually see handwritten uh\n3591.0s: documentation where they say don't\n3592.319s: invest you know don't don't provide\n3595.02s: mortgages in this community because if\n3596.4s: black people live there don't don't\n3597.66s: provide mortgages could support three\n3599.16s: good people if you don't provide\n3600.48s: mortgages because Jewish people live\n3601.68s: here so these federally backed mortgages\n3604.799s: um where we're distributed in a racist\n3606.359s: manner we know in the U.S wealth is\n3609.119s: generated by by purchasing pumps right\n3611.7s: so we actually we know that there's huge\n3613.5s: wealth implications of this work I think\n3615.119s: California actually instead of study\n3616.74s: calculated reparations\n3619.02s: um for black people associated with the\n3621.42s: same to California based on this work\n3623.24s: but anyway I I was interested in\n3625.76s: unpacking this for New York City\n3628.799s: and there was already stuff published on\n3631.26s: this but my colleagues at Nasa\n3634.319s: um were not interested you know what I\n3635.94s: mean and and as Corey kind of explained\n3638.339s: most of my colleagues in NASA identify a\n3641.46s: lot of them identify as white a lot of\n3642.72s: them are not people of color and they\n3644.88s: would not touch this and I was shocked\n3646.26s: because this had been published this\n3647.46s: worked with similar work to the\n3648.839s: published in climate the Journal called\n3650.76s: climate and sounds like based on this\n3653.339s: work I've done with South Bronx tonight\n3654.48s: I bet even in New York City where\n3656.7s: there's been so much change since the\n3658.44s: 1930s I bet we'll find a similar pattern\n3660.78s: sure enough we we unpack the data and if\n3664.68s: if low grades are radial for D so these\n3666.839s: are areas where the homeowners loan\n3668.64s: corporations that do not invest\n3670.68s: in areas with a are areas where you\n3674.04s: would you should invest you see that you\n3676.319s: have higher land surface temperatures in\n3678.42s: the poorly rated areas across New York\n3681.48s: City\n3682.26s: and and then what we also found is that\n3684.359s: when you look at the normalized\n3685.38s: difference vegetation index which is\n3686.94s: index it helps you understand vegetation\n3689.64s: abundance and vegetation Health you see\n3692.04s: less lower mdvi so in theory less\n3694.74s: vegetation\n3696.24s: um and air support raise and this is\n3697.799s: consistent with the previous slide you\n3699.78s: know more heat more heat exposure less\n3702.48s: vegetation less Green Space so anyway my\n3705.48s: work with soft rocks unite\n3707.4s: um pointed me towards this this research\n3709.98s: even though my colleagues at Nasa gifts\n3712.68s: were uncomfortable with this research\n3714.18s: when my students and team would\n3716.099s: presented sometimes when I wasn't there\n3717.66s: they would tell them oh you know you\n3718.799s: should take the word racism out of your\n3720.72s: slide or things like that and I had to\n3723.0s: push back on that just really realizing\n3725.339s: that you know back to my Durban example\n3727.5s: just my colleagues to identify as white\n3729.24s: are very uncomfortable talking about\n3731.099s: race and racism\n3732.66s: and I did my own homework and research\n3735.119s: and realized that\n3737.4s: um you know we're all kind of\n3738.599s: socializing us not to talk about race\n3740.28s: and racism but particularly in white\n3742.14s: households it's likely that your parents\n3744.66s: never will talk to you about anti-black\n3746.64s: racism or white supremacy the entire\n3749.28s: time you grow up even if you ask about\n3750.9s: it even if you ask about a Rodney King\n3753.18s: or\n3754.799s: um I know the incident most my parents\n3757.14s: will not talk about racism they might\n3759.059s: say oh there's some bad people they\n3760.74s: won't explicitly talk about anti-black\n3763.5s: racist and the white supremacy so this\n3765.359s: this is natural to some extent\n3768.059s: um but you know we have to understand\n3770.339s: how this intersects my work and this is\n3771.96s: just kind of a really clear example\n3773.339s: where this is published work where\n3774.78s: people are getting research funding to\n3776.88s: explore this work where this has\n3778.619s: important implications for how we design\n3780.18s: cities how we think about microclimates\n3782.16s: uh but this is something my colleagues\n3784.02s: at Nasa had really overlooked\n3786.48s: um and and could make this work could\n3787.98s: have been done really years ago\n3789.66s: huh\n3791.28s: all right\n3793.14s: um so I want to talk a little about some\n3794.819s: best practices real quickly and mostly\n3797.04s: I'm just going to point you towards a\n3799.859s: resource that you can use again I'm\n3802.98s: really interested in anti-racist in my\n3805.02s: work so creating racial Equity\n3807.319s: addressing racial inequities\n3810.299s: um I'm I'm less of the diversity and\n3812.339s: inclusion export expert per se that's\n3815.099s: definitely where Dr Cog Burns expertise\n3817.559s: but I've been really successful with a\n3820.859s: diversifying climate science and\n3822.42s: integrating racial equity in my work so\n3824.04s: I have I'm hopeful that uh you know I\n3827.52s: can answer questions and give you more\n3829.079s: insights later\n3830.88s: um this is a great source this is Ali at\n3833.94s: all where they talk about six essential\n3836.04s: constructs for effective anti-racism\n3839.46s: and you know there's there's a variety\n3841.799s: of things on here I think on your own\n3843.359s: you should take a look at this and and\n3845.16s: see what applies well to you\n3847.799s: um one thing to note as you have a\n3850.319s: research lab it's important let's talk\n3852.359s: about race because race May intersect in\n3853.98s: ways you don't you don't realize\n3856.559s: um so for example I was and during my\n3859.02s: PhD doing uh I got sent to South Georgia\n3861.599s: to collect data from farmers in south\n3863.76s: Georgia\n3865.2s: um my my research advisor European uh\n3868.74s: folks of my um research team East Asian\n3871.92s: and European and white white American\n3874.38s: and they didn't occur to them that is it\n3877.02s: actually safe for Christian to go to\n3879.24s: South Georgia to collect this data now I\n3882.599s: was fully aware and everyone in my my\n3884.52s: circle was like be safe\n3887.0s: I'll be travel during the day you know\n3890.04s: do these things uh there's there's Clan\n3892.92s: down there there's there's all these\n3894.299s: folks you need to be worried about I\n3895.98s: have family from South Georgia so I'm\n3897.359s: very aware of the culture\n3900.119s: um but it never came up to them it never\n3902.04s: came up to them that this actually could\n3903.48s: be a safety risk for me to do this work\n3905.52s: so you need to but if you can't ever\n3907.079s: talk about race it will never come up so\n3910.14s: take but take a look at this that's a\n3911.4s: real example that can offer from my\n3913.68s: experience\n3915.359s: um this also this work by chaudry on 10\n3918.18s: simple rules for building an anti-racist\n3920.099s: lab\n3920.88s: take a look at this one thing I would\n3922.619s: just point out to you and again this is\n3924.18s: on the safety the safety side\n3928.02s: um I've had my colleague live you Mrs\n3931.02s: true story who's at who's at University\n3933.24s: of British Columbia it's actually told\n3935.22s: me she left New York and went back to\n3937.859s: Canada before she finished her post-op\n3939.66s: because of racist attacks she was\n3941.64s: receiving you know anti-asian hate type\n3944.7s: experiences she was receiving here and\n3947.4s: this is the postdoc uh this is not like\n3949.44s: and this is not like years ago this is\n3951.42s: just like a year ago\n3953.059s: so and and I wonder how many of you\n3956.22s: during that time here were talking to\n3957.96s: your post and hopefully this was\n3959.28s: happening but when we think about racist\n3961.5s: violence against\n3963.359s: um and I can give you examples from my\n3965.22s: time as well in undergrad and grad\n3967.14s: school this is not like Far and Away\n3968.819s: this is not a long gone thing this is\n3970.859s: happening in present day\n3972.839s: um so again you have to be open and and\n3975.119s: make yourself available to talk about\n3976.799s: race and racism\n3979.38s: um and one thing I would know you know\n3981.599s: this came up quite a bit uh of doing my\n3985.14s: work is the collaboration Networks\n3987.48s: you're part of you'll think a lot about\n3989.28s: how to create opportunities for folks to\n3990.839s: get grants\n3992.46s: um in Publications and one thing I'll\n3994.98s: note two is that uh before I far closed\n3998.64s: I'm probably over again is that in my\n4001.819s: experience where I was the only the only\n4003.98s: African-American student in my program\n4006.4s: my research lab actually didn't have any\n4008.72s: Americans other than me uh for the most\n4011.599s: part it's pretty much all folks from\n4012.92s: East Asia Africa our Europe\n4016.819s: um but I was the only African-American\n4018.079s: in the entire environmental School of\n4019.88s: mechanics and Water Resource program\n4021.799s: when I was there\n4023.599s: um the unique experience I had was that\n4026.359s: I would say almost every Professor I had\n4029.24s: told me I solved a problem in a way that\n4031.88s: no other student it had it ever solved\n4034.22s: these are fluid mechanics problems these\n4035.9s: are statistics problems and you know I\n4039.079s: would say I think part of that is just I\n4040.46s: had different training I have a\n4041.48s: different background than them I'm\n4043.76s: approaching the problems in different\n4045.319s: ways and this is this is a common thing\n4047.299s: if you go to this article you'll see the\n4049.7s: references where students at the margins\n4052.52s: students from underrepresented\n4054.319s: backgrounds actually come up with novel\n4055.76s: Solutions right they're avoiding the\n4057.079s: group think that often happens and I\n4060.74s: often see this in my own experience with\n4062.299s: my students so just want to also point\n4064.52s: out the value proposition around\n4066.02s: innovation in your research that comes\n4068.359s: from diversity\n4072.2s: thank you yes so we want to uh open it\n4075.14s: up to get your reactions and thoughts\n4077.119s: and I know we're putting a lot on your\n4078.68s: plate but want to see how you're feeling\n4081.38s: um you know just to quickly add that you\n4083.72s: know this is not fun to talk about we\n4085.52s: don't enjoy doing it I'd rather be doing\n4087.079s: my research I'm sure you'd rather be\n4089.18s: doing yours but this is a part of our\n4092.78s: reality in terms of uh people who care\n4096.02s: about the world that we that we occupy\n4098.179s: and I'm assuming you're one of those\n4099.259s: people and this is this is a critical\n4100.88s: piece of it and so uh you know we want\n4103.94s: to support your journey and continue on\n4105.92s: our own Journeys related to this work so\n4108.38s: we've highlighted what we're doing here\n4110.179s: at leap we've offered some food for\n4112.04s: thought to question and challenge your\n4113.9s: own beliefs uh Christian has offered\n4117.62s: concrete examples of the ways in which\n4119.779s: the EI and anti-racism can intersect\n4121.819s: with climate adaptation research and\n4124.819s: we've offered some best practices and\n4126.38s: again there's a whole host of resources\n4128.06s: in addition to the ones that we've\n4129.44s: shared that we will will make available\n4131.66s: to you\n4133.279s: um and then we'll move into thinking\n4134.9s: about strategic planning we see this as\n4136.58s: being foundational to your ability to\n4138.5s: think about who am I what are my spheres\n4141.5s: of influence what can I actually do\n4143.48s: what's in within my realm of power and\n4145.46s: influence to do something about\n4147.739s: um and what am I going to do right so\n4149.66s: we're trying to set up our conversation\n4151.94s: for that\n4153.08s: um I think for the sake of time I'll\n4154.339s: save the spheres of influence reflection\n4156.319s: and move that to the second part but I\n4158.239s: would like to open it up and get your\n4160.16s: reactions and thoughts and the ways and\n4161.96s: what's coming up for you and ways in\n4164.299s: which this is intersecting with with\n4165.859s: your life as as a researcher and\n4167.779s: scientist\n4173.42s: you have Johnny in the back\n4185.9s: but being here to talk about this my\n4188.66s: reaction was um partly about the\n4191.96s: implicit bias side of things and I I'm\n4194.299s: somebody who's all in the past I've been\n4196.58s: aware of this idea that it's actually\n4198.56s: not as helpful as we might have\n4200.9s: initially thought but it's really\n4201.98s: interesting to hear you say Courtney\n4203.42s: that has just now been seen as it is not\n4205.52s: useful at all because in the past in\n4207.679s: various committees I've been with\n4209.06s: somebody who's advocated for it and just\n4211.04s: speaking from my own experience I\n4212.48s: actually personally found it very useful\n4214.58s: so that's my reaction I'm saddened to\n4217.34s: hear that it's not you know on a broader\n4219.14s: scale it's not seen as useful at all\n4220.58s: interesting and sad to hear that and I\n4223.52s: guess\n4225.44s: I mean for example like the recruitment\n4228.02s: stage\n4229.1s: being aware of your implicit bias like\n4231.14s: you said allows you to put in in a\n4234.199s: system like a like a rubric or something\n4236.48s: to avoid you just relay relying on your\n4239.0s: own Instinct and I guess that was the\n4241.28s: way the way that I always thought\n4242.36s: implicit bias training really helped but\n4245.36s: yes but in a broader sense it's not\n4247.159s: really making any difference which is\n4248.54s: just you know it's unfortunate\n4250.46s: unfortunate no it does that action to\n4253.219s: what's helpful about implicit bias\n4255.02s: research is that we know how pervasive\n4256.94s: it is and that it influences your\n4258.86s: behavior what we don't have empirical\n4260.659s: evidence for is that your awareness is\n4262.88s: the thing that changes your behavior you\n4265.46s: have to take some conscious step to\n4267.56s: implement a strategy to overcome your\n4269.48s: own bias so creating a rubric blinding\n4272.36s: resumes Etc is an action that helps\n4274.76s: overcome your bias that's really useful\n4277.28s: um but simply being aware that I might\n4279.08s: be biased in and of itself is not useful\n4282.32s: and then efforts to actually reduce bias\n4284.54s: there's not empirical evidence to\n4286.219s: suggest that that is sustainable\n4289.34s: that makes sense\n4292.4s: it's another question in the back\n4301.94s: uh thanks for really great presentation\n4303.62s: thank you um one thing I was wondering\n4305.659s: about is how this interacts with like\n4308.42s: open source software and the community\n4311.3s: tools that like everyone here's work\n4313.64s: basically relies on like\n4316.28s: the data structure and machine learning\n4318.26s: libraries like they're all built in this\n4321.02s: weird way that that doesn't really exist\n4323.54s: in like the normal workplace where\n4326.12s: they're kind of mostly built out of like\n4328.34s: individual Spare Time contributions and\n4331.4s: then if they get big enough they end up\n4332.84s: with like corporate sponsorship\n4334.76s: and that model doesn't really map on\n4337.82s: very well to like a normal workplace\n4340.1s: like you don't have research groups\n4342.739s: where people just do stuff in their\n4344.179s: evenings and then once the research gets\n4346.1s: good then it gets funded\n4349.04s: um the other things weird about those\n4351.199s: communities from Like A diversity\n4353.659s: perspective is that it's all online and\n4355.58s: you don't even necessarily know who\n4357.08s: you're talking to like you don't\n4359.06s: actually have to put your real name\n4360.199s: anywhere\n4362.179s: um and\n4364.34s: but yet those communities are not\n4367.1s: diverse\n4369.26s: um and well partly because of those\n4371.06s: reasons and partly the things I don't\n4372.56s: understand and I guess I just wondered\n4374.179s: if you had like thoughts on any of that\n4375.98s: or like resources any of that because it\n4377.48s: does cross over a lot with like the work\n4379.28s: that you do here\n4380.54s: yeah I think one example is one that\n4382.28s: Christian gave around\n4384.199s: um insular collaborations and the people\n4386.12s: we tend to work with\n4387.92s: um\n4388.659s: realistically we know right empirically\n4390.86s: we know that white people in particular\n4392.36s: have very segregated networks most of\n4395.239s: you or most of you have very white lives\n4397.82s: both professionally and personally so\n4400.4s: then when you seek out people to work\n4401.9s: with for a hobby or a side project\n4404.06s: you're working you tend to work with\n4405.56s: people who look like you and your\n4407.48s: networks tend to be more segregated than\n4409.52s: other groups of people so it contributes\n4411.98s: in part to that kind of cycle I think\n4414.62s: part of how we're trying to address some\n4416.659s: of that with uh leave is say the suite\n4419.9s: of tools through the through Lee pangeo\n4421.88s: and trying to engage diverse\n4423.86s: stakeholders at the very beginning to\n4425.659s: say this is what this is how would you\n4428.12s: use this what kind of data do you need\n4429.92s: what kinds of questions do you have how\n4432.199s: might we set this up it makes it a\n4434.0s: little bit more accessible in terms of\n4436.1s: how to use it maybe we need to film a\n4438.14s: tutorial that helps people to work their\n4440.3s: way through it to get them started but\n4442.219s: we have to think very actively about who\n4444.26s: are we Consulting when we're thinking\n4445.64s: about the design of those tools in terms\n4447.86s: of user interface days for instance and\n4451.1s: how are we invested in making it as\n4453.02s: accessible and usable as possible in\n4456.02s: terms of do we take time we have\n4457.94s: dedicated to LEAP to create a tutorial\n4460.82s: or create a curriculum related to that\n4462.679s: tool so that it's also accessible\n4464.96s: because people have that that\n4466.28s: educational resource so that's one way\n4468.98s: to think about it\n4473.36s: so um I have a observation over the\n4477.44s: years\n4479.0s: um so I'm I'm having both positions as a\n4483.38s: recipient of\n4484.58s: of certain microaggression or something\n4487.159s: like not so small aggression\n4489.62s: um and also on the other hand I also\n4491.54s: academic leaders who try to make a\n4493.88s: difference and try to create what I've\n4496.159s: found is that by Simple by simply\n4498.98s: assuming that\n4501.44s: um under representative member of under\n4504.38s: groups can advocate for themselves who\n4507.56s: are assuming that a one or two leader\n4509.48s: can make a huge difference is not is is\n4513.32s: a delusional assumption that I feel that\n4516.8s: what I really needed is a is a large\n4519.26s: scale bystander training like to give\n4521.78s: people the two things one is the skill\n4524.6s: to recognize microaggressions and toxic\n4527.8s: behavior and practices\n4530.36s: um which I think the the inclusive bias\n4533.179s: training does you know touch a little\n4534.739s: bit upon that but recognition is not\n4537.26s: enough\n4538.46s: um concrete ways for people to engage in\n4541.52s: the dialogue to intervene as a bystander\n4544.1s: once they run nice what other ways that\n4547.28s: they can each\n4548.92s: contribute to to make to to to to\n4551.84s: improve improve the the experiences uh\n4555.86s: of of those of members we bring into our\n4559.88s: community try to diverse it's only we\n4562.28s: were only set up set ourselves up to\n4564.32s: fail if we bring people into our group\n4566.36s: and only\n4568.34s: only make them experience you know toxic\n4572.06s: um well without our without intended no\n4575.06s: like as people say no one really like\n4576.86s: intend\n4578.26s: well I won't say no one but most people\n4581.54s: don't intend uh what happens so I wonder\n4585.14s: what are some of the suggestions about\n4587.78s: such a bystander training and\n4591.199s: yeah I think it's you know it's um like\n4593.719s: to to Johnny's Point as well it's it's\n4596.06s: it's not that being aware of your bias\n4597.86s: is not good right that you may have a\n4600.5s: clearer sense that I may be doing\n4602.54s: something whether I'm aware of it or not\n4604.219s: that's having a negative impact on\n4606.02s: people and that awareness is a good\n4607.64s: thing\n4609.26s: um but it's not sufficient\n4611.9s: um and\n4613.34s: um but I think I think I do think it's\n4615.26s: helpful in terms of helping us see that\n4617.12s: our good intentions are not are also not\n4619.94s: sufficient in terms of training I really\n4622.76s: struggle with this and so I've even\n4624.739s: talked about like some of you have\n4626.179s: talked with you about your thoughts and\n4627.62s: how you're presenting your talks and\n4628.82s: I've talked about you're sometimes\n4630.86s: presenting some really complex details\n4632.96s: and you're pouring it into a container\n4634.64s: my container that has a lot of holes\n4636.679s: that can't hold those complicated\n4638.48s: details I need you to build and plug\n4640.64s: those holes and build the container that\n4642.86s: can hold that information in a\n4644.719s: meaningful way I see training around Dei\n4647.06s: and as in a very similar way most people\n4649.52s: have not done sufficient work around why\n4652.46s: do we even have to do it in the first\n4655.04s: place why does it exist what are the\n4657.14s: root causes don't have firmly\n4659.179s: established educated competent beliefs\n4662.0s: about the underlying reasons for Dei we\n4665.239s: tend to jump to training and it's very\n4667.46s: difficult to jump to soft skills this is\n4669.44s: what you do in your lab when you don't\n4671.48s: understand why it's necessary in the\n4673.28s: first place or you don't even fully\n4674.9s: believe that you have somehow\n4676.88s: contributed to the problem or that your\n4679.46s: bias is somehow really still leaking\n4681.86s: through in spite of your best intentions\n4684.02s: and until we correct that I see soft\n4686.54s: training as being a bit more more\n4688.64s: challenging it's important but there's\n4690.739s: some steps that need to happen prior to\n4692.36s: that\n4694.82s: um I I got a question for uh Chris\n4696.56s: Christian\n4697.64s: um\n4698.659s: uh yeah I'm back here um uh I really\n4702.56s: enjoyed your presentation and I had a\n4704.659s: question just about your time at Georgia\n4706.159s: Tech I thought that was really\n4707.179s: interesting\n4708.199s: um I was curious what were the things\n4710.179s: that the community did in your time\n4712.28s: there that you thought were help helpful\n4714.199s: that you'd want to share that you know\n4716.36s: we could try to replicate others to\n4718.219s: replicate like things like like old\n4720.56s: models are kind of groups that you're\n4722.54s: part of it I was just curious whether\n4723.739s: things in community that you know it\n4726.199s: sounds like it was not very inviting but\n4727.82s: was there something that was you know\n4729.679s: what I'm curious about what was\n4731.3s: everything that did make inviting that\n4732.86s: that we could try to you know learn from\n4734.96s: yeah I mean it ties to the last question\n4738.199s: I'm too I I actually so my dream was to\n4741.199s: go to MIT\n4742.36s: and I and I so I I was signed between\n4745.58s: MIT and Georgia Tech and I wanted to go\n4748.46s: to MIT because there was three faculty\n4751.46s: of color there that I was thinking of\n4753.5s: working with\n4754.88s: um you guys probably even know these\n4756.14s: folks uh one was Dada at the copy\n4759.98s: um Raphael Ross and uh the other's Name\n4764.12s: Escapes me uh he's Sudanese and I went\n4766.94s: there and you know it was cool it was\n4768.26s: interesting\n4769.58s: but I experienced a microaggression with\n4772.159s: a white I think German student you know\n4774.86s: and it was a white American student who\n4776.36s: actually did the bystander trading thing\n4777.98s: I'm talking I'm I'm I probably lost a\n4781.46s: little bit of an accent but I was\n4782.659s: talking and and the German student says\n4785.0s: to me you know I can't understand I'm\n4787.52s: sorry can you say I don't understand\n4788.54s: your dialects and the the the white\n4792.56s: female student said you know kind of\n4794.719s: looks like you know you're going to\n4796.4s: scare him away you know like uh and she\n4798.44s: just kind of turned and was like no no\n4799.82s: he he's has an accent and he's from a\n4802.28s: different region but you know and at\n4804.38s: that moment I was kind of like okay like\n4805.699s: this isn't terrible but this was still a\n4807.86s: microaggression obviously I was\n4809.36s: experiencing microaggressions the whole\n4810.8s: time I was in Boston\n4812.719s: um you know very different than Atlanta\n4814.219s: you know but um\n4816.8s: at the end\n4818.48s: when I looked around there was I didn't\n4820.1s: see I didn't see any black around\n4821.96s: students there was one black female\n4823.76s: student graduating and I was kind of\n4825.26s: like I don't want to be the only black\n4826.34s: student here so Georgia Tech the\n4829.28s: environmental fluid mechanics program\n4830.6s: was all 12 white men\n4833.84s: um no women\n4835.699s: uh uh either from America Europe but the\n4839.179s: students were very diverse\n4840.86s: and when I and I knew and my\n4843.26s: understanding was when you're in\n4844.159s: graduate school you're going to interact\n4845.0s: interact a lot with students and so\n4846.86s: that's exactly what happens interact\n4848.6s: with a lot of students from the\n4849.8s: so-called Middle East from East Asia\n4851.96s: almost no interaction with the white\n4854.12s: American students it had microaggression\n4855.86s: experiences with white American suicide\n4857.36s: Georgia Tech and I just kind of found\n4859.88s: this Sanctuary with the other students\n4862.52s: of color you know in my program\n4865.64s: um so I would say if I was not able to\n4868.64s: create those bonds with them\n4870.86s: um you know I've studied abroad in Japan\n4872.42s: you know I have a lot of friends from\n4873.98s: different cultures it was easy for me\n4875.44s: but the relationships between the white\n4878.239s: American students and the white faculty\n4879.98s: which is different it was just it was a\n4881.3s: look it was just they were able to talk\n4883.1s: and convene and we actually actually\n4885.26s: perceived bias and who who's winning\n4887.719s: people's proposals happen when did they\n4889.82s: take their python exams\n4892.28s: um when when did they defend\n4894.62s: um and I and I've talked about the bias\n4896.179s: and faculty told me stop talking about\n4898.76s: this Christian if you want to graduate\n4900.08s: this is straight straight I mean\n4901.46s: straight up with you they told me stop\n4903.86s: talking about it so I would say to you\n4906.739s: um there was not there was not this\n4909.14s: thing there other than\n4911.719s: um the black grad Student Association\n4913.219s: for me and that was really that was like\n4916.82s: my sanctuary and then just the fact that\n4919.46s: I was a big enough student leader on\n4921.08s: campus where\n4922.699s: The Faculty couldn't intimidate me to\n4924.32s: not you know describe the program the\n4926.78s: program the way I saw it\n4931.64s: um\n4932.739s: one or two more questions yeah this is a\n4936.02s: spectacular and I think I mean there's\n4938.6s: so many layers\n4941.14s: how many layers of Challenge and\n4943.28s: opportunity uh the one I'd like to bring\n4945.38s: up which I learned as a journalist\n4947.12s: covering climate change you know now I'm\n4949.1s: like 35 years\n4951.02s: the biggest mistake I made\n4953.78s: was being climate Centric\n4956.36s: and not looking at what is the problem\n4958.82s: here and I want to I started talking to\n4961.34s: social scientists and getting into\n4963.62s: developing countries\n4965.12s: and seeing that vulnerability\n4968.0s: as in durbined the flooding just\n4969.8s: recently when you look at well what just\n4971.54s: happened there\n4973.04s: and I Catherine Sutherland who's a\n4975.739s: expert in urban\n4977.3s: I'm at risk in in Durban\n4981.14s: said it was all about Injustice and\n4983.06s: who's living in floodplains and the\n4985.28s: media only wanted to know how much of it\n4987.02s: was climate change\n4988.4s: so there's a climate change\n4991.219s: the biggest level of bias I think we\n4995.0s: have in this community whether you're a\n4996.44s: climate journalist or a climate\n4997.64s: scientist is we're starting from the\n5000.58s: foundational idea that climate change is\n5002.679s: the problem\n5004.06s: the word change as opposed to climate\n5006.699s: risk\n5008.14s: and in one of my opportunities and when\n5010.3s: I train journalists now anywhere in the\n5012.46s: world or talk to scientists and say just\n5015.1s: wake up in the morning\n5016.96s: and start your day with climate risk\n5020.8s: and just and there's a formula I could\n5022.96s: show the slide uh Diana liverman a great\n5025.84s: social climate scientist geographer led\n5028.6s: me to this way of looking at climate\n5029.98s: risk is exposed risk is a function of\n5032.08s: the hazard you know there's a hazard\n5034.3s: free world there's no risk but it's much\n5036.76s: more a function of exposure and\n5037.96s: vulnerability and as soon as you start\n5040.0s: say I'm at risk how do I reduce climate\n5042.88s: risk instead of thinking how do I slow\n5044.679s: climate change\n5046.239s: focusing on slowing climate change is\n5047.86s: actually race it's actually very biased\n5049.9s: toward\n5051.219s: uh that element of the system it misses\n5053.92s: hi it's obscures\n5056.56s: the other drivers of risk and\n5058.9s: vulnerability that you start to say\n5060.94s: who's vulnerable and it immediately\n5063.34s: the race the racial and poverty and uh\n5066.699s: like it was marginalized that all comes\n5068.98s: to the foreground\n5070.3s: so just starting like having a little\n5072.82s: camera in your head that can flip a\n5075.64s: little filter that's like\n5077.26s: okay get us out of that climate change\n5079.6s: centrism which goes right the ipcc I\n5082.239s: wrote once whenever it wouldn't have it\n5085.179s: wouldn't have been better if we had an\n5086.44s: intergovernment panel on climate risk\n5088.9s: in 1970\n5091.06s: climate change is one driver of risk but\n5093.28s: all these other elements would be in the\n5094.48s: foreground instead of in the background\n5095.679s: so that's the one thing I think and I\n5097.239s: could talk further about this to anyone\n5099.34s: thank you\n5101.02s: um I think we have a time for a final\n5102.58s: question from online\n5105.699s: yeah hi can you hear me yes this is\n5108.94s: Marcus Hi Marcus hi um I really liked uh\n5113.32s: your point Courtney about\n5115.48s: um sort of how how narrow are spheres of\n5118.06s: collaboration are this is something I've\n5120.04s: always felt like I tend to just\n5122.199s: collaborate with people who I end up\n5123.76s: talking to and hanging out with at\n5125.32s: conferences and I feel like it sub\n5126.88s: selects uh in a way that isn't really\n5130.12s: fair in a way you know but um I guess\n5133.3s: the the question I wanted to ask is if\n5135.28s: there's a plan at leap to sort of take\n5139.239s: the the young scientists and and I and I\n5141.64s: want to focus on the young scientists I\n5143.26s: think because\n5144.34s: um I think that's where a lot of the um\n5147.28s: sort of filtering out of of\n5150.219s: um\n5151.06s: the filtering out happens that sort of\n5153.159s: supports\n5154.239s: um lack of diversity and lack of\n5156.639s: inclusivity\n5157.96s: is there sort of a plan to take young\n5159.88s: scientists post-docs phds and sort of\n5162.4s: take them to the next level to build\n5164.38s: their spheres of community to sort of\n5166.96s: bring them to the point where they can\n5168.4s: write a proposal do we have a plan that\n5170.739s: like postdocs will be ready to write a\n5172.48s: proposal at the end of their postdoc\n5174.04s: like uh is there some sort of structure\n5176.8s: that we're building to set these people\n5179.08s: on a path where they have an advantage\n5181.42s: and where they have a sort of diverse\n5183.639s: group of collaborators you know do are\n5186.34s: we giving them all the tools that they\n5188.679s: need\n5189.639s: um I think that would be nice if we\n5191.02s: could do that\n5192.28s: I think that's a great idea Marcus we\n5194.32s: haven't talked about that as a\n5195.52s: collective I'm sure some individual pis\n5197.62s: are thinking about it that way but I\n5199.6s: really like the idea of standardizing\n5201.46s: both the professional and Social\n5203.02s: Development around these issues but also\n5205.36s: the opportunities\n5207.04s: um that are made available in terms of\n5208.48s: writing grants papers Etc and making\n5210.219s: sure we're being consistent in what ways\n5212.199s: can we at the organizational level of\n5215.92s: leap help support that so I definitely\n5218.38s: made note and this is exactly the kind\n5220.42s: of thing that's really helpful when you\n5221.679s: complete the survey for me to to know\n5223.6s: what sorts of things you think are\n5224.8s: really important or where you'd like\n5226.659s: support and just ideas you have in\n5228.52s: general so thank you for that Marcus\n5232.199s: thank you thanks so much again oh we\n5235.78s: have 10 minutes oh okay was there\n5238.06s: another there was another question here\n5239.5s: yeah okay okay\n5246.4s: um to address tien's point about\n5249.42s: microaggressions do you two think you\n5252.34s: can deal with multiplications like on\n5253.84s: the Fly because like most micro\n5256.06s: aggressions are like remarks which are\n5258.28s: like really hard to calculate oh like\n5260.32s: five seconds later you realize that but\n5262.239s: then like the person's gone so that's\n5263.8s: like\n5264.76s: a little bit annoying\n5266.62s: yeah it's part of what's so uh\n5269.92s: harmful about micro was misleading it's\n5273.04s: part of what's so harmful about subtle\n5274.86s: exposures to uh these kinds of harms and\n5278.32s: threats because they're difficult to\n5279.639s: make the other person aware of and it\n5281.739s: would take a long conversation and we\n5283.239s: don't have a video to run back and show\n5285.52s: them exactly what they said and what\n5286.96s: they did they may not have done their\n5288.699s: own work related to this so it's really\n5290.92s: really challenging\n5292.36s: um it's part of I reference my work in\n5294.04s: virtual reality and it's part of why I\n5295.84s: created that experience where you're a\n5297.52s: black male as a child Adolescent and\n5300.1s: adult experiencing racism from that\n5302.679s: perspective in virtual reality because\n5304.9s: you're able to represent some of those\n5306.58s: subtleties like being ignored that's\n5309.4s: difficult to explain to someone that\n5311.02s: that you know 10 milliseconds that you\n5313.36s: didn't look at me was a was a\n5314.8s: microaggression it's difficult to\n5315.94s: explain that to someone when they\n5317.199s: haven't experienced it themselves\n5319.719s: um but yeah it's a it's a challenge and\n5321.88s: I would say for myself I have learned to\n5323.86s: navigate and cope with those things I\n5325.9s: wouldn't be here in this space at\n5327.82s: Columbia in particular if I hadn't but\n5330.4s: they're from a health perspective those\n5332.08s: hits are actually quite significant and\n5333.76s: add up over time which is why we call\n5336.04s: the VR experience a thousand cut Journey\n5338.679s: it's just cut cut cut cut day after day\n5342.159s: um that that definitely add up\n5343.42s: physically and mentally yeah I'll just\n5346.96s: say quickly I mean it evolves as your as\n5350.08s: your role evolves as your status evolves\n5352.179s: you know when I was younger it was very\n5353.98s: different for me than it is now so I\n5358.36s: would say you know if you're if you're a\n5360.34s: black man\n5361.719s: um probably about 12 or 13 there's the\n5364.54s: shift from you being cute and adorable\n5366.48s: to women clutching their purses in the\n5369.88s: elevator or kind of white people\n5371.8s: crossing the street when they walk by\n5374.26s: you and so I think for a lot of young\n5376.9s: black men in America they think how can\n5380.139s: I make myself more comfortable like make\n5382.12s: white people more comfortable and my\n5384.52s: perception was the opposite mine was\n5386.679s: like oh there's nothing wrong with me\n5388.84s: something's wrong with them you know um\n5391.3s: very much uh thinking of racism as and\n5394.06s: and bias our racism as um kind of a uh\n5399.46s: would you say pathology pathology yeah\n5401.739s: yeah at a young age I thought of it as a\n5403.54s: pathology so\n5405.1s: for me I think it was not the same but\n5408.84s: now I do tell people so what I'll do is\n5411.88s: for example I'll get an email from a\n5414.58s: white woman and it's Christian and Dr\n5418.0s: Johnson I like to be with you and and in\n5423.639s: my signal my signature light is Dr\n5425.08s: Christopher get out of it so I'll I'll\n5427.42s: usually reflect be very calm when I\n5430.179s: respond\n5431.199s: and I'll just kind of send an email and\n5433.36s: say hey I just want to point this out to\n5435.04s: you sometimes we don't say doctor when\n5437.199s: there's women and people of color uh\n5439.54s: that person my colleague Dan Bader is\n5441.58s: actually not even a PhD\n5443.86s: um but I am a PhD and it's in my\n5447.1s: signature lie uh you know so so those\n5449.32s: are kind of I'll do that and\n5451.42s: the response goes either way but usually\n5453.94s: to your point in the moment I don't\n5455.86s: always respond sometimes I I want to be\n5458.8s: calm when I respond to something I don't\n5460.06s: notice until later and I think for\n5463.06s: students you just want to have a safe\n5464.679s: space where they can go to someone\n5466.06s: because if it's their PHD advisor right\n5468.58s: or they're closing it they can't go to\n5469.96s: them right so you've gotta you want to\n5472.42s: have a culture where there's someone\n5473.56s: they can talk to someone they can go to\n5475.36s: if they're the only proud person the\n5477.94s: only black person the only South Asian\n5479.86s: person or whatever an entire program who\n5482.32s: can they go to to talk about that it's\n5483.82s: just something to think about but thank\n5486.1s: you for bringing up about my progression\n5487.54s: time it's different for me now\n5490.54s: um but but it was always easy in some\n5493.719s: ways it wasn't so difficult I always\n5495.34s: thought it was racist methodology and I\n5497.44s: still think of racist Miss mythology\n5498.699s: it's hurting people that identify as\n5500.26s: white in ways and not always\n5502.48s: talking about\n5504.52s: Dave\n5506.38s: yeah so uh thinking back to Marcus's\n5508.78s: point and when she made that sort of\n5510.699s: intentionally diversifying our\n5512.8s: collaborative networks I guess which is\n5514.78s: a probably a goal of leap I'm curious\n5517.12s: about your perspective about engaging\n5519.1s: with MSI so an end card is a lot more of\n5521.739s: intentional\n5523.36s: activity to try to engage with my\n5525.699s: minority serving institutions which\n5528.04s: seems to me on the face of it like a\n5529.54s: good thing to do but I'm curious whether\n5530.92s: there's what your thoughts are in Pros\n5532.96s: or cons uh related to that and then you\n5536.38s: know if it's Pro\n5537.88s: um\n5538.6s: then I guess within Leaf we should maybe\n5540.699s: be thinking along those lines too to\n5542.98s: find ways to to bring in the MSI\n5545.679s: institutions Mentor yeah so I think like\n5548.62s: I think engaging minority serving\n5550.12s: institutions is really important I also\n5552.46s: think that\n5553.96s: um\n5554.8s: I have a longer set of thoughts around\n5557.139s: this around in terms of what what skills\n5559.239s: are necessary to do the work that you\n5560.86s: need and that how that if you are more\n5562.719s: expansive about that that might broaden\n5564.46s: even the kinds of disciplines that you\n5566.32s: go to and where you recruit so\n5568.12s: minorities serving the institutions are\n5569.92s: a good solid place to start there's\n5572.38s: other institutions and also potentially\n5574.239s: other disciplines where you'll find more\n5575.98s: diversity where people could potentially\n5578.08s: be caught up to speed right to do the\n5579.82s: kinds of work that you want to do so I\n5582.1s: definitely think that's that's part of\n5583.84s: what we should be doing I think there's\n5585.52s: also organizations uh that are Tech\n5588.76s: focused environment focused climate\n5590.86s: Justice Focus climate Science Focus that\n5592.96s: are attached to particular Affinity\n5594.52s: groups that we should be engaging as\n5596.679s: well both in terms of in solidarity but\n5599.32s: also in terms of recruiting and bringing\n5601.179s: those people into the work that's\n5602.139s: happening at Lee the con is when you\n5604.48s: bring them into a context where they're\n5606.82s: isolated they're the only person\n5609.52s: um you haven't really you're not\n5611.139s: introducing them into a lab or people\n5612.639s: have really accounted how their\n5614.199s: experiences may be different you haven't\n5616.54s: done the work with your community where\n5619.0s: they aren't going to be perceived as\n5620.86s: deficient in some way or that some\n5622.659s: accession has been made in order to\n5624.4s: recruit them which again in both\n5626.44s: explicit and implicit ways is going to\n5628.36s: color their experiences in the lab what\n5630.82s: they're included in how they're\n5632.44s: perceived going to microaggressions the\n5635.5s: number of conversations where I feel\n5637.06s: like it starts with someone assuming\n5638.62s: they're smarter than me it's pretty\n5641.02s: common right and so if someone's coming\n5642.94s: into a context where they haven't done\n5644.56s: their own work around their own biases\n5646.9s: and their own practices related to how\n5648.639s: they interact with people you're\n5650.08s: potentially bringing them into a toxic\n5651.58s: environment so there's there's multiple\n5653.02s: steps that need to happen but it is an\n5654.699s: important way to engage\n5659.5s: we have five minutes if anyone else yes\n5661.54s: Cara\n5662.67s: [Music]\n5667.719s: uh maybe addressing how to address like\n5671.02s: outside of leap like larger structural\n5673.0s: issues within like the neurosciences\n5674.86s: community and like what are effective\n5676.239s: strategies to do that\n5678.34s: I think the the Norms that we set here\n5680.62s: and the ways that we're trying to build\n5682.36s: and think about this again not as\n5684.04s: trainings that we go through but ways in\n5686.32s: which we're trying to build it and\n5687.58s: integrate it into the work uh that we're\n5689.86s: doing here at least and documenting that\n5691.659s: and disseminating that in various ways\n5693.52s: through public engagement through\n5694.84s: written documents Etc I think is an\n5697.3s: important part of influencing those\n5698.8s: broader uh structures I think a lot of\n5701.139s: people care about this and they have no\n5703.0s: idea what to do or they've tried a\n5705.28s: number of things and the needle just\n5706.6s: hasn't moved and they feel stuck and so\n5708.88s: I think the more that we can communicate\n5710.5s: if we're successful why were we\n5713.32s: successful what did we do if we weren't\n5715.42s: why why weren't we successful in really\n5717.639s: being very critical and thoughtful about\n5719.08s: that I think that's a really important\n5721.9s: um step to trying to help other\n5724.0s: well-intentioned people who want to do a\n5726.04s: good job at this and then I think also\n5728.44s: continuing to build and share resources\n5730.42s: that already exist where people have\n5732.04s: told us exactly what to do\n5734.38s: um but there has to be a sense of\n5735.88s: responsibility that it's not the Dei\n5738.28s: person's job to change geoscience and\n5740.739s: geosciences right it's your job right\n5742.659s: and so how do we help more of us take on\n5745.48s: that responsibility\n5747.1s: um in the in this work\n5751.06s: Savannah\n5755.98s: oh sorry I missed uh Mr oh sorry go\n5758.679s: ahead uh yeah my question was about\n5761.5s: something it was like\n5764.62s: yeah\n5765.48s: notice that\n5772.3s: presentations on\n5778.659s: it's wonderful\n5783.46s: yeah I think that so many it's just not\n5785.56s: a part of our\n5787.3s: um curriculum and discussion across the\n5789.28s: board even outside of Columbia and\n5790.78s: outside of leave and I think we have to\n5792.699s: to Center in I think so many people feel\n5794.5s: ill-equipped to address it\n5797.38s: um but it's so important not certainly\n5800.02s: in terms of physical differences and\n5802.54s: ability but also those invisible\n5804.4s: differences that show up when someone's\n5806.92s: working in a lab where they may have a\n5808.78s: learning disability or they may be\n5810.1s: neurodivergent in some way that it's\n5812.26s: important for us to be able to have\n5813.58s: conversations about that and how do we\n5815.5s: need to think about how we have\n5817.54s: conversations with our with our students\n5819.4s: and postdocs Etc so I now know that this\n5823.239s: is this I knew before that this was\n5824.8s: Central and we'll we'll integrate that\n5826.42s: into our our learning and conversations\n5829.239s: um and help people deal with it in more\n5831.28s: meaningful ways but it it's it's it's\n5834.3s: essential and often invisible which is\n5837.58s: why I think it gets ignored so much\n5841.02s: last question\n5843.4s: yeah I don't know if I have a question\n5845.38s: as much as like we've talked a little\n5847.12s: bit about this yesterday Courtney but\n5848.92s: like trying to figure out your sphere of\n5851.38s: influence and I feel like we all can\n5853.06s: probably make like a larger impact\n5855.52s: within our department if we're willing\n5857.739s: to like step up and value Dei as like\n5860.699s: important and an integral part of\n5862.84s: research and not like a separate\n5864.3s: activity like I know our department I've\n5866.98s: tried to get faculty involved in like\n5869.26s: rewriting like the code of conduct or\n5870.82s: like reevaluating how we do crowd\n5873.219s: Admissions and like making sure we\n5874.9s: include land acknowledgments at the\n5876.34s: beginning of our talks like it feels\n5877.719s: really small and like stuff that's\n5879.58s: manageable but then like when you see\n5881.139s: departments that are doing that it like\n5882.82s: can really easily disseminate to like\n5884.56s: the college or then other departments\n5886.719s: and other schools and like those are\n5888.34s: things that I think we can individually\n5889.78s: work on\n5890.86s: and like examples of things that like\n5894.52s: when then students come visit and they\n5896.26s: see that these are things that you've\n5897.639s: prioritized like it can make minority\n5899.86s: students especially feel like it's not\n5901.96s: like performative allyship and it's\n5903.94s: something that everyone is like willing\n5905.32s: to to put an effort to make better so\n5908.199s: like if anybody has any ideas or like\n5910.42s: wants ideas of things that they could do\n5912.46s: I I'm the GI person in my department at\n5914.8s: UCI so I can talk about it all day thank\n5918.46s: you and stuff yeah yeah and I look\n5920.44s: forward to sharing we talked about\n5921.52s: different resources I look forward to\n5923.08s: you sharing those so that we can make\n5924.46s: sure they get disseminated\n5926.26s: um and so in part two we'll close now\n5927.82s: but in part two we're going to get\n5929.02s: really concrete right about where is\n5931.54s: where are my roles where do I have power\n5933.34s: influence what are some specific goals\n5936.34s: and actions that I can take related to\n5938.92s: these commitments\n5940.6s: um and we're going to focus excuse me\n5942.82s: today we'll focus on one goal and one\n5945.04s: outcome but we'll have you do some\n5947.139s: homework and fill this out in a more\n5950.02s: substantial way and try to create a\n5952.6s: system of accountability about that and\n5954.88s: come back to it a year from now and see\n5957.1s: how much progress uh We've made so\n5959.26s: hopefully we can get very Concrete in\n5961.239s: our second session uh to help people\n5963.28s: decide exactly how they're willing to\n5964.9s: commit and how they want to move forward\n5966.699s: and I understand that's that can be\n5968.32s: difficult and challenging and that's why\n5970.42s: we're here to try and help you do that\n5973.06s: and then again provide additional\n5974.5s: resources to help support you so we're\n5977.38s: overdue for a break we'll take the break\n5979.179s: and uh we'll come back I don't know how\n5981.219s: we've adjusted the schedule but I'll let\n5983.199s: you take over\n5990.04s: um thank you all for in engaging and so\n5993.04s: thoughtfully with uh with part one\n5996.4s: um we will you know continue to create\n5998.739s: opportunities to have these kinds of\n6000.3s: conversations and hope you will continue\n6001.86s: to engage uh with us but we also are\n6004.62s: quite aware that we can't just talk that\n6007.199s: we need to do things differently as well\n6009.12s: so we want to help support you and\n6010.739s: you're you're thinking around that\n6013.139s: um to get started we want you to take\n6015.54s: two minutes just to yourself you can\n6017.219s: write it you can use your device\n6019.92s: um and your device will actually be your\n6021.6s: computer or laptop or iPad will be\n6023.159s: useful for this next phase if you have\n6024.9s: it with you but we want you to take just\n6027.179s: two minutes to reflect on your spheres\n6028.92s: of influence so think very concretely\n6030.719s: about the multiple professional roles\n6033.719s: that you hold uh what are your general\n6036.3s: responsibilities in those roles and in\n6038.82s: what ways do you have power and\n6040.199s: influence related to those roles and so\n6042.179s: this will be helpful in terms of\n6043.679s: identifying goals and concrete actions\n6046.8s: because you'll link it back to your\n6048.48s: Reflections around this so we'll give\n6049.92s: you two minutes to do that and then\n6052.26s: Christian will start to walk us through\n6054.36s: the Strategic uh plan\n6056.58s: um the document for the Strategic plan\n6057.96s: the slides you'll use are on the meeting\n6060.239s: uh annual meeting website so you can\n6062.4s: link directly to part two of this\n6064.56s: session and it'll take you to those\n6065.82s: slides so we'll give you two minutes and\n6067.38s: then we'll we'll check back in\n6074.58s: okay and you can you can keep working on\n6076.92s: this I know some of us hope to wear mini\n6078.6s: hats especially more senior people in\n6080.699s: the room so what we first like you to do\n6082.679s: is just the the person next to you if\n6084.54s: you're in a little cluster just to sort\n6086.34s: of bounce off what kinds of roles are\n6087.96s: you identifying and start to just think\n6090.6s: together what types of uh\n6094.98s: action what types of power influence do\n6097.139s: you have related to that and start to\n6098.52s: share that with the person next to you\n6100.38s: it's just a sounding board just to talk\n6101.82s: out loud about what it is if that's\n6103.8s: coming up for you and they may be able\n6105.179s: to give you some some insights um so if\n6108.119s: you could take about uh just a few\n6111.06s: minutes to do that we don't have time to\n6112.86s: do the full discussion here so we can\n6114.719s: move into\n6116.94s: and if you want to flag one of us down\n6119.159s: we're help happy to come help as well\n6125.58s: uh just in a pair or in a small group\n6128.219s: just share what you came up with what\n6130.32s: you're coming up with in terms of your\n6131.82s: power right influence\n6140.639s: okay\n6143.82s: so recognizing that that may not feel\n6146.04s: like enough time but hopefully\n6148.86s: um you started to see what sorts of\n6150.3s: things came up for other people things\n6151.679s: maybe you didn't think about or imagine\n6153.38s: but let's just take a couple of minutes\n6155.52s: what types of\n6157.32s: uh spheres that came up for you in terms\n6160.02s: of uh related to your role your\n6162.3s: influence what types of categories are\n6164.28s: you falling into just so I can sort of\n6166.44s: track some of it\n6169.92s: yeah or educator okay\n6175.139s: yeah UCL loud student\n6178.98s: graduate student undergraduate\n6181.98s: Brad\n6185.159s: okay okay\n6186.5s: it sometimes makes a difference okay\n6189.9s: yes\n6191.4s: mentor\n6193.98s: yes\n6196.739s: connector of people\n6200.639s: others\n6202.199s: reviewer\n6203.94s: in the back\n6206.34s: management\n6219.719s: and sometimes these are formal roles\n6221.4s: like I think in your case as a Dei\n6223.02s: fellow and sometimes it's just your\n6224.46s: personality that you were a connector of\n6226.02s: people which also matters yes\n6235.26s: okay yeah\n6237.42s: researcher okay\n6239.219s: so you get the idea the kinds of the\n6240.96s: kinds of roles that we occupy you\n6242.46s: probably wear multiple hats how did you\n6244.8s: interpret power and influence what sorts\n6246.659s: of things were coming up related to that\n6251.639s: but yeah\n6256.08s: policy so you control the policies in\n6258.6s: your lab sometimes you're on committees\n6260.28s: in your your department okay\n6263.58s: others\n6269.219s: so capacity building maybe okay\n6277.56s: evaluations and Grading\n6280.26s: it's a big one\n6285.659s: reporting behave is what you need\n6288.08s: reporting behaviors\n6293.46s: so going back to like Ally bystander\n6296.639s: the roles\n6298.5s: yeah\n6304.98s: recommendation letters\n6308.4s: resources\n6311.699s: okay Mr Hannah\n6316.619s: hiring recruitment job posting\n6319.98s: okay so you get the idea that if you\n6322.02s: have some control over the positions\n6323.52s: that get made about that thing that's a\n6325.199s: power that's a potential to influence\n6327.36s: and so when you move into the next\n6328.98s: section with uh which Christian will\n6330.719s: walk us through we're going to name some\n6333.119s: of those uh goals that we have we're\n6336.06s: going to name associated actions\n6338.48s: excuse me and think about the ways in\n6340.679s: which we can actually move the needle\n6342.78s: even in a short period of time\n6345.239s: potentially there's you know there's\n6346.619s: load hanging fruit and there's bigger\n6348.0s: things that are better the long game but\n6349.56s: we're we're going to try to think about\n6351.06s: a combination of those\n6353.04s: or beautiful\n6362.639s: um so you guys maybe have heard the\n6364.619s: phrase strategic Plan before\n6367.56s: um usually it starts with like a vision\n6369.48s: so you're imagining that you want your\n6372.6s: system or your Society or your\n6374.34s: organization to be like\n6376.02s: and it's it's a good idea to think of of\n6378.9s: the most ideal state of that\n6381.06s: organization now think of you know allow\n6383.82s: all the constraints to go away just\n6385.86s: think about what would be the most ideal\n6387.36s: lead the most ideal Colombia our most\n6390.06s: ideal academic space\n6392.699s: um and imagine what the goals might look\n6395.46s: like\n6396.239s: to get there\n6397.98s: um so today we're gonna actually think\n6401.1s: about goals for the next school year and\n6403.44s: then ultimately we want you to think\n6404.699s: about the next four or five years but\n6408.119s: this is an example from NASA this is\n6410.639s: actually from NASA's deia strategic plan\n6413.1s: so this is this is publicly available\n6414.42s: this is a classified you can find us\n6416.94s: online it's linked in the resources as\n6419.159s: well it's under the resources and\n6421.5s: they're sewing themes here on the left\n6423.719s: so they have a theme of Workforce\n6425.58s: diversity a theme of Workforce equity\n6428.04s: and inclusion and then they write out\n6429.96s: the full goal make their goal is recruit\n6432.9s: hired or pain and so forth and then on\n6435.9s: the right is the outcome this is really\n6438.0s: important so\n6440.28s: um kind of to the point that that\n6442.739s: Courtney and others have expressed\n6444.0s: earlier it's not the intention is not\n6447.54s: enough you know we want outcomes right\n6450.42s: just like anything you do you'll find\n6452.52s: this if you work in Industry you'll find\n6454.56s: this academic you've got to get to the\n6456.0s: outcomes you've got to publish the\n6457.38s: Articles you've got to win the grants\n6459.239s: you've got to write the Books right so\n6461.76s: it's so important to align your goal and\n6464.76s: your outcomes and so what we're going to\n6467.219s: do as a first step for strategic\n6468.96s: planning is you individually are going\n6470.94s: to think about\n6473.179s: d-e-i-d-e-i a and maybe anti-racist\n6476.58s: goals and think about what the outcome\n6479.88s: would be that and just quickly when\n6482.82s: you're thinking about action steps I\n6484.56s: need to get to the outcome it maybe get\n6486.96s: support it may be fine resources on you\n6490.08s: may not know actually what to do just\n6492.06s: yet so there may be an interim step um\n6494.58s: so education finding resources getting\n6496.86s: support might be one of the steps that\n6498.48s: you identify as being essential to being\n6500.219s: able to move forward\n6502.86s: so we're going to get this going today\n6504.719s: just focused on one goal for the next\n6508.44s: upcoming year this is something you can\n6510.239s: do based on your spirits of influence\n6513.48s: okay and then we'll and then you'll\n6515.639s: further Define this homework\n6518.34s: um you'll build something out that's\n6519.659s: more robust and what's nice is we've\n6522.119s: created kind of a\n6523.619s: an opportunity for us to review this\n6525.42s: next year so next year when you guys\n6527.699s: come back again you can look back at\n6529.38s: what you came up with today would you\n6530.94s: come up at come up with later and and\n6533.52s: see\n6534.36s: um if your perspective has changed if\n6536.159s: you've made progress and we'll try to\n6538.08s: think of as well about interim\n6539.58s: accountability systems whether you\n6541.44s: partner with someone or whether you use\n6543.0s: me as a point of accountability whether\n6545.82s: we just coordinate asynchronously and\n6548.1s: update as things move along I think\n6549.9s: there's a few different options there\n6552.6s: um\n6554.34s: yeah\n6556.08s: so I I think you so yeah so right here\n6558.3s: you can find\n6559.92s: um oh you have a link I'll just yeah so\n6562.139s: we're going to share the I guess do they\n6564.06s: have access to the link to the the\n6565.679s: slides are on the meeting agenda where\n6567.9s: you can get all of the slides so for\n6569.52s: part two if you're able to access that\n6571.26s: you don't need them necessarily you can\n6573.0s: just take notes but we've created a\n6575.159s: template for you to use um so today\n6577.26s: we'll focus on one goal and one action\n6579.84s: but hopefully you'll be able to spend\n6581.88s: some time filling this out uh uh more\n6585.06s: fully um and we'd like you to not today\n6587.4s: you don't have to but we were asking you\n6589.32s: to identify four goals for the year we'd\n6591.9s: like one of those goals to be\n6593.34s: specifically focused on Race they don't\n6595.26s: all have to but to think about that as\n6597.179s: one outcome that you're interested in\n6599.28s: moving the needle on\n6600.78s: um so if you can access the slides from\n6602.46s: for part two on the meeting agenda you\n6604.199s: can go ahead and do that or you'll just\n6605.34s: be able to take notes and you can fill\n6606.719s: in the the template later\n6609.659s: um so getting the slide no just copy the\n6612.179s: template to your machine so you have it\n6615.119s: um as opposed to editing that live\n6617.639s: Google doc and then just put your last\n6620.82s: name in there in the beginning you can\n6623.159s: put your name and the spheres of\n6624.719s: influence that's not urgent right now to\n6626.76s: put a photo but you can put your name\n6628.739s: and spirits of influence and this is and\n6631.139s: this is kind of what it's going to look\n6632.34s: like so here you can have your name\n6635.1s: experience influence photo and photo is\n6638.04s: just to visually hold yourself\n6639.179s: accountable put your face there yeah or\n6642.659s: it could be a Pokemon that just\n6644.159s: remembers you or whatever you like\n6646.92s: um and then\n6648.3s: here you can map the goals to\n6652.8s: the outcomes so just as a basic starting\n6655.38s: point\n6657.179s: um you can insert one sentence goals you\n6660.36s: know we want them to be short and sweet\n6661.8s: like we're not trying to we want we want\n6664.32s: to be kind of direct when we set goals\n6666.179s: we don't want to kind of meander around\n6667.86s: too much so we would suggest\n6671.159s: one sentence goals and a one sentence\n6673.739s: outcome focusing on the red part just\n6676.44s: for 2023 2024\n6678.78s: so again to clarify we're asking you to\n6681.42s: do this more fully after we leave here\n6683.4s: so we already have a template set up for\n6685.5s: four goals for this year and then you\n6687.719s: have a second set of documents for next\n6689.699s: year but for today we're focusing on one\n6691.8s: goal and one outcome so that you can\n6693.719s: think more deeply about it I'm thinking\n6695.88s: that's template is there one with more\n6697.44s: space yes yeah so this is so this one\n6700.139s: this is be the one you could use for\n6701.88s: today just lack of space and beer you do\n6705.36s: decide to use the template\n6707.34s: or one sentence goals\n6709.8s: and then list the outcomes you intend\n6712.8s: towards our Target if you don't get four\n6715.26s: not the end of the world but of of your\n6718.38s: goals at least one race related kind of\n6720.719s: recognizing when we get an equity\n6722.46s: conversations in in spaces that are\n6724.8s: pretending white we tends to revert to\n6726.42s: gender Equity I reverse or ableism or we\n6729.719s: tend to avoid discussions about race so\n6732.36s: we're trying to be deliberate about in\n6733.8s: your goals make sure one of your goals\n6735.84s: relates to race\n6737.76s: so we're going to give you about 10\n6739.44s: minutes to do this if you come up with\n6741.9s: more goals that's fine or more outcomes\n6743.639s: that's fine we just didn't want to put\n6744.9s: too much pressure on people to do that\n6746.639s: and then we'll come back and again share\n6748.679s: as a full group you don't have to break\n6750.06s: into smaller groups to get a sense of\n6751.619s: what you're coming up with so this is\n6753.3s: just practice it's just an attempt to\n6754.86s: try and be more concrete about what it\n6756.6s: is we envision ourselves being able to\n6758.88s: do\n6759.6s: um so take 10 minutes again wave your\n6761.639s: hand if you want us to come uh help or\n6764.52s: support or talk through anything and\n6766.5s: then we'll come back together can I\n6768.6s: answer any questions about this now\n6770.1s: before we we go into the 10 minutes\n6773.52s: okay great\n6783.0s: okay\n6785.219s: so what's coming up what um\n6789.0s: you know uh you may be hesitating not\n6792.06s: sure what to say not sure if you're the\n6794.46s: person who'd be who should be showing up\n6796.139s: to do anything and help anyone uh what\n6799.08s: kinds of issues are coming up or what\n6800.46s: types of things are you do you feel like\n6801.719s: you have clarity about that you're\n6802.8s: identifying and it can change you can\n6804.96s: modify it but it's helpful for the group\n6806.52s: to hear what's coming up for you because\n6808.32s: it might help inform the direction they\n6810.3s: go\n6811.44s: um as well so what sort of thing yeah\n6813.6s: Lauren\n6815.46s: yeah please\n6818.34s: do we need to do the microphones\n6823.26s: I think it's for online the online\n6824.94s: people yeah oh yeah\n6827.34s: um\n6827.88s: so I I I can share my strategic goal and\n6831.78s: then maybe I'll say first of all what's\n6833.58s: my issue what's my question okay I think\n6836.639s: I'm confusing the\n6838.8s: how to accomplish\n6840.78s: to go with the output and the outcomes\n6843.42s: in\n6845.52s: so my goal is to produce research that\n6849.179s: centers on schools as racialized\n6851.82s: organizations in terms of what kind of\n6854.699s: opportunities to learn about climate\n6856.199s: they provide to students\n6859.26s: but I'm not sure what is the output of\n6861.6s: the outcome is the outcome that you're\n6863.4s: going to have professionals and policy\n6865.02s: makers that are more aware\n6867.0s: or am I\n6868.5s: missing a step a more immediate yeah\n6870.9s: that's an outcome a more immediate\n6872.58s: outcome maybe I present a paper at X I\n6876.3s: write a paper on X I provide a report to\n6879.3s: the Department of Education I consult\n6881.82s: with the education around schools as\n6883.5s: racialized spaces and then the how comes\n6886.5s: in the between that what method are you\n6888.42s: going to use to engage in that kind of\n6890.04s: research\n6891.0s: yeah and to the extent you can like it's\n6894.3s: nice when they're quantifiable so I will\n6896.82s: a publication one plus Publications one\n6900.54s: two plus officials I think I think you\n6902.82s: talked about reaching I'll have\n6904.5s: communication with our little site my\n6906.179s: work\n6907.32s: but it doesn't have to be quantifiable\n6908.88s: but it's nice when it can be and how is\n6911.699s: the strategy so we don't we don't have\n6913.92s: that in the template but\n6915.54s: that that's a big part of the Strategic\n6917.34s: plan is what's your strategy from\n6918.84s: getting from your goal to your outcome\n6921.239s: which may require some thought yeah and\n6925.139s: that could fall under the the action\n6926.46s: piece as well the hell yeah others\n6931.98s: I guess the common theme was uh skill\n6933.96s: training but to make it more impactful\n6938.34s: one critical aspect is making sure we\n6940.02s: advertise into groups that not know\n6941.699s: about disability want to learn or may\n6943.8s: not know that they should uh learn\n6946.739s: further their careers so actively\n6949.56s: advertising these trainings to\n6950.94s: underrepresented minorities would be one\n6952.98s: way to go about that so what was the\n6955.199s: first piece I missed the first part uh\n6957.44s: just making sure that we advertise the\n6960.6s: experience\n6963.239s: skill training and advertising\n6966.0s: um the tools to build like skills\n6968.1s: themselves but also the knowledge of\n6969.96s: what you need to have in order to do\n6971.58s: this kind of work\n6973.8s: um\n6981.42s: yeah yeah so that's and just to add like\n6984.179s: that's a that's a good way to use your\n6986.639s: knowledge transfer team and and me as a\n6988.98s: Dei person to try and connect you with\n6990.84s: organizations with which we already have\n6992.82s: a relationship our future science for\n6994.739s: instance is one in-house sleep\n6996.719s: organization where a lot of you may be\n6998.639s: able to have that kind of impact but\n7000.86s: yeah that's that's it exactly\n7006.5s: thank you\n7007.639s: that came up actually in a break when I\n7009.44s: was talking so you know that's not like\n7012.739s: that could be the goal to some extent\n7014.36s: and the outcome is\n7016.159s: we publicize that this many\n7018.199s: organizations this many institutions\n7020.0s: what I liked is the\n7022.4s: the constraint so I would say let's say\n7025.159s: what would you normally advertise let's\n7027.619s: say\n7028.52s: maybe just like uh talking to the\n7030.26s: science funding science I would say we\n7032.739s: will not send out we will not send out\n7035.9s: any advertisement becoming science until\n7037.58s: we've reached 10 organizations we've\n7040.34s: already reached out to 10 organizations\n7041.9s: that are most people of color women and\n7044.119s: that hard constraint will make sure it\n7045.679s: gets done because you need to advertise\n7047.179s: to Columbia science yeah if you if you\n7049.34s: don't do that constraint you'll\n7050.659s: advertise the Columbia scientific the\n7051.98s: hour before you send it to 10 of those\n7054.98s: those other translations we'll put that\n7056.48s: constraint like oh we don't even get to\n7057.739s: advertise it the normal way we would\n7059.3s: until we've already sent it yeah to\n7062.0s: those organizations I don't normally\n7064.04s: there's like a percentage rate as well\n7065.719s: so if you don't advertising those things\n7068.0s: ahead of time then you come up with a\n7069.86s: space that people who already have those\n7071.96s: they already have exposure anyway so\n7073.76s: yeah\n7077.0s: yeah we have time for one we have time\n7078.739s: for one more uh uh again this was just\n7081.5s: to get you started for us to try and\n7083.239s: support and give you some examples but I\n7085.219s: am an ongoing resource to help you think\n7087.02s: about this and hopefully we have your\n7089.239s: commitment to try and flesh this out and\n7092.239s: get more concrete I had a slide about\n7094.099s: are your beliefs aligned with your\n7096.44s: actions and this is a way to do that\n7098.54s: right I often have people ask me\n7101.02s: exacerbated about Dei and what can I do\n7103.699s: and nothing is working this is what you\n7105.32s: do this is where you start and try to\n7107.119s: get really concrete about what you have\n7109.04s: control over you can't fix everything\n7111.199s: related to structural racism in society\n7113.78s: but there are some things that you have\n7115.52s: influence over so hopefully you can\n7117.199s: spend some time giving that some thought\n7118.76s: and I'm more than happy to to help\n7121.099s: support you and your thinking both in\n7123.199s: conversation and also in terms of\n7124.639s: providing resources I want to thank\n7127.52s: Christian for joining us and continuing\n7130.159s: to do the work that you do in this space\n7131.659s: and thank you all for being so\n7132.8s: thoughtful and engaged we really\n7134.3s: appreciate you we know these aren't easy\n7136.159s: conversations to have so thank you and\n7138.44s: we need to move into the next session\n7139.699s: thanks so much\n7149.119s: so so I have some of those here that I\n7153.199s: would like to respond to in the earlier\n7155.0s: section\n7155.9s: so so\n7157.46s: um initially we're hoping to give\n7158.96s: everyone an update of the education\n7160.52s: program but I think education has been\n7163.4s: included in a lot of public\n7165.08s: announcements this year I think most\n7166.699s: people know whether we're doing so I\n7168.32s: will go a very quick round of updates\n7170.3s: just to remind everyone that what we\n7173.0s: have been doing on the education front\n7175.219s: so this is almost like a almost like a\n7178.159s: landscape of of things we're doing so we\n7181.28s: have a curriculum so we try to teach our\n7183.139s: courses\n7184.76s: um Pierre's course machine learning for\n7187.34s: environmental engineering and Sciences\n7188.96s: and is available on GitHub so first for\n7192.02s: our colleague from other Institute if\n7193.76s: you want to replicate the core use part\n7195.38s: of the course or for the\n7198.08s: excuse students and and post that if you\n7200.42s: want to learn certain Concepts or the\n7202.159s: slides and and examples are on there\n7204.98s: already so feel free to\n7207.199s: um you know you review them and then we\n7210.139s: in the fall\n7211.88s: we did the readings in climate data\n7214.099s: science so earlier today I remember it\n7217.28s: was the first focus group report that\n7221.119s: was mentioning that uh when you review\n7223.88s: paper sometimes it's hard for you to to\n7226.699s: pinpoint uh the personal perspectives on\n7231.32s: a methods used or sometimes it's very\n7233.42s: hard to unpack a paper I often I for\n7237.26s: young researchers when you read the\n7239.0s: published work then use you need to you\n7242.3s: need to understand the culture of the\n7245.239s: representation of researching papers is\n7247.159s: not the same as in textbook right\n7248.78s: textbook tend to be comprehensive but\n7250.94s: the paper you already have one narrative\n7252.679s: and then you need to look through that\n7255.739s: narrative to learn so that you can you\n7258.5s: can integrate the idea into your own\n7260.36s: research So based on that the the\n7263.119s: readings in climate data science course\n7265.099s: at Greg and I led in the fall was\n7267.44s: precisely try to create an environment\n7270.199s: where we can just talk about papers not\n7273.199s: just take the paper as their um as their\n7276.08s: face value or take everything claim in\n7278.84s: the papers\n7280.4s: um for granted we actually want to\n7282.8s: answer some dumb questions right I think\n7286.159s: there was another uh focus group point\n7288.92s: that we need to have place where we can\n7290.78s: just feel free to ask dumb questions so\n7293.06s: that uh the reading climate data science\n7295.099s: was was designed to be coupled with the\n7298.639s: lead lecture and lip seminar so that so\n7301.58s: so that when you listen to the\n7303.98s: presentations you don't want to ask you\n7305.9s: don't want to interrupt the speaker too\n7307.639s: often or you want to have some expanded\n7310.159s: conversation about certain aspects of it\n7312.44s: but they never feel the moment is right\n7315.38s: in the middle of seminar or even in the\n7318.02s: reception to have such conversation so\n7320.3s: we the reading in climate data science\n7322.28s: course is like a topic course for Docker\n7325.4s: students um current literature and we\n7327.8s: are hoping to iterate that course\n7330.08s: further to be more tight connected with\n7333.92s: um with ongoing research so at the very\n7336.8s: end the final the final project the\n7339.32s: final is not project the final is a\n7341.659s: small reading project for the student we\n7344.3s: invite the student to focus on some of\n7346.58s: the readings and then pinpoint a few\n7349.159s: things that I think are actionable in\n7351.44s: their own research direction or\n7352.58s: something they're interested and then\n7354.44s: try to outline their interest of\n7356.36s: potentially pursue that further so we\n7358.94s: believe we are envisioning this as as a\n7362.659s: exercise to build up Community to allow\n7365.36s: the doctor student to know each other\n7366.86s: but also allow them to to get more out\n7371.239s: of the lecture courses uh the lecture\n7373.639s: the seminars from the leap organizers\n7375.739s: and and also to learn how the soft\n7378.08s: skills of Reading literature the soft\n7379.88s: skills of identify questions and\n7382.88s: problems from literature so that that's\n7385.04s: the second course the third one is a\n7387.26s: climate prediction challenges which is\n7389.78s: actually two things one is a course a\n7391.88s: project-based learning the other is a\n7393.739s: collection of small challenges we're\n7396.199s: trying to create I think there is a lot\n7398.179s: of appetite for for challenges that can\n7401.54s: engage researchers we start with three\n7404.119s: small challenges last year hurricane\n7406.099s: predictions we we turned one of uh whip\n7410.48s: whipping\n7412.239s: water stratification like temperature\n7414.86s: certification project into a physics\n7417.44s: informed machine learning project and\n7419.659s: which we have returned guillen's test\n7422.78s: lab data set into a a challenge on\n7425.599s: spatial temporal modeling so those are\n7429.32s: as we as all the focus group activity or\n7432.32s: the risk activity going forward I\n7434.06s: believe that this effort can move in in\n7438.08s: two ways one is that we can continue we\n7440.84s: will continue creating such challenges\n7442.94s: big and small but these challenges can\n7445.46s: be used for our own courses but but that\n7447.739s: can also be used in embedded in other\n7449.96s: courses and a lot of machine learning\n7452.42s: courses have now all you Universal\n7455.06s: campuses in include a final project\n7457.82s: yearly students need to find their own\n7460.46s: projects they all work on sometimes the\n7462.92s: same thing and I sometimes I feel as an\n7465.8s: instructor how many cats versus dog\n7468.56s: prediction project I can agree like you\n7471.32s: you but I always encourage my students\n7474.44s: to uh to consider projects that inspired\n7478.46s: by Universal research but it's very hard\n7481.04s: for student Master student undergraduate\n7483.619s: students to identify research project\n7485.54s: out of it so I think as a resource\n7487.82s: center what we can do is to meet the\n7491.179s: student halfway so we don't have to\n7493.36s: solve like fully Define the the research\n7498.199s: product for them but I we can we can\n7500.0s: unpack the science unpack the data get\n7502.82s: them started a little bit before so that\n7505.52s: they can take it from there\n7507.38s: and many of such opportunities this I\n7509.42s: will touch upon them later and then uh\n7512.06s: everyone uh enjoyed the boot camps so so\n7515.179s: last night we were here we had the\n7517.099s: weather first momentum boot camps and\n7519.619s: then and then we just had another one in\n7522.5s: um\n7523.88s: a little bit over a week ago or 10 days\n7526.58s: ago and and at the the teachers College\n7529.159s: Learning Center which everyone enjoyed\n7532.219s: both the intellectual content our the\n7534.98s: intellectual content the community and\n7536.96s: also the space so we look forward to to\n7539.84s: continue doing that and we will iterate\n7542.36s: I took notes earlier today when the\n7545.599s: focus group talking about they want to\n7547.159s: learn Advanced skit they want to learn a\n7549.679s: fortune so we can discuss and you know I\n7552.8s: want I think Ryan and Julius and you\n7555.32s: know the Education team we can discuss\n7557.0s: about what's possible we will we will\n7559.159s: not I'm not committing that we'll be\n7561.739s: doing all of this ourselves and then but\n7564.08s: we can take a take a leadership of\n7566.78s: discussing what will be the best way of\n7569.0s: of organizing such learning activities\n7572.599s: um and then uh forthcoming so so this is\n7576.26s: the the first time we will talk about\n7578.0s: this in the leap community that for the\n7581.0s: proposal we're talking about a full\n7582.56s: course certificate that engage including\n7584.84s: a lot of background courses and then the\n7587.179s: challenge of that operation is that that\n7589.28s: has to happen\n7591.08s: um not just at Columbia but but\n7592.76s: elsewhere I need to be organized online\n7594.38s: then we recognize that many of those\n7596.96s: background courses such as machine\n7598.94s: learning course or climate science\n7600.619s: course or even Computing course already\n7603.02s: exists in in nearly all institutions so\n7606.26s: what leap contribute to that certificate\n7608.599s: is this the final course in in machine\n7611.84s: learning for environmental Earth\n7614.659s: sciences that a Capstone experience and\n7617.54s: take all the students with the right\n7620.599s: background\n7621.92s: um to another next level in climate data\n7624.32s: science research so we are in in an\n7626.3s: active discussion with Columbia a\n7629.119s: various team of trying to create such a\n7632.119s: micro credential that would allow us to\n7635.96s: support such need at skill\n7640.4s: um so uh so those are uh those are\n7644.06s: things typically happen uh during the\n7646.58s: semester or very close to semester and\n7649.099s: leave some we got busy during summer so\n7651.56s: in in summer uh we can think of we think\n7654.38s: of three main activities we have the ru\n7656.92s: and and then the ru's goal is to provide\n7660.92s: risk experiences for undergraduate and\n7664.219s: the key word here is a research\n7666.199s: experiences not necessarily research\n7670.239s: activity there are differences in there\n7672.92s: and then it took me a while to learn the\n7675.139s: differences and it's very important to\n7676.82s: know the difference that the for our EU\n7679.28s: program the value the the the the focus\n7682.04s: is to engage students in research and\n7685.58s: allow them to experience research so the\n7688.28s: focus shouldn't be that that activity\n7690.32s: they do would be super valuable for the\n7693.38s: risk itself it may because some of our\n7696.08s: Ru students you know produce\n7699.44s: research results that lead to that could\n7702.92s: be later being published but sometimes\n7705.619s: research we all know research fail uh\n7708.8s: and and then so the focus should be\n7710.96s: engage them and support them to\n7713.119s: experience research so that they become\n7714.679s: interested in pursuing research after\n7717.38s: the undergraduate it's a way of\n7719.239s: broadening participation is a way of\n7721.34s: building up the future and a way all\n7724.159s: have a responsibility of of that so the\n7727.28s: reu program I have this um goal and we\n7731.179s: also are envisioning the summer momentum\n7734.06s: fellows being a mechanism to to engage\n7737.179s: data science doctor students in doing a\n7739.699s: research intern the more the idea needs\n7743.3s: to be mapped out more into a more\n7745.58s: concrete plan but but I we believe that\n7749.0s: it's a mechanism that is more suitable\n7751.76s: for data science students who have a\n7754.219s: focusing methodology research but\n7756.02s: they're willing to spend one summer to\n7758.179s: be to have an immersion so think about\n7760.159s: this as a research immersion that they\n7762.38s: take what they know in machine learning\n7763.82s: and then immerse themselves with a\n7765.8s: research group with a climate science\n7767.54s: research focus and then you know if they\n7770.36s: do patient computation mcmc and we can\n7773.48s: do the matchmaking with IA with a team\n7776.119s: and if they do transfer learning or\n7777.92s: Active Learning\n7779.48s: um we can then that for them the the\n7782.48s: goal is to to Really contribute to the\n7785.3s: research learning through experience and\n7787.639s: the idea is that they may become they\n7790.219s: may find out whether they can contribute\n7792.08s: the research in a in a three-month\n7794.599s: period and then the the outcome would be\n7798.139s: the either either research fail or the\n7801.26s: time this idea didn't work but also the\n7803.78s: positive outcome would be they become\n7805.219s: interested let's say engage to become\n7807.5s: collaborators and and then integrate a\n7810.739s: climate science application as part of\n7812.659s: their dissertation so that will be a\n7814.94s: win-win for for both sides for the\n7816.98s: hosting uh research group and for the a\n7819.98s: student themselves\n7821.659s: then we heard from Oren about our summer\n7824.36s: Institute for kcr teachers and and I'm\n7827.179s: not going to repeat on that but but uh\n7830.06s: powerful participation are forthcoming\n7832.34s: and and I will catch upon that a little\n7834.86s: bit later\n7835.88s: and then you're seeing a version of this\n7838.219s: in uh here's presentation that we really\n7840.86s: want participation from researchers in\n7843.44s: the education effort not because we\n7846.86s: cannot not be well not simply because\n7849.199s: that we can we cannot do do all of these\n7852.44s: ourselves like it's not just because of\n7855.08s: short of Labor that we need uh we need\n7857.78s: human resource but because I I with I\n7861.139s: think there are natural values so what\n7863.06s: do we want from one to four I say we\n7866.78s: want you to be your brilliant self I\n7869.119s: want you to everyone enjoy research\n7870.86s: we're here because we enjoy research we\n7873.32s: believe that we can contribute our\n7875.3s: research to solve important problems and\n7879.26s: and then when I think about education\n7881.599s: programs I feel there is a role that\n7884.9s: researchers can play just being\n7886.34s: themselves and another then as a\n7889.219s: research team as an education leadership\n7890.96s: team is around the creates mechanism and\n7894.44s: infrastructure and programming so that\n7896.659s: you come in being yourself but you still\n7898.88s: contribute uh meaningfully to the\n7901.34s: education effort\n7903.139s: um so we want you to participate in\n7906.02s: things that you care about so I we have\n7909.08s: many many ways that researchers can\n7910.82s: participate a broader participation uh\n7914.54s: convergence between machine learning and\n7916.58s: climate data science uh or self like\n7919.34s: creating challenges and any we have\n7922.219s: heard a lot of comments throughout these\n7925.04s: two days that many people care about\n7927.38s: these topics and then if you care about\n7929.78s: it and we can we can design mechanism\n7932.9s: for you to lead or participate in things\n7936.56s: in this direction that you care about\n7938.659s: and then to make it to have this\n7941.06s: alignment I feel Synergy and convergence\n7943.78s: is is is how we can effectively doing\n7947.9s: research education not a transfer bi at\n7950.599s: the same time\n7951.8s: um at the new center\n7954.139s: and and then um we also want activity to\n7957.98s: benefit your research and I'm gonna talk\n7960.98s: a little bit about that\n7962.599s: um and then so so search several several\n7965.54s: several uh mechanism I actually wrote\n7967.28s: this last night without hearing all the\n7969.44s: all the discussion today so this is very\n7973.699s: much in sync with uh what we have\n7976.46s: discussed so far and we want we would\n7978.619s: like to\n7979.639s: um invite researchers to co-design\n7981.98s: prediction challenges based on your\n7983.9s: research\n7985.52s: um especially if you say I\n7988.76s: um sometimes use analogy with when I was\n7991.82s: at data Science Institute I I say I want\n7994.579s: our research to think that they they\n7996.619s: enter the candy store of machine\n7998.78s: learning and they know other people have\n8001.599s: enjoyed the candies and they look and\n8003.219s: they all look very shiny and then they\n8004.84s: they they they so you go to the the top\n8007.78s: Journal of your field and not like in a\n8010.06s: candy store and you see some of the most\n8011.8s: exciting research being driven by\n8014.02s: Machine learning and are you imagine\n8016.0s: yourself in such a store and I said I\n8018.28s: want that and then education can allow\n8021.46s: you to explore that because you may want\n8023.679s: that but do you really know you'll want\n8025.36s: that and then I think a lot of time the\n8028.42s: our our the with our internal battle is\n8031.659s: I think I want that but I'm not sure I\n8034.239s: can't have that\n8036.04s: and and should I stop what I'm doing and\n8038.98s: I know should I step out of my comfort\n8040.9s: zone and then say I want that and and I\n8045.46s: want to have that and that's a big\n8047.5s: decision sometimes education allows you\n8050.739s: to step out of your comfort zone a\n8053.199s: little bit\n8054.76s: um and then at the same time\n8056.199s: contributing to education effort so you\n8058.54s: you even if you if you decide I you know\n8061.659s: that's not something I would enjoy so I\n8064.0s: I am glad I tried but my conclusion is\n8067.96s: that I would step back and do my Euro\n8070.42s: research business as Europe but at least\n8072.159s: you contribute to education effort and\n8074.86s: then that's also a very effective way of\n8076.48s: learning it I remember\n8078.82s: um came to my office a few years ago and\n8082.3s: I initially were talking about\n8083.5s: collaborations and then we talk about\n8085.42s: one idea of you gaussian process and I\n8087.639s: literally just stepped out of my office\n8088.84s: grab a doctor students and then knowing\n8091.599s: that they would do a course project and\n8093.099s: I was just asking whether and look\n8095.38s: whether they're interested in talking to\n8097.119s: a student and start doing this product\n8098.619s: it's it's a great way of of co-design\n8101.679s: something\n8102.579s: and so you can also um the machine\n8105.34s: learning instructor if you want to we\n8107.98s: all know that there's nothing better to\n8109.48s: learn than to teach\n8110.98s: uh so if you're hosting a a climbing\n8114.28s: challenge prediction challenge in your\n8116.02s: course you will you will have to learn a\n8118.48s: little bit you will read a lot of final\n8120.159s: reports about it and then you you you\n8122.92s: you may you may you may have climate\n8125.38s: science student in your class if you\n8127.54s: have if you have a reputation now your\n8129.579s: class class challenges Inspire that\n8131.679s: climate science research so machine\n8133.3s: learning structures can learn climate\n8136.36s: science this way well uh climate\n8138.82s: researchers I sometimes think if you if\n8142.239s: you think that you already know what you\n8144.639s: want in machine learning with a weak\n8146.26s: idea and you are willing to work with\n8148.179s: not a big class of 500 students you\n8151.48s: don't want to go to Carl's class and\n8152.8s: talk to the 500 student and they all\n8155.079s: rush to your office and want to do your\n8156.94s: project but if you say I'm willing to\n8159.239s: Mentor one team and I want to wander one\n8162.82s: team to consider transfer learning and\n8164.86s: then you have a well-defined and our\n8166.84s: team can help you with that definition\n8168.159s: then you can show up to Carl's class to\n8170.619s: a 5 five minutes project pitch saying\n8173.86s: that this and Carl can say this is this\n8175.96s: you can use all the computer original\n8177.28s: Vision tools and then the idea is a car\n8179.86s: needs to grade those projects anyways or\n8181.719s: some version or try gbt integrate that\n8183.76s: anyway so the so naturally the students\n8187.599s: is learning and is supported in a\n8189.88s: learning environment but somehow you\n8191.56s: will get a taste of the research so I\n8194.8s: think as these are the ways and then for\n8198.099s: the ru students because the goal is to\n8201.399s: create this experience the the go the so\n8205.059s: we do want\n8206.559s: the the the people who participate in in\n8210.099s: creating research project for IU\n8211.78s: students to think more long term that\n8214.24s: where we are preparing a Thailand\n8216.16s: pipeline so so the the the the the\n8218.76s: immediate return may not be high but it\n8221.8s: is one of the mission of that so we are\n8224.08s: inviting researchers to participate but\n8226.3s: with a warning label saying that we're\n8228.34s: not giving you five students that will\n8230.679s: clean your data set and then you will\n8232.78s: many amazing things will happen for your\n8235.3s: research but many amazing things will\n8237.34s: happen if these five students decide to\n8239.859s: pursue a research career in climate data\n8243.04s: science uh but so the PHD fellows I\n8245.62s: think the the immediate return could be\n8247.599s: high uh so you if you have a good match\n8250.84s: between you risk projects and the\n8253.599s: research interests of that doctor\n8255.639s: student who is interested in doing a\n8258.58s: data a machine immersion in your in your\n8261.58s: lab and you can actually get pretty\n8263.559s: serious about what research you would\n8265.179s: like to do together\n8267.82s: um in addition that from time to time\n8270.76s: for the summer Institute for creating\n8273.04s: activities we are hoping that\n8275.74s: researchers will will participate\n8278.439s: so what um we also want to make it easy\n8281.74s: for you I have already touched upon this\n8283.66s: uh we have Design Studio interns who are\n8286.42s: Master students who can uh so one idea\n8289.479s: is that you have python codes for your\n8291.399s: paper and you sometimes you don't want\n8293.8s: to share them because you're embarrassed\n8295.359s: by how messy they look and you just also\n8298.3s: you just don't want to share them\n8300.04s: because you know the moment you share\n8301.66s: them people will email you because they\n8304.42s: cannot run them they want you to help\n8306.76s: them I got I got those emails too so so\n8309.7s: so so so and a master's students are\n8312.219s: looking for risk experience all the time\n8314.26s: we have thousands of them on Colombia\n8316.24s: campus and they are looking for research\n8318.54s: one research activity for them to read\n8321.219s: the paper read your code and create a\n8323.38s: clean reproducible Jupiter notebook out\n8326.679s: of it and and yes you will need to spend\n8329.559s: time with the student you will Mentor\n8331.42s: the students but that that effort will\n8334.3s: pay back when when you have a clean\n8336.519s: beautiful uh Lee Pandi already a Jupiter\n8341.019s: notebook that can save your effort and\n8343.92s: amplify the impact of research at scale\n8347.5s: so that's the the kind of thing that you\n8350.5s: it's educational because you're offering\n8352.899s: students research experience and you may\n8355.0s: even make it make it fun and you can\n8357.7s: even do a half of some people just you\n8359.62s: know think about visualizations uh think\n8363.16s: about uh Innovative way of introducing a\n8366.7s: concept of climate science to data\n8368.559s: science a lot of these can be turned\n8371.8s: into learning activities and then\n8374.859s: leverage the energy and the Curiosity of\n8377.62s: many students on campus and at the same\n8380.019s: time can be beneficial\n8381.639s: another Design Studio we you are now\n8384.399s: saying you should be the one designing\n8385.899s: it and we are I personally will be more\n8388.42s: than excited to meet with whoever have\n8392.14s: such need have such uh such desire to be\n8396.16s: open to the discussion and then to show\n8397.96s: you that nearly everything we do as\n8400.96s: researcher can be turned into learning\n8403.72s: activities but the key is is to identify\n8406.899s: the right students the right group of\n8408.88s: Learners that you're you will be engaged\n8411.64s: with not every activity is appropriate\n8414.34s: for undergraduate not activity is\n8416.08s: appropriate for a doctorate student\n8418.479s: um so identify the right learner\n8420.34s: identify the right format should it be\n8422.979s: course based should be summer should it\n8425.02s: be a intensive hackathon should be a\n8427.899s: asynchronous challenge that would create\n8429.82s: on GitHub and GitHub and just broadcast\n8432.58s: them through the the email newsletter\n8434.859s: and all of these are choices we can make\n8437.88s: to to design is that there's a human\n8441.04s: centered design element to this and I\n8444.399s: remember the mentioning of soft skills\n8446.38s: such as project management\n8447.34s: Communications and and and then human\n8451.12s: centered design is another thing that\n8453.88s: that that that make you a better\n8455.859s: researcher that also make you better\n8457.42s: educator\n8459.399s: um you know so um so the lead pandu team\n8463.359s: is more than ready to discuss with you\n8465.34s: about the data and Computing need if you\n8468.22s: are for both research and education\n8470.74s: because it's true are really coupled and\n8472.78s: whenever we\n8474.28s: um and the pandu team has been\n8476.439s: advocating for open science for years\n8478.899s: and many of them involve education of\n8482.859s: open science practices at scale is\n8485.56s: advocating for reproducibility in in the\n8488.74s: before leave proposal there was another\n8490.479s: proposal called dicks data\n8493.899s: in terms of geoscience\n8497.14s: um in there we're advocating for open\n8499.24s: science the creating the Innovation\n8501.399s: ecosystem that's supported by better\n8503.979s: computational practices for\n8506.439s: geoscientists and and then\n8509.2s: um learning how to become better\n8511.78s: computational science scientists is\n8513.399s: painful if you're doing on yourself on\n8515.68s: your own you know in your lookup like a\n8518.319s: stack Overflow or read it and then try\n8520.78s: to make sense of all the comments I\n8522.52s: computer science you don't do it they do\n8524.74s: it in groups they do they they hand out\n8527.8s: together they they they complain about\n8530.979s: how confusing certain you know comments\n8534.1s: are they so they so they figure things\n8536.08s: out together and and then education is a\n8539.439s: great way to to join such a community\n8542.74s: um if you're ambitious you can join a\n8544.6s: community of 50 students if you worry\n8547.42s: about your bandwidth you join community\n8548.8s: of three two three and even two to three\n8550.6s: doing things together uh would make it\n8553.06s: more fun and more rewarding and then\n8555.28s: you'll see the growth you see\n8556.72s: conversions that just byproducts of this\n8559.6s: effort to make even better I meant that\n8562.479s: the education teams here I'm talking\n8564.28s: about jiha uh Charles and I like orange\n8567.34s: leaves the summer Institute so it's\n8569.319s: you're the team but you don't I'm not\n8572.08s: testing you our Logistics the three of\n8574.42s: us can really discuss with you uh\n8577.84s:  how can we be helpful with\n8580.3s: logistic application forms review\n8582.479s: applicants identify space you know\n8586.0s: ordering snacks you know I'm not making\n8589.359s: announcements and Catherine is more than\n8592.72s: happy to tweet and linking everything\n8595.18s: that that every every excitement come\n8598.359s: out of such effort\n8600.1s: um\n8601.2s: then\n8602.979s: so the most natural the most low-handing\n8606.1s: fruits for educational activities that\n8609.22s: can benefit research is exploration of\n8611.92s: ideas uh one one time I hosted a course\n8616.6s: project for OCR optical character\n8620.939s: recognition that some researcher was\n8623.74s: hoping to look for to to evaluate\n8626.859s: algorithms that the correct for arrows\n8628.96s: in OCR and and then he asked me ideas I\n8632.92s: have no idea I don't know that\n8634.72s: literature and I and then I said how can\n8637.06s: I\n8638.5s: um learn and incidentally I was also\n8640.42s: looking for a project idea for a course\n8642.7s: I was teaching like we you we use common\n8645.22s: data framework which means that the\n8647.859s: whole class work on the same challenge\n8650.319s: at the same time and the share ideas so\n8652.78s: I said okay so how come and talk to my\n8655.06s: ta so we we review the list literally\n8657.76s: very quickly identify a a bunch of\n8661.3s: papers and assign the paper to randomly\n8664.3s: assign the paper to teams and each team\n8666.939s: is tasked to evaluate uh a pair of\n8671.8s: algorithm for OCR Arrow correction using\n8675.46s: a common data set we created so if you\n8678.1s: think about that I am interested in will\n8680.74s: learn\n8681.939s: um\n8682.96s: um mcmc or patient framework or or\n8686.1s: convolution neural network or lstm all\n8688.96s: those things I want to learn and I have\n8691.84s: no time of\n8693.22s: I have it will be a very slow process\n8696.46s: for me to learn all the paper in in a\n8699.7s: matter of semester if you put in a\n8703.18s: structural education setting you were\n8705.46s: forced to structure the problem first\n8707.14s: and then the students go out but then\n8709.54s: they present when they present you can\n8711.819s: ask difficult questions that's why I\n8713.62s: said show up be your brilliant self we\n8715.96s: all have done this we show up to\n8717.88s: seminars we show up to conferences we\n8720.46s: show up to cease of Defense when we\n8723.04s: listen to the research we think about it\n8725.2s: and we can ask great questions and\n8727.6s: imagine how that is relevant to our\n8729.34s: research so when you do projects this\n8731.8s: way in a classroom you show up you don't\n8734.319s: have to prepare much and you don't kind\n8736.6s: of test that sometimes I just ask her to\n8739.18s: show up without knowing what she will be\n8741.64s: saying but when she walk around working\n8743.8s: with each team I I don't think that you\n8746.439s: have a difficulty coming up with\n8748.18s: feedback to the teams and then the team\n8750.399s: try out ideas and then sometimes our\n8752.62s: idea well no way but sometimes our idea\n8754.84s: works so that's a great way of\n8756.76s: exploration of ideas and then for the\n8759.399s: doctor student and postdoc this is also\n8761.859s: a great way of communication is is when\n8765.16s: you communicate with students you\n8766.6s: suddenly realize that you need to\n8769.0s: create multiple ways of explaining the\n8772.78s: same concept if you're first saying\n8775.12s: climate attribution they look like blank\n8778.359s: at you and you need to about what I mean\n8781.78s: is that so so a lot of this is a soft\n8784.84s: skill in communication\n8787.42s: um recruitment of talents I opened some\n8790.12s: by different discipline have different\n8791.979s: way of admitting doctor students in\n8794.62s: statistics we have a committee model but\n8797.02s: in some discipline you have a lab model\n8799.54s: that you recruit directly into your lab\n8802.42s: um there's no better way of of learning\n8805.24s: the the ability of students through\n8807.88s: educational programs so um\n8811.12s: um and then the third the third level of\n8813.34s: benefits are just the soft skills that\n8815.74s: project management management\n8817.2s: interpretation and translation skills um\n8820.84s: that I mean translation skill means that\n8823.12s: you are working with people from other\n8825.399s: disciplines with with a different level\n8827.5s: of Technical Training and then the more\n8830.74s: you you participate the more you can you\n8834.22s: you can benefit from that on your\n8837.64s: professional skills and I think\n8841.12s: that was my but let me let me another\n8844.06s: thing is that\n8845.92s: um if we go back to\n8848.56s: this one\n8850.06s: um\n8850.8s: these lineup of programs offers\n8854.58s: different way of Engagement in terms of\n8858.399s: time in terms of Topic in terms of level\n8862.899s: right so if if you if you all of this\n8868.66s: um can be designed so if you say 10 I\n8871.42s: teach semester courses I cannot really\n8873.04s: commit to work with students in a\n8875.26s: Capstone projects through our semester\n8877.359s: but I'm I am curious about what they can\n8880.12s: do you can be a judge for hackathon\n8883.479s: that's a one-day commitment and that\n8886.42s: you'll learn a lot through that I have\n8888.52s: been judges for cataston for for\n8890.46s: elections for Smart City design for\n8893.56s: gentrification you you sort of when you\n8896.92s: listen to 10 presentation talking about\n8899.56s: why it is important than what they did\n8901.6s: and why is you you sort of learn a lot\n8904.54s: it's really an easy way to do and if you\n8907.42s: say I want this to be meaningful to my\n8910.96s: own research I'm willing to spend time\n8913.06s: one hour a week uh with Ico students and\n8917.14s: that is a mentor research and we can set\n8919.359s: up a section and you know in I don't\n8922.24s: know about other institutions in\n8923.56s: Colombia students can take for credit\n8925.66s: for mental research or they can be hired\n8928.18s: as research assistant those mechanisms\n8930.64s: can be explored so so\n8932.939s: we want\n8934.84s: what do we want we want you but we don't\n8938.14s: want you to do anything that you would\n8940.479s: not want to do we try to convince you\n8943.5s: that there are ways that you can uh you\n8947.5s: can be part of this and then that's what\n8949.12s: we call education research integration\n8951.1s: so with that I'm happy to take questions\n8970.24s: very quick one how do you develop the uh\n8973.12s: the list of climate prediction\n8974.439s: challenges that are offered for that\n8976.479s: course so so we were doing it for the\n8979.6s: first year I I basically I went through\n8982.18s: the pi named and search up their papers\n8985.859s: and rest some of the latest papers and\n8989.02s: then if the paper have a GitHub\n8990.46s: repository\n8992.8s: um I will review to see you know I I'm\n8996.22s: not I'm not I'm not trying to create my\n8999.939s: own challenges I'm not going to find a\n9002.16s: paper that does not have a GitHub does\n9004.319s: not have a have somebody I know I'm just\n9006.72s: saying I want to create a project out of\n9008.399s: that so for Education we are not focused\n9012.42s: on doing the most Cutting Edge we're\n9015.0s: trying to create learning\n9017.52s: um learning experiences so for the\n9019.56s: research we want to want them to be\n9021.42s: education integration ready but if a\n9024.6s: researcher see the benefit and they say\n9027.18s: I don't have a clean GitHub repository\n9029.34s: but I want to participate then we will\n9032.1s: need a more extensive development that\n9034.92s: because they come to me that uh\n9036.6s: naturally I have Pi engagement already\n9038.399s: then we will hire a design student\n9041.1s: intern to develop that there are two\n9042.78s: ways\n9060.18s: um I wonder if there's any possibility\n9061.92s: for uh am I\n9065.28s: sorry yeah a possibility for the\n9069.0s: multi-institutional\n9070.52s: [Music]\n9071.76s: join class because you already mentioned\n9074.64s: like every class materials from peers\n9076.8s: and years uh on the kid of repo so\n9079.979s: everyone can um recreate in their own\n9082.979s: institution but I think there could be\n9085.02s: benefit to bring all together and this\n9088.319s: especially I think like teaching\n9089.939s: faculties may be able to save their time\n9092.76s: by sharing teaching load\n9094.92s: right so yeah curious like yeah I want\n9098.819s: you to explain what do you mean by join\n9101.76s: class\n9102.96s: um so\n9105.479s: same class like happening at the same\n9108.24s: time but at multiple locations so let me\n9111.0s: wear my department chair hat here\n9114.0s: so as a department here if Pierre is my\n9116.819s: faculty and he want to teach his course\n9119.04s: and he want to collaborate with Mike for\n9121.5s: a course in Irvine they have decided\n9123.78s: that they're going to share lecture peer\n9126.0s: teach path might teach half is through\n9128.16s: zoom and and in that I I would not have\n9132.54s: objection I it's not that teaching law\n9135.18s: is more of Pierre is fully in charge of\n9138.0s: the course and there is a syllabus and\n9141.42s: in many courses are guest speakers\n9143.1s: they're rotating things so so to me\n9145.439s: Pierre is fully responsible of that\n9148.14s: course implementation and education\n9150.18s: evaluation at Columbia whether he would\n9153.18s: like to invite other instructors from\n9155.64s: other institutes to teach in his class\n9158.58s: that's up to him to decide same with\n9160.8s: Mike I believe whatever I think our\n9163.2s: universe work this way what is\n9165.18s: complicated I see Eric there what's\n9167.76s: complicated is is to is to openly is to\n9172.14s: is to say you'll be taking a Columbia\n9175.02s: course right so that will appear as a\n9177.42s: Columbia course on your transcript and\n9179.64s: it's not it's not impossible it just\n9182.819s: have another administrative hurdle that\n9185.04s: you need to do a and you you need to be\n9187.2s: at the meta as a non-degree student I'm\n9189.84s: going to take and then that need to be\n9191.16s: online that so that's why I asked you\n9193.56s: what do you mean by joint if you mean\n9195.42s: that they will cover the the lecturing\n9199.319s: uh the coordinate some lecturing having\n9201.84s: some gas become guest lecture to each\n9204.12s: other classes that's totally that's a\n9207.12s: totally mechanism people already using\n9208.8s: but if you're thinking that this course\n9210.72s: is officially processed between UC\n9214.2s: Irvine and Colombia I honestly don't\n9216.479s: even know what that means\n9222.24s: here by a presentation I was wondering\n9224.939s: say we have like a summer research\n9227.939s: program and we are trying to hire say\n9230.34s: like an undergrad or Master student I'm\n9233.04s: just curious like what sort of support\n9235.08s: you can provide and say like finding the\n9238.319s: student possibly funding them training\n9240.72s: them and so on so jihei would uh we were\n9244.5s: we were officially mapping that out next\n9247.439s: week which we have a workflow so what\n9250.02s: the workflow from the research\n9251.46s: perspective from the researcher\n9253.38s: perspective is that we will call for a\n9256.14s: resub description so basically we we\n9258.42s: want to have a call for people to\n9260.64s: contribute research project in terms of\n9263.1s: what you're envisioning as the long-term\n9265.859s: project what is the short-term summer\n9268.319s: project how the children program fit in\n9271.02s: the long-term project and most\n9273.12s: importantly is that what are the\n9274.74s: learning outcomes of this experience\n9276.18s: that you're thinking the student will\n9277.38s: benefit from because they will ask those\n9279.479s: questions to us and we don't know how to\n9280.979s: answer on your behalf in additional what\n9283.38s: are the deliverables a student of\n9285.42s: America is about what are the potential\n9287.7s: deliverables of the research whether it\n9289.859s: will be a a software visualization\n9292.68s: papers all of the above and then\n9296.64s: um and then what are the prerequisites\n9298.8s: like do you prefer to have a junior\n9301.5s: senior students Master students what\n9304.319s: other for uh prerequisite skills you\n9307.14s: would like to have so with all this\n9308.819s: information we will listen in one place\n9313.08s: where all the product description and\n9314.76s: students submit an application an um\n9317.52s: blanket blanket application to all the\n9320.64s: projects how to to select the product\n9322.56s: they will choose their preferences and\n9324.78s: we will send the pis a collection of\n9328.08s: students for them to look at and then\n9329.7s: they um they will you know they will\n9333.54s: um start the matchmaking\n9338.76s: we also partner with Amazon Shores\n9342.3s: program and also a few other\n9345.68s: similar summer IU programs so they put\n9348.899s: the students first and then they try to\n9351.0s: match uh with a student into research\n9355.02s: group and centers so having such a\n9356.819s: collection project will also allow us to\n9359.04s: share with the administrator of the\n9361.319s: program and they will share the project\n9362.76s: with respect students and they will\n9364.92s: approach us\n9372.6s: I had a comment and a question\n9375.18s: um the comment is um thank you so much\n9378.24s: for making these courses so portable\n9380.76s: um I recognize all the institutional\n9382.26s: barriers to getting things actually for\n9383.939s: credit but like the fact that pierce\n9386.22s: course was able for UC students to audit\n9389.58s: um work seamlessly and and the demand\n9391.859s: was amazing\n9393.12s: um and so anyone who's at a different\n9395.28s: institution\n9396.54s: um this we're hearing great things about\n9398.22s: this course and and um spread the word\n9400.74s: like it would be great to see this take\n9402.06s: off it's a real\n9403.56s: it's a real impact um\n9406.58s: so the Columbia engineering school\n9408.96s: supported the leap in a way that\n9411.06s: students that is a part of the leap\n9414.3s: Community can add it through the\n9416.52s: Columbia video Network\n9419.04s: um at no cost to tune to them right I\n9421.56s: remember the video\n9423.06s: you added them right as auditing as\n9425.7s: auditing students so to the extent that\n9428.28s: NSF monitors are our legacy and our\n9430.859s: impact in this way that's our\n9432.18s: quantifiable like impact that is going\n9434.819s: to help our Transit renewal and that's\n9436.38s: so wonderful and we should make sure to\n9438.0s: sustain it and if it's working here and\n9439.859s: think about it in\n9441.84s: um in the climate challenge prediction I\n9443.52s: don't know if it's as portable or not\n9444.6s: some courses are hard but we shouldn't\n9446.22s: make work I think my innovation of\n9450.54s: making that affordable is that we design\n9452.58s: the challenges and then we're happy we\n9455.34s: can we're happy to engage instructors\n9457.26s: who are waiting to use them in their\n9458.76s: course so we can do it as a group\n9460.859s: session we can also do it office hour uh\n9463.8s: section that they they they eventually I\n9466.68s: want to grow the collection of climate\n9468.3s: prediction challenges almost like a\n9469.859s: candy store and people pick it up and\n9472.08s: but they want to know how to use it well\n9473.939s: how to eat it then then we will we can\n9476.819s: do that in a very short\n9479.04s: um tutorial section so that will make it\n9481.859s: portable\n9483.54s: um and then the question was uh can you\n9485.64s: tell us a bit more about the PHD\n9486.78s: Fellowship a program in the summer how\n9488.46s: big is the pool how how are people being\n9490.5s: yeah and I was it was were we exchanging\n9494.04s: comments maybe Pierre can cheer yeah\n9496.5s: that's still in development but we're\n9498.479s: thinking about that as a way to also\n9500.16s: Engage The Machine learning community so\n9502.26s: I'm going to talk a little bit about\n9503.819s: that later today like yeah\n9506.16s: um stay tuned\n9510.6s: I'd also want to mention that you know I\n9515.1s: you know I'm\n9517.859s: sometimes I have a hard time recalling\n9519.78s: how I actually feel like when I was a\n9521.64s: doctor student\n9523.92s: um but I I remember when I was a\n9525.899s: doctor's student or even as a junior\n9527.28s: faculty you sometimes wonder what should\n9530.46s: you do what I should be doing like\n9532.62s: whether this is something I should be\n9534.0s: doing I think there are I think all the\n9536.58s: pis or the senior faculty in this room\n9538.46s: recognize that there are competing\n9540.899s: priorities there are values in PhD\n9544.08s: students and posts are participating in\n9546.0s: educational activities but at the same\n9548.399s: time there are only so many hours in a\n9550.14s: day and we fully understand that so we\n9552.84s: will We would like so what do we do in a\n9555.78s: leap Education team is we encourage all\n9558.42s: the doctors during the postdoc to\n9560.24s: consider this because there are actual\n9562.859s: benefit but have a conversation with\n9564.84s: your with your advisor with your Mentor\n9567.3s: in how much and in what forms would be\n9571.68s: the best way for you to participate uh\n9574.439s: for your professional growth because\n9576.42s: there are a lot of benefit in terms of\n9578.939s: you know making making you attend you\n9582.12s: into a better community cater turns you\n9584.1s: into a better educator turn you into a\n9586.2s: better researcher actually by by doing\n9588.78s: that so there are ways that\n9591.72s: um we can cover a lot of those bread and\n9594.479s: butter activities ourselves but the\n9597.12s: researcher participation make it more\n9601.74s: amazing and wonderful and then we we can\n9604.62s: run a very boring version of everything\n9607.439s: you see but the more participation we\n9610.08s: have from research the more exciting the\n9612.3s: more engaging and more beneficial the\n9614.399s: program will be for our students and for\n9616.319s: our researchers\n9617.7s: so I just want to say this to the doctor\n9619.92s: student and post that in the audience\n9621.8s: that that discusses with your Mentor if\n9626.399s: you're interested we have one more\n9628.319s: minute for a pressing question or\n9631.26s: comment\n9633.42s: s\n9635.33s: [Music]\n9642.54s: I'm loving so much about how the\n9643.979s: organization of leap actually works I'm\n9645.66s: really impressed so I'm going to speak\n9647.16s: for people who are outside of lovely\n9649.5s: um you talked about the researchers the\n9650.939s: students within the program but there's\n9653.1s: going to be a lot of people outside of\n9654.78s: this collaboration across the United\n9656.64s: States and other countries you're like\n9658.2s: what you're doing is so cool\n9660.78s: what are your thoughts about having that\n9663.18s: impact outside of this formal\n9664.92s: organization I you may not have a\n9666.66s: student audit at Columbia but materials\n9669.42s: are there joining on web Zoom is that is\n9671.88s: that part of the Mandate of leap or is\n9673.38s: like no we gotta Focus internally\n9677.28s: um we're building up so a lot of the a\n9679.8s: lot of effort last year was we're\n9681.359s: building up this everything you've seen\n9682.859s: would build up from uh I think with the\n9684.96s: exception of Pierce course that exists\n9686.7s: before lead and then some of the ngos\n9689.1s: are existed before they leave a lot of\n9690.78s: things we you see uh build up last year\n9693.6s: and and then we are hoping to create\n9696.42s: materials that can be used by anybody\n9698.7s: including the micro credential program\n9700.62s: I've seen the Mandate we are we are do\n9704.28s: we have two spots of Monday one is that\n9706.2s: we want to want our education effort to\n9708.3s: support the research we want we want to\n9710.58s: empower our own students doctor students\n9713.64s: undergraduate students to to develop a\n9716.04s: recent career in climate data science\n9717.78s: that is a very important mandate in\n9720.12s: order for what leap's mission to be\n9722.16s: sustainable to be to to contribute to a\n9725.819s: better future the other is that what\n9728.58s: they what we created should be\n9730.74s: disseminated more broadly so so our boot\n9734.04s: camp is already available to people\n9736.14s: outside even though it's because it's in\n9738.78s: person so it's geographically\n9740.16s: constrained but it's recorded that not\n9742.979s: recording can be used uh by other\n9745.74s: institutions to engage their their local\n9748.62s: community and and then we are creating\n9751.5s: open to creating online online video\n9754.56s: that teach machine learning and that can\n9757.68s: be also shared in in ways to engage with\n9761.12s: Learners and researchers outside the\n9763.399s: immediate leap community\n9766.08s: and if I may add that we may receive\n9768.24s: signing from Madonna to actually expand\n9770.1s: uh more globally especially in the\n9772.439s: developing world\n9775.56s: right with that I want to thank chanya\n9778.26s: and please be engaged you're very\n9779.819s: important yeah if you're interested\n9788.359s: with the benchmarks for CSM and first\n9791.34s: for summarizing a little bit what we\n9793.14s: discussed uh what I presented yesterday\n9794.939s: so just to professionally with your\n9796.439s: memory so again what we want to do is we\n9798.96s: want to Target a climate uncertainties\n9802.08s: again on a range of a couple of decades\n9804.06s: typically to 2060 and again we know that\n9806.88s: a lot of those uncertainties are coming\n9808.38s: from physical processes so we want to\n9810.359s: actually improve that two different ways\n9812.939s: like we want to improve metrics again uh\n9815.64s: uh training tweaking or tuning the\n9818.04s: parameters that we have in the models\n9819.54s: and improving the closures of those\n9821.64s: different parameters\n9823.56s: uh in the tragic plan that Gideon\n9826.38s: referred to a minute ago so we actually\n9828.72s: again defined that as different\n9829.8s: objectives so we talk about improving\n9831.479s: pharmacies and that relates to the\n9833.52s: parametization focus group so we expect\n9835.38s: there that machine learning could help\n9837.06s: actually do a better job so that was a\n9839.22s: lot of the discussions we had\n9841.319s: we also want to automatically calibrate\n9843.899s: the es7 that will relate to what we will\n9846.24s: present in a minute how do we actually\n9848.22s: Benchmark that how do we use the metrics\n9850.68s: that we have and how do we actually\n9852.359s: actually evaluate progress right so and\n9854.7s: that was actually part of the the\n9856.5s: estimation estimation Focus but again\n9858.899s: that's very very tightly connected to\n9860.939s: the metrics so I hope you realize that\n9864.06s: and the last objective in terms of the\n9866.7s: related to the focus groups is to\n9868.38s: advance motor evaluation so again\n9869.939s: developing different metrics bringing\n9871.68s: those metrics together and that relates\n9873.78s: back again to what Dave is going to\n9875.22s: present in a minute so how do we\n9877.02s: actually quantify progress really uh and\n9879.54s: and towards what what goals and metrics\n9882.54s: and in the end we again want to get\n9884.88s: basically our new and improved\n9886.38s: projections right that's the ultimate\n9887.819s: goal that we have but really the\n9890.16s: question is what and how do we Define\n9891.96s: better okay so that's really what Dave\n9894.24s: is going to mention\n9896.76s: foreign\n9904.56s: here just asked me to make this\n9905.939s: yesterday so hopefully this is going to\n9908.22s: be suitable for the for this discussion\n9909.84s: but\n9911.04s: um just in case anyone doesn't know who\n9913.02s: I am just want to make sure you\n9914.1s: understand who I am because I think it\n9915.84s: sets the context I'm Dave Lawrence I've\n9918.06s: been incar for 20 years and that whole\n9920.04s: period I've been involved in in the\n9921.72s: development of CSM I essentially my\n9923.939s: career has been all centered around CSM\n9927.12s: um you know I have some scientific\n9928.319s: presence but really I feel like my\n9930.479s: legacy if there's going to be one is\n9931.68s: through my contributions to to the CSM\n9933.72s: effort\n9934.979s: um and as such you know my one of my\n9938.16s: jobs was to lead the developmental land\n9939.66s: model component of CSM but I've also\n9941.939s: been involved in other leadership\n9943.08s: aspects of CSM and essentially I've been\n9945.6s: in the room for most of the major\n9947.7s: decisions most of the sausage making\n9949.8s: that's gone on in the patient of CSM for\n9952.439s: the last two decades so I feel fortunate\n9954.66s: to be in that position but I also feel\n9956.04s: like I'm trying to be a resource to the\n9958.5s: lead project from that perspective of\n9960.54s: having that that historical knowledge so\n9963.66s: um Okay so\n9965.46s: the thing we're going to need to do in\n9966.96s: leap where we want to do really anytime\n9968.399s: we're doing model development but in\n9969.54s: leapis in particular is to establish\n9971.64s: whether or not we've made the model\n9973.2s: better and the model projections better\n9976.5s: um of course it's quite hard to\n9977.76s: establish that you made a model\n9978.78s: projection better right because we don't\n9980.34s: have the validation data to really\n9981.96s: assess that we can do hind casts and we\n9984.12s: do do that and that may be applicable\n9985.439s: but we are going into unknown territory\n9987.359s: with uh climate change it's a harder\n9990.24s: problem for example than weather where\n9991.62s: we can continually validate\n9993.66s: um so most of the time what we do is we\n9995.1s: try to assess whether or not we've made\n9996.479s: the model better compared to historical\n9998.52s: observations and then it's a little bit\n10000.38s: of a hope that it's going to be better\n10002.24s: in terms of projection so in case anyone\n10003.979s: hasn't already thought through that\n10005.6s: problem before that's that's no one to\n10007.46s: say\n10009.02s: um\n10009.68s: so yeah how do we assess and track\n10011.3s: practice the CSM as we make weak\n10013.16s: developments so it really to really kind\n10014.899s: of get there I think it helps a little\n10016.22s: bit to understand\n10017.72s: for me to sort of explain the process of\n10019.46s: model development that goes on we have\n10020.96s: this sort of uh idealized Circle that we\n10023.24s: try to follow when we're building a new\n10025.22s: model generation\n10026.66s: and so with ncsm and really all the\n10028.64s: other system models around the world\n10030.8s: um the cycle tends to be on about a\n10032.479s: seven year time scale which those of you\n10035.06s: who are in the field realize it's the\n10037.16s: same time scale to ipcc reports so we\n10040.16s: are just trying to stay far enough ahead\n10042.14s: of the next ipcc report that we can\n10044.18s: boost the next generation of big model\n10045.859s: simulations that can then support the\n10048.439s: right the writing of that document so\n10049.939s: it's not scientifically driven and\n10052.04s: you'll hear scientists complain all the\n10053.72s: time that you know this is not the way\n10055.16s: you decide when to make the model\n10056.359s: version\n10057.319s: we've tried to break out of this cycle\n10058.88s: many times we've never successfully\n10060.439s: broken another cycle because funding\n10062.42s: models are built around it so that's the\n10064.88s: cycle so we got about seven years to\n10066.439s: build a new model version from the time\n10068.18s: when we released the last Model version\n10069.439s: and so during that sort of seven year\n10071.66s: cycle and leap is going to try to insert\n10073.52s: itself into that seven year cycle\n10075.38s: um so we had our model release csm2\n10077.96s: um that was like three or four years ago\n10079.399s: now\n10080.42s: um what happens subsequent to that is we\n10082.64s: do these big Integrations they're all\n10084.439s: out there for the community to review\n10085.52s: and evaluate and the community does that\n10087.979s: they go they assess models they identify\n10089.66s: the weaknesses hopefully their strengths\n10091.34s: sometimes weaknesses as what people like\n10093.38s: to focus on which is fine that's great\n10096.14s: um and then they try to say oh how can\n10097.76s: we make the model better so they come\n10098.96s: back through our working group structure\n10101.18s: and propose new parameterizations like\n10103.7s: what leap is going to do to or new\n10106.1s: features to add for new processes that\n10107.78s: you want to represent in the system\n10109.7s: um you know the working group will then\n10111.14s: review those and consider them these\n10113.24s: ideas are presented in working meetings\n10114.859s: obviously we want published work so rely\n10117.08s: on so people try to publish papers we\n10119.479s: try to encourage people to publish\n10120.5s: papers on the work\n10122.02s: in this case what leap is trying to do\n10124.34s: is get into this part of the process\n10126.5s: with new leap machine learning inspired\n10129.62s: algorithms that can that can change the\n10131.42s: game\n10133.1s: um and so here's what I want to\n10134.359s: advertise I've spoken to a bunch of you\n10135.74s: already at this meeting but the twice\n10138.319s: annual working group meetings that we\n10139.819s: have worked in the CSM project what\n10141.92s: really is the opportunity to to learn\n10144.62s: what's going on across the whole\n10146.24s: modeling project in the summer meeting\n10149.24s: we get 350 400 people so this is a big\n10151.819s: project and leap is a big project as\n10155.18s: well so leap can actually make a\n10156.74s: demonstrable difference to the overall\n10158.479s: effort but really only if we show up to\n10162.26s: those meetings because people don't show\n10163.939s: up those meetings it's not like it's the\n10165.92s: rule if you don't show up you don't get\n10167.06s: your stuff integrated into the model but\n10169.16s: effectively the people that show up to\n10171.02s: these meetings and present and argue for\n10172.819s: argue the case while the small\n10174.26s: Improvement needs to be made are the are\n10176.0s: the activities attempting to get\n10177.02s: integrated so our next set of meetings\n10179.54s: is coming up in in I think the\n10181.34s: atmosphere model work group starts in a\n10182.66s: week and a half\n10184.04s: um and registration is open it's really\n10185.66s: open to anyone there's no we never say\n10187.7s: anyone can't come almost every working\n10189.859s: group has an open call for talks we try\n10191.96s: to accept everyone one who wants to give\n10193.28s: a presentation it's really an\n10194.42s: opportunity to share what you're doing\n10196.16s: and as much as that is to learn what\n10198.319s: everyone else across the community is\n10200.12s: doing to see how it intersects so that\n10201.74s: we don't duplicate effort you see\n10203.479s: synergies you see collaboration\n10204.92s: opportunities so I really encourage\n10206.78s: everybody to to attend its hybrid so you\n10209.24s: can come in person we love that it's\n10210.979s: gonna be really fun as we saw in this\n10212.66s: meeting to be talking to people in\n10213.859s: person but we are going to maintain a\n10215.3s: hybrid hybrid component here and going\n10217.76s: forward\n10219.319s: okay so that's you know that's part of\n10221.359s: the process you kind of get involved in\n10222.62s: these work group meetings have a new ml\n10224.42s: guided algorithm\n10226.16s: um you know usually uh we're actually\n10229.22s: getting close to the stage where three\n10230.72s: or four or five years into the\n10231.8s: development cycle we start trying to\n10233.72s: really pull it all together so if\n10235.22s: there's you know 15 to 20 different\n10237.08s: projects where people are trying to\n10238.28s: advance the model we say okay we're\n10240.14s: going to try now at ncar to bring this\n10242.66s: all together and start doing these new\n10244.64s: simulations to understand whether or not\n10246.979s: the model is is gotten better where it's\n10249.8s: gotten worse where we need to you know\n10251.479s: spend a little bit more time evaluating\n10253.04s: things sometimes it's done as a big\n10255.38s: selection of of uh model developments\n10257.42s: all done together sometimes it's done\n10259.52s: one-off it all depends on how much time\n10261.5s: we have how big it change it but that\n10263.3s: we're making\n10264.92s: and so then it's at that stage when we\n10267.319s: start to evaluate\n10269.06s: um the model how it's doing so often\n10270.439s: it's a component model stage where maybe\n10272.78s: you know you had an addition in this\n10274.46s: case an example coming from the lab\n10276.08s: model so you know we want to say how is\n10278.0s: the model doing compared to the prior\n10279.26s: versions\n10280.819s: um and so what's happened in the last\n10282.92s: uh five years or so or maybe a little\n10285.38s: bit longer than that is there's a lot\n10287.0s: more standardized metrics packages we\n10289.64s: call them that allow you to evaluate the\n10291.979s: models in a systematic way\n10293.78s: I'd like to sort of tell a story because\n10295.28s: for new people coming in you say well\n10296.899s: this is so obvious you said why haven't\n10298.58s: you been doing this forever\n10300.319s: um the thing is the amount of obseries\n10301.88s: Earth observations we have now compared\n10303.8s: to like even a decade ago is really it's\n10306.62s: almost unfathomable\n10308.12s: I remember sitting in meetings back when\n10310.58s: I was helping develop clm4\n10313.46s: um the community lab model version 4 for\n10315.2s: for CSM ccsm4 and csm1 so it's about 10\n10318.8s: to 12 years ago we would run it through\n10321.68s: our diagnostic package which all it did\n10323.24s: was make plots of everything not\n10324.979s: compared to any observations because\n10326.12s: there are virtually no observations of\n10327.38s: land surface quantities we wanted so we\n10329.3s: would sit around in a group in a meeting\n10331.22s: and say look at gross primary\n10333.2s: productivity you know the most important\n10334.7s: quantity for the carbon cycle on land\n10336.68s: and we look at the map we go\n10339.38s: looks pretty good what do you guys think\n10342.859s: and that was the decision we go some\n10345.02s: would say\n10346.52s: you know nobody will say anything\n10347.66s: someone would say well it looks a little\n10349.04s: higher than the tropics and you go why\n10350.479s: do you say that like it just feels like\n10351.8s: it so\n10353.18s: um\n10354.74s: you know it's I'm a little bit\n10356.0s: exaggerating but really there's very\n10357.319s: little data even even like a decade ago\n10359.24s: and now we have these huge arrays of\n10361.22s: data sets and this package that a\n10362.66s: project that I've been involved in is\n10363.92s: sponsored by DUI has put together you\n10366.56s: know a metrics package that involves 35\n10368.6s: variables 90 plus global Regional and\n10370.7s: site level data sets which we can then\n10372.26s: evaluate you know just like that\n10374.96s: um and it takes about two hours for the\n10376.46s: package to run so the the change has\n10378.859s: really been episodic and that's kind of\n10380.66s: where leap is riding this wave of new\n10382.76s: observation so here's just an example of\n10384.68s: showing clm4 4.5 and 5 and red just\n10387.8s: indicates that the model performance is\n10389.54s: worse for this range of different\n10390.68s: metrics it's all there's a huge amount\n10392.12s: of information that's embedded down\n10393.92s: below this and it's an interactive\n10395.54s: website when when you run this on online\n10397.58s: no ideac has gone mostly from red to\n10400.46s: Green which is a good sign that the\n10401.96s: model has improved when you're\n10403.399s: evaluating all these different\n10404.18s: quantities so that's one way we try to\n10406.22s: evaluate these models with these big\n10408.08s: standardized metric packages\n10411.92s: um and then and then it's like so then\n10413.6s: that kind of will happen each it's a\n10415.46s: working group and model component will\n10417.68s: kind of be doing this process\n10419.72s: um you know sort of continually over the\n10421.16s: period of three to four years and then\n10423.26s: you know at about two years before we\n10425.06s: want to release the model we try to\n10426.26s: bring all the components together and\n10427.76s: try to Value what happens in the fully\n10429.2s: coupled system and so we're actually\n10431.0s: starting that process now within the\n10433.16s: trying to work towards csm3 and that's\n10436.1s: where we you know we try to finalize the\n10437.96s: component models we try to identify the\n10439.46s: problems that we're having in the couple\n10440.6s: model system uh this is where we do\n10442.7s: automated calibration if we build in the\n10444.62s: capabilities to do automated calibration\n10446.06s: uh and then we also then we'll do\n10448.22s: simulations to support the release of\n10450.26s: input documents model we try to run a\n10452.54s: bunch of different control simulations\n10453.74s: so the community has confidence that\n10455.24s: we've produced the model\n10457.04s: um that is viable\n10458.84s: um in terms of leap the idea here is you\n10461.3s: know if we get some leave activities\n10462.5s: into into this development cycle or the\n10464.24s: next development cycle\n10465.8s: um as with anything we put in the model\n10467.12s: there's switches and so I have this\n10468.979s: here's risk mitigation because you know\n10470.96s: some Community is is still nervous about\n10473.24s: about taking on machine learning based\n10476.06s: parameterization so we need the ability\n10477.979s: to switch things on and off really\n10479.3s: easily and if we find we don't get\n10481.279s: agreement across enough of the CSM\n10482.899s: community and we can turn it off but\n10484.7s: still have it there as a research tool\n10486.26s: right so we have that capability\n10489.319s: um you know this is really where ncar is\n10491.42s: going to need to take the lead on on\n10493.22s: this activity because it is it does\n10494.899s: require having a large number of experts\n10497.42s: in the room to discuss all the\n10498.92s: challenges okay so and that's why I said\n10501.439s: the Bayesian prime minister as mentioned\n10503.06s: again okay so what do we have now so\n10505.34s: we're going to try to get towards this\n10506.84s: discussion this afternoon about what we\n10508.52s: can possibly do to establish whether or\n10510.56s: not the leap activities are making an\n10512.18s: improvement\n10515.18s: um it is still a little bit of a wild\n10516.74s: west I I know at Encore that's way I\n10519.26s: don't you know I'd be I'm always curious\n10521.06s: to hear what's happening in other\n10521.899s: modeling centers but it's not like we\n10523.7s: have we say this is our set of things\n10525.2s: you might like you know like standard\n10526.58s: like if you're going going to the Moon\n10528.02s: you would have a standard list of things\n10529.16s: you're ticking off it's not like that\n10531.14s: it's much more Arty uh than that we have\n10534.92s: a lot of packages we run them\n10537.04s: semi-regularly but not all the time we\n10539.54s: have people look at them semi-regularly\n10541.1s: but not all the time each one of these\n10543.08s: packages will produce thousands to tens\n10545.72s: of thousands of plots so how do you\n10548.18s: evaluate whether or not the model's good\n10550.1s: nobody can look through it all so\n10551.54s: everyone picks their favorite things\n10552.8s: they look at it so we we get together\n10554.479s: and we we say we're going to run all\n10556.04s: these diagnostic factors that we have\n10557.479s: and try to establish what the model is\n10559.279s: okay\n10560.72s: um and really that's the off from the\n10562.34s: barrier the bar that we're trying to get\n10563.96s: above is is it okay\n10566.12s: um the first thing we do is we say oh\n10568.04s: you know is the sea ice a reasonable\n10569.479s: level so that we'll actually see some CS\n10571.58s: decline\n10572.779s: um is the uh is is Enzo looked like even\n10575.54s: quasi-reasonable not not an amplitude\n10577.58s: that's six times too large we'll ask\n10579.8s: about the topic without my energy\n10581.0s: budgets to ask because you know are we\n10582.5s: are we balanced um is the thermal haline\n10584.779s: circulation the mlc in the right\n10586.64s: ballpark you know those are the first\n10588.38s: questions we asked where we get past\n10589.64s: that bar and then we kind of go to these\n10591.14s: packages and say tell them what I was\n10592.88s: doing and really if the model's not\n10594.62s: doing well\n10596.0s: at that point in the game there's not\n10597.56s: tons that we can do we might do a little\n10599.24s: bit of calibration hand tuning like\n10600.74s: Pierre has mentioned which is you know\n10602.6s: not very satisfying we're hoping that\n10604.16s: leap will be able to make us not be able\n10605.479s: to do that but this left tuning actually\n10607.52s: that goes on that I think maybe a lot of\n10609.319s: people actually anticipate a lot of it\n10611.72s: is you try to build your good models a\n10613.34s: couple of them together and then see how\n10615.26s: it works\n10616.279s: but here's one thing we were doing\n10618.26s: during the development cycle of csm2\n10621.68s: um uh John fasillo at Encore had built\n10623.779s: this package called the climate model\n10625.1s: assessment tool which is you know\n10626.84s: similar in some ways to this tool built\n10628.64s: in Europe called the esm valve tool um\n10630.68s: you won't be able to see any of this but\n10632.06s: basically it's another color-coded thing\n10633.56s: where on the on the on the y-axis there\n10636.08s: is different variables\n10637.76s: um you know big large scale variables\n10639.26s: that we want to track like precipitation\n10640.88s: temperature winds\n10643.04s: um gradients\n10644.479s: um Enzo Diagnostics and and then on the\n10647.18s: bottom is actually in this case it's\n10648.68s: showing all the different Earth system\n10649.7s: models when we were developing the model\n10651.319s: we were just showing CSM comparisons to\n10653.6s: model simulation to model simulation and\n10656.3s: what you see here is you can then you\n10658.1s: know track which variables or if models\n10659.779s: doing well and also whether or not\n10661.399s: through time or across different model\n10663.14s: different models we're doing well in\n10665.54s: this case and I'm always cautious to say\n10667.399s: this you know CSM is a is a good model\n10669.5s: it starts off from pretty good base in\n10671.96s: this case it's you know the different\n10672.92s: model version of CSM are towards the the\n10675.439s: left there which is among the better\n10676.819s: models doesn't mean this model by\n10678.5s: Perfect by any stretch and doesn't mean\n10679.88s: it's going to be better at everything\n10682.52s: um but in a synthesized way it's among\n10684.62s: the better models in the world which is\n10685.939s: a good starting point for leafy coming\n10687.8s: on\n10688.7s: so we have these different packages we\n10690.62s: run them and try to use them to evaluate\n10692.72s: the model\n10693.62s: okay so just in the last few minutes\n10695.42s: here I wanted some ideas to sort of spur\n10697.34s: our discussion this afternoon you know\n10699.26s: how can leap Advance the science versus\n10701.3s: the model evaluation\n10703.16s: um which helps us answer this question\n10704.779s: about how can we track leap's progress\n10707.779s: um some Initial Ideas I have one is you\n10709.939s: know it'd be great if some people here\n10711.74s: in leap learned how to utilize and uh\n10714.859s: and hopefully enhance existing metrics\n10716.6s: packages\n10717.8s: um these are all open source packages at\n10719.6s: this point\n10720.859s: um you can run them on your own machine\n10722.66s: or on on cyan or orato super computers\n10726.439s: and then car\n10727.96s: I often try to get grad students or\n10730.16s: postdocs who work with me to to run\n10731.779s: through rage because it's really like a\n10733.16s: richer way to even just understand the\n10735.02s: model right just poking through plots\n10736.52s: after plot not having to build all that\n10738.92s: you know infrastructure to look at all\n10741.2s: the different fields in the model\n10744.5s: um\n10745.04s: hopefully leave can develop new metrics\n10747.8s: that that you know value model\n10749.42s: performance for quantities are important\n10750.8s: to LEAP especially those focused on\n10752.359s: adaptation so a lot of the existing\n10754.46s: packages the emphasis is on like\n10756.14s: large-scale features of the climate\n10758.42s: system what is the temperature mean\n10759.68s: temperature seasonal mean temperature\n10760.88s: what is the precipitation what are the\n10762.62s: the wind speeds of the upper atmosphere\n10764.479s: do you have a PPO\n10766.58s: um but isn't as much emphasis on the\n10768.26s: things that actually you know are\n10770.06s: affecting humans uh or ecosystems\n10773.42s: um so evaluation of heat extremes is\n10775.399s: actually relatively rarely done uh\n10776.899s: precipitation intensity distribution we\n10778.52s: do that sometimes\n10780.319s: um but it's not always a standard a\n10782.24s: standard metric study drought and flood\n10784.52s: crop growing season length things like\n10786.2s: that so leap I think can come in here\n10788.18s: and try to help out here and develop\n10789.74s: metrics where so we can then integrate\n10791.359s: into these packages so we're attracting\n10792.92s: these things going forward to things\n10794.06s: that really matter\n10795.439s: and\n10796.64s: um\n10797.479s: I just want to give an example of I\n10798.979s: think a nice example of groups like\n10801.2s: cherry picking from my own research but\n10803.66s: um of an example of a project where\n10805.34s: we're trying to evaluate uh you know\n10807.2s: trying to understand whether or not you\n10808.34s: can use our system models to predict\n10809.84s: water availability on land in in rivers\n10813.14s: and so what this shows is the question\n10814.88s: you want to have is we know climate\n10816.02s: change is going to happen with that\n10817.76s: climate change is going to likely almost\n10819.319s: certainly going to be a change in\n10820.22s: temperature there may be an increase or\n10821.779s: a decrease in precipitation depending on\n10823.279s: where you are\n10824.72s: um and so we can observe using\n10826.22s: inter-annual variability you know how do\n10828.92s: how does the Colorado River respond to a\n10831.74s: Wonder B increase in temperature 400\n10833.96s: degree decreasing temperature how does\n10835.7s: it respond to a 10 percent repeat some\n10837.14s: precipitation or 10 decrease in\n10838.46s: precipitation and then you say that's\n10840.14s: what we want the models to reproduce how\n10842.0s: do the models do with that so what you\n10843.92s: see here is that this is I'll show each\n10845.72s: circle there in the in the circle around\n10847.76s: it is uh from a different Earth System\n10849.979s: model from actually cmap 5 the previous\n10851.66s: generation of cmip we see is that\n10854.0s: there's a few models that are kind of\n10855.319s: capturing that relationship correctly\n10856.76s: but the majority of them are not getting\n10858.56s: it right so then you would say well\n10860.3s: should I really be using you know Stream\n10862.58s: flow information that's coming out of\n10863.96s: your system model to do my impacts\n10865.76s: research and the answer that would\n10866.72s: probably be no if all the models were\n10868.52s: lying there at the center of that of\n10869.96s: that dot then you say okay I can\n10871.34s: probably have some confidence in that so\n10872.96s: that's kind of impacts relevant metric\n10875.0s: you can assign a number to this to see\n10877.7s: how good the model is\n10879.26s: other things we can do is develop new\n10881.6s: process oriented metrics for leap\n10883.04s: targeted processes I think this is\n10884.3s: something that Lee could really focus in\n10885.56s: on you know if we're going to advance\n10887.24s: the parameterization you can ask the\n10888.859s: question what are the key features of\n10891.14s: the model that are going to advance that\n10893.6s: I can test directly\n10895.76s: um you know relate to that\n10896.779s: parameterization that's like an\n10898.46s: important step the leap can do before we\n10900.2s: kind of get back to ask these bigger\n10901.46s: questions about did the temperature\n10902.479s: patterns get better to the\n10903.859s: precipitations patterns get better you\n10906.02s: know the question is did we make the\n10907.52s: cloud microphysics better and does that\n10909.439s: improve a cloud or whatever simulation\n10912.08s: that's an important question so we need\n10914.0s: to develop process oriented metrics and\n10916.1s: here's an example of what I I think is a\n10918.08s: good process oriented metric this is\n10920.6s: capturing snow insulation and so the way\n10923.359s: you read this curve here is on the on\n10925.399s: the x-axis is snow depth\n10928.58s: um it's called effective snow depth here\n10929.899s: I don't need to explain why that is and\n10931.04s: now on the y-axis is a measure of the\n10932.54s: insulation so a low value means there's\n10934.819s: low insulation so when there's no snow\n10936.56s: the soil temperature ends up being\n10938.66s: pretty close to the the atmospheric\n10940.04s: temperature as you expect as you get\n10941.899s: more and more snow there's snow provides\n10944.359s: insulation so there's the ground\n10945.979s: temperature is going to be quite a bit\n10947.84s: warmer than atmospheric temperature in\n10949.22s: Winter and so there's a Russian data set\n10952.16s: where they've tracked this for for a\n10953.72s: couple of decades over many hundreds of\n10956.0s: sites in Russia and so you can build\n10957.439s: that that gray and the and the black\n10959.479s: line there is what the observed\n10961.22s: relationship is between snow depth and\n10963.56s: insulation and then you can see what all\n10965.06s: the models are doing what you see is\n10966.8s: there's only two or three models which\n10968.359s: are actually getting that snow relations\n10969.92s: that's no insulation relationship right\n10971.96s: most of the models are are doing a\n10974.18s: pretty poor job so it's an example of a\n10976.04s: much it really captures just that one\n10977.84s: process it's no insulation of the soil\n10980.96s: um actually there's quite a few\n10982.279s: processes using the snow that lead to\n10984.14s: that but still it's kind of zeroing in\n10985.819s: on one thing\n10987.2s: I think that's all I want to say except\n10988.88s: for the one last thing is that we can\n10990.38s: also develop new ml based observational\n10993.38s: data sets of the work that Galen was\n10994.939s: talking about with the pco2 and there\n10997.22s: should be other opportunities for that\n10998.3s: where there's sparse data but we want to\n11000.34s: evaluate a global model with it we can\n11002.319s: use ml to develop these new data sets\n11004.54s: that can then get integrated into these\n11006.279s: analysis factors so I will stop there\n11009.1s: thanks\n11012.819s: oh yeah I just love to do this slide too\n11014.979s: after I appear out of it\n11016.479s: um\n11017.2s: we're also uh starting to plan towards\n11019.779s: Computing for leap and one of the things\n11022.24s: we can do within leap is to apply for\n11023.979s: the large allocations on the ncar\n11025.779s: supercomputers\n11027.34s: um Cheyenne and and coming in June the\n11029.439s: direct show and so that allocation\n11031.54s: request is available twice per year\n11034.72s: um and you know in general these things\n11036.76s: get granted at some level that we will\n11038.859s: get some resources if we apply for it\n11041.14s: um that needs to be led by somebody\n11042.279s: outside of bencar\n11044.08s: um so\n11045.22s: I think the idea here is that we are\n11047.2s: going to start trying over the next\n11048.46s: month or so to collect information about\n11050.979s: what Computing needs people have as we\n11053.439s: run up to a marched allocation request\n11055.479s: and so initially let's run\n11058.0s: um some of that discussion through Wayne\n11059.319s: our new integration engineer uh and if\n11061.779s: Wayne has you know questions about how\n11063.399s: to deal with it then he can you know\n11064.72s: work with me to figure out how that\n11065.92s: allocation requests thank you\n11071.74s: right uh this is for for great my\n11074.859s: understanding what you actually see is\n11075.88s: mostly built for analysis\n11078.7s: um uh with the computational resources\n11080.68s: are mostly there to do analysis and\n11082.24s: model Integrations the big Integrations\n11084.52s: you're going to need to do if you're\n11085.42s: running with CSM can't be done with the\n11087.76s: two ICC framework currently and so this\n11089.439s: is for ability to access the large\n11091.66s: computations you need to do versus model\n11093.64s: simulations\n11097.06s: yeah\n11098.319s: um I'll go since I interrupted things\n11100.66s: um\n11101.439s: I really like what you're saying about\n11103.18s: the Diagnostics packages and uh like\n11106.72s: getting people familiar with the\n11108.399s: Diagnostics I feel like this aligns with\n11110.859s: a lot of different things we're trying\n11111.819s: to do and believe it's a great way to\n11113.2s: understand what modeling centers care\n11114.64s: about what are the important variables\n11116.319s: what do the what do people look at\n11120.88s: perspective I have\n11122.319s: from someone who's worked very hard on\n11124.3s: developing like general purpose analysis\n11126.399s: software is that sometimes I feel like\n11128.2s: the Diagnostics\n11130.0s: Frameworks just live in their own you\n11132.88s: know\n11133.68s: monolithic world like and I guess in\n11136.12s: talking most about esm valkpool which is\n11137.859s: the one I know the most but whenever\n11138.819s: I've looked at it it's like this has\n11140.439s: nothing to do with my like normal python\n11142.8s: workflow like the process for doing that\n11145.24s: it feels so\n11147.279s: um\n11148.24s: so intimidating and like a lot of work\n11150.76s: to to learn to use\n11153.279s: um and you know here we were talking\n11154.899s: about education how do we teach people\n11156.399s: about the tools so like we can teach\n11158.56s: people about using those tools but I'm\n11160.0s: also curious to hear your take on\n11161.5s: whether there's a\n11163.24s: effort or maybe some of those other\n11165.16s: packages you mentioned that are more\n11167.38s: interoperable and sort of modular in\n11169.18s: such a way that we could just like bring\n11170.92s: in components of those functions without\n11173.08s: necessarily having to like use the full\n11175.18s: end-to-end framework and like to be real\n11177.34s: specific like a lot of them assume\n11178.6s: you've got files like net CDF files on a\n11181.84s: on a disk and like here we've got like\n11183.76s: Czar data in the cloud so often it's\n11185.62s: just like well we're stuck like it\n11187.12s: doesn't work at all there's no way to\n11188.5s: even move forward yeah it's a really\n11190.359s: excellent point and and we obviously\n11192.279s: recognize this this is a you know top\n11194.68s: your conversation all the time\n11196.66s: um these packages are so big at the\n11198.64s: moment that it that it's you know hard\n11200.08s: to convert them into something that's a\n11201.34s: little bit more flexible we would love\n11203.38s: to do it and if leap like has a you know\n11205.66s: motivation to help us transition towards\n11208.06s: that right we were totally be up for it\n11210.22s: I\n11211.0s: um yeah there's a recognition yeah that\n11212.92s: the world is moving towards us like on\n11215.26s: the Fly ability to just get data from\n11217.06s: anywhere and this is not built like that\n11219.76s: um just like their system model itself\n11221.38s: it's these things have legacies that are\n11224.02s: big\n11225.1s: um that are hard to sort of like\n11226.3s: redirect really quickly so it's on our\n11228.939s: radar but we don't have like a like a\n11230.979s: clear plan it takes money it takes a ton\n11233.14s: of money right to do that\n11234.64s: maybe a great a larger discussion we\n11237.58s: could have like I mean kind of uh\n11239.74s: aligned with what we are doing with\n11240.819s: carbon pen as well but involving the\n11242.38s: whole Community as well like that could\n11244.54s: really help\n11245.74s: maybe I teach you could be an\n11247.24s: opportunity\n11248.5s: oh Dave so at uh I guess we're trying to\n11250.96s: more uh systematically use a single\n11253.54s: column model um experiments for both in\n11256.72s: the parameter estimation sense the\n11258.04s: constraint parameter the state space as\n11260.439s: well as for routine evaluation of\n11262.3s: processes is that an effort that goes on\n11264.88s: at ncar\n11266.26s: we definitely have a single column model\n11268.06s: and we use it uh whether we're getting\n11271.3s: the stage or we're like using it\n11272.62s: systematically to you know make\n11274.899s: decisions about our model\n11276.1s: parameterizations but we'd say it's more\n11278.56s: Case by case like it's not like we say\n11280.359s: we definitely go to single column model\n11281.92s: first and then we go to Global\n11283.66s: um it's more like for a specific project\n11285.279s: they might say that single column model\n11286.779s: is appropriate place to do your\n11287.979s: development and then it goes to Global\n11289.6s: but it's not like we have a\n11291.42s: systematic decision that always go that\n11294.46s: way but we do use it yeah and that is\n11297.64s: another as you sort of mentioned\n11298.96s: yesterday it's a great opportunity to\n11300.819s: get involved without this big\n11302.56s: computational expense you know if you're\n11304.06s: just getting used to to running\n11305.38s: atmosphere models you know run the fully\n11307.42s: fully you know the full atmosphere model\n11309.22s: it costs a lot of money it takes a long\n11310.84s: time soon call model runs like that so\n11316.359s: but\n11327.88s: got hundreds I don't think uh I think\n11331.24s: it's in the tens yeah tens of millions\n11333.52s: yeah\n11334.54s: I don't usually do this myself because\n11336.16s: we have our own allocation process for\n11337.899s: that for the CSM project\n11345.34s: right if it ends up being limiting\n11346.66s: because you're only what putting one in\n11348.04s: that's not good either but I think we\n11350.14s: can evaluate that going forward if we if\n11352.06s: we're running up against that problem\n11354.04s: you know we could even go to sizzle and\n11356.62s: say here's our situation and we they\n11358.3s: would potentially listen to us it's a\n11360.16s: big enough project that they you know\n11361.6s: they could spend the rules potentially\n11362.979s: but we can we'll kind of deal with that\n11364.42s: problem if we come across it\n11374.02s: okay so the second record session we\n11376.24s: left will be on that edge transfer you\n11377.8s: know and um and really trying to connect\n11379.72s: the dots between what we've seen in\n11381.22s: terms of research education and all the\n11383.38s: way to the next transfer\n11384.88s: and as Courtney mentioned earlier so we\n11387.76s: are really seeing that as being\n11388.899s: integrated so the education component\n11390.819s: knowledge transfer and Dei so that's\n11392.859s: really what we've been trying to achieve\n11394.359s: so I hope you got a taste of that over\n11395.8s: the last two days you know that leap is\n11398.08s: more than just research right there's a\n11399.46s: big educational component there's a big\n11401.2s: knowledge transfer component and the\n11403.3s: data infrastructure is actually trying\n11405.16s: to support all of that at once right\n11407.14s: that's really the very core of what we\n11409.18s: are trying to do here\n11411.34s: and I just wanted to maybe mention that\n11413.8s: because we haven't talked too much about\n11415.12s: that but that those are some of the\n11416.62s: objectives that we have specifically on\n11418.42s: the knowledge transfer site from the\n11420.1s: Strategic plan so a lot a lot of that\n11422.68s: really to bi-directional knowledge\n11424.18s: transfer and you got a taste of that\n11425.56s: yesterday so uh the first objective\n11427.899s: being trying to solicit input from\n11429.88s: multiple corporate and public\n11431.26s: stakeholders on really uh important and\n11434.02s: relevant climate metrics right so that's\n11435.88s: what we are trying to do like trying to\n11437.8s: not just be the scientists providing\n11439.66s: data and providing information to the\n11442.359s: stakeholders but also trying to gather\n11444.04s: some of that and they've mentioned some\n11446.14s: examples can we have like impact driven\n11448.06s: metrics as well as opposed to just the\n11450.279s: sciency metrics that we have uh the\n11453.04s: second one being that to disseminate\n11454.54s: deep information to multiple corporate\n11456.76s: and public stakeholders so we got a\n11458.319s: taste of that as well from Vanessa we\n11460.42s: talked about that also with Courtney\n11461.979s: yesterday and then also to increase the\n11464.92s: utility so I hope you got a sense of\n11466.6s: that as well from carbon plan in\n11468.34s: particular that we are trying to really\n11470.319s: increase the understanding and of the\n11472.12s: importance of reliable data and trying\n11474.52s: to see how people can actually use that\n11476.439s: in their in their uh companies in\n11479.2s: particular\n11480.16s: and then the last point being that we\n11482.5s: also want to make all leap research uh\n11484.899s: and existing for instance and we we've\n11487.6s: got that from Julius like existing data\n11490.6s: in particular open source and broadly\n11492.58s: accessible and you saw that I mean now\n11494.68s: that the barrier has really been lowered\n11496.24s: in terms of using that data and starting\n11498.1s: to potentially do some interesting\n11499.72s: science with the data that we have and\n11501.399s: providing that to about range of\n11503.14s: stakeholders so we see that as really\n11504.939s: this inclusivity I was mentioning\n11506.68s: earlier so really and again the data\n11509.14s: infrastructure is really critical for\n11510.76s: all of those species\n11514.18s: so to get back just to connecting the\n11516.76s: dust so that's going to be the breakout\n11518.02s: session uh and we see that as really\n11520.12s: knowledge transfer in terms of\n11521.56s: translation and convergence so that's\n11524.02s: what he will try to address in that\n11526.0s: particular knowledge transfer in that\n11527.62s: particular breakout session sorry and I\n11529.899s: want to emphasize that this record\n11531.04s: session is not just from P for people on\n11533.439s: the knowledge transfer side so please\n11535.0s: the scientists in the room attend that\n11537.46s: particular breakout sessions we don't\n11539.2s: want to have only people in the CSM\n11541.779s: Benchmark session we also want to have\n11543.399s: people that are actually trying to\n11544.779s: connect with us so if you're interested\n11546.22s: in that please join that\n11549.22s: and uh there's this foot that's actually\n11551.38s: uh totally used for the a few times you\n11553.84s: know so we're thinking of translation in\n11555.88s: terms of external uh knowledge transfer\n11558.34s: and internal knowledge transfer right so\n11560.56s: and the external one is actually very\n11562.18s: imaginary to this quote from uh manavi\n11564.399s: at the time and so in a nutshell he was\n11566.5s: saying that understanding climate change\n11567.939s: and also he was talking about predicting\n11569.56s: climate change is very difficult but the\n11571.899s: most difficult part is actually related\n11573.279s: to politics and Society you know at the\n11575.26s: end of the day so how do you actually\n11576.34s: translate that make use of the data make\n11578.859s: sure that people can actually use this\n11580.479s: information in the end and so we really\n11582.64s: see that as being a key role for the\n11584.74s: knowledge transfer especially the\n11586.12s: external part of leap you know so it's\n11587.859s: not about just creating the best science\n11589.359s: but also making sure that this goes in\n11591.64s: the in the hands of the people\n11594.7s: and we also see that in terms of\n11596.8s: internal translations so again in the\n11599.2s: breakout session try to think about\n11600.46s: those two aspects external internal\n11602.56s: translation and again very much related\n11604.899s: to the fact that we have potential uh\n11607.18s: barriers you know across disciplines you\n11609.399s: know between the machine learning and\n11610.96s: the data scientists on the one hand and\n11613.12s: the climate scientists but also across\n11615.22s: uh climate science uh disciplines as\n11618.1s: well right\n11620.74s: and really that's what we want to do and\n11623.26s: we want to basically assess especially\n11625.18s: be meeting and first meeting like how\n11627.16s: are we doing in terms of translation can\n11629.74s: people understand what we are doing\n11631.0s: across disciplines within the climate\n11632.979s: science disciplines and can they get\n11635.02s: that across disciplines between machine\n11636.76s: learning and the climate science so try\n11639.16s: to address that within the breakout\n11640.779s: sessions try to get a sense as to\n11642.399s: whether we are doing a good job and we\n11644.02s: can understand each other right we are\n11645.46s: very diverse group which is great but we\n11647.8s: also want to make sure we can\n11648.88s: collaborate and we can create synergies\n11650.859s: across right so it requires some level\n11653.2s: of of convergence and again of humidity\n11655.6s: and translation and that's really how we\n11657.7s: believe we can connect the dots you\n11661.18s: and that's again the fact that we are\n11664.0s: across many different uh components you\n11666.279s: know I I showed that picture yes as we\n11668.26s: are covering new atmosphere ocean land\n11670.24s: and a nice you know cryosphere for the\n11672.279s: climate science but we're also covering\n11673.96s: data science and we also have many\n11676.0s: different levels of maturity as well so\n11678.1s: some people are very confident with\n11679.54s: machine learning they can use the the\n11681.1s: the wording or the vocabulary but some\n11683.56s: people are just getting started right so\n11685.12s: make sure you actually understand each\n11686.56s: other make sure you're trying to be\n11688.3s: inclusive when you talk to people\n11689.5s: because they might not have that learn\n11691.3s: that that understanding right now okay\n11693.16s: so make sure you do we can create that\n11697.439s: and there was a key thing that came up\n11700.359s: you know especially over the last year I\n11702.64s: would say since we studied is that\n11704.26s: building convergence is not a symmetric\n11706.84s: Road right and the way we were framing\n11709.3s: that and that's a at least I mean that\n11710.979s: could be what you could gather from that\n11712.96s: particular picture it sounds that it's\n11714.64s: symmetric in a sense but we are really\n11716.859s: feeling more and more that it's actually\n11718.18s: not asymmetrical right so there's a lot\n11720.939s: of appetite to actually use machine\n11722.439s: learning across disciplines right and\n11724.3s: climate science is not uh is not uh\n11727.18s: different from that but also machine\n11729.64s: learning scientists in particular in\n11731.26s: very high demand and I'm sure Cal could\n11732.88s: speak to that which means also that they\n11735.46s: have a limited time and also potentially\n11737.26s: interest in actually learning the domain\n11739.359s: knowledge that that we have and so\n11741.22s: climate science is just going to be for\n11743.2s: a lot of them just one of the\n11745.18s: applications that they have right so we\n11747.22s: really need to bridge that Gap so we\n11748.96s: need to actually go their way and try to\n11751.3s: find mechanisms by which we can actually\n11753.34s: facilitate that bi-directional uh\n11756.22s: knowledge transfer right so that that\n11757.899s: convergence in between so that's I think\n11760.66s: one of the main challenges that we are\n11762.399s: going to face moving forward and that's\n11764.02s: something we need to address as a\n11765.76s: community to try to think about that in\n11767.859s: the breakout sessions uh and again uh\n11770.38s: ideas are very welcome to you\n11773.2s: a couple of things we are trying to do\n11774.819s: for that is trying to again to lower the\n11776.92s: barriers so we talked about all of the\n11778.72s: data infrastructure that we have so we\n11780.34s: can potentially make things much much\n11782.68s: easier so you could actually use a\n11784.42s: climate data set to show you that as\n11786.939s: opposed to imagenet right so it seems\n11788.92s: that we're almost there right I mean we\n11790.779s: are very very close to that but we also\n11793.6s: need to actually Define benchmarks right\n11795.46s: I mean that's really how we can define a\n11797.319s: machine learning problem in particular\n11798.76s: is that in vehicular benchmarks and\n11800.92s: things that we can do and I'm going to\n11802.54s: show you an example in a minute and\n11804.7s: again we can leverage a lot of the lip\n11806.62s: NGO platform that we have right now to\n11808.42s: actually include that uh community and\n11810.88s: we discussed a lot of that as well in\n11813.04s: the the focus groups and uh Roberts you\n11815.439s: mentioned some of that that could be one\n11817.12s: of the potential outcomes as well of the\n11818.859s: focus group so try to think about those\n11820.779s: things like how can we actually get\n11822.76s: those people more involved how can we\n11824.38s: actually bring them our way\n11826.42s: we also we are trying to facilitate\n11828.819s: those things so we also trying to put\n11830.56s: resources towards you you know like to\n11832.479s: actually help uh we have the convergence\n11834.58s: luncheon that I mentioned uh yesterday\n11836.38s: to actually help between advisor and\n11838.06s: advisees across disciplines right so so\n11840.34s: we can actually present problems uh in a\n11842.859s: relatively uh welcoming setup\n11845.5s: we will have the summer PhD fellowship\n11848.38s: program for three months so we can\n11849.88s: actually support especially data\n11851.92s: scientists or or machine learning uh PhD\n11855.16s: students that we want to apply their\n11856.66s: skill set to a particular climate\n11859.24s: problem right so that's really what we\n11861.22s: would want to do in the end\n11863.62s: um and we would love to hear from you\n11865.3s: also in terms of the suggestions you\n11866.8s: know and uh either now or on slack but\n11869.56s: also try to think about that during the\n11871.12s: breakout sessions right how can we\n11872.68s: actually get the machine Learning\n11874.3s: Community more involved in terms of in\n11876.52s: terms of leap and uh making sure that\n11878.979s: they can actually uh help us\n11881.38s: and I just wanted to mention one thing\n11883.66s: so that's one thing I've been using in\n11884.979s: my class that I that I found\n11886.479s: particularly useful is this Benchmark\n11888.279s: data set which is called climate bench\n11890.62s: uh started as a community of users\n11892.84s: actually Cara has been also involved in\n11894.34s: a in a couple of them as well but that's\n11897.04s: really lower the the barrier right so\n11899.26s: you have a bunch of Benchmark data sets\n11901.24s: a bunch of uh different models that you\n11903.58s: can use it's a very well organized and\n11905.92s: structured data set we can actually even\n11907.42s: lower the bar we actually tried that\n11909.279s: during the boot camp with Julius we can\n11911.319s: actually even do and use the data on the\n11913.3s: cloud using the panzero but those are\n11915.279s: things that are very useful because then\n11916.84s: we have very clear benchmarks and we\n11919.06s: know what success means right so so\n11920.859s: those are things we would want to do uh\n11922.96s: through potentially the different focus\n11924.279s: groups and this can lead to papers right\n11926.5s: that was a paper that was actually\n11928.06s: driven as a community so that could be\n11930.22s: the hope for the focus groups who have a\n11932.56s: few of those uh data sets and those\n11934.66s: benchmarks that hopefully will be will\n11936.7s: be cited also widely in the future\n11940.06s: so I think that's all I had for that and\n11942.46s: then we can basically I don't know if\n11944.2s: people have any questions and then we\n11945.58s: can go into the December account\n11946.779s: sessions thanks\n11958.479s: okay okay so let's get back to the final\n11960.76s: round uh of this meeting uh so we will\n11964.12s: have the summary of the breakout\n11965.439s: sessions and I don't know who wants to\n11967.479s: get started between the events Courtney\n11970.06s: is eating why don't you go Dave\n11978.88s: okay so I didn't have any time to\n11981.34s: prepare slides so I'm just going to try\n11983.2s: to go off of memory of the dominant\n11985.0s: themes of our of our discussion which\n11986.62s: was very\n11987.52s: wide-ranging I think it was fun just for\n11989.38s: people to\n11990.46s: to think about how we evaluate nurses to\n11993.16s: model\n11994.66s: um so the themes that I recall during\n11997.72s: the discussion the first one is actually\n11999.22s: not uh benchmarking CSM but I think is\n12001.439s: an important one that came up quite a\n12002.64s: bit as ease of use\n12005.04s: um that we could use that as a metric uh\n12008.16s: for leap if leap can contribute in some\n12010.979s: way or ways to make the model easier to\n12013.439s: use more accessible to a wider group of\n12015.72s: people that came up several times that\n12018.54s: um to potentially through the parameter\n12020.58s: estimation efforts I think that's one\n12022.26s: way that we can you know come up with a\n12024.3s: more rapidly come up with a with a\n12026.399s: usable model\n12028.439s: um but also there's probably use cases\n12032.34s: um there was uh at least one person who\n12035.16s: said that they've been to the CSM\n12036.3s: tutorial taking the tutorial and come\n12038.58s: out of them not really understanding how\n12039.899s: to use the model which is totally normal\n12042.24s: so we need to make sure that everyone\n12044.04s: understands that that's totally normal\n12045.359s: but then also trying to give up uh\n12047.76s: situations we can explain you know\n12049.5s: creative and and productive uses of the\n12051.479s: model\n12052.62s: um to get people started so\n12054.779s: um\n12055.56s: you know maybe we can add that into into\n12057.12s: our sort of leap long-term plans about\n12058.62s: use of use\n12059.88s: um in terms of actual benchmarks for\n12061.439s: evaluating Earth system models\n12063.899s: um you know\n12065.16s: we spend a decent amount of time\n12066.479s: discussing you know what would be new\n12068.16s: like we have these metrics packages that\n12069.72s: already exist they can be used obviously\n12071.88s: Brian was suggesting they could be\n12073.439s: modernized to be more flexible but that\n12076.08s: could be a leap activity but uh maybe\n12077.88s: not the way Leaf fauna invests its money\n12080.64s: um but instead to do this thing where we\n12082.439s: focus in on on metrics that are related\n12084.359s: to you know\n12086.46s: directly to the adaptation so extremes\n12089.16s: throughout like I suggested\n12091.74s: um heat waves and things like that and\n12093.54s: so Ryan was suggesting you know doing\n12095.52s: this thing where we put together our top\n12097.14s: 10 metrics come up with a number even if\n12099.899s: it's not really super scientifically\n12101.58s: validated but still have that as a sort\n12103.859s: of a signature\n12105.359s: um thing coming out of leap so I think\n12107.22s: it's worth considering right there are\n12108.96s: the there are the limitations of uh if\n12110.76s: you're doing that but also through the\n12111.899s: gas and power especially when trying to\n12113.76s: communicate with people outside of our\n12115.26s: field uh trying to understand it so\n12117.24s: that's one one theme\n12119.46s: um uh two other themes that sort of came\n12122.7s: up that I can recall\n12124.68s: um is uh is this parameter estimation\n12128.22s: um and can we you know use get to the\n12130.859s: point where we can come up with\n12131.939s: reasonable parameter sets for the fully\n12134.22s: coupled system and then be able to run\n12136.319s: you know ensembles and simulations with\n12138.6s: with parameter sets to get\n12141.0s: um an understanding uncertainty related\n12142.859s: to uh parameter uncertainty which is\n12145.56s: essentially you know we haven't done\n12147.06s: that in your system online community at\n12148.8s: all yet but we know it's an important\n12150.899s: part potentially really big part of of\n12153.24s: our total uncertainty and so\n12155.52s: um I think that could be it's a hard\n12156.96s: project to do actually because of\n12158.279s: because of computational constraints but\n12160.68s: um it could be a lead stretch goal for\n12162.12s: maybe almost on the 10 time scale\n12165.18s: and then the last uh topic that\n12167.46s: resonated with me and I invite any of\n12169.2s: anyone else to really uh chime in here\n12171.84s: was was um suggested by by Greg which\n12174.66s: was that you know we are making this\n12177.18s: assumption that if we build a good model\n12179.52s: of for present-day conditions and it's\n12181.08s: useful for projection but that if you\n12183.479s: actually go and probe this team of five\n12184.8s: and see what sips archive and look at\n12186.84s: the quality of your\n12188.52s: um\n12189.239s: uh of your simulation and then compared\n12191.04s: to the projections that it's giving\n12192.6s: you're not seeing a good cons you're not\n12194.58s: seeing constraints necessarily if I'm\n12196.5s: getting this right on ECS that is\n12198.84s: related to you know uh a variety of\n12202.08s: fields within your model that might be\n12203.58s: simulated well or not well so\n12205.56s: um that does raise some concern that\n12206.939s: just building a better model with this\n12208.26s: actually give you a better projection so\n12210.08s: Greg's suggestion if I'm getting it\n12212.16s: right is to is to probe the cmf5 and the\n12214.08s: CM of six data sets and look for\n12216.12s: relationships using machine learning\n12217.56s: which could then probe this really fully\n12219.14s: relationships between mean Fields\n12222.899s: um more important on the features of the\n12224.04s: model and then the you know the impacts\n12226.26s: oriented things that we're trying to\n12228.42s: predict and seeing if there's something\n12229.62s: in there that we should be targeting for\n12231.479s: model improvements\n12233.279s: um that would really be have an impact\n12234.84s: so I thought that was a pretty good idea\n12236.04s: that we could explore going forward so\n12238.68s: those are the four four themes that I\n12240.6s: remembered no one else have a\n12243.12s: another big one\n12255.54s: okay so for contacts the KT session we\n12258.42s: were imagining all the scientists would\n12260.1s: be in the cesm and it would just be us\n12262.62s: having a fun little exercise trying to\n12264.359s: make connections and make sense out of\n12265.739s: all the science that we've seen but\n12267.66s: thankfully Pierre hyped up our session\n12269.46s: and so many of you came to join us and\n12271.26s: we were so appreciative so it really\n12273.42s: turned into a combination of the KT team\n12276.779s: reflecting on what they were taking away\n12278.939s: from these sessions and there's been\n12280.62s: some really meaningful gains and\n12282.72s: engagements for us since we've been here\n12284.46s: and also the scientists talking to us\n12287.34s: about uh what's interesting to them what\n12289.979s: they need and also what they've been\n12291.359s: learning over the course of the past\n12292.5s: couple of days so a quick summary of all\n12294.12s: of that so from the KT side\n12297.42s: um uh lots of people really liked uh\n12300.239s: Johnny's talk uh it was one of the\n12302.88s: things that we understood best we used\n12305.58s: it as an example to say this is what we\n12307.8s: think we're taking away from what you\n12309.359s: said and we weren't too far off and so\n12311.46s: that was a good example example of being\n12314.1s: able to clarify something that's\n12315.899s: necessarily complicated although I know\n12317.76s: it was a much simplified version\n12320.279s: um what is clear is clearer now is how\n12324.3s: your different projects fit into the\n12326.1s: broader leap strategic plan the league\n12328.859s: strategic plan is also clearer to us so\n12331.02s: those challenges what it is that we're\n12332.88s: trying to do listen we've been hearing\n12334.92s: this for three years now and we're just\n12336.66s: getting to the one like oh that's what\n12338.22s: we're doing so we're getting to a point\n12340.08s: where that's clear but partly we're\n12341.939s: what's supporting that are your projects\n12344.399s: as practical examples of what the\n12346.56s: challenges are and this meeting sort of\n12348.54s: created some of those connections from\n12349.979s: us\n12351.239s: um there's a comment about the need to\n12353.939s: chunk and find the chunks of your work\n12356.399s: so creating chunks to help you\n12358.08s: communicate\n12359.22s: key pieces of your work without having\n12361.979s: to convey all of the details and\n12364.319s: thinking about ways that the KT team can\n12366.239s: be useful and thinking about that and we\n12369.359s: know not all of this is relevant right\n12370.979s: now but this is helpful for us to engage\n12372.72s: in it from earlier stages\n12375.96s: um and then on the science side there\n12378.12s: was an expression of a deep fear as it\n12380.7s: relates to uh knowledge transfer that\n12382.8s: people just won't care that you're doing\n12384.779s: all of this work and you know 50 of the\n12387.6s: general public will still believe\n12389.52s: whatever it is that they believe\n12391.319s: um and so that's disheartening\n12394.02s: um there are\n12396.239s: um\n12398.64s: oh some uh how do you improve the way\n12401.88s: people respond to science and so there\n12403.92s: was some discussion around that and\n12405.66s: there was these Reflections on very\n12407.16s: concrete examples that that some of the\n12409.02s: scientists had in terms of uh when\n12411.0s: people are able to understand it and\n12412.62s: interact with it using the example of AI\n12414.96s: they're likely to have more trust in it\n12417.479s: and also if they're able to imagine how\n12420.12s: it has specific impacts on their lives\n12422.7s: things that are proximal to them that\n12424.979s: seems to build more trust uh what's\n12427.439s: missing seems to be science\n12428.88s: communication public speaking public\n12431.46s: engagement types of preparation that's\n12433.38s: something that some of the senior\n12434.88s: scientists were identifying that they\n12436.26s: just had the winged and figure it out\n12437.76s: over the course of their careers and\n12439.979s: we're trying to not have our Junior\n12442.02s: Scholars and Senior Scholars have to do\n12444.479s: that but that's what we're here to try\n12446.399s: and help support you in and then another\n12449.1s: scientist provided an example uh this\n12451.5s: was from Mike\n12452.76s: um an example of speaking to a\n12454.56s: stakeholder provided really interesting\n12456.779s: insight about something very practical\n12459.18s: that they are equipped to do\n12460.739s: specifically related to data\n12462.479s: visualization that was inspiring and\n12464.939s: useful so it was an example of another\n12467.819s: thing that we're trying to set up\n12469.08s: opportunities to speak to different\n12470.7s: stakeholders get a sense of what they\n12472.26s: care about what they're interested in\n12473.52s: what questions are important to them\n12475.38s: what kinds of data they're interested in\n12477.42s: using or engaging with in ways in which\n12479.819s: that may potentially or not shape what\n12482.04s: we're doing on the science side so this\n12484.62s: has been great and thank you all for\n12486.54s: joining us\n12492.84s: we are a little bit ahead of time so I'm\n12495.359s: gonna get some into some including\n12497.939s: remarks so I first of all wanted to\n12500.16s: thank you all of us to all of you to uh\n12502.38s: to be joining and I think I really love\n12504.359s: to see how sincerely engaged you were I\n12507.06s: think throughout the the days especially\n12509.22s: you went to the poster sessions through\n12511.08s: the knowledge transfer Dei we could see\n12513.239s: a lot of an education component we could\n12514.92s: see a lot of Engagement throughout the\n12516.3s: different activities for me but not just\n12517.859s: the research right so I think we're\n12519.479s: really starting to create something to\n12521.04s: create a community which is really\n12522.3s: fantastic to see uh personally I thought\n12524.76s: that was a great success so and I hope\n12527.04s: that you share the same feeling that\n12528.54s: that I do I also hope that now you\n12531.54s: realize and you got a sense that leap is\n12533.399s: more than just research right so the\n12535.319s: knowledge transfer or the education the\n12537.239s: are really important pieces of of leap\n12539.76s: and we really want to get you engaged\n12543.18s: you know so feel free to contribute so\n12544.979s: Tian was actually mentioning if you want\n12546.779s: to get engaged on the education\n12547.979s: component please reach out if you want\n12550.5s: to get engaged on the knowledge transfer\n12552.3s: RDA please research you know we are\n12554.279s: really looking for for people and we are\n12557.04s: always uh that would be great to get\n12558.72s: your contribution\n12563.399s: back that was back in 2019 you know I\n12565.68s: was like in my office and I had a lot of\n12567.54s: stuff I was telling the story that you\n12569.34s: know I had a lot of things at the time\n12571.08s: and I'll say okay let's do that I'm sure\n12573.06s: that's gonna work and uh you know long\n12575.76s: story short so we had a pre-proposal\n12577.92s: proposal a couple of like site visits\n12580.2s: etc etc so pretty much a roller coaster\n12582.84s: in terms of drama you know like Joys and\n12584.939s: then stress and then we didn't know will\n12586.92s: we get funded and stuff but at the end\n12589.14s: of the day a lot of that we were kind of\n12590.46s: dreaming like and we said you know maybe\n12592.38s: that will actually be happening and that\n12593.939s: would be a great thing to do like uh for\n12596.04s: the community in terms of having an\n12597.479s: impact uh at the time you know I think\n12599.939s: we were a couple thinking that you know\n12601.56s: the planets were lying I mean we had\n12603.239s: pretty much everything in place you know\n12604.979s: AI we had the data infrastructure you\n12607.62s: know we had a couple of people in the\n12609.42s: room you know and a lot of interest as\n12611.46s: well in terms of the impact of climate\n12613.08s: change and and I think you know over the\n12615.18s: last two days it was great to actually\n12616.62s: start crystallizing that and then seeing\n12618.96s: that actually the dream is actually\n12620.16s: getting coming through right so that's\n12621.899s: that's fantastic at least for me to\n12623.88s: exceed that and also showing that\n12626.22s: together we can have actually more\n12627.899s: impact you know and really that\n12629.58s: connecting the dots is also a way for us\n12631.62s: to be together and to us be more than\n12634.08s: the sum of our parts you know so to me\n12635.58s: that was actually quite a moment to\n12637.14s: actually witness that over the last two\n12638.7s: days\n12640.26s: um I think we've shown that we will be\n12642.18s: successful I'm sure you know I think we\n12644.279s: can work together we can see that we are\n12646.02s: interested in couple of uh items not\n12648.3s: just again research but we want to\n12650.04s: really have an impact in the world and I\n12652.319s: think we've been quite successful we've\n12654.239s: created a community so again with what\n12656.64s: we wanted to do in this meeting so we\n12658.26s: wanted to create a community so I think\n12659.76s: check we were trying to converge I think\n12662.939s: some of that we are trying to do yes and\n12664.979s: we are trying to to to get some success\n12667.02s: here across many disciplines and across\n12668.939s: different activities and I think also\n12671.22s: trying to think about impact you know\n12672.54s: how can we actually communicate how can\n12674.34s: we translate the science that we do to a\n12676.739s: broad range of stakeholders so I think\n12678.66s: we're really getting started uh but it's\n12680.52s: already quite exciting I would say at\n12682.26s: least from my personal perspective you\n12684.3s: know\n12685.26s: um so I can't wait to actually see the\n12686.76s: outcomes that come out of leap and to\n12688.739s: really see the Legacy I can see a lot of\n12690.72s: younger people in the room and I just\n12692.7s: can't wait to see where you you'll end\n12694.319s: up in five or ten years from now so\n12695.939s: that's going to be a really really\n12696.779s: exciting so I want to thank you all for\n12699.12s: joining and I'll see you next year\n12702.02s: and in the meantime I wanted to also\n12704.46s: thank Aaron Catherine and GA for the\n12707.1s: very smooth and super organized meeting\n12713.22s: yeah it's been uh\n12715.2s: been truly fantastic you know we've seen\n12717.06s: the a lot of leap logos everywhere that\n12719.04s: was awesome to see and we have our Max\n12721.2s: finally uh and I also wanted to thank\n12724.38s: Galen and the executive committee for\n12726.359s: the great agenda that they put together\n12728.04s: I think it went really really well we\n12730.439s: could see a lot of the PCS connecting\n12732.18s: all together so that required quite a\n12734.1s: bit of work uh a lot of those things\n12736.08s: make uh you know an event really\n12738.12s: successful things to all of you"
    },
    {
        "class": "YouTubeVideo",
        "title": "Uncertainty Quantification for Remote Sensing",
        "videoId": "JgW9ysIAzGk",
        "url": "https://www.youtube.com/watch?v=JgW9ysIAzGk",
        "publishedAt": "2025-03-03T20:16:54Z",
        "transcript": "4.56s: it's uh it's was great pleasure for me\n6.68s: to introduce today's speaker Amy\n8.96s: Riverman to who is from NASA but not\n12.16s: this not NASA in New York City but NASA\n14.32s: from all the way from California and I\n17.359s: was the one who put her name down for\n19.48s: this lecture because I took on myself to\n23.08s: bring more statisticians to this uh to\n26.64s: the lectures of climate data science\n28.8s: because I believe that a lot of time we\n31.599s: talk about how to convert climate\n33.48s: science with data science um and then\n36.6s: data science includes statistics in\n38.719s: particular that we're in alip we want to\n41.2s: bring more observational data into uh\n44.719s: climate modeling and I cannot think of a\n46.96s: better speaker than Amy so it's with\n49.399s: great pleasure for me to introduce her\n51.8s: from\n53.32s: this my second introduction second\n57.719s: intruction that's very funny um it is a\n61.079s: delight to invite uh to have Amy\n63.519s: Braverman here so Amy got her PhD from\n66.28s: the UCLA and statistics and in\n69.24s: 1999 um but she's been working at JPL\n71.759s: since 1997 because she said she was the\n74.2s: world's worst graduate student and they\n75.72s: wouldn't give her an office after seven\n77.32s: years and it took her nine um but she's\n80.28s: making up for lost time um so we've\n82.759s: known each other because we were each\n84.4s: involved earlier in our careers in doing\n86.799s: spatial aggregation or data reduction\n88.72s: for remote sensing data\n90.6s: um Amy's stayed the course and I have\n92.64s: not um but um we have had I I can't\n96.36s: think we were trying to think uh as we\n98.119s: were talking last night uh about all the\n100.0s: different conversations we've had about\n102.04s: exactly this question you know when you\n103.68s: make a remote sensing measurement how\n105.6s: well characterized uh is that um so I\n108.64s: look forward to this thank you very much\n110.36s: Robert and thank you all for having me\n112.2s: it's really really a pleasure and an\n114.2s: honor to be here I've heard about leap\n116.399s: for many years now and um have have\n119.56s: always wanted to visit and then Co\n121.24s: happen so um so thanks for having me um\n125.159s: I am going to talk about uncertainty\n127.039s: quantification for remote sensing data\n129.16s: that's the title I usually give the this\n131.599s: talk um but what's new in this talk is\n134.28s: that uh we're now doing it in a way that\n136.28s: respects the spatial context of an\n139.04s: individual image I mean some of you may\n140.519s: know that when data uh when remote\n142.4s: sensing data are processed typically for\n145.68s: Speed and to be able to take advantage\n148.12s: of parallelism by using mult mle cores\n151.239s: um the algorithms are often applied one\n153.44s: pixel at a time um and when you do that\n156.239s: you're sort of sacrificing the\n157.64s: information that you might get by\n159.68s: leveraging information from nearby\n161.319s: pixels about a current pixel of Interest\n163.36s: so this is uh um uh this talk is very\n167.92s: recent um in fact you're the first\n169.879s: people to get it except that I tried to\n171.64s: dry run it on Tuesday for some people\n174.2s: and it was a predictable disaster so if\n175.76s: it's a little rough around the edges I\n177.0s: hope you understand um the work is joint\n179.44s: with two two colleagues from JPL um\n182.36s: Nicholas Bond and Jonathan Hobbs um and\n185.48s: two colleagues from elsewhere Emily Kang\n188.239s: from the University of Cincinnati who's\n189.599s: been my spatial statistics coach for\n192.2s: many years uh and a young man named Joe\n194.879s: Keim Tara who is currently getting his\n196.84s: PhD with sudipto bannery at\n199.879s: UCLA right so there's the uh obligatory\n203.64s: outline I'm GNA talk about some sort of\n206.319s: conceptual stuff at the beginning and\n207.799s: then go into a specific example\n210.159s: involving a recent Miss mission called\n212.56s: emit which is on the International Space\n214.519s: Station and providing um remote sensing\n217.56s: data used to study uh um the\n221.879s: distribution of mineral dust uh uh on\n225.319s: the surf uh from the surface of the\n226.92s: Earth into the atmosphere in the hope of\n228.519s: improving climate model climate models\n231.439s: um and I just have uh the first results\n235.4s: of of this Enterprise to show you\n237.56s: there's not a lot of it but there's some\n239.12s: of it so I'll show you what that is um\n241.599s: when I thought of coming here um I\n243.36s: wanted to make this talk at least seem\n245.319s: relevant to what you're doing uh so I\n249.12s: gave it a little bit of thought and\n250.319s: thought about Ai and ML and how that is\n252.519s: used in climate science and um I know\n255.84s: that at least as of a few years ago um\n258.959s: much of the emphasis was on climate\n261.88s: model output and comparing the output of\n264.36s: one model to the output of another model\n266.36s: or comparing the output of a model under\n268.24s: one set of assumptions to the same model\n270.639s: under a different set of assumptions but\n273.44s: um perhaps I'm outdated um and uh remote\n277.4s: sensing data provides a vast source of\n279.36s: information for confronting your model\n281.88s: predictions um with actual observational\n284.479s: evidence with a caveat that you'll all\n287.479s: understand in a few minutes um if you\n289.4s: don't already understand it so if you're\n291.16s: going to do AI if you're going to do\n292.919s: machine learning to learn about the\n295.28s: Earth system from remote sensing data it\n298.039s: would be a good idea to understand what\n300.8s: went into the remote sensing data that\n302.32s: you're looking at because as I like to\n303.88s: tell many of my stat friends you know\n306.12s: there is no thermometer in space um\n309.08s: that's not how we measure things it's\n310.759s: all inference it's all inferred from\n313.8s: electromagnetic Spectra um uh acquired\n317.28s: from from space from spaceborn\n319.28s: instruments um I know just sort of the\n322.0s: basics which is that the uh two major\n324.88s: roles of remote sensing data in the\n326.52s: climate modeling Enterprise include the\n328.919s: use of the data to develop\n330.12s: parameterizations for subgrid scale\n332.039s: processes that you can't um resolve\n334.88s: directly um but then also I and I ran\n338.12s: around in this space for a little while\n340.24s: um back in the uh 2011 range when I was\n344.08s: working more closely with Robert um\n346.8s: which is you know can you can you\n348.639s: actually develop I think what they\n350.84s: called metrics um for how well a\n354.319s: particular climate model or a model run\n356.16s: under certain assumptions was performing\n358.4s: by comparing it to data and in fact NASA\n360.44s: stood up a whole big uh thing that was\n364.16s: called OBS for myips if any of you have\n366.12s: heard of that which was an attempt to\n367.96s: take NASA data sets and make them put\n370.8s: them in a form that was more easily\n372.68s: comparable to um the output of climate\n375.84s: models uh these are typically grided\n377.36s: data sets at relatively coarse\n379.84s: resolution um and I don't honestly know\n383.36s: myself how successful that was um it\n386.44s: seemed to me that because every climate\n387.919s: model has its own output resolution or\n390.24s: at least that used to be the case that\n391.8s: this made things pretty hard because\n393.68s: then the first step you always had to do\n395.84s: was to get everything on the same\n397.44s: spatial grid if you wanted to do these\n399.36s: comparisons um my beef as a statistician\n404.039s: with all of this is that there is no\n406.4s: uniformly uh accepted standard for how\n409.759s: you describe the uncertainties that are\n411.599s: attached to these remote- sensing data\n413.919s: products that are put out and that\n415.08s: really does compromise their utility\n416.8s: because if Mission a reports on\n419.639s: certainty using a particular scheme that\n422.4s: they cooked up for themselves and\n424.16s: Mission B does the same then there's no\n426.759s: way to immediately compare the two based\n428.919s: on their uncertainties I mean\n430.28s: uncertainty is in a way\n433.479s: um I will use a pretentious phrase a\n436.28s: lingua franka for uh translating back\n439.28s: and forth and understanding what the\n440.639s: strengths and weaknesses of different\n441.96s: data sets are um so I've been up and\n445.12s: hopping up and down about this for some\n447.039s: time and um so far NASA has not is not\n451.599s: listening to me by providing money but\n454.479s: um we can hope um so I do want to say\n457.479s: that this is a work in progress talk um\n460.12s: not all aspects are fully developed in\n461.919s: fact I've I've spent four years on this\n465.479s: problem so far which is sort of the\n467.0s: speed at which I do things and now you\n468.879s: can understand why I was a bad graduate\n471.12s: student um uh and and most of that time\n475.68s: was spent on um uh learning enough\n479.639s: spatial statistics thanks to Emily Kang\n483.199s: to uh be able to program up what I\n485.44s: wanted to program up which has to do\n487.319s: with learning um the the um how to model\n492.199s: a spatial field as a gaussian process\n494.72s: and the rest of it was stuff that\n496.319s: followed on Heritage that we've done in\n497.879s: other areas um the one\n501.8s: overarching um requirement for this kind\n505.639s: of a methodology which we are and I\n508.759s: shouldn't say NASA hasn't come through\n509.919s: with money I am the lead for uncertainty\n512.2s: quantification for the upcoming surface\n514.039s: biology and geology Mission which some\n515.599s: of you may or may not know about um\n517.68s: that's the next big NASA Mission uh\n521.039s: it'll be the second contribution to\n522.76s: What's called the Earth system\n523.719s: Observatory which is the next Suite of\n526.6s: um remote sensing Earth observing remote\n528.64s: sensing missions and the data that I'm\n530.279s: going to show here is actually the\n531.959s: precursor Mission the emit data is\n534.24s: precursor for the surface biology and\n536.8s: geology visible shortwave infrared\n539.839s: instrument that is going to be flying\n541.24s: there will also be a thermal instrument\n543.72s: um and there are many fascinating\n545.24s: statistical problems associated with\n547.32s: that new mission one of the big ones is\n550.0s: the um uh these new data sets are at\n553.8s: 30ish 60-ish meter resolution Global\n557.24s: land\n558.24s: surface um for a long time hopefully\n561.04s: more than the three nominal years of the\n562.519s: mission that's a lot of data right the\n565.399s: current the EOS that's Earth observing\n568.079s: system um a emissions were more like 1\n571.04s: kilometer resolution so you can imagine\n573.64s: what the increase in volume is about to\n576.399s: be so uh we have to be able to do what\n578.64s: we're doing in a way that's\n579.64s: computationally feasible um Robert said\n582.839s: there might be some people in the room\n584.16s: who don't know a lot about remote\n585.8s: sensing um so I just put together a\n587.64s: couple of quick slides um probably you\n590.88s: can imagine what's going on here you've\n593.079s: got the spacecraft that's the Observer\n594.8s: flying along uh in passive remote\n597.32s: sensing the sun is showering the Earth\n599.2s: with photons those photons travel\n601.6s: through the atmosphere and change energy\n603.959s: states essentially as they travel\n605.76s: through um so they're impacted by the\n608.16s: gases in the atmosphere and the\n609.32s: composition of the atmosphere they hit\n611.24s: the surface where they are scattered uh\n613.92s: in different ways depending on um\n616.839s: depending on this on the scene um\n619.16s: there's also emission all the way\n620.959s: through which means that things are\n622.959s: blurting out additional photons um that\n626.04s: that had been uh let's say stored in the\n628.72s: Earth um before they're burped back out\n631.959s: and then those photons go back out\n633.48s: through the atmosphere the whole thing\n634.92s: happens again and they're seen by the\n636.56s: satellite the satellite looks down and\n639.92s: discretizes the spatial scene below it\n643.36s: into pixels right because it's a big\n645.72s: camera um and it also discretizes the\n648.36s: electromagnetic spectrum into bins and\n650.959s: essentially what it's doing is counting\n652.32s: photons that fall into different bins\n655.04s: that are um acquired over different\n658.44s: pixels so in every ground pixel you have\n662.2s: a high-dimensional vector of um what's\n665.839s: started out as Photon counts and then\n667.519s: through the magic of data processing\n669.04s: become something called\n670.44s: radiances um and um those there there is\n674.079s: the signature of the composition of the\n676.48s: atmosphere and the surface in what is\n678.68s: seen by the spacecraft because it's been\n680.24s: impacted along the way right and the the\n682.88s: retrieval problem in remote sensing is\n684.839s: about inferring what the state of either\n687.2s: the atmosphere or the surface or some\n688.6s: property the is from those noisy Spectra\n691.44s: because the instrument observes with\n693.639s: noise um a typical polar orbiting\n695.8s: satellite has a trajectory like this uh\n698.519s: and if it's passive remote sensing it's\n700.0s: only taking data on the daylight side of\n701.44s: the earth so depending how wide that\n703.44s: swath is you uh you'll have gaps between\n707.12s: swats on the same day because as the as\n709.279s: the thing goes around this way the Earth\n710.68s: is turning this way underneath it\n713.88s: um okay so at Nasa and other space\n717.68s: agencies I think most space agencies\n719.959s: have taken on this terminology for how\n722.44s: the data are processed um level zero are\n725.24s: the raw Photon\n726.8s: counts um that's what gets dumped to the\n731.16s: ground and um on the ground there's this\n734.48s: this series of steps that take place the\n737.12s: first is georectification and\n738.8s: calibration of the radiances\n740.639s: georectification is assigning a specific\n743.279s: location um I think you can think of\n745.16s: that as a latitude and longitude um uh\n748.199s: to every pixel\n749.8s: and the calibration of the radiances\n751.56s: kind of ensures that if the detectors\n753.56s: have you know decayed over time that you\n755.92s: put everything back so that the radiance\n757.92s: in one spectral band uh is sort of\n760.68s: directly comparable to the radiance in a\n762.32s: different spectral band um then the\n764.68s: magic happens that's called level two um\n767.36s: level two is where we do this big\n768.92s: inference procedure where we say we've\n770.88s: seen uh Spectrum now what can we infer\n773.8s: about the Earth from it and that is done\n776.72s: through inverse modeling um so my big\n779.72s: take-home message is these data aren't\n782.959s: the way they aren't data the way a\n784.839s: statistician thinks of them they are\n786.399s: themselves\n787.72s: inferred um and then there are two other\n790.04s: levels of data processing that I won't\n791.48s: go into here level three are the\n793.8s: so-called statistical summaries of level\n795.92s: two on a uniform SpaceTime grid this is\n797.519s: how Robert and I met um this this was\n800.6s: something NASA mandated because in the\n802.48s: Eos era in particular there was so much\n805.279s: data that your average scientist\n807.519s: couldn't use it and maybe didn't care\n809.199s: about 1 kilometer resolution they were\n811.56s: doing Global Studies they wanted things\n813.48s: maybe on a one degree by one degree grid\n815.44s: so the question was how do you sort of\n817.72s: summarize these data in a way that\n819.92s: remains faithful to them but um makes\n822.279s: them lower spatial resolution um so\n824.88s: Robert and I both I guess cut our teeth\n827.24s: on writing documents about how to\n829.279s: compute means and standard deviations\n831.519s: which is how that has been typically\n833.199s: done um so since these data are really\n836.639s: inferred yes so level one is where all\n841.04s: of the god uh adjustments are made you\n844.6s: take those curvatures and flatten them\n847.48s: yeah that's right that's right I guess R\n850.839s: happens yeah okay yeah yeah I mean it\n853.56s: depends what the final format of the\n854.959s: data being produced are most things are\n856.759s: in hdf now if that's a familiar\n858.8s: terminology no talk to you about that\n861.04s: later um since these things are inferred\n863.759s: we really should have uncertainties\n866.399s: attached to each one of these things\n868.56s: that we prod\n869.839s: um so here's my model of an observing\n872.399s: system um think of this as what takes\n875.24s: place in a single Pixel uh the things in\n878.079s: Gray are things that we do not get to we\n880.16s: do not get to know uh the things in blue\n882.8s: are things that we get to know um the\n885.639s: true state of the system whether it's\n887.759s: the atmosphere or the surface or some\n889.48s: combination is uh I'm denoting that by X\n892.88s: um everything here is actually a vector\n894.92s: even though I I'm so I'm not going to\n896.36s: make a big fuss about that but um nature\n899.56s: is is uh what we call the forward\n902.16s: function the forward function is what\n904.399s: converts um what converts that state\n908.079s: into a Radiance Vector we think about\n910.8s: that that noisess Radiance Vector uh is\n914.32s: observed by our instrument with some\n915.639s: measurement error Epsilon and it is that\n918.24s: thing I'm calling an observation is this\n919.959s: noise this noisy Radiance uh which is\n923.32s: then put into this gigantic retrieval\n925.56s: algorithm which is a very complicated uh\n928.04s: Mission specific piece of software that\n930.959s: attempts to get back at that State\n933.279s: estimate um now the retrieval algorithm\n936.0s: itself like I said it's a big lump of\n937.48s: code uh and it has buried inside it a\n940.519s: forward model not to be confused with\n942.68s: the forward function the forward model\n944.6s: is our best representation of what that\n946.759s: forward function is but it is not the\n949.199s: truth um for Speed and\n953.24s: um because sometimes we just don't know\n955.759s: certain things um that is by by\n959.44s: definition it has to be kind of a crude\n962.12s: representation um B I've called what\n964.72s: I've called B here are other parameters\n966.8s: that the typically the forward model but\n968.88s: also the retrieval need in order to\n971.12s: execute so spectroscopy would be such a\n973.639s: thing those are things that you need to\n975.12s: know in order to do the retrieval and in\n977.12s: order to run the forward model um if the\n980.839s: retrieval algorithm is an implementation\n982.8s: of bay which is common now um uh that b\n986.959s: would include uh the prior mean and\n989.44s: prior covariance Matrix of the data that\n991.519s: you're going to start with and then I've\n993.48s: recently invented something called gamma\n995.48s: which uh is computational artifacts um\n999.199s: algorithms iterative algorithms\n1000.759s: sometimes don't converge to Global\n1002.04s: Minima they only converge to local\n1003.56s: Minima sometimes they fail uh this is\n1007.04s: going to depend on things like the the\n1010.04s: the finess of the solution grid even the\n1012.56s: way you parameterize the vertical\n1015.0s: distribution of the atmosphere these are\n1016.519s: all things that can cause uncertainty um\n1020.6s: so like I said that R is often an\n1022.68s: implementation of bay that looks to\n1025.12s: approximate the posterior distribution\n1027.0s: of the true State given the radiance\n1028.4s: which sounds like a perfectly reasonable\n1030.12s: thing to do and it and it is um however\n1033.48s: if you do that the only source of\n1035.319s: uncertainty that is being Incorporated\n1037.079s: there is the uncertainty associated with\n1038.679s: Epsilon and there are all these other\n1040.919s: choices inside the retrieval algorithm\n1043.12s: that are going to that are going to\n1044.28s: cause uncertainties like the the gamma\n1047.12s: might really literally cause very\n1049.039s: ability and what you get from one run to\n1051.52s: another to another run or if you just\n1053.6s: change the parameter slightly change the\n1055.559s: B slightly you're going to get a\n1056.6s: different answer because it might be\n1058.16s: chaotic in there who knows um so can I\n1061.6s: ask you a quick question\n1063.96s: sure which instruments are you using I\n1067.84s: haven't gotten that there there are two\n1070.919s: atmospheric\n1073.039s: Windows sorry I missed\n1075.36s: that there are two atmospheric w\n1079.799s: window uh can you wait just\n1082.48s: AIC Micron\n1085.12s: level okay I'll ask you lat that on ask\n1087.88s: me later on um because I'm going to get\n1090.159s: to that okay so um I have come to the\n1093.24s: conclusion that if uh what that the a\n1096.36s: definition of uncertainty that is useful\n1098.559s: here is the joint distribution between\n1100.88s: the true state and its\n1103.52s: estimate and uh if I could know the true\n1108.159s: State I could get at that and the way I\n1111.76s: would want to express that uncertainty\n1114.0s: would be through the conditional\n1115.2s: distribution of the true state after\n1116.88s: seeing the estimate because the estimate\n1119.36s: now incorporates all those other\n1120.52s: assumptions and scientific knowledge\n1122.6s: that I was able to bring to bear in the\n1123.84s: retrieval procedure um as opposed to\n1127.039s: just relying on the radiance itself and\n1130.48s: propagating only Epsilon so now we are\n1133.0s: going to propagate uncertainty due to\n1135.44s: the B's and the gamas as well as the\n1138.08s: Epsilon\n1139.24s: and much of that might be in might might\n1142.36s: reflect itself in terms of a bias here\n1145.2s: because typically when the retrieval\n1147.32s: algorithms are run people pick values\n1149.4s: right you pick a fixed value for you use\n1151.72s: a spectroscopy that is fixed you're not\n1154.0s: treating that as a random variable um\n1156.36s: the gamma might have a random component\n1158.28s: but typically more often than not this\n1160.84s: uh the choice of a specific B to run\n1163.64s: this thing uh will be different you'll\n1166.44s: get a different answer than if you run a\n1168.36s: different then if you choose a different\n1169.919s: B to run it um okay so what we're what\n1173.48s: I'm after now is this conditional\n1175.24s: distribution of the true state after\n1177.44s: I've seen the retrieval estimate um how\n1180.32s: am I going to get at that because I\n1181.559s: don't know the true State well I'm going\n1183.08s: to run a big simulation experiment where\n1186.0s: I'm going to uh get an ensemble of let's\n1190.24s: call them plausible true States uh and\n1193.28s: then I'm going to run this experiment\n1194.84s: here where I'm going to use for my\n1197.24s: forward function and I know this is this\n1199.799s: is what we call an inverse crime and\n1201.44s: I'll say more about that in a minute I'm\n1203.36s: going to use my forward model to produce\n1206.44s: the synthetic radiances that uh um that\n1210.76s: are associated with the TR with each\n1212.48s: true state I'm going to add synthetic\n1214.76s: measurement error I'm going to get a\n1216.48s: synthetic observation and then I'm going\n1217.76s: to push that through my retrieval and\n1219.919s: now I've got for every true State I put\n1222.32s: in I've got a state estimate that came\n1224.0s: out and that's an empirical Ensemble\n1226.28s: that I can\n1227.36s: interrogate um now why do I want to\n1229.88s: interrogate it I want to interrogate it\n1231.52s: because I'm going to put a probability\n1233.12s: model on those two things and I need to\n1237.72s: estimate the parameters of that\n1239.08s: probability model and then when it comes\n1241.2s: time to evaluating the probability of x\n1244.919s: given xat I will plug in a true instance\n1247.919s: of xat the state estimate um this is I\n1252.159s: without knowing it um at the time this\n1254.84s: turns out to be an instance of something\n1256.679s: that's very popular in statistics now\n1258.159s: called simulation based inference where\n1260.32s: you use physical modeling to generate\n1262.799s: training sets to train stuff and it\n1264.559s: might be a neural network in my case it\n1267.32s: it's going to be a gausian mixture model\n1269.799s: um to learn properties of the system and\n1272.44s: then you use that to make inferences or\n1274.2s: you use that to uh to um Express the\n1277.6s: uncertainty of the output when you have\n1280.0s: a real instance of the\n1282.2s: thing okay um so there is I said that\n1285.76s: there's an inverse crime here friend of\n1287.84s: mine calls it that\n1289.08s: which is in the way I set this thing up\n1291.96s: um I have used the same fat both as the\n1295.0s: forward function and in the retrieval\n1296.76s: and that is everybody will agree that's\n1299.159s: overly optimistic I mean I think that's\n1301.0s: a useful thing to do for making sure\n1302.6s: your code works but that's that would be\n1305.679s: way overly optimistic because you'd be\n1307.84s: assuming not going to get to the end of\n1309.799s: this uh because you would be assuming\n1311.76s: that um your retrieval algorithm knows\n1314.679s: what nature is doing perfectly so our\n1316.919s: solution to that was to say well\n1319.039s: can we corrupt our observation why Sim\n1323.24s: in a way that appropriately penalizes us\n1325.279s: for that and we call that model\n1327.52s: discrepancy so what we want to do and\n1330.159s: this is a different talk so you have to\n1331.559s: invite me to come back to give a talk\n1333.84s: about how we got at model discrepancy\n1336.36s: for our application um you're just going\n1338.88s: to have to trust me um for this talk\n1341.919s: that we got it in at least in the\n1343.6s: ballpark um and model discrepancy here\n1346.44s: is um the evaluation of the true\n1350.64s: state by the true forward function minus\n1354.159s: the evaluation of the true State at my\n1356.799s: forward model using my forward model and\n1359.72s: that is sort of the corruption to why\n1363.12s: that I want to add um in order to to do\n1366.6s: this penalty and it's hard because uh I\n1368.919s: don't know what the true state is so how\n1370.279s: am I going to evaluate this and that's\n1371.6s: the model discrepancy talk um all right\n1375.08s: let me go here okay so now the other\n1377.72s: thing is that in\n1378.96s: in the remote sensing world and in the\n1380.799s: climate World spatial relationships\n1383.12s: matter right these algorithms are\n1385.2s: typically applied one pixel at a time\n1387.6s: but when people go to analyze it or when\n1389.44s: you go to compare it to your climate\n1391.12s: model you're looking at a whole spatial\n1392.279s: field of these things and so maintaining\n1395.4s: spatial context and making sure that we\n1397.159s: do this in a way that also provides not\n1400.08s: just the uncertainty within an\n1401.48s: individual pixel by itself but lets us\n1404.88s: get at the Joint distribution between\n1406.64s: what's going on in one pixel and another\n1408.24s: pix\n1409.039s: that's important so instead of just\n1411.2s: doing the probabil getting getting some\n1413.48s: grip on the probability distribution of\n1415.159s: the true State given the retrieve state\n1416.88s: in pixel a and then separately in pixel\n1419.2s: B I want to be able to do things like\n1421.88s: give me the uh probability um the\n1424.919s: conditional probability of what's going\n1426.32s: on in pixel a comma pixel B given the\n1430.2s: retrieved estimate in pixel a and pixel\n1432.88s: B I'll get to that in a little bit so I\n1435.52s: need some spatial notation here I need\n1437.36s: to distinguish between spatial locations\n1439.679s: in spatial stat we usually call the\n1441.559s: spatial location s um which is a vector\n1444.64s: of say latitude and longitude or some\n1447.279s: some kind of spatial index um and uh\n1451.08s: we're so our true State Vector at\n1452.6s: location s is X of s and everything else\n1454.679s: as you see here um the one other thing\n1457.039s: worth mentioning here is that um uh the\n1460.88s: retrieval algorithm is trying to be the\n1462.84s: inverse of\n1464.48s: fat um but it's not right due to all\n1468.88s: kinds of computational considerations\n1470.52s: and lack of knowledge um we wish it was\n1473.039s: but it isn't um okay now if I have a\n1476.039s: spatial field an entire scene of these\n1479.159s: State vectors that's the Blackboard X\n1482.039s: and everything else as is the\n1485.88s: um modeled observation Vector is what I\n1489.159s: get when I stuff X hat back into fat\n1491.88s: that's the Y hat uh the spatial field of\n1494.64s: measurement error is um those are\n1497.559s: typically taken as independent\n1499.279s: identically distributed from Pixel to\n1500.84s: pixel so that's a giant diagonal matrix\n1503.6s: and the model discrepancy Matrix is Big\n1506.2s: D there um which lives by the way in the\n1510.039s: space of radiances because I'm going to\n1512.2s: add it to the radiance to corrupt the\n1513.72s: radiance to penalize myself for having\n1515.679s: committed the inverse crime okay so\n1518.399s: here's a picture of the kind of\n1520.52s: simulation experiment I want to do it's\n1522.76s: got It's it's the analog of what I did\n1524.679s: above where I wasn't concerned about\n1526.88s: spatial location it starts over over on\n1528.72s: the left there with the thing I'm\n1530.76s: calling XP for parent now the parent\n1534.679s: that I'm going to use in what I'm about\n1536.32s: to do is an actual retrieved spatial\n1540.24s: field from the instrument I'm looking at\n1542.12s: which is emit which I will tell you\n1543.76s: about shortly um and I put this over\n1547.76s: here um to remind you that that actually\n1550.48s: did come by applying our retrieval\n1552.72s: algorithm and this little uh this this\n1554.88s: less than sign here is my way of saying\n1556.96s: applied pixel by pixel\n1559.24s: um the retrieval algorithm applied to\n1561.88s: the actual noisy Radiance field that we\n1564.0s: got that gives me my uh State my\n1568.24s: estimated State field X hat here and I'm\n1571.399s: going to do something very boot strappy\n1573.279s: here I'm going to do what amounts to a\n1575.2s: parametric bootstrap I'm going to take\n1576.6s: that one spatial field that I have I'm G\n1579.08s: to fit a gausian process to it and then\n1581.6s: I'm going to simulate multiple\n1582.96s: realizations of that spatial field\n1584.64s: that's what's going on across the top um\n1588.12s: uh\n1589.0s: and if I do this right then that stack\n1591.799s: of X stars there should um have the same\n1596.799s: overall statistical structure as the\n1598.799s: original which is xat but should show an\n1601.76s: appropriate amount of variability and I\n1603.32s: know that in in the world of observing\n1605.039s: system simulation experiments people\n1607.52s: often just add white noise to try to\n1610.32s: corrupt their thing but that that's that\n1613.32s: is going to miss providing the proper\n1617.12s: spatial correlation that is natural to\n1619.52s: the scene that you would also want to\n1621.96s: mimic so I won't go into that so now we\n1624.76s: go from that we uh we stuff that back\n1628.679s: into our F hat this is the first part of\n1631.72s: the inverse Pro the inverse crime I add\n1634.279s: the synthetic measurement I'm going to\n1636.08s: undo the inverse crime by adding this\n1637.919s: extra piece of random variability in the\n1640.32s: spatial field of model discrepancy and\n1642.679s: I'm going to get some a stack of um\n1646.399s: simulated Radiance fields called the Y\n1648.799s: daggers there and I'm going to put those\n1651.6s: in the retrieval and I'm going to get\n1653.0s: these X hat daggers over here that are\n1657.039s: kind of this is like that Ensemble that\n1658.84s: we had earlier that matched the\n1661.399s: synthetic truth with its synthetic State\n1664.159s: estimate but it's at the level of the\n1665.6s: entire spatial field at one\n1667.48s: time does that make\n1669.6s: sense okay good all right so your just\n1673.6s: to make sure I your empirical noise\n1676.2s: which matches the empirical noise the\n1678.76s: thing you're observing yeah\n1682.919s: simulate yeah the the what the\n1686.84s: simulation from the GP is an attempt to\n1689.2s: mimic natural variability of the scene\n1691.6s: as opposed to using the naive way the\n1693.6s: naive way would be to say the scene is\n1695.279s: the scene and I'm just going to add IID\n1697.32s: noise which is done a lot which has done\n1699.559s: a lot cut right right um and the other\n1702.72s: thing is that having that stack of\n1705.08s: things that I can see but what's key to\n1707.0s: the uncertainty quantification aspect of\n1709.159s: this in the first place it's also key to\n1710.919s: getting that model\n1712.36s: discrepancy have you ever\n1714.76s: tried interrogating GP beta hat with\n1719.72s: regard to different versions of colored\n1721.44s: noise from signal processing to see if\n1723.08s: you're getting a mixture of colors no\n1726.399s: I've not tried that we'll talk about\n1728.64s: that yeah thank you um typically that\n1731.799s: that that instrument measurement error\n1734.24s: is a pretty small component of the\n1735.96s: overall uncertainty that infects this\n1738.96s: it or it might be who knows I mean the\n1741.559s: the the the most the largest bit of\n1744.84s: uncertainty comes from all the\n1747.32s: assumptions made here including the\n1749.559s: forward model um and those computational\n1753.0s: compromises there that's where they\n1754.799s: that's where you get a lot of\n1756.32s: uncertainty from yes could you just\n1759.279s: maybe give it like an example of what\n1761.039s: kind of parameters are in Theta what\n1763.6s: kind of parameters are in Theta like\n1765.399s: just an example oh um what what we're\n1767.799s: gonna for our GP we're going to use a\n1769.36s: matern 1/2 and the parameters of that\n1772.559s: would be a length scale parameter which\n1774.2s: is sort of the correlation distance and\n1776.88s: the um and the and the overall the\n1780.399s: variance of each um not of the no not of\n1783.88s: the noise but this is we're now talking\n1785.519s: about modeling the natural variability\n1787.679s: of the scene does that make sense all\n1790.88s: right so if you look at this picture I'm\n1792.32s: going to break this picture into two\n1793.679s: parts the simulation part which is where\n1796.6s: I spent the last four 4 years and 9\n1799.44s: months um and then there's the\n1801.679s: experiment part which is the last three\n1804.36s: months so I have a gross amount of\n1806.84s: detail on the simulation experiment that\n1809.44s: most of you are probably not that\n1810.72s: interested in so I might just sort of\n1812.24s: flash by that and if you want to follow\n1813.72s: up with me later about that I'd be happy\n1815.24s: to do it um the experiment part is\n1817.84s: pretty straightforward also because we\n1819.48s: just used operational software to do the\n1822.519s: experiment which was to push every pixel\n1825.36s: in each of these B sheets of xstar\n1828.08s: through this\n1829.64s: system okay so uh now our Ensemble of\n1833.96s: spatial Fields uh yes the the gaussian\n1838.0s: process is it trained on\n1841.159s: multiple\n1842.72s: uh\n1844.799s: Fields no well that's a question um\n1849.24s: in in the in the initial instance that\n1852.96s: that I'm working on now the idea is to\n1855.799s: train it only on the particular granule\n1859.559s: of data for which I want to get the\n1861.2s: uncertainties I I'll say about that when\n1862.639s: I get to the application because in\n1865.039s: order to keep up with the data\n1867.88s: flow um we want to be able to do this\n1872.08s: using data only from that scene so that\n1874.72s: I don't have to you could right and and\n1877.44s: there are some reasons why you might\n1878.72s: want to if you if if I trained the GP\n1881.76s: just on the scene I'm looking at then\n1884.679s: the GP model that I get applies only to\n1886.679s: that scene\n1888.559s: um so what happens when I go to another\n1890.519s: scene am I going to get some kind of\n1893.0s: discontinuity for example at the\n1894.799s: boundary of the two scenes that's a\n1896.32s: worry so for that reason it might be\n1898.32s: worth doing it on a whole day or a whole\n1901.2s: season or a whole year and that's a\n1903.48s: decision that is yet to be made but it's\n1906.039s: mostly for the spatial variability and\n1907.72s: not any sort of and not what sorry any\n1910.679s: sort of temporal variability that's\n1912.08s: correct that's right we're fix freezing\n1913.96s: this thing in time for the time being\n1915.519s: that's right um Okay so on yeah just a\n1918.919s: reminder there's people in radio land so\n1920.96s: if people ask questions can you\n1922.72s: summarize or oh yes okay so the qu that\n1925.76s: that question was what do you train the\n1928.0s: GP on the single scene that we're\n1929.919s: looking at at the moment or on a whole\n1932.44s: day's worth of scenes or a month worth\n1934.159s: of scenes how do we do that we haven't\n1935.88s: decided yet um we're too early on in the\n1938.559s: process but uh if you ask me in a year I\n1940.799s: might have an answer for you\n1944.559s: um okay so now how are we going to summ\n1948.08s: ize this this this is something I\n1949.84s: already said um the I can certainly do\n1954.279s: for a given pixel I can get the\n1956.12s: conditional distribution if if I do this\n1958.44s: simulation and I have capital B\n1961.72s: simulated spatial fields in my\n1964.32s: simulation experiment then I would have\n1967.08s: in any pixel I have capital B instances\n1970.32s: of uh the synthetic true field and the\n1973.519s: synthetic estimate that goes with it and\n1976.039s: if B is large enough I can fit some kind\n1978.24s: of probability model like a gausian\n1980.96s: mixture is what um we have done when we\n1984.08s: did the non-spatial version of this was\n1986.039s: to fit a gausian mixture model to that\n1988.6s: uh and produce uh the conditional\n1990.84s: distribution of the true um the true\n1994.559s: State given the retrieved state in any\n1996.44s: pixel but I already said that that's\n1998.639s: that's not enough for me I want to be\n2000.84s: able I want I want a user to be able to\n2002.76s: come in and draw a polygon around a\n2004.88s: collection of pixels and then somehow\n2006.76s: represent to them what the conditional\n2008.88s: distribution of all those true states\n2010.6s: are given all their estimates and um\n2013.76s: I'll be perfectly honest and say haven't\n2015.159s: figured that out yet um I think that's a\n2017.44s: that's a very very hard problem and\n2019.84s: we're just starting to work on that now\n2021.32s: so I don't have anything to show you of\n2023.08s: that nature um but what I do have is\n2026.48s: that single Pixel version that I can\n2028.0s: show you for a couple pixels here um the\n2030.48s: other part about this is how can we make\n2032.32s: this fast it's got to keep up with data\n2034.519s: flow um and um the first two years of\n2038.399s: trying to do this I spent trying to um\n2041.88s: estimate the parameters of my spatial\n2044.519s: field um using uh gradient descent and\n2048.52s: that took way too long um partly because\n2051.44s: the field was way too big and I should\n2055.24s: also say I need a non-stationary model\n2057.879s: here not a stationary model so I will\n2060.32s: show you um now I will show you about\n2063.679s: right the emit Mission okay so the\n2066.359s: answer to the question uh which was\n2068.599s: asked which was what instrument are you\n2070.04s: using it emit um and uh the Earth\n2074.32s: mineral Earth surface mineral dust\n2076.56s: investigation experiment you can see it\n2078.639s: it's on the space station so it's not\n2080.52s: doing the polar orbit it's with the\n2082.079s: space station which means it's kind of\n2083.359s: got an odd orbit um but for the purposes\n2086.119s: of this talk that's not super important\n2089.159s: um it measures in the visible short wave\n2091.44s: infrared it has 285 channels so those uh\n2095.119s: Radiance vectors are 285 in length so\n2098.16s: every pixel every 60 meter pixel on the\n2100.76s: ground has a 285 dimensional uh Radiance\n2104.0s: Vector associated with it um you can see\n2107.56s: the the science goals here are noble of\n2110.04s: course um and that's kind of a picture\n2114.079s: of what the of what an emit Radiance\n2116.72s: Cube looks like it is 1,42 pixels in one\n2121.0s: dimension 1280 pixels in the other\n2123.079s: horizontal Dimension and there are\n2125.88s: 285 radiances in H one now um You may\n2130.839s: ask what is the state Vector we're\n2132.16s: trying to observe well it's something\n2133.56s: called surface reflectance which has the\n2136.079s: same Dimension as the radianes it's also\n2137.839s: a 285 dimensional Vector uh and what it\n2141.64s: effectively is is the contribution to\n2144.16s: the total Radiance that you can ascribe\n2146.32s: to the surface so this process of\n2149.8s: converting a Radiance to a reflectance\n2151.839s: in the field is sometimes called\n2153.0s: atmospheric correction which is where we\n2155.119s: attempt to take out the influence of the\n2156.72s: atmosphere um because the atmosphere\n2159.119s: here is a nuisance it's the surface we\n2160.839s: care about there are many other places\n2162.599s: where the atmosphere is what we care\n2164.359s: about and the surface is the nuisance\n2166.16s: but in this particular case it's like\n2167.64s: this um folks have Clive Rogers book in\n2172.359s: the year 2000 many of you are probably\n2173.839s: familiar with that he uh put forth a\n2176.2s: method for applying Baye rule to this\n2178.2s: problem to try to infer the posterior\n2182.0s: distribution of uh the state given the\n2184.96s: radiance uh from the radiance\n2186.8s: measurements the noisy Radiance\n2188.0s: measurements here the atmospheric\n2189.8s: correction is done along the way you\n2192.079s: take this full State Vector which is 287\n2195.04s: Dimensions not 285 which in includes\n2198.24s: characterization of the water vapor\n2199.96s: content and aerosol characteristics of\n2202.04s: the atmosphere you do the Baye thing and\n2204.44s: then you throw away the water vapor in\n2206.319s: the atmosphere and you're left with the\n2209.079s: uh atmospherically corrected surface\n2210.96s: reflectance Vector that is then going to\n2213.0s: be further input into algorithms to\n2215.24s: derive things like this mineral mineral\n2217.8s: composition of the surface um it can\n2220.079s: also be used for studying snow and ice\n2222.119s: properties on the surface and vegetation\n2224.4s: characteristics which is what SBG will\n2226.56s: do that was not part of ID's primary\n2228.599s: Mission uh here's just a short thing on\n2231.4s: the OE retrieval um it's an iterative\n2234.64s: algorithm that searches for the map\n2236.56s: estimate um remember we're doing this\n2238.48s: one pixel at a time um so you're dealing\n2240.839s: with a sample of size one here that\n2242.64s: you're trying to do this on which to a\n2244.92s: statisticians seems a little hinky but\n2246.599s: that's what you do\n2248.16s: um and uh sort of notably here um what\n2254.079s: it it gives you under the gaussian\n2255.8s: assumption the map estimate is the mean\n2257.839s: of the\n2258.76s: posterior and the covariance Matrix\n2261.16s: Associated the 285x 285 covariance\n2263.599s: Matrix of the posterior uh is jigged up\n2266.68s: this way as a linear approximation um\n2269.4s: which NL cresy some of you know who NL\n2271.4s: is pointed out at one point uh that's\n2274.92s: actually not right because the posterior\n2277.64s: variance should not depend on the state\n2280.079s: um and what you see almost universally\n2283.359s: uh when you do this is that these\n2284.68s: covariance estimates are too small um\n2288.0s: way too small and sure they are because\n2291.119s: uh they only propagate the instrument\n2293.0s: measurement error now some people have\n2294.839s: tried to do other things to augment that\n2296.96s: but that's still not standard\n2298.8s: practice um okay so it's important to\n2301.4s: emphasize here that our objective is not\n2304.359s: here to improve the retrieval or the\n2306.359s: forward model although what we're doing\n2308.28s: here could be used um to do that um it\n2311.88s: is to quantify the uncertainty and the\n2313.8s: operationally retrieved quantities warts\n2316.359s: and all artifacts and all bad guesses\n2319.76s: and all um as estimates of their true\n2322.68s: counterparts um so we carry out that\n2325.4s: spatial simulation experiment um to\n2329.96s: understand how the different assumptions\n2331.56s: along the way in this chain affect the\n2334.96s: flow of information from start to\n2338.0s: finish\n2339.76s: um let's see I want to do so there's an\n2342.44s: emit scene that's everybody's favorite\n2344.8s: emit uh RGB image over Mono Lake\n2347.48s: California you can see it's uh lot of\n2349.64s: snow lot of mountains some water um and\n2354.2s: it's wintertime so there might not be\n2356.16s: much vegetation that can be seen there\n2358.319s: it's that 1280 by4 by\n2361.599s: 1242 uh image um I truncated 1242 to\n2365.68s: 1232 for reasons that are that that are\n2368.48s: coming having to do with the number 16\n2371.52s: um and um it's a I think I I need to\n2375.4s: talk about um two different ways of\n2378.0s: arranging the data uh different ways of\n2380.52s: arranging the data might be useful in\n2381.92s: different settings one is what I call\n2384.0s: the array form which is the cube right\n2386.88s: 1232 by 1280 by 285 the other way is\n2390.28s: what I call the tabular form where we\n2391.96s: let each row be a pixel and each column\n2395.28s: be a wavelength so it's that would be\n2397.88s: in this case it's about 1 and A5 million\n2400.16s: rows and 285\n2403.4s: columns um and when we're talking about\n2406.52s: the array form I I got into Julia a\n2409.92s: couple years ago Julia has a wonderful\n2411.44s: thing called a block array if anybody\n2413.16s: knows that so you can index a pixel the\n2416.0s: normal way which is to say pixel I pixel\n2418.359s: J row and column but you can also say\n2421.079s: I'm going to I'm going to uh subdivide\n2423.96s: my big array into blocks of a certain\n2426.56s: size and then you can can index any\n2428.04s: pixel within any block as the j i pixel\n2431.8s: in the lcai block and that turns out to\n2434.44s: be convenient too um so I just want to\n2437.56s: say we did that now here's the here's\n2439.0s: the meat of the simulation part of the\n2441.48s: experiment which is to take that parent\n2444.16s: field fit the GP to it and then simulate\n2447.079s: from the GP and as you can imagine this\n2449.68s: is and do this in a non-stationary way\n2451.88s: by the way so how are we going to do\n2453.76s: that I I'll get to the non-stationary\n2455.4s: part in a minute um\n2458.24s: first thing we do is Project X well we\n2461.119s: take XP in its table form get the get\n2464.28s: the um do a principal component\n2466.76s: projection of the data into the leading\n2469.56s: principal components um six principal\n2472.52s: components here capture virtually 100%\n2474.839s: of the variation in the data um so that\n2477.96s: was kind of happy uh and those are W\n2481.92s: those columns of the projected data into\n2484.0s: those six dimensions are W1 through W6\n2486.44s: here\n2487.88s: um and we're going to hold W1 and W2\n2492.44s: constant and call that the trend in our\n2495.56s: simulation and then we're going to fit\n2499.48s: separate uh gausian process models to W3\n2503.28s: four five and six and simulate from\n2506.76s: those superimpose them back on the trend\n2509.88s: undo the principal component simulation\n2511.839s: and then we have our simulated\n2513.88s: field okay and by the way um yes so the\n2518.2s: the gaussian process here um does the\n2520.48s: spectral co-variability as well as the\n2522.319s: spatial coari yes right yes um the\n2525.56s: question was does the gaussian process\n2527.319s: account for spectral variability as well\n2528.56s: as spatial variability and I I think the\n2530.68s: answer to that is kind of yes um the\n2533.2s: principal component\n2535.2s: transformation is the way of of getting\n2537.68s: that in there um in order to do this in\n2540.319s: a non-stationary way and for\n2541.96s: computational Speed we're going to uh\n2544.44s: divide the scene into a 77 by 80 aray of\n2547.599s: blocks and we're going to fit those four\n2550.76s: gausian processes separately in each\n2553.4s: block using a stationary matern\n2555.88s: model um and then when we come to\n2559.2s: actually simulating the replicates um I\n2562.4s: I have a not a very clever trick for how\n2565.04s: to do that in a way that leads to a\n2566.96s: non-stationary\n2568.44s: field um I think I already talked about\n2572.0s: this uh reverse the principal component\n2574.48s: projections there we go I'm sure many of\n2575.76s: you have done this kind of thing your\n2577.24s: elves uh to reduce Dimension um this is\n2580.119s: just some details on the principal\n2581.8s: component transformation um which is to\n2584.72s: make clear the top row here which is\n2586.48s: that the covariance Matrix um of the\n2588.96s: table form of X is what we're using um\n2592.24s: here are the principal components the\n2594.079s: six principal component Fields uh and\n2596.76s: there's the scree plot over there um and\n2599.68s: we chose two to fixed to be the trend\n2602.0s: because we started with one and it ended\n2605.48s: up not working properly um because there\n2607.559s: was too much natural variability in the\n2609.28s: scene if we simulated over five of the\n2612.96s: six principal\n2614.48s: components um so there's that and uh\n2617.72s: that's kind of The Blocking strategy\n2619.68s: there this is not a 77 by 80 blocking\n2622.88s: this is like a 10x10 blocking but you\n2624.599s: wouldn't be able to see anything it\n2625.64s: would just be a big red blob if I did\n2628.079s: the 77 so we sequentially number the\n2630.76s: blocks in this\n2632.16s: way um and then for each block we fit a\n2636.2s: turn one2\n2637.96s: um with those length scale parameters\n2639.48s: and now the problem becomes how do you\n2641.04s: estimate those length scale the length\n2643.28s: scale and the variance parameters of the\n2644.88s: mat return that's the sigma LK and the\n2647.359s: row LK in a way that's fast enough for\n2649.96s: this problem and that's why I said you\n2651.72s: know two years was trying to make\n2653.2s: gradient descent do that in under 10\n2654.96s: minutes a block and that was too much so\n2657.64s: then came I went to the Joint\n2658.96s: statistical meetings last summer and I\n2660.8s: went to a session on um something called\n2664.44s: amortized inference right and there were\n2667.2s: some folks there um Matt sainsbury Dale\n2669.72s: and Andrew Z Manan among others who\n2672.599s: talked about uh this this Julia package\n2675.64s: that um Matt has created as part of his\n2678.04s: PhD work at the University of Woolen\n2679.68s: gong um called neural estimators so so I\n2682.92s: kind of like this I hope I'm not blowing\n2684.44s: it out of proportion but uh it's a\n2686.4s: brilliant idea um and uh what it says is\n2690.119s: you know uh fitting fitting a spatial\n2692.319s: model can be computationally\n2694.599s: expensive but so what if you did the\n2696.599s: following what if you took um a bunch of\n2700.319s: plausible parameter values on some kind\n2702.48s: of parameter grid and at each grid point\n2705.52s: of the parameter grid you generated a\n2707.28s: spatial field or a pile of spatial\n2708.88s: fields at that parameter value and then\n2711.119s: you used a neural network to train that\n2713.48s: thing backwards which is the input then\n2715.92s: becomes the spatial field and the output\n2718.28s: becomes the parameter that's what they\n2720.359s: did it was very clever it's very very\n2722.44s: very very very fast um it's almost\n2725.079s: instantaneous for the prediction part\n2726.96s: training it for that emit granu took\n2729.44s: about 30 seconds which seems fairly\n2731.92s: reasonable um so that is what we used to\n2735.52s: uh to get the spatial parameters for\n2737.0s: each of the\n2738.24s: blocks um and there they there they are\n2741.2s: for blocks three four and five I\n2742.76s: couldn't get Block six on or W6 on there\n2745.88s: without making everything too small and\n2747.64s: it's eh you know looks okay um I I\n2751.04s: haven't done\n2752.4s: anything to check it I admit that Matt\n2755.52s: is actually working on that he's\n2757.0s: collaborating with us now and we are\n2759.04s: actually working on that but uh then the\n2761.359s: question is how do you do the simulation\n2763.68s: and many of you might be familiar with\n2765.04s: the notion of conditional simulation of\n2766.559s: a spatial process where uh okay so now I\n2769.88s: have my blocks I'll go to the first\n2772.2s: block um I'm going to go to the first\n2774.64s: block up here number one in the upper\n2777.119s: left corner and I'm going to\n2778.24s: unconditionally simulate that from the\n2779.8s: gausian process for that block then I'm\n2782.599s: going to go to block two and I'm going\n2785.04s: to simulate block two conditional on\n2787.0s: block one and then I'm going to simulate\n2789.72s: block three conditional on block two and\n2791.76s: so forth and so forth except that that\n2794.359s: is too expensive because those are very\n2797.28s: high those are 256 dimensional\n2799.92s: simulations because 16 by 16 is 256 so\n2804.599s: we did instead is when we got to block\n2806.48s: two we conditioned only on the the\n2809.04s: bottom edge of number one when we get to\n2811.4s: block three we condition only on the\n2812.96s: bottom edge of number two when we get\n2814.839s: around to the top of the next column we\n2817.44s: condition on the left edge of the\n2819.52s: previously simulated block which would\n2820.839s: be number one and then we get to the to\n2823.119s: this one\n2824.16s: here we condition on the whoops the\n2828.04s: bottom\n2829.24s: Edge the bottom Edge in other words you\n2832.2s: condition only on the edges of the\n2834.44s: adjacent blocks that have already been\n2836.359s: simulated um so I will go past that okay\n2840.119s: so that's what's being shown here um uh\n2844.24s: there's all kinds of detail in the\n2845.599s: backup slides I'm not going to go into\n2847.319s: it um for time um this believe it or not\n2851.0s: if you can see it I hope you can see it\n2852.68s: maybe you can't not on this screen this\n2854.8s: is this is actually an animation yes do\n2858.68s: the Ed yeah be very careful with regard\n2863.48s: to how boundary conditions they act as\n2867.599s: artifacts um well you get what you get\n2870.68s: right I mean it is what it is yeah um in\n2873.68s: that simulation um but because of the\n2876.359s: screening effect it should be should be\n2879.76s: true that the conditional distribution\n2881.48s: of a block given a set of conditioning\n2883.839s: variables that just happens to be the\n2885.24s: edge of the adjacent previously\n2886.72s: simulated block should only depend on\n2889.48s: that right okay um you probably can't\n2892.44s: see it I think you can't see it in the\n2893.96s: room at all but the W3 four five and six\n2897.2s: are changing slightly here W1 and W2 are\n2899.92s: not because they're treated as Trend so\n2902.119s: this is sort of the scale of the natural\n2903.8s: variability that is being simulated here\n2906.319s: and it is um it has the the statistical\n2911.4s: properties of the original Parent data\n2914.119s: set because that's how we created it um\n2916.92s: so here's an RGB image of the same thing\n2919.48s: and you can see it maybe a little bit\n2920.839s: better here um so if you just put IID\n2924.0s: noise on there you'd probably you'd\n2926.319s: still see the overall spatial structure\n2928.24s: with the mountains and the lake and all\n2929.599s: that but the fuzziness would just be\n2931.599s: white\n2932.52s: noise um so here we have kind of\n2934.96s: spatially structured fuzziness\n2938.44s: um okay so now the experiment part I\n2940.72s: think I said what I wanted to say about\n2942.16s: that which is that we just push this\n2945.04s: thing through the operational software\n2947.2s: after deriving the model discrepancy the\n2949.0s: model discrepancy is not part of the\n2950.44s: operational software um\n2953.76s: and uh I had a a little bit of detail on\n2956.48s: how those things are I think I already\n2957.64s: said the measurement errors there is\n2959.359s: actually a separate measurement error\n2960.52s: for each pixel that is calculated from a\n2963.52s: formula that was fitted um at a time\n2966.92s: when they had laborator when they had\n2968.319s: the instrument in the laboratory and it\n2970.079s: corrects for certain things I don't\n2972.92s: really know all the details of that um\n2976.04s: the derivation of model discrepancy is a\n2978.2s: is a completely separate talk and I\n2979.4s: would love to talk to any of you about\n2980.68s: it because I imagine that model\n2982.4s: discrepancy characterizing forward model\n2984.72s: error uh forward model structural error\n2987.64s: as separate from the input errors would\n2991.04s: be something that that is potentially of\n2992.839s: interest to a lot of people in a lot of\n2994.76s: areas um so\n2998.44s: armed now with the result of the\n3000.16s: simulation experiment going to a single\n3003.319s: Pixel at a time we learned the\n3005.2s: parameters of the gausian mixture model\n3007.44s: using that synthetic joint\n3009.48s: distribution um we used the r package\n3012.48s: mclust to do that which conveniently you\n3014.599s: can call from directly from Julia um and\n3018.799s: uh the this is just a little bit on the\n3020.28s: gausian mixture density gaussian mixture\n3022.24s: is a family of gaussians each of which\n3024.559s: can have its own mean vector and\n3025.839s: covariance Matrix and a set of mixing\n3028.079s: weights or probabilities and uh so so\n3032.4s: this model has those parameters those\n3034.599s: things are all learned from the\n3037.319s: simulation um yada yada yada I won't um\n3041.799s: I will not dwell\n3044.48s: um then we have the usual formulas for\n3047.559s: gaussian conditioning so if I want the\n3049.52s: conditional distribution of true State\n3052.599s: given retrieved State I plug them into\n3055.24s: this equation and the\n3058.04s: um um the daggers and the Stars refer to\n3062.2s: different things that are learned from\n3064.2s: aspects of the simulation the key thing\n3066.44s: here is that um if I wanted the\n3069.24s: conditional distribution of of x given X\n3072.0s: hat dagger if I wanted the conditional\n3073.24s: mean I would use this formula if I\n3075.16s: wanted the conditional variance I'd use\n3076.72s: the one underneath and if I wanted the\n3078.359s: mixing weights I'd use that one and what\n3079.799s: I have done here was plugged in X hats\n3082.88s: and X's from the simulation just to\n3084.839s: illustrate but in reality\n3087.44s: I don't know what the true X is that's\n3088.92s: why I'm doing this and what I'm going to\n3090.52s: plug in is an actual X hat not not a\n3093.88s: simulated one from the experiment does\n3095.68s: that make sense or seem clear at least\n3099.16s: um okay finally I can simulate from that\n3102.16s: distribution if I want to visualize it I\n3104.599s: can simulate from that conditional\n3106.24s: distribution so um as a way of looking\n3109.52s: at the result of that after having\n3111.0s: pushed everything back into the original\n3113.2s: space the original reflectance space\n3116.92s: um I'm not going to I'm not going to\n3118.24s: dwell on that that's the kind of thing\n3119.559s: we got um so what you're seeing here is\n3123.24s: the blue envelope are draws from that\n3126.92s: conditional distribution of the true\n3128.28s: State given the retrieved State the\n3130.599s: green line is the actual retrieved\n3133.24s: State and uh I thought I try telling\n3138.119s: remote sensing people that they\n3141.0s: retrieval has a problem they won't like\n3143.559s: it right they don't nobody likes being\n3145.799s: told that they don't especially if\n3147.2s: they're all they've already produced Gob\n3148.76s: of data that way but I showed this to\n3151.72s: somebody on the emit team and he didn't\n3153.799s: scream um he thought these results were\n3156.599s: plausible what you see here is that\n3158.28s: there is some\n3159.88s: bias um in uh the blue envelope are is\n3163.799s: the um this represents a 100 draws and\n3167.44s: remember I only did the simulation I\n3169.119s: don't think I said I only did it with 10\n3171.079s: replicates because it was hard and each\n3174.599s: replicate is two gigabytes\n3177.0s: um so it was a little difficult to\n3178.68s: maneuver around we're going to beat That\n3180.72s: by putting all the computations on one\n3182.92s: on a supercomputer instead of doing them\n3184.68s: partly on my laptop and partly on the\n3186.52s: laptop of uh Nicholas Bond um but I\n3189.92s: showed this to him and his was yeah I\n3192.4s: mean it could be it could be um this\n3195.4s: this feature here this sort of\n3197.559s: persistent feature here um between 500\n3201.04s: and about 750 nanometers in all the\n3203.92s: plots is indicative of uh specified\n3207.2s: atmospheric properties particularly\n3209.16s: aerosol properties um and uh potentially\n3213.72s: also top uh the failure to include 3D\n3217.4s: effects of radiative transfer due to\n3219.24s: mountains and\n3221.16s: topography um and that you can well\n3223.72s: understand I mean people are well aware\n3225.52s: that the routine radiative\n3228.079s: transfer um algorithms that are used are\n3230.64s: typically 1D algorithms so they're not\n3233.2s: picking up some of these effects of\n3234.52s: topography and that would you would\n3236.559s: expect cause some kind of uh issue also\n3239.96s: the spike over here at about just short\n3242.72s: of 1500 Nicholas said ignore that that's\n3246.079s: at the shoulder I'm not sure what that\n3248.0s: means but but you some of you do that's\n3250.4s: at the shoulder and that's kind of a\n3252.04s: known artifact so I was pleasantly\n3254.799s: surprised to get something that I wasn't\n3256.599s: yelled at and screamed at about and that\n3259.72s: and that my collaborator thought was at\n3262.68s: least plausible and I'm not saying this\n3264.68s: is the final answer there are lots of\n3266.359s: decisions that were made along the way\n3268.0s: that could affect what this endp looking\n3270.24s: like and there's an awful lot of\n3271.2s: tinkering to be done before we get there\n3274.0s: yes thing you said it didn't quite catch\n3277.359s: um this is some kind of impact this\n3281.96s: Spike here that has to do with the fact\n3285.079s: that there's a\n3286.76s: gap um and he didn't elaborate I didn't\n3289.64s: we didn't have time to discuss it in\n3291.0s: great detail but uh he didn't seem\n3293.319s: concerned about that um um so I'm just\n3297.359s: going to I'm going to try to wrap it up\n3298.64s: quick here um so all this we call this\n3301.44s: thing an observing system uncertainty\n3303.319s: experiment instead of an observing\n3304.72s: system simulation experiment and all it\n3307.559s: is is an observing system simulation\n3309.24s: experiment that people in the field do\n3311.0s: all the time but with a maybe a more\n3313.92s: careful treatment of how you create what\n3318.2s: I think you would call in the Aussie\n3319.52s: World a nature run but what you do with\n3322.2s: that you use an ensemble there instead\n3323.76s: of a single thing and maybe people do\n3325.119s: that in AIS to I know and a more careful\n3329.079s: treatment of how you interrogate the\n3330.52s: output I've seen lots of people just\n3332.0s: looking at root mean squared error as a\n3334.48s: measure of how these things relate to\n3337.28s: each other but that's really trying to\n3339.28s: clobber a lot of information into a\n3341.039s: single into a single number it blurs\n3343.4s: between bias and variability and I think\n3345.119s: people do care about that um this is an\n3349.0s: instance of this notion of simulation\n3351.72s: based inference which a fell at Kyle\n3353.64s: cranmer at Wisconsin\n3356.4s: who's now the head of the data Science\n3357.72s: Institute there came up with he's a\n3359.88s: physicist um but but very clever and\n3362.4s: very sort of feels kind of modern and um\n3366.359s: is um has connections to uh\n3370.52s: likelihood-free inference and statistics\n3372.599s: and things like basian uh basian\n3375.76s: computation um let's see what else do I\n3379.4s: lots of methodology questions here for\n3381.28s: my stat friends um or and for my domain\n3384.839s: scientist friends like like where do you\n3386.52s: draw the line between what's considered\n3388.0s: Trend and what you're going to simulate\n3389.88s: over the first time I did this when we\n3392.16s: just used the first principal component\n3394.0s: as Trend what we ended up with was a\n3397.039s: whole bunch of negative surface\n3398.359s: reflectances and negative radiances and\n3400.92s: that is just not physical so that's when\n3403.599s: we went to number two but there would be\n3404.96s: many ways nothing says you have to use\n3407.119s: the first of anything maybe I should\n3408.799s: freeze one of the\n3410.559s: others um but who knows okay what so\n3413.839s: what we're trying to do here is we are\n3415.2s: trying to mimic natural variability\n3418.24s: we're trying to find a way to mimic\n3419.4s: natural variability this is not\n3422.559s: necessarily the Rolls-Royce method of\n3424.4s: doing it but it is a method of doing it\n3427.119s: uh and that leads to the question of\n3428.839s: what exactly do we mean by natural\n3431.039s: variability you know what is it when you\n3433.28s: can when you only get one look at the\n3435.079s: scene on a particular day at a\n3437.359s: particular time what does it mean to be\n3441.559s: considering variability in that context\n3443.92s: there is only one on that day at that\n3446.28s: time but nonetheless I mean in\n3448.119s: statistics we face that all the time\n3449.72s: we're talking about alternative\n3451.88s: plausible outcomes as far as I can tell\n3455.039s: I that's my take um the statistical\n3458.16s: properties of these neural estimators\n3459.64s: that is a big deal there's a lot of\n3460.76s: people working on that right now there's\n3462.92s: Matt sainsbury Dale tells me there are\n3464.92s: people out there working on convergence\n3466.52s: results for that so that's a relatively\n3468.76s: new thing um like he said he said always\n3471.16s: check it against mcmc which I haven't\n3473.0s: done um I'm hoping he'll do that for me\n3476.559s: um we need emulators for both the\n3478.359s: forward model and the retrieval takes\n3480.28s: too long to run these things the only\n3481.76s: reason we could do this uh for this\n3483.96s: exercise was because we used 128 cores\n3486.76s: and so on but in order to keep up with\n3489.96s: operational um processing it's going to\n3492.2s: have to be a lot faster than that um the\n3495.2s: question of over what data should the\n3497.0s: model be estimated the gausian mixture\n3499.319s: that that that's a good question um that\n3502.4s: is exactly one of these methodology\n3504.359s: questions uh and is there a a way a way\n3508.559s: to do this kind of description of the\n3510.92s: conditional distribution of the true\n3512.119s: State given retrieve state for multiple\n3514.64s: pixels at the same\n3516.72s: time that is feasible and when you don't\n3519.72s: know I mean a user who knows whether\n3521.839s: robbert Pinkus is going to go in there\n3523.319s: and draw a little tiny box around a few\n3526.039s: pixels or a big box around a lot of them\n3529.68s: um so we're going to have to face that\n3531.28s: whoops and uh here's what I my my my\n3537.599s: stealth reason for coming here is that\n3539.24s: this whole idea originated from some\n3541.359s: work that I did about 10 years ago in\n3544.079s: trying to develop um better ways of of\n3546.76s: assessing whether two climate model runs\n3549.039s: were quote unquote similar enough or\n3551.4s: similar to within their internal\n3553.4s: variability and um this GP simulation\n3556.4s: idea follows naturally we did that work\n3558.359s: for time series where we broke down a\n3561.76s: Time series we did a wavelet\n3562.96s: decomposition of Time series and we\n3564.44s: simulated over the finer scales\n3567.16s: and then um my colleague Anu chatter G\n3570.2s: he developed some hypothesis testing\n3571.76s: procedures I took that to a climate\n3573.039s: model meeting and they yelled and\n3575.039s: screamed that that's not that's not the\n3577.2s: internal variability that there's\n3579.44s: there's a whole notion of internal\n3580.72s: variability specific to that field and\n3582.72s: they didn't want to they didn't want to\n3584.079s: think about this one um and if it does\n3587.92s: if if this if this can be convincing to\n3590.119s: climate modeling people then maybe\n3591.88s: there's a whole um Enterprise in making\n3595.0s: in formulating hypothesis\n3596.559s: tests to assess whether two climate\n3598.92s: model runs are similar or whether a\n3600.76s: climate model run produces a data set\n3603.2s: that is similar to an observed one and\n3605.28s: I'm going to stop there it's probably\n3606.92s: lunchtime by now there's some some\n3609.52s: references and there's some contact\n3611.52s: information so thank\n3620.039s: you\n3621.92s: I\n3624.079s: hi hi thanks Amy mhm I wanted to ask and\n3627.96s: this relates to your question on natural\n3630.079s: varability I want to ask like what\n3632.799s: happens when you have like massive data\n3635.24s: imbalances or outliers your data so like\n3639.319s: you know 99% of the clouds you see are\n3642.68s: not saying this as a fact but if your\n3644.64s: data is like mostly liquid water clouds\n3647.76s: what happens when you're trying to\n3649.0s: simulate those ice clouds which are just\n3651.16s: as important what happens when your data\n3653.319s: has a hurricane right so that was a a\n3659.16s: reason for using the actual data as the\n3663.0s: source the as the parents right I mean\n3665.92s: if it's in you're you're right I mean\n3667.64s: the your the algorithm that gave rise to\n3670.079s: the parent data set which is actually\n3672.28s: the retrieve data set might have all\n3674.0s: kinds of problems in it it's true but um\n3678.0s: and this did come up in the model\n3679.359s: discrepancy part of the work which is\n3682.119s: you kind of have to make the assumption\n3684.68s: that your retriev data is at least good\n3688.079s: enough that you can regard the\n3691.559s: truth as a realization from the same\n3694.72s: process that gave you the retrieval it's\n3697.24s: not the same realization but it's a\n3700.88s: different realization so if if and and\n3704.48s: my argument for that I thought I was\n3705.76s: being very Sly was to say that if the\n3707.48s: people that produce these data sets\n3709.48s: can't say that then they have no\n3711.48s: business putting this out to the\n3713.52s: community and saying this is a\n3714.839s: representation of reality\n3717.319s: um so like with many things I mean we\n3719.96s: live with the sample we have um it is\n3723.24s: possible that if you wanted to explore\n3726.039s: the impact of something like that um you\n3729.559s: could you could do it as kind of a\n3732.079s: simulation experiment where you force\n3733.52s: those artifacts in and see see what\n3737.68s: happens and\n3739.799s: quantify quantify the properties of the\n3743.039s: truth given the retrieved which in that\n3746.52s: case if there's should show\n3750.4s: bias if that were if that were true\n3752.559s: because presumably you're asking because\n3754.4s: the ice clouds and the water clouds have\n3756.48s: different effects on the radiance yeah\n3759.2s: yeah yeah thank you we have a couple of\n3762.88s: questions from\n3764.64s: online first how do you handle the back\n3767.839s: scattering component and from the same\n3771.2s: uh guest would you please let me know\n3773.079s: how you have included the aerosol data\n3776.0s: to the radiance distribution okay those\n3778.48s: are all I think they're both radiative\n3780.44s: transfer questions that has to do with\n3783.4s: the forward Model F and the\n3785.359s: retrieval and um that answer would have\n3788.0s: to come from my collaborator Nicholas\n3789.72s: Bond who ran those\n3796.92s: algorithms think we have time for one\n3798.92s: more question in the room or online\n3808.48s: was really interesting talk I'm\n3809.559s: wondering if you could give a very quick\n3811.96s: summary of your model discrepancy\n3814.16s: construction talk oh oh yeah I figured\n3817.96s: people would want to hear about that I\n3819.359s: did so um let me see what I can do here\n3824.039s: um there's a four o'clock slot yeah I do\n3828.2s: I do and if you're the person who was\n3830.44s: online in in the meeting I have with and\n3833.599s: Marcus\n3837.68s: no okay never mind never mind okay so\n3841.119s: here's the here's the discrepancy stuff\n3843.559s: right which is\n3845.76s: um what we're interested in is this\n3849.799s: um is this term this Delta X this\n3853.119s: notation that is supposed to suggest\n3855.279s: that at the true X the true State the\n3858.24s: difference between what you get when you\n3859.88s: apply the forward function and the\n3862.48s: forward model whatever that is and um\n3867.319s: if you do a little one thing we\n3868.96s: routinely have access to in remote\n3872.16s: sensing data processing is something\n3873.839s: that's called the spectral residual\n3875.799s: which is the difference between the\n3877.279s: observed Radiance Y and the so-called\n3880.079s: model Radiance y hat which is what you\n3882.839s: get when you stuff your retrieved\n3884.44s: estimate back into your forward model uh\n3887.24s: and we want to leverage that and so if\n3888.52s: you do a little bit of algebra you see\n3890.119s: that the spectral residual um with the\n3892.68s: error term can be decomposed into two\n3894.839s: pieces one is piece we want and the\n3897.24s: other is the the other piece is the\n3899.92s: impact of using the wrong\n3905.279s: X if you apply the forward model to\n3909.039s: those two pieces now little more algebra\n3911.799s: you end up with this which is that um if\n3915.319s: you take the The observed Radiance is y\n3917.96s: minus Epsilon here the sign change just\n3920.0s: because stuff is moving around and this\n3922.64s: piece here and this is the problematic\n3924.24s: piece because I don't really know what\n3926.0s: is but if I'm willing to make this\n3927.799s: assumption that X is a draw from the\n3930.079s: same distribution that gave rise to\n3932.44s: those X\n3933.96s: stars then I can do this with that\n3936.839s: approximation and it does\n3939.079s: seem in a toy example it certainly\n3942.119s: produced something not exactly right but\n3945.079s: interesting and useful and in this\n3947.68s: example I suspect that some of those\n3950.079s: artifacts were due to the way the model\n3952.52s: discrepancy was done so it's it's it's\n3955.92s: the lowest least intrusive assumption\n3959.44s: one could make and still believe that\n3961.64s: there's any skill whatsoever to your\n3964.24s: retrieval so I'm happy to talk about\n3966.24s: that more later if people want\n3970.4s: to all right I think that's all the time\n3973.319s: we have Amy thank you so much for your\n3975.039s: time and your presentation thank you"
    },
    {
        "class": "YouTubeVideo",
        "title": "Bridging Educational Divides: A Research-Practice Partnership to Empower Climate Change Education",
        "videoId": "oKu8M9ueHUg",
        "url": "https://www.youtube.com/watch?v=oKu8M9ueHUg",
        "publishedAt": "2025-03-03T22:45:31Z",
        "transcript": "5.08s: hi everybody we're gonna get started we\n8.16s: have um two great leapers today uh first\n12.08s: we have Christina Torres Christina is a\n14.599s: doctorial candidate in Science Education\n17.32s: at Teachers College Columbia University\n20.08s: she is a research associate at the\n21.96s: center and the center coordinator at the\n24.119s: center for sustainable Futures with a\n26.4s: research interest in climate change\n28.08s: education Christina is also an adun\n30.519s: professor at the Fashion Institute of\n31.96s: Technology part of the Sunni system\n34.76s: where she teaches an ecology and\n37.16s: environmental problems\n40.52s: course I think we're missing some\n44.52s: text okay great with\n50.0s: that we were just talking about how um\n53.68s: my students are just some of the most\n55.84s: well-dressed people I've ever seen in my\n57.6s: life um so yeah I teach any ology course\n60.399s: to students that are going into\n61.359s: sustainable fashion anyway thank you all\n63.64s: so much uh and everybody to who is\n65.84s: online listening I'm so excited today to\n68.28s: talk about our summer Institute which is\n70.56s: a program done here at leap in\n73.08s: partnership with the center that I come\n74.759s: from over at Teachers College the center\n76.479s: for sustainable Futures and the New York\n78.96s: City Public Schools office of energy and\n81.36s: sustainability really with this program\n83.439s: we're thinking critically on how we can\n85.84s: take all of this amazing research that\n87.92s: is done at leap other uh research being\n90.72s: done on the broader impacts of the\n92.079s: climate crisis and local um Solutions\n95.52s: being done here in New York City and\n97.52s: bring it into New York City public\n99.92s: schools so I'm going to frame a little\n102.56s: bit about our research that was done way\n105.159s: before the Institute of how we\n106.96s: understand what teachers need talk about\n109.0s: the Institute also talk a bit about a\n111.759s: winter climate Institute which is fairly\n113.88s: new we did one iteration of it in 2024\n116.96s: we just had last week our second\n119.039s: iteration of it a lot of that is using\n121.439s: what we learned through our leap summer\n123.2s: Institute to bring to a much larger\n125.119s: network of teachers and then open up for\n127.799s: discussion hopefully towards the end for\n129.879s: the implications of this work on higher\n132.12s: education\n134.56s: institutions so we're really fortunate\n136.959s: at Teachers College at our Center for\n138.68s: sustainable Futures to have a research\n140.64s: practice partnership with the New York\n142.72s: City Public Schools office of energy and\n144.48s: sustainability for over a decade now and\n147.44s: it's through this work with uh this\n150.4s: part of New York City Public Schools\n151.92s: where we've been able to get an inside\n153.84s: look into how teachers think about\n155.879s: climate change how they're integrating\n157.48s: climate change into their lessons before\n159.959s: any of this teacher preparation and\n161.76s: programs existed and we know from uh\n164.72s: surveying and talking to teachers that\n166.64s: at least a third of New York City\n168.48s: teachers are already integrating one\n170.68s: module about climate change into their\n172.84s: work but we've identified four main\n175.36s: barriers to teaching about climate\n177.36s: change there's a misconception that\n179.519s: climate is just a science topic it's not\n181.959s: something that could be addressed in any\n183.959s: subject cross discipline K12 it doesn't\n186.599s: matter if you're teaching a young\n188.36s: student or a student that is going off\n190.0s: to college knowledge gaps resource gaps\n194.2s: and preparedness teachers want to be\n196.28s: surrounded with a network of folks that\n198.159s: are also working on this to bounce ideas\n200.72s: off of they want to also feel prepared\n202.599s: to answer critical questions from\n204.44s: students it's not like students aren't\n206.68s: confronting the realities of climate\n208.56s: change not just through their lives\n211.0s: their livelihoods but also through media\n213.519s: right so making sure teachers are\n214.76s: prepared to answer those questions and\n216.64s: engage with\n217.879s: students we've also through surveys have\n220.48s: learned what types of questions teachers\n222.56s: have specifically for scientists around\n224.76s: climate change uh most teachers have\n226.76s: never interacted with or engaged with a\n229.08s: scientist their questions are incredibly\n231.439s: broad not just from understanding why\n234.64s: what is happening is happening how we\n236.56s: can move forward but also really rich\n238.879s: policy related questions questions that\n240.799s: you wouldn't necessarily ask a scientist\n243.48s: so this is the inspiration for our\n246.959s: transdisciplinary approach to the summer\n249.04s: Institute making sure that we have\n250.4s: experts Across The Sciences the social\n253.04s: sciences psychology education\n256.04s: Etc so the summer Institute empowers New\n259.239s: York City Educators to engage in climate\n261.079s: change education by building connections\n263.16s: between the climate research that we're\n264.68s: doing here at leap local and social\n266.919s: impacts and K12 classrooms we we started\n270.16s: with Elementary School teachers in\n271.759s: summer 2023 because of the unique\n274.08s: challenges associated with teaching this\n276.72s: topic with young children also the vast\n279.32s: majority of resources that do exist uh\n281.84s: to address climate change in classrooms\n283.6s: is for older children uh last summer in\n286.56s: summer 2024 we did middle school\n288.56s: students uh teachers as you could guess\n291.16s: this upcoming summer 25 we will be uh\n293.759s: addressing High School uh\n296.56s: teachers uh this is just a brief\n298.52s: breakdown of the demographic of both of\n300.4s: our teacher cohorts from 23 and 24 uh\n304.039s: there was an emphasis on accepting\n306.16s: teachers from Title One school so\n308.12s: schools in the New York City public\n309.44s: school system that have the most need um\n312.08s: you'll also see here that we had a good\n314.08s: percentage of sustainability\n315.639s: coordinators that's a unique thing in\n317.919s: New York City Public Schools where every\n320.0s: school is mandated to appoint someone to\n323.319s: this role called a sustainability\n325.039s: coordinator they don't necessarily need\n326.84s: to be a teacher they can be a school\n328.479s: counselor they can be administrator but\n331.0s: it's a really interesting Dynamic that\n332.56s: we have here in New York City where we\n334.08s: actually have someone appointed to do\n336.039s: this work so activating that person and\n338.6s: helping them build a network within\n340.039s: their school is key uh to getting this\n342.28s: information out\n343.639s: there we have four main learning\n346.039s: objectives uh not only developing the\n348.52s: teachers's own working knowledge about\n350.28s: climate change but situating that\n351.919s: knowledge in a local New York City\n353.88s: context understanding the connections\n355.96s: between CL climate change and their role\n358.16s: as educators and finally the deliverable\n361.28s: of this institute is for them to create\n363.28s: a standard align module lesson plan\n366.24s: activity that is aligned across grade\n368.919s: subjects um and they can choose which\n371.28s: ones that they want to\n373.639s: address so the kind of brief timeline of\n377.16s: what a summer Institute looks like hence\n379.319s: even though the name is Summer Institute\n381.039s: we are working with these teachers for\n382.479s: an entire Academic Year so they apply in\n385.68s: the spring semester so right now we are\n387.72s: actively accepting educa um applications\n390.36s: for our high school cohort that we will\n392.16s: be working with this summer we then work\n394.639s: with them for um an an entire week over\n397.8s: the summer so you'll see cohort one was\n400.44s: four days cohort 2 which was Middle\n402.639s: School was 5 days where then the next\n405.759s: academic year meeting with them during\n407.72s: office hours during a fall meeting and a\n410.44s: spring meeting to continue to address\n413.319s: challenges of them integrating what they\n415.28s: learned over the summer Institute to um\n418.16s: connect them with resources that we have\n419.919s: in higher education that they might not\n421.639s: have access to and ultimately this\n424.28s: year's um Academic Year work ends in a\n427.68s: final Showcase in April where they can\n430.0s: showcase what they actually did with\n432.319s: what they learned over the summer during\n434.039s: The\n435.16s: Institute this is a brief look at I\n437.479s: won't go into the de the detail details\n439.84s: but a brief look at what each summer\n441.84s: Institute looked like uh for our first\n444.44s: iteration with Elementary School\n446.28s: students uh we really focused on\n448.4s: building community teachers I should say\n450.879s: we really focused on building community\n452.68s: on our first day on day two we started\n455.319s: digging into the science on how to ask\n457.24s: critical questions with young children\n459.199s: in New York City on day three we brought\n462.12s: in curriculum experts from Teachers\n464.159s: College to understand how can we use\n467.24s: what we've learned to address critical\n469.28s: reading writing and Mathematics\n471.56s: standards that we see in elementary\n473.039s: school um classrooms and finally on day\n476.199s: four we uh created a lot of space for\n479.039s: them to do group work on um planning out\n482.319s: what they will be doing for the academic\n484.24s: year\n485.24s: ahead this past summer with Middle\n487.479s: School teachers you'll see we expanded a\n489.12s: day we're like we need another day with\n490.599s: these teachers so five full days 9 to5\n493.56s: and you'll see that um the middle chunk\n495.759s: of these days two three and four are all\n498.44s: situated in an area of leap research um\n502.639s: the moving from the elementary to the\n504.8s: Middle School context created a new host\n507.479s: of opportunities along with challenges\n510.039s: um instead of having teachers Elementary\n512.12s: School teachers that are with the same\n513.479s: group of students all day we now have\n515.479s: hyp specialized teachers right in middle\n517.479s: school there's a separate science\n518.919s: teacher from a history teacher to an\n520.44s: English teacher so our goal with really\n523.039s: grounding this in different areas of\n524.839s: leap research was to spend the morning\n528.12s: doing a um not only listening to LEAP\n531.2s: researchers lecture but doing Hands-On\n533.959s: components of experiments that they\n536.0s: could actually do in the classroom with\n538.04s: their students and in in the afternoon\n540.64s: work with curriculum experts from New\n542.88s: York City public schools from Teachers\n545.12s: College to understand how do you take\n547.68s: this cuttingedge research and bring it\n550.079s: into a history class into a seventh\n552.24s: grade English class an eighth grade\n553.959s: science class um so that was really\n556.279s: exciting um we have Kate who actually\n559.519s: zoomed in to give her talk on clouds it\n562.2s: was fantastic we actually brought the\n564.2s: teachers outside to look at and identify\n566.8s: clouds um we have an one teacher who's\n569.56s: actively uh using the resources that\n572.32s: Kate introduced in his uh seventh grade\n575.0s: geometry class right now so very\n576.64s: exciting\n577.6s: stuff we have a growing interest in our\n580.2s: program as you could see uh for our\n582.36s: first iteration with Elementary School\n583.839s: teachers we got 700 applications for\n586.24s: Middle School teachers we have we got\n587.8s: almost 700 applications so it's really\n590.64s: exciting uh that not only our program is\n593.64s: the word is getting out but there's a\n595.12s: real growing interest among New York\n597.16s: City Educators to um take part in a\n600.36s: program like\n601.959s: this from 2023 with our elementary\n604.64s: school cohort we could see that teachers\n606.6s: feel more informed about climate change\n609.399s: they are more convinced that human\n612.04s: activity is contributing to climate\n613.959s: change rather than natural cycles this\n616.16s: is\n618.279s: prepost in particular when we ask them\n621.2s: qualitatively which sessions uh left the\n623.959s: most impact on them they noted sessions\n627.04s: on the science of climate change the\n629.68s: practice of climate science so not only\n631.959s: showing them data and models how do we\n634.6s: actually collect that data how do we\n636.399s: know what we know and sessions on the\n639.0s: social aspects of climate change in\n640.92s: particular leap own Courtney session and\n643.399s: Jay shuttleworth um who was a TC Alum\n646.16s: who actually did a session with the\n647.68s: elementary school teachers on how to\n649.399s: build a learning library in an\n651.12s: elementary school classroom around\n652.56s: climate\n654.48s: change and like I said we work with them\n656.959s: for the entire year and in uh April of\n660.16s: last year we got to see what the\n661.68s: elementary school teachers produced and\n664.32s: we saw an incredible wide range of\n667.639s: lessons and activities that the teachers\n669.56s: ended up doing with their students\n671.639s: everything from a school counselor doing\n674.519s: a social emotional learning aligned\n677.12s: lesson for students to really think\n679.44s: critically about how they're feeling\n681.2s: about climate change and used uh the\n684.279s: characters from The Pixar movie Inside\n686.76s: Out as a way to help these young\n688.92s: students students Express their feelings\n691.44s: we had uh teachers this is a fourth\n693.44s: grade teacher um use PPM air quality\n697.0s: monitors for them to take air quality\n699.56s: measurements throughout different areas\n701.079s: of their\n702.48s: school we had a special education art\n705.48s: teacher use art as a way for students to\n708.079s: address their understandings of the\n709.92s: ocean and finally we had a teacher from\n712.639s: Brooklyn um connect climate to food\n715.32s: access and a really interesting lesson\n717.72s: uh that uh used shopping circulars from\n721.16s: different uh\n724.72s: supermarkets at the end of uh again with\n727.48s: our Middle School teacher cohort\n729.0s: teachers felt more\n731.36s: informed but what I really want to\n733.279s: highlight is this empowerment and\n736.279s: specifically this advice seeking Network\n738.92s: that's what we're calling it how\n740.16s: teachers not only are feeling more\n742.36s: comfortable to an to answer students\n744.76s: questions about climate change but they\n746.639s: feel like they're connected to a group\n748.519s: of teachers and peers that they can ask\n750.76s: questions to and rely on related to this\n753.68s: pedagogical\n755.959s: practice so what are our next steps our\n758.88s: final showcase for Middle School is\n760.6s: coming up very soon April 1st 2025 you\n763.24s: are all invited send me an email it'll\n765.48s: be at Teachers College in the Smith\n767.0s: learning theater um if you want to see\n769.44s: what our Middle School teachers have\n770.76s: been working on this year we as I've\n773.0s: said a bunch of times already we are\n774.8s: currently accepting a new cohort of high\n777.16s: school teachers if there's a high school\n778.76s: teacher in your life who would be\n780.76s: interested in joining us uh please let\n782.6s: me know I have a QR code at the end of\n784.279s: the application our next summer\n786.04s: Institute will be July 21st to 25th\n789.92s: 2025 I do want to quickly touch on our\n792.839s: midwinter Institute because instead of\n794.92s: our summer Institute which we're looking\n797.32s: at 40 to 50 teachers this is a cohort of\n800.6s: 500 that we had invited to Teachers\n803.56s: College last midwinter the 20th to the\n806.639s: 22nd 2024 and quite literally last week\n809.92s: the 18th to the 20th\n812.079s: 2025 um and this is done as part of our\n814.48s: research practice partnership the office\n816.56s: of energy and sustainability does all of\n818.399s: the coordination and and program\n820.279s: management of this and the first\n823.12s: iteration of this midwinter Institute\n825.079s: was to connect teachers with part their\n827.88s: partner organizations that they have at\n829.72s: New York City public schools so it could\n831.6s: be city government NOS cbos Museum\n834.72s: institutions to show teachers the\n836.68s: resources that they have available to\n838.72s: them related to climate change education\n841.399s: this year they took a different approach\n843.48s: they started on day one grounding the\n845.8s: teachers in climate science very\n847.88s: similarly to how we approach our summer\n849.68s: Institute it's great that we have this\n851.44s: um working relationship with them we um\n854.32s: at our Center then hosted unpacking\n857.04s: sessions small groups with teachers to\n859.32s: really think about how they can start\n861.44s: bridging this science into their\n863.399s: classrooms on day two they it was\n865.92s: conference style where they were able to\n868.079s: choose which session that they went to\n869.959s: related to climate put on by partner\n872.16s: organizations with the goal by the end\n874.12s: of this week for them to submit an\n877.44s: outline of their scope and sequence so\n879.839s: their actual curriculum and the inroads\n882.639s: to where they see climate change fitting\n885.12s: into their existing\n887.68s: curriculum so this is the data from 2024\n890.759s: we know teachers are more informed about\n892.88s: climate change after the midwinter\n895.399s: Institute again talking about this\n897.519s: advice seeking Network that they had\n899.519s: positive attitude changes on climate\n901.519s: change education after the 2024\n903.839s: midwinter Institute knowing how to\n906.12s: integrate climate change into their\n907.959s: lessons understanding that climate\n909.759s: change is related to the subjects that\n911.48s: they teach and having access to\n914.839s: resources we have a lot of Rich data\n917.72s: from 2025 like I said before it only\n920.44s: happened last week so none of it is\n922.16s: analyzed yet um we have a lot of\n925.199s: pre-post data but we also have a lot of\n927.48s: qualitative on the ground data where we\n929.92s: had all different researchers from\n931.56s: Teachers College going and talking to\n933.319s: teachers observing sessions um I do want\n936.6s: to highlight one thing that we did do in\n939.12s: this unpacking session on Day one last\n941.44s: week which was grounded in this figure\n943.68s: which you probably are all familiar with\n945.36s: it's from the ipcc 2023 report um really\n949.279s: looking at the generational differences\n952.0s: of not just the past of um the lifespan\n956.279s: of different individuals but really\n957.6s: looking towards the future and how\n959.6s: climate change is ultimately an\n961.399s: intergenerational issue um so after the\n965.0s: first science talk that our teachers had\n967.48s: they actually we broke out into small\n969.519s: groups and teachers were able to look at\n972.88s: the um all of the these different\n976.079s: scenarios and understand and have\n978.759s: discussions on what does this mean for\n980.72s: their teaching you may be familiar with\n982.56s: this activity Orin did this during the\n984.399s: annual meeting um so we're really\n986.44s: excited that we had the chance to do\n988.04s: this with teachers\n991.36s: so I'd like to end today quickly with\n993.44s: thinking about the role of higher\n995.36s: education institutions in supporting\n997.519s: teachers around climate change education\n1000.36s: we see higher education institutions as\n1002.839s: incubators temples and hubs that can\n1005.6s: Empower teachers to engage with climate\n1008.0s: action what do I mean by that temples\n1010.839s: that hold a whole lot of knowledge and a\n1012.88s: whole lot of resources that not might\n1014.8s: not be accessible to folks outside of\n1016.88s: higher education hubs to connect\n1019.839s: Partners this institute is a great\n1022.12s: example of this connecting New York City\n1024.4s: public schools with our Center at\n1026.4s: Teachers College with everyone here at\n1028.24s: leap and incubators really cultivating\n1031.559s: Talent not only the next generation of\n1033.679s: undergraduate and graduate students but\n1036.12s: also how can we bring in teachers and\n1038.679s: other Community Partners that might\n1040.559s: benefit uh from programs like these and\n1043.559s: we hope that this partnership will serve\n1045.24s: as a model for future Partnerships\n1047.36s: around climate change education\n1049.08s: inspiring strategic collaborations\n1051.039s: between K12 education systems and higher\n1053.799s: education institutions and like I\n1056.48s: promised here is the QR code which\n1058.679s: brings you to the application you could\n1060.52s: learn more about our summer Institute\n1062.12s: there if you know any High School\n1063.28s: teachers if you have any questions I'm\n1065.559s: more than happy to take them over email\n1068.039s: and I will yield my time thank\n1073.84s: you are we doing questions now or are we\n1076.44s: waiting to the end um no let's do\n1079.32s: questions\n1087.159s: now okay not fully formulated but I love\n1090.44s: that you have this showcase where you\n1093.52s: bring and I just want to make sure I\n1095.12s: understand it you you bring the cohort\n1096.799s: back to present basically how they have\n1099.96s: changed their behaviors based on this um\n1104.28s: so that that's really wonderful I I'm\n1106.2s: curious to know if you also get feedback\n1108.24s: from them about like how the students\n1110.52s: themselves react to that and just to\n1112.76s: understand that whole process and then I\n1114.159s: think like again it's just so wonderful\n1116.52s: to see follow-up evaluations taking\n1119.159s: place it's not done as much as it should\n1121.52s: be um I am curious about if there's also\n1124.799s: some effort going into thinking about\n1126.52s: like rewriting curriculum at the New\n1129.12s: York state or New York City level more\n1131.64s: broadly um yeah the question is you know\n1134.96s: you can have these individual teachers\n1136.88s: who will take this on as some of their\n1138.76s: activities but is there also like a\n1140.48s: larger more institutional kind of\n1142.799s: initiative to sort of tweak or push or\n1145.12s: Implement thanks thank you so much for\n1147.2s: your questions um about the Showcase the\n1149.48s: Showcase blew us out of the water\n1151.159s: because last year was our first time\n1152.799s: doing it with our first cohort\n1154.6s: essentially each group that worked\n1157.0s: together in pairs gave a one minute\n1159.039s: lightning Talk of the things that they\n1161.159s: did with their students and then we had\n1164.24s: all different calling them cubicles is\n1166.96s: not the right term breakout sessions\n1169.32s: um where teachers brought student\n1171.08s: artifacts all of the work that the\n1172.88s: students did so whether that was artwork\n1174.84s: written work etc um actually the actual\n1178.32s: lesson plans on PowerPoint where we were\n1180.679s: able to see what the students actually\n1182.64s: did photos their written work sometimes\n1185.48s: videos of their reactions so lots of\n1188.12s: really interesting both like post\n1191.039s: quantitative um surveys that we have\n1193.96s: from these teachers but also the actual\n1196.28s: Rich qualitative work that the students\n1198.799s: did um in regards to curricula it is a\n1202.84s: um an ongoing question and an ongoing\n1205.4s: effort and um Nationwide you might be\n1208.88s: familiar that New Jersey was the first\n1211.24s: state in um the US to mandate climate\n1214.28s: change education across K12 it's the\n1217.039s: only state that has that going there is\n1218.679s: efforts to do this right now here in New\n1220.44s: York state um we are lucky to have a\n1223.2s: partnership with a um an organization\n1225.88s: called subject to climate um which makes\n1229.2s: climate change lessons cross discipline\n1231.6s: K12 completely open source and during\n1234.52s: climate week last year they unveiled\n1236.24s: their New York State Hub so I would say\n1238.919s: a lot of that work of thinking\n1240.6s: critically of uh rewriting and making\n1243.4s: this stuff open source is happening in\n1245.28s: partnership with New York City public\n1246.84s: schools and subject to climate so to\n1248.96s: answer your question yes and there's a\n1250.64s: lot of really interesting people working\n1252.159s: on it right\n1254.159s: now thank you so much"
    },
    {
        "class": "YouTubeVideo",
        "title": "Summer 2023 Research Experiences for Undergraduates (REU) Final Presentations - Intro. to ClimSim",
        "videoId": "eVaugP3dFVE",
        "url": "https://www.youtube.com/watch?v=eVaugP3dFVE",
        "publishedAt": "2023-08-02T18:17:53Z",
        "transcript": "6.12s: hi everyone welcome\n8.28s: um this summer there are six students\n10.139s: undergrad students carrying out research\n12.48s: under the guidance of the pi postdocs\n15.66s: and the doctoral students they are\n18.119s: Thomas Mark Amanda Rebecca Sammy and\n21.84s: zuba\n23.22s: um they most of them just finished their\n24.96s: second year of college study and they\n26.939s: come from a very diverse background\n28.68s: including geological engineering\n31.5s: computer science and interdisciplinary\n33.96s: studies today they are going to give us\n36.78s: a presentation to summarize what they\n39.54s: have been working on in the past five\n41.34s: weeks and to show us their current\n44.399s: results of their research questions\n46.14s: before they start we'll have some that\n49.219s: he is a postdoc at UC Urban and also a\n52.86s: league member to give us a short\n54.48s: introduction of the data set claimsing\n57.239s: that all the students use for their\n59.219s: research yeah welcome sandek and thank\n61.62s: you\n63.66s: hi everyone I will give you a very quick\n66.84s: um overview and background of this\n69.96s: Crimson data set let me share this\n72.36s: screen"
    },
    {
        "class": "YouTubeVideo",
        "title": "Machine Learning Rain to Improve Weather and Climate Prediction with Andrew Gettelman, NCAR",
        "videoId": "5r_ZrHA6L_s",
        "url": "https://www.youtube.com/watch?v=5r_ZrHA6L_s",
        "publishedAt": "2022-09-22T01:54:37Z",
        "transcript": "5.98s: [Music]\n8.28s: so from a climate perspective it's a\n10.26s: little more subtle\n11.58s: um clouds don't directly kill people\n13.44s: with respect to climate but there's this\n15.36s: image of the planet shows essentially\n16.859s: the two important things about clouds um\n19.859s: from a climate perspective clouds are\n22.32s: white\n23.58s: and clouds are cold\n25.859s: and the white part is they reflect\n27.84s: energy away from the earth so if you see\n30.119s: this Cloud deck it's white if you think\n31.98s: of that orange bit is being glint off\n34.86s: the darker ocean the darker ocean will\n37.5s: absorb more energy than the clouds and\n39.78s: you see how high those towers are from\n41.46s: space they're much colder than the\n42.96s: surface so they radiate the tops of\n45.3s: those clouds radiated a much colder\n46.8s: temperature and they radiate energy back\n48.84s: down they act as a blanket to keep\n51.059s: energy in in the Earth's system\n52.7s: radiating at a colder temperature\n56.1s: um the white part is the shortwave\n57.66s: radiation the\n59.699s: um\n60.36s: the cold part is the long wave or\n62.1s: infrared radiation\n63.899s: so what does this look like\n65.04s: quantitatively well\n67.2s: this shows the scale of the cloud\n68.52s: radiative effect so what you do is you\n70.26s: look at the the top of the atmosphere\n71.939s: fluxes and then you recalculate that\n74.1s: assuming the cloud wasn't there\n76.2s: and you can make calculations like this\n78.54s: and so at the top\n80.04s: that's the shortwave effect the white\n81.96s: clouds and it's a uniformly basically a\n85.14s: cooling effect\n86.24s: you'll notice it is zero over the\n89.04s: brightest surfaces so over the deserts\n91.02s: and over the ice sheets the underlying\n94.14s: surface is very bright without the\n96.06s: clouds so the cloud doesn't do much but\n97.979s: over the dark ocean those effect cooling\n99.72s: effects get fairly large\n101.46s: and then if you look at the long wave\n103.979s: those are the the coldest clouds the\n106.5s: largest long wave warming that heat\n108.18s: trapping is where the clouds are the\n109.56s: coldest in the tropics so those are the\n111.18s: high thin Cirrus in the tropics and\n114.119s: thick clouds in the storm track regions\n116.34s: and that's about 26 watts of cooling the\n119.34s: shortwave is about 40 watt or sorry 26\n122.1s: watts of warming 40 watts of cooling you\n124.5s: get a net effect of cooling the planet\n126.119s: by something like 20 watts per meter\n127.86s: Square\n128.819s: so if you doubled carbon dioxide you\n131.7s: would increase the radiative forcing of\n134.34s: the planet you'd warm it by four watts\n136.26s: per meter squared\n137.76s: and so small perturbations to This Cloud\n141.18s: number because of say changes to the\n142.98s: environment might have a big lever on\n146.7s: um that warming signal and this is what\n149.34s: we call a feedback\n151.8s: um\n152.76s: and the overall feedback that what's\n155.52s: important to understand about how much\n156.84s: energy we're going to get in the future\n158.28s: is understanding the sum of all these\n160.02s: feedbacks\n161.099s: the largest feedback is the Planck\n163.8s: feedback that's just Sigma t to the\n165.18s: fourth so if you warm up a surface it\n167.4s: radiates more energy away that's the\n168.959s: negative feedback on which against all\n170.76s: these things push against\n172.14s: water vapor is the largest greenhouse\n174.48s: gas and it's a very strong warming\n176.64s: effect\n178.14s: um if you warm up the planet you get\n180.72s: more water vapor in the atmosphere that\n182.64s: increases the heat trapping of water\n183.959s: vapor and that is a very that's a\n185.879s: positive feedback\n187.379s: the lapse rate feedback is slightly\n189.239s: negative because more water vapor raises\n191.519s: the emission height and that cools off\n194.04s: the emission that changes the emission\n196.2s: temperature\n197.099s: and so if you they act in opposition to\n199.319s: each other so the sum of those two\n200.4s: things is is\n201.9s: um they sort of offset and what I'm\n203.94s: showing is a series of different model\n205.62s: simulations cement 3 being older models\n208.14s: from 2006.\n210.06s: cement 5 being models from 2013. this\n212.519s: appeared in the previous ipcc report I\n214.68s: just haven't updated the figure\n216.9s: um and then you'll notice this Cloud\n218.819s: term these Cloud feedbacks this is how\n221.22s: the cloud rated effect responds to\n223.98s: warming the planet and it's all over the\n226.319s: place uh it's the largest uncertainty in\n228.959s: coming up with that total number which\n230.34s: is the total feedback\n231.9s: and then the Albedo feedback is small\n233.879s: and fairly positive that's uh the fact\n236.28s: that if you warm up the planet you tend\n237.9s: to melt the snow and ice and the surface\n240.18s: gets darker\n241.319s: but the cloud feedbacks are complicated\n243.12s: and these models they don't even all\n244.5s: agree on the overall sign of the\n245.94s: feedbacks and that makes it very\n247.379s: important to understand what's going on\n248.64s: for for climate\n250.86s: and so the way we calculate these\n252.54s: feedbacks in the future is using uh\n254.4s: numerical models and\n256.38s: um the way we calculate uh the future\n258.72s: weather in the next couple days is also\n260.88s: using numerical models and\n264.96s: um what is a climate model or a weather\n267.18s: model well it's essentially a giant set\n269.34s: of integrated spreadsheets where you can\n271.979s: think of at every point on the planet\n273.479s: you have a budget\n275.34s: and it's a budget of mass and energy\n277.44s: it's the amount of water and clouds it's\n279.54s: the amount of water in the atmosphere\n280.979s: it's the temperature\n283.08s: um it's where the properties of the land\n284.4s: surface and you link all these\n286.44s: spreadsheets together you undergo\n287.759s: transformation processes at each of\n289.62s: these points and then they all\n291.54s: communicate with each other and they\n292.8s: will get linked together and you iterate\n294.419s: just forward in time a sort of a giant\n296.82s: budget exercise and you do this in three\n298.86s: dimensions over every point on the\n300.24s: planet\n300.96s: and that hopefully representing all\n303.479s: these processes gives you a uh realistic\n306.66s: set of solutions and it actually\n309.06s: generally tends to work pretty well\n311.82s: so what is cloud microphysics and where\n313.86s: do the clouds fit in all this well this\n315.419s: is sort of a\n316.56s: a notional time-step Loop of going\n319.38s: through all these processes you start\n320.88s: with a Dynamics which is how the air\n322.32s: moves around\n323.52s: you then calculate exchanges with the\n325.74s: surface but then as a representation of\n328.62s: sort of non-local turbulence or vertical\n330.6s: motions deep convective thunderstorm\n332.82s: motions that move air up and down in the\n334.86s: atmosphere\n336.12s: there's then usually a shallow\n337.5s: turbulence that controls sort of the\n339.18s: shallow shallow clouds boundary layer\n341.58s: what's happening near the surface of the\n342.96s: Earth can be cloudy or it can just be\n345.36s: turbulent and not cloudy and then all\n347.94s: that information gets passed to a cloud\n349.44s: microphysics scheme\n351.12s: and the microphysics essentially and and\n353.52s: the names and orders on here correspond\n356.46s: to the community atmosphere model which\n358.38s: is what's in uh cesm the community or\n360.66s: System model\n362.52s: um that takes condens condensed water\n366.3s: and it speciates it it turns it into\n369.32s: uh rain it turns it into or it freezes\n373.08s: it it calculates the number it\n375.36s: calculates in certain cases the number\n377.58s: concentration or size of the different\n379.02s: particles and it takes information both\n381.66s: from the turbulent schemes and the\n384.84s: large-scale sort of condensation along\n387.24s: with an aerosol model that aerosol model\n389.88s: gives you the amount of particles in the\n391.44s: atmosphere if you have more particles\n392.759s: you tend to form more Cloud drops they\n394.44s: tend to be smaller that affects the\n396.24s: evolution of the system and all that\n398.22s: information gets passed to a\n399.84s: representation of the radiator transfer\n401.699s: so you calculate both the gaseous and\n404.1s: cloudy Sky radiative transfer how the\n406.44s: energy moves in the system that gives\n408.36s: you an updated state\n409.979s: and you now have new updates and and\n413.4s: tendencies on things like temperature\n414.84s: and all the different water and chemical\n416.46s: species then you pass that to the\n418.5s: Dynamics again and you use the\n420.3s: geophysical fluid dynamics equations to\n421.979s: iterate that forward in time\n423.66s: and then it starts again\n425.52s: repeat and of course the computer is\n427.259s: doing it much faster than I just\n428.819s: described it hopefully\n431.28s: um and it's doing it at every point on\n432.96s: the planet\n435.0s: so there's several different types of\n436.68s: microphysics schemes and these are used\n438.66s: in models at different scales\n441.66s: um let me guess\n443.22s: it's a laser pointer right there we go\n445.74s: ah here we go\n447.9s: um and they go sort of from from simple\n450.9s: simplified bulk schemes to bin schemes\n454.44s: to lagrangian or particle-based schemes\n456.68s: and typically as the schemes get more\n460.199s: complex the scale of the model that\n463.259s: we're working with goes down because we\n465.539s: can't they get more complex and we can't\n467.4s: afford to run them in larger and larger\n469.56s: computers\n471.12s: so for Global and mesoscale models so\n473.52s: Global models are run at Scales from say\n476.759s: 10 kilometers up to 100 kilometers for\n478.86s: the weather or climate mesoscope models\n481.02s: go down to a few kilometers usually over\n482.639s: one region of the planet we typically\n484.74s: use a bulk scheme and you either Define\n487.88s: say one moment which means you're just\n490.259s: prognosing a mass you say you have X\n493.259s: amount of water in the atmosphere and\n494.94s: you may give it a diagnostic size you\n496.979s: may say that those particles are\n498.96s: 10 microns in diameter about the width\n501.539s: of a human hair\n503.36s: or you can actually have a prognostic or\n506.22s: predicted uh second moment which would\n509.46s: give you a functional form where you can\n511.139s: actually predict the size distribution\n512.52s: which would be that sort of PDF that\n514.14s: I've shown there\n515.58s: a bin scheme\n517.68s: instead of representing the mass in of\n520.38s: the total amount of say cloud particles\n523.44s: you would represent the mass in each of\n525.779s: a discrete number of size categories and\n528.779s: you might have 30 different sizes that\n531.36s: would then make up an actual\n532.68s: distribution but each one of those\n534.36s: little bars on the histogram could go up\n536.64s: and down independently by interacting\n539.16s: with the other bars and with the rest of\n540.839s: the environment\n542.1s: that's called a bin scheme\n544.74s: and those are often used either in\n546.54s: mesoscale models or even in smaller\n548.519s: idealized parcel models or in large\n550.5s: Eddie simulations which are trying to\n552.3s: represent the actual turbulent motions\n554.16s: in the atmosphere fairly small scales\n556.74s: and then finally you have another class\n559.56s: which is lagrangian or particle-based\n561.48s: schemes where you're actually\n562.5s: representing individual particles\n565.44s: as sort of statistical representations\n567.959s: of a set of particles and there's\n571.62s: sometimes called super particles because\n572.94s: you calculate how they interact with\n574.38s: with the different other different size\n576.0s: particles that are present or Cloud\n577.98s: drops and then you statistically\n580.56s: multiply that by the number of drops in\n582.54s: each of those size categories so but\n585.24s: it's a little more detailed and it\n586.38s: actually follows those particles as they\n587.94s: move through the atmosphere so that's\n589.98s: the most computationally expensive\n592.2s: typically what we do is we use these\n594.899s: bulk schemes\n596.64s: um\n597.899s: and you have a series of processes this\n600.839s: is a really nice figure from Axel Cipher\n603.36s: um what we do is we represent different\n605.16s: classes of uh\n608.16s: of of clouds so there are Cloud droplets\n611.76s: and Cloud ice there is snow which is\n614.459s: sort of a fast falling ice and raindrops\n616.86s: which is the fast falling liquid and\n619.019s: then some schemes intermediate to that\n620.7s: there's a intermediate mixed phase\n622.92s: that's either called commonly grapple or\n625.5s: hail and it's basically ice that has\n628.62s: rhymed liquid onto it that's frozen or\n631.08s: slushy and has different properties\n633.66s: um\n634.56s: all these things and then there's water\n636.36s: vapor at the top and these all have\n637.98s: Transformations between them\n640.32s: um key processes are these mixed phase\n642.12s: processes that exchange between the\n645.3s: liquid and ice or the freezing process\n647.279s: for cloud ice conversion processes where\n650.279s: the vapor deposits on from one class to\n652.38s: another and then aggregation processes\n654.899s: where\n656.459s: um particles will grow and change size\n658.32s: so they may fall faster when you get\n660.3s: things like brain formation and then ice\n662.76s: is in particular is\n665.339s: liquid Cloud drops or spheres and we\n667.62s: know their density because it's liquid\n668.88s: water so that makes them easier to deal\n671.519s: with than ice particles which number one\n673.5s: are sort of metastable\n675.66s: I uh you can have ice or liquid at some\n677.88s: freezing temperatures in the atmosphere\n679.32s: so you actually have to freeze it and\n681.06s: when it freezes it's not easy to\n682.8s: calculate and depends on the other\n684.92s: aerosol particles in the atmosphere and\n687.72s: the density and fall speeds can vary\n689.22s: strongly by the shape and how the\n690.48s: particles grow\n691.74s: so there's a lot of complexity in Cloud\n694.38s: microphysics that govern\n696.42s: the importance of these Cloud rate of\n698.279s: properties and the importance of things\n699.54s: like formation of grapple and hail\n702.24s: um which can grow to extreme sizes in\n704.279s: the right conditions and become damaging\n707.16s: so rain formation is really a often\n710.339s: called a collision coalescence process\n711.66s: so you start with a population of small\n713.82s: drops\n715.019s: they're moving around but they tend to\n716.64s: be falling a little bit because they\n718.62s: undergo gravitational settling and the\n720.6s: bigger they are the faster they fall and\n722.88s: they'll actually hit other drops and\n724.14s: we'll start collecting them and so the\n725.76s: larger ones get larger and at some point\n728.7s: they start falling fast enough that\n731.16s: they're really it runs away and they go\n733.079s: into raindrops so the radius gets bigger\n735.18s: as they sort of self-collect each other\n737.339s: and then we sometimes call this a auto\n739.92s: conversion as they start falling faster\n741.72s: and then they accrete smaller drops\n744.24s: these blue ones or they self-collect\n746.7s: each other on the rain side and that\n749.16s: line that dashed line where we decide\n751.2s: what's cloud and rain is somewhat\n752.88s: arbitrary\n753.959s: and we usually do that in the bulk\n755.7s: distributions where we have to actually\n756.899s: have two classes of those\n759.36s: so approximating the rain formation\n761.82s: process in the bulk scheme looks\n763.32s: something like this so we have\n765.0s: Cloud droplets going into raindrops and\n767.1s: I'm going to spend most of this time\n768.3s: most of my time talking about liquid\n770.76s: um ice is\n772.139s: fascinating and I know several of us the\n774.66s: table spent a lot of time worrying about\n775.86s: it but we're going to start with just\n777.48s: trying to do the liquid problem today\n780.54s: um\n781.5s: so we approximate sort of this Auto\n784.5s: conversion and accretion process and\n789.06s: that's one of the things we do so we\n790.8s: have this evaporation condensation of\n792.54s: crowd drops to start with that we get\n795.24s: the cloud droplets to begin with and\n797.279s: that's usually we just look at the\n798.72s: amount of water vapor and the\n799.92s: temperature and if it's super saturated\n801.36s: we form Some Cloud drops\n804.06s: um Auto conversion is approximating this\n806.459s: stochastic collection process and it's a\n809.22s: little bit artificial because we're\n810.48s: moving things from cloud drops to\n811.92s: raindrops when it really is a continuous\n813.42s: distribution and I'll show this tends to\n815.639s: be a little bit uncertain\n817.62s: um evaporation of raindrops is also\n819.48s: important in a lot of these systems and\n821.639s: evaporation of raindrops causes changes\n823.86s: in energy it actually you put energy\n826.079s: into evaporating uh evaporating water\n829.139s: and so it actually cools the atmosphere\n830.88s: this is very important for driving the\n833.399s: organization of deep Vector emotions\n836.519s: um and it can be difficult because the\n837.899s: evaporation would be size dependent\n840.24s: and then there's a lot of things in this\n842.519s: picture that are still unknown which I'm\n844.44s: not going to get into\n846.24s: um\n847.019s: quite today but it can actually affect\n849.3s: some of these things\n851.1s: so traditionally\n853.56s: we learned this Auto conversion and\n855.54s: accretion process and that's a\n857.459s: deliberate choice of term\n859.32s: um with a very simple model in this case\n862.74s: it's a regression\n865.019s: to a more detailed model so you take the\n867.6s: explicit Auto conversion rate which is\n869.279s: calculated in this case from large Eddie\n872.04s: simulations using an explicit bin model\n874.139s: with all those calculations\n875.82s: and you then come up with a fit for how\n879.48s: the cloud drops of some size changing\n882.12s: the raindrops and then another fit for\n884.699s: how the raindrops accrete the cloud\n888.18s: drops and you'll notice that on the top\n891.24s: equation here\n893.22s: Auto conversion\n895.139s: is a positive factor of the mass of\n898.68s: cloud drops so the more Cloud drops you\n900.66s: have oh sorry not the more the more mass\n904.32s: you have the higher the auto conversion\n906.3s: it is inversely proportional to the\n909.06s: number concentration so the more drops\n910.86s: you have the smaller they are and they\n913.199s: don't tend to fall as fast they don't\n914.639s: tend to turn into rain as quickly so if\n916.079s: you think about having a few big drops\n918.0s: they tend to fall out faster if you have\n920.04s: a lot of small drops they don't really\n921.36s: turn into rain very easily\n923.22s: and then accretion is simply a\n925.079s: mass-based thing\n926.519s: um it's based on the mass of rain and\n928.38s: the massive condensate\n930.12s: so this is an emulator it's an empirical\n932.82s: fit to another model that we call truth\n935.76s: um there's quite a bit of scatter here\n937.8s: and you'll notice how that functional\n939.42s: form gets extrapolated\n943.139s: there we go\n945.42s: that's the 420 to Albany or something\n950.22s: um so what we decided to do is let's see\n952.62s: if we can use new techniques to actually\n954.48s: cut out the middleman here so we're\n957.0s: going to try to build a machine learning\n958.38s: emulator for the stochastic collection\n960.06s: process to do this more correctly or\n963.779s: um at least to try to to cut to\n966.66s: basically see if we can do this in a in\n968.88s: a more varied and and detailed way\n971.82s: so again the bulk scheme on the right we\n974.399s: just have that black line basically\n976.44s: the bin scheme allows us to represent\n978.54s: all these different populations of the\n980.88s: number of drops in each of these\n982.26s: different size categories\n984.18s: so one of the reasons we don't do this\n987.0s: is because if we have 32 variables which\n989.519s: is typically what we'd use in the bin\n990.839s: scheme it's much more expensive than\n992.76s: four\n993.66s: four is what we do in the bulk scheme we\n995.639s: have mass and number for both liquid and\n997.5s: rain\n999.0s: um\n1000.079s: so what we're going to do is actually\n1001.399s: break up the bulk distribution so take\n1003.5s: that functional form as the black line\n1004.94s: and just simply turn it into a bunch of\n1006.86s: bins and we can do that for the liquid\n1009.139s: and for the rain\n1011.72s: um\n1012.259s: and then we can actually insert the sort\n1014.779s: of detailed process for the stochastic\n1017.66s: collection and have all these bins\n1019.82s: interact\n1020.839s: and then we're going to recompose our\n1022.16s: distribution after we've done that\n1024.38s: and that's actually great we've done\n1027.799s: this using the stochastic collection\n1029.36s: kernel from the Tel Aviv University or\n1031.579s: Tau in microphysics scheme\n1034.28s: and we're replacing the existing\n1036.38s: treatment in cesm or Cam 6 which is a\n1041.0s: the atmospheric General circulation\n1042.98s: model that's in cesm\n1045.319s: and when we do that we get some\n1047.299s: interesting results that'll show but it\n1049.16s: actually slows down the entire model by\n1051.08s: a factor of five\n1053.0s: so it becomes a little bit unusable for\n1054.62s: climate simulations\n1056.179s: so we're then going to build a neural\n1057.679s: network emulator of this as truth and\n1060.32s: see if we can put it back into Cam and\n1062.24s: recover all the higher order moments and\n1064.22s: statistics we want but also see if we\n1066.26s: can recover the speed\n1068.12s: and the punch line is we actually think\n1069.799s: we're able to do this and we think we\n1071.24s: get some really interesting results that\n1072.559s: would justifier\n1074.179s: so what this is and so what we're\n1076.94s: actually doing is what we're predicting\n1078.679s: is we are running the process rates or\n1082.039s: sorry we are running the process and we\n1083.9s: are coming up we start with an initial\n1085.46s: distribution\n1086.6s: and we end up with a final distribution\n1089.179s: we take the final distribution of bins\n1091.4s: and we recompose that back into these\n1094.4s: black distributions these bulk horns\n1098.78s: um and then we look at the difference\n1100.039s: between the initial bulk form and the\n1102.14s: final bulk form and we call that the\n1104.0s: tendency over that time step\n1105.919s: and then the tendency is what we apply\n1107.78s: to the model and the tendency is what we\n1110.24s: actually use the machine learning model\n1112.22s: to emulate so\n1114.679s: we put this in and the training data is\n1117.14s: actually calculating it instantaneously\n1118.88s: in the climate model and what we're\n1121.46s: trying to do then is we have the inputs\n1123.14s: of the atmospheric State and the initial\n1125.96s: size distributions of the rain and the\n1128.299s: liquid and the output is the Tendencies\n1131.419s: on that at each of these points\n1135.2s: and when we do this so let's just focus\n1137.419s: on not the emulator but just putting the\n1138.98s: bin code in there\n1140.96s: um the Emu or sorry the bin code is the\n1143.539s: purple line which is very close to the\n1145.76s: blue line on the top and the orange line\n1149.36s: is the bulk scheme and what we're\n1151.82s: showing is the log of a series of\n1154.58s: process rates which is this is the rain\n1158.12s: tendency uh qrdt this is the number the\n1162.559s: rain Mass this is the number\n1163.82s: concentration for\n1166.52s: um\n1167.12s: liquid this is the number concentration\n1169.52s: for rain when it is less than zero and\n1172.58s: this is the number concentration for\n1173.84s: rain when it is greater than zero the\n1177.62s: um condensate mass is simply the\n1179.84s: negative of the rain Mass because the\n1182.72s: condensate becomes rain so one's minus\n1185.24s: one's Plus\n1186.559s: and so we're actually going down to some\n1188.12s: pretty small numbers these are in units\n1189.919s: of mixing ratio or number concentration\n1193.66s: per second and we're looking at typical\n1197.36s: time steps on the order of\n1200.36s: um a thousand seconds so 10 to the third\n1202.64s: second so these are still these are\n1204.98s: moderate numbers but you can see they're\n1206.419s: actually very different distributions\n1208.12s: between the stochastic collection model\n1210.86s: which is the bin code in these lines and\n1214.22s: you can see we get sharp peaks in\n1218.299s: um the control code when we look at\n1220.1s: these uh Tendencies so there's some big\n1222.559s: differences here but they're actually\n1224.72s: you can see the punch line\n1226.94s: the blue line that you can barely see is\n1229.46s: the distribution from the emulator it\n1231.44s: actually reproduces quite well the\n1234.86s: um training data which is what the\n1236.36s: purple one is\n1238.64s: and so this is actually looking at in a\n1240.38s: slightly different this is actually just\n1242.0s: looking at a scatter plot of what these\n1244.7s: Tendencies look like and just to note\n1247.16s: you know once we start getting down in\n1249.38s: this region here where there's all the\n1251.179s: scatter these are really not significant\n1253.76s: amounts of liquid water\n1255.86s: um they're we're talking about\n1256.7s: Tendencies of on the these are on the\n1258.5s: order of a part below 10 of the ninth is\n1261.919s: like a part per million per time step\n1264.26s: it's a very small amount for most of the\n1266.24s: atmosphere so we actually\n1268.94s: you get some differences between the bin\n1271.039s: and the bulk scheme but they do tend for\n1272.84s: the significant parts of the\n1274.16s: distribution up here they tend to line\n1276.44s: up somewhat um rain number is kind of\n1278.9s: all over the place which is interesting\n1282.02s: um but\n1283.58s: basically what this says is that in the\n1286.52s: control case we get more frequent small\n1289.84s: QR and changes in number concentration\n1293.299s: and it's compensated by less frequent\n1295.28s: higher values and these numbered number\n1298.64s: concentration Tendencies for rain are\n1300.32s: larger in the um existing microphysics\n1303.98s: code here than they are in the Tau bin\n1307.039s: code so there's some fundamental and\n1309.559s: systematic differences between the\n1311.0s: detailed treatment and the existing\n1312.2s: treatment\n1313.94s: so now how do we emulate this well it's\n1316.22s: kind of interesting we um\n1318.44s: run it for two years we obtain\n1320.48s: instantaneous hourly output we sample it\n1322.76s: we don't get every hour we sample it\n1324.62s: over the over the annual cycle and we\n1326.539s: did take it over the whole planet\n1328.4s: and the diurnal cycle also we filter and\n1331.52s: sub-sample the data to find the grid\n1333.2s: points with realistic amounts of cloud\n1335.059s: water so we sort out a lot of those\n1336.74s: small points\n1338.6s: um there's a bunch of transfer\n1340.34s: transformation and normalization of the\n1342.02s: inputs and outputs so we sort out points\n1344.659s: that are where the Tendencies are zero\n1346.52s: and we also normalize and put them in\n1348.919s: log space\n1350.299s: and then\n1351.86s: um their classifier networks to classify\n1354.14s: the zero and non-zero and then deep\n1356.12s: neural networks to predict the non-zero\n1358.52s: values and then most of what I'm going\n1361.039s: to talk about is evaluating interpreting\n1362.659s: these neural network predictions this is\n1364.58s: done actually with a series of different\n1365.9s: emulators in the original version\n1368.419s: um the David John is working now with us\n1372.14s: on\n1373.4s: seeing if we can't streamline this into\n1375.38s: sort of one\n1376.82s: network using some different methods\n1380.299s: and I should say we are embedding\n1383.419s: basically we train it offline\n1385.94s: and then we get a series of weights for\n1388.46s: the network and I'm not going to talk in\n1390.02s: too much detail about the network design\n1391.52s: but there's more detail in the paper we\n1393.38s: can talk more about that but then\n1396.38s: that's basically applied as a series of\n1398.48s: weights to calculate the results in line\n1401.6s: in the climate model uh directly\n1404.059s: interfacing with the Fortran code\n1407.0s: so this is the same plot as before\n1409.4s: except instead of showing the bin code\n1412.159s: versus the control this is the bin\n1414.919s: versus the emulator and now things are\n1417.38s: looking much better it's basically on\n1418.7s: the one-to-one line for the high density\n1421.22s: of points all the way down and you can\n1422.659s: see the r squared values on these things\n1424.159s: are approaching one for the accuracy in\n1427.7s: almost all cases so then the emulator\n1430.1s: actually seems to work to reproduce the\n1432.08s: process that we want when we train it\n1434.9s: um I showed this before the blue line\n1436.76s: and the purple line are very similar uh\n1439.159s: the density is similar and it looks much\n1441.799s: more similar obviously than the control\n1443.24s: which is what we would hope\n1446.419s: um\n1447.26s: what's interesting of course is that\n1449.659s: when we run this we then apply these\n1452.179s: Tendencies and occasionally we get\n1454.159s: answers that don't really work in the\n1456.08s: model\n1457.24s: the climate model microphysics is what\n1460.039s: we call time split which means you take\n1462.02s: one time and all the different processes\n1464.24s: that you saw on that spaghetti diagram\n1466.34s: for cloud microphysics\n1468.32s: are calculated based on the same state\n1471.679s: and when they're combined they don't\n1473.179s: always add up so we have a series of\n1474.799s: constraints and fixtures on things\n1477.5s: and we do actually put a an individual\n1479.78s: constraint and a mass fixer on\n1482.9s: the emulator Tendencies to make sure\n1484.7s: that when we come up with the final\n1485.96s: result we're not creating or destroying\n1488.059s: water\n1488.84s: if we're converting from liquid to rain\n1491.6s: from cloud drops to raindrops we want to\n1493.76s: make sure we have the same mass of water\n1495.5s: that we end up with is when we started\n1497.9s: and occasionally this doesn't work and\n1500.12s: actually it doesn't work quite a lot of\n1502.46s: the time you'll see almost 30 percent of\n1504.14s: the time we have to make some\n1505.159s: adjustments\n1506.299s: and it's typically happening low in the\n1508.58s: atmosphere and it's typically happening\n1510.919s: in the subtropics and for those of you\n1513.2s: familiar with patterns of clouds and\n1516.44s: what the general circulation of the\n1517.7s: atmosphere looks like these are sort of\n1520.159s: the dry regions on the planet there's\n1521.9s: not many clouds there and there's not\n1523.28s: much water there so the emulator\n1525.64s: Tendencies are being corrected we've\n1528.14s: discovered really when we're in parts of\n1530.24s: the distribution that probably don't\n1531.32s: matter very much\n1532.58s: now we're still trying to verify that\n1534.44s: and we're trying to get this number down\n1535.7s: as small as we can because we don't want\n1538.039s: this to be affecting the answer and this\n1539.6s: is on the edge of some areas where there\n1542.12s: is significant cloudiness and so we want\n1543.74s: to make sure we're not actually\n1545.12s: affecting the answer when we do this so\n1547.64s: that's one of the things we have to\n1548.48s: watch out for\n1550.1s: um\n1551.72s: as I'll say in the conclusions I don't\n1553.46s: really believe this is too much of a\n1554.96s: problem we do this all the time\n1556.64s: partially it's because we have this time\n1558.44s: split way of doing the numerics\n1561.02s: and\n1562.58s: the processes are all uncertain their\n1564.32s: interactions are uncertain this\n1565.94s: constrains them by the ultimate thing\n1567.44s: that we know which is basically the laws\n1569.179s: of thermodynamics\n1571.76s: and if you look at the mean state so\n1573.5s: this is now looking at Global results\n1574.94s: from these different simulations uh\n1576.98s: these are free running climate model\n1578.36s: simulations they're about five years\n1579.86s: each we've run it with the control case\n1582.08s: we run it with the bin microphysics and\n1585.26s: we run it then with the emulated bin\n1587.36s: microphysics in green and you can see\n1590.36s: there's quite a bit of spread in the the\n1592.46s: temperatures over the uh the global\n1595.64s: temperatures over time and there's quite\n1597.5s: a bit of spread in the cloud fraction\n1600.32s: um this is the rain mass and the liquid\n1603.32s: mass and you can see\n1605.24s: they generally within the there's not a\n1607.52s: huge change it doesn't it radically\n1609.26s: alter the climate uh there is some\n1611.299s: systematic change and the blue line here\n1614.059s: and the liquid there is a reduction in\n1616.22s: overall Cloud liquid with the new either\n1618.5s: the emulator or either the bin code or\n1622.039s: its emulator but those tend to be pretty\n1623.84s: similar\n1625.279s: this is perhaps one of the most\n1626.84s: interesting things do we really need to\n1628.46s: do this if it doesn't change the climate\n1629.96s: well I got all this trouble\n1631.58s: let me see if I can explain uh this plot\n1633.799s: a little bit\n1634.88s: so what this shows is it shows the rain\n1638.48s: rate which is the colors as a function\n1641.659s: of the size of the cloud drops the\n1643.76s: effect of radius so bigger is over here\n1646.22s: and the amount of liquid water in the\n1648.02s: atmosphere\n1649.279s: and what you can see is that these\n1652.159s: colors you can see the scale here for\n1653.659s: the rain rate this is in millimeters per\n1656.12s: day\n1656.9s: so when you have very large drops and\n1659.9s: you tend to get\n1661.64s: more uh you know very large Cloud drops\n1664.58s: you tend to get more of them falling out\n1666.02s: as I said which means you don't have as\n1667.4s: much liquid water and it also means you\n1669.679s: have higher rain rates these are the\n1670.82s: high rain rates but what you'll notice\n1672.98s: is that you can have high rain rates\n1675.5s: almost along this line in the control\n1677.299s: code where even for very small particle\n1681.26s: sizes you get at high liquid water path\n1684.5s: you do get significant Auto conversion\n1686.419s: and accretion that's that extrapolation\n1688.88s: of that log scale that I showed on the\n1691.159s: plot\n1692.179s: um\n1692.799s: originally from the original curtain\n1695.299s: often kogan so this is actually not\n1698.419s: observed when you tend to have small\n1699.559s: Cloud drops you really don't seem to\n1700.82s: have there really isn't observed to be\n1702.559s: rain\n1703.52s: and\n1704.84s: there's typically a threshold that\n1706.7s: people talk about it's something like 15\n1708.02s: microns in fact\n1710.12s: it's so noticeable from observations\n1712.1s: that some people on these bulk schemes\n1713.9s: impose a threshold where they don't\n1715.76s: allow Auto conversion accretion to occur\n1717.799s: until you get 15 Micron drops\n1720.799s: when we put in the bin code\n1723.5s: that whole distribution changes\n1725.659s: there are now no more significant rain\n1727.52s: rates for any liquid water path with all\n1730.039s: these small effective radio effective\n1732.02s: radius you you see this onset of\n1734.779s: precipitation occurring much more at\n1736.94s: this 15 Micron level which is not\n1739.1s: something we're specifying it's an\n1740.6s: emergent property of doing this in the\n1742.039s: climate model\n1743.24s: which is actually really neat because\n1745.279s: this is a pathology of the climate\n1747.2s: models that leads to them raining\n1748.64s: probably too often\n1750.98s: and you can see that this higher order\n1753.159s: uh the sort of higher order metric is\n1756.919s: reproduced almost exactly with the with\n1759.08s: the machine learning algorithm that we\n1760.76s: can actually get that and recover that\n1763.399s: um and again I should note the one in\n1765.799s: the middle costs five times as much as\n1767.419s: the other two to run\n1769.34s: but we get the same result on the right\n1770.96s: with the machine learning algorithm at\n1772.94s: essentially the cost of the control\n1774.2s: model\n1775.22s: so this is actually really interesting\n1777.02s: to us and we think it produces some\n1779.179s: really nice results that it it's\n1780.74s: producing something we really think we\n1782.779s: should be doing for the rain process\n1785.84s: but we we're not doing in the bulk\n1788.12s: scheme\n1789.14s: this just shows the precipitation\n1790.82s: intensity so\n1793.159s: um the control model is here it doesn't\n1795.32s: produce that much intense rain\n1797.419s: uh we're getting more intense\n1800.059s: precipitation\n1801.86s: um when we actually put in this emulator\n1804.08s: which is also probably a good thing uh\n1806.899s: these are high high amounts but they\n1809.059s: happen very infrequently and this just\n1811.22s: shows one of the issues with putting in\n1813.14s: the mass fixer is it does constrain the\n1816.14s: liquid water so we don't run out of\n1817.82s: water that actually reduces the rain\n1819.679s: rate you can't have you don't want to\n1821.539s: this reduces the rain rate to something\n1823.7s: that's um more uh a little more\n1826.7s: reasonable uh particularly at the high\n1828.799s: end basically and you can see the\n1830.539s: emulator does a good job of reproducing\n1832.159s: these statistics two the differences out\n1835.039s: here you can see these error bars they\n1837.02s: start to be very low frequency and so\n1839.179s: it's hard to tell what's actually\n1840.679s: different out there\n1842.899s: this is one of the other interesting\n1844.279s: results so\n1845.659s: um one of the problems with climate\n1847.76s: models and you can see and and actually\n1851.72s: an argument it wasn't really an argument\n1853.88s: it was a discussion over whether this\n1855.919s: data is real or not uh this morning\n1860.12s: um not with anybody in this room but you\n1862.64s: can see that overall satellites would\n1865.1s: indicate that it rains about 20 of the\n1867.14s: time\n1868.22s: and the control climate model would\n1870.08s: indicate it rains about 80 percent of\n1872.059s: the time\n1873.08s: and that's a big difference\n1875.899s: um this is the total frequency and this\n1878.12s: is the frequency just from the large\n1879.559s: scale precipitation that's governed by\n1881.12s: the cloud microphysics this includes say\n1883.1s: convective clouds that are handled by a\n1884.779s: slightly different scheme\n1886.52s: so when we introduce the uh\n1890.059s: the new bin code whether we emulate it\n1892.46s: or not all of a sudden we get a\n1894.5s: significant reduction in the subtropical\n1897.38s: regions and the shallow clouds in their\n1899.36s: precipitation\n1900.44s: which is pretty dramatic and does a much\n1902.659s: better job of reproducing the\n1904.399s: observations and that again goes back to\n1907.539s: this sort of thing where\n1910.039s: we don't get the onset of precipitation\n1912.26s: until we hit a threshold of drop sizes\n1915.44s: which is related basically to this\n1918.38s: um so that's another good thing actually\n1919.7s: it gets rid of the sort of fact that we\n1921.679s: tend to be drizzling way too much in a\n1923.84s: lot of these regimes uh in the climate\n1925.76s: model it does not help where you have\n1928.1s: ice precipitation to higher latitudes\n1929.899s: because we're only messing with the warm\n1931.64s: rain process\n1934.46s: um and this is just some plots that show\n1937.159s: uh we are getting some differences in\n1939.86s: the liquid water path but not much in\n1942.44s: the ice not much in the cloud fraction\n1944.679s: and a little bit of difference in Cloud\n1946.76s: drop numbers these are sort of overall\n1948.08s: climate statistics uh some differences\n1951.32s: pretty substantial\n1953.679s: in um\n1956.24s: the cloud Optical depth but not moderate\n1959.659s: changes in the overall Cloud radiative\n1961.279s: effects the the shortwave in the long\n1963.2s: wave here so it does reproduce a\n1965.12s: reasonable climate\n1966.74s: and this is one of the other last\n1968.12s: interesting results\n1969.679s: um the Blue Line This is looking at the\n1972.799s: cloud feedback so it's the cloud\n1974.48s: response to warming up the planet sort\n1977.48s: of an idealized calculation this is in\n1979.88s: the long wave so this is changing it's\n1982.64s: generally positive this is the shortwave\n1984.86s: it's also positive but it gets a little\n1986.179s: negative at higher latitudes\n1988.159s: and what's interesting is that there's a\n1990.44s: pretty big difference between the new\n1992.539s: emulator code\n1993.98s: and the existing code it middle\n1997.159s: attitudes of the Southern Hemisphere\n1999.039s: that seems to be related to a higher ice\n2001.72s: fraction\n2002.919s: because we're doing\n2004.96s: um\n2005.559s: because we are changing the rain\n2007.059s: formation process it does impact super\n2009.399s: cool liquid and that's where you see\n2011.62s: this at higher latitudes we have a\n2013.72s: larger ice fraction we think that\n2015.22s: actually tends to lower this Cloud\n2016.84s: feedback uh pretty substantially\n2021.519s: so in summary we've been able to take\n2023.86s: this new detailed bin model rain\n2025.539s: formation and it improves many aspects\n2027.64s: of the climate simulations and\n2028.899s: particularly the rain onset the\n2030.76s: frequency it may improve the liquid ice\n2032.74s: balance and it may adjust the climate\n2034.12s: sensitivity\n2035.86s: um we can use instead of neural networks\n2038.08s: to emulate this we recover the speed\n2040.179s: that we don't slow the model down we can\n2042.82s: reproduce all the statistics we've\n2044.32s: looked at in a in a sort of climate\n2046.6s: sense\n2047.559s: and this is sort of a hand-built set of\n2051.159s: emulators with separate networks or\n2052.96s: positive and negative tendencies in some\n2054.76s: respects we have to separate out zeros\n2057.22s: we have to do all these log transforms\n2058.72s: the numerics are not perfect and we\n2060.7s: sometimes need uh Mass spectrums to put\n2062.859s: on this\n2064.24s: so Lessons Learned um these processes\n2067.419s: really challenge the machine learning\n2068.74s: methods there's many orders of magnitude\n2070.78s: that's what we usually use log\n2071.919s: transforms to get things a little more\n2073.419s: regular\n2074.8s: sorting out the zeros and treating\n2076.419s: positive negative Tendencies separately\n2078.04s: is also important\n2079.96s: and it's not clear if we actually would\n2081.76s: expect to get absolute conservation most\n2084.04s: of the problems we're seeing where we\n2086.44s: put these guard rails on it\n2088.3s: um we're trying to make sure they don't\n2089.98s: dominate the answer\n2091.54s: and they only kick in for large edge\n2093.46s: cases so I guess the other thing I'll\n2095.679s: note is that in doing these feedback\n2097.54s: calculations\n2100.359s: um we've actually run the model with\n2101.92s: increased SS increased warmer\n2103.839s: temperatures and we run it with\n2105.22s: temperatures that the model was never\n2106.96s: trained on\n2108.76s: and it's still stable so one of the\n2111.82s: advantages of emulation at the process\n2113.32s: level is we think by sampling the whole\n2115.359s: planet over all the seasons that we're\n2118.54s: not really going at a sample because\n2120.04s: this is an isolated process and as long\n2122.619s: as we are seeing some of these\n2125.98s: representation somewhere on the planet\n2127.96s: we can actually emulate it um so we\n2130.06s: haven't had too much trouble with\n2132.22s: stability when we run it either with\n2134.98s: increase sea surface temperatures or\n2136.9s: even running it with say aerosol with\n2138.46s: running it with 1850 conditions in the\n2140.44s: past\n2141.22s: we've been able to actually go out of\n2143.02s: sample for some of the climates on this\n2144.7s: which is kind of important\n2146.8s: and the next steps\n2148.48s: um we're working with David John to\n2150.22s: simplify these networks\n2152.14s: um we're building this in as an option\n2154.72s: for the standard cesm code we're sort of\n2157.9s: regularizing the interfaces and as an\n2160.42s: example of how to do these neural\n2161.68s: networks and put them in Fortran codes\n2163.24s: to do process emulation as a series of\n2165.28s: weights\n2167.079s: um and trying to generalize the\n2168.7s: interface a little bit so people can\n2170.02s: apply it different places\n2171.7s: and then we're developing sort of more\n2173.74s: tutorial based packages a toy training\n2176.2s: data and full training data for people\n2178.66s: to explore the emulators on their own\n2180.28s: and then a sort of workflow for doing\n2183.82s: the machine learning training and doing\n2186.66s: uh messing with the output from the\n2189.52s: model we have a single column version of\n2191.56s: the model and you can actually run that\n2194.02s: on a laptop we have a whole Docker\n2197.02s: container that you can download that\n2199.24s: will allow you to run an entire Earth\n2201.46s: System model in one column on your on a\n2203.619s: reasonable laptop\n2205.18s: and we're also trying to to basically\n2207.16s: get eventually the training data kind of\n2209.68s: in the leap pangeo cloud and then have a\n2213.22s: good workflow for python that would\n2215.68s: allow people to read in the data and do\n2217.42s: machine learning training then export it\n2219.76s: and be able to test it in these single\n2221.92s: column models or or hand it off and be\n2224.5s: able to run it in the Fuller System\n2225.64s: model"
    },
    {
        "class": "YouTubeVideo",
        "title": "Data Enhanced Two Stream Methods for Computing Atmospheric Flux Transfer",
        "videoId": "IMY-79qVUXA",
        "url": "https://www.youtube.com/watch?v=IMY-79qVUXA",
        "publishedAt": "2025-03-03T20:21:55Z",
        "transcript": "3.879s: hi everybody um we're going to get\n7.48s: started uh so first up today we have\n10.519s: Dion ho Dion is a PhD candidate in the\n14.28s: department of Applied Mathematics and\n16.039s: applied physics advised by Lamont\n18.52s: research Professor Robert pinkis he is\n21.0s: interested in pdes numerics and their\n23.16s: applications to atmospheric radiation he\n26.56s: graduated from Yale nus College us\n30.359s: stands for National University of\n32.079s: Singapore with a Bachelor of Science and\n34.64s: a major in mathematic mathematical\n37.16s: computational and statistical Sciences\n39.76s: in his undergraduate years he worked\n41.6s: with the United transform lab to further\n44.44s: Dev develop the United transform Focus\n46.92s: method for solving high order pdes and\n50.32s: separately also researched on the\n51.76s: nonlinear share\n53.879s: equation thanks\n56.359s: Dion thanks Kate hello it's good to be\n60.399s: here and to present my research once\n62.64s: again I think many of you have seen my\n64.32s: past\n65.799s: presentations um so yeah let's get\n68.04s: started\n73.72s: oh okay so yeah today I'll be talking\n77.28s: about my work for the past over two\n80.799s: years now actually um on data enhance to\n84.84s: stream\n86.439s: methods and so just as a brief\n89.24s: introduction\n90.72s: what we are interested in calculating is\n93.32s: the reflectance and\n95.64s: transmittance of sunlight in particular\n98.6s: though I'll say that my research is\n100.92s: applicable to more than just sunlight\n102.64s: and radiative transfer in general is of\n104.32s: course about long wave as well as the\n105.719s: short wave but today we'll be focused on\n108.28s: shortwave radiation the sunlight so the\n111.56s: what we are really trying to calculate\n113.04s: is this\n114.24s: reflectance uh which is just the amount\n116.68s: of incoming sunlight that is reflected\n118.6s: back out into space and the\n120.28s: transmittance so the percentage ratio of\n123.64s: sunlight that is transmitted through the\n125.719s: atmosphere through clouds uh to the\n128.2s: Earth\n129.92s: surface so this is generally done using\n132.959s: this two stream in other words two\n135.04s: directional model so you have one\n137.68s: equation for the upward flux one\n139.64s: equation for the downward flux and just\n142.879s: evaluating the fluxes at the boundaries\n144.879s: will give you your reflectance and\n147.519s: transmittance so this is the most\n149.92s: simonia scattering model for computing\n152.319s: radiative\n153.8s: fluxes and by so I emphasize here on the\n158.239s: word scattering and the fact that this\n160.64s: is a shortwave model because generally\n162.64s: if you're modeling longwave radiation\n165.159s: scattering is considered to be\n167.44s: negligable um well let's debate on that\n170.28s: but yeah so usually you omit the\n172.44s: multiple scattering Parts if you are\n175.04s: focusing on the long\n177.92s: wave so an alternative to the two string\n180.879s: model just to give you a sense of what\n182.959s: is happening is a high angular\n186.0s: resolution model and the point here is\n188.799s: that you can see my diagram over here\n192.08s: you will basically try and resolve the\n194.36s: radiative transfer in more than just the\n196.92s: upward and downward Direction you try\n198.84s: and resolve it in like multiple angles\n202.36s: um so you have like polar exal angle and\n204.56s: you try and resolve it in multiple\n207.4s: directions so for climate models this\n210.76s: High angular resolution model is too\n213.64s: computationally expensive hence you use\n215.879s: the twoam right and that's where is\n218.56s: Pimon is\n220.519s: important however this model over here\n223.28s: provides our ground truth so when we\n225.56s: want to compare the results of tuing\n228.0s: model we are basically comparing to this\n230.36s: High angular resolution model the one\n233.599s: thing I would add that in a way even\n236.28s: this model is not so-call like the\n239.239s: perfect radiated transfer model because\n241.959s: it is still a plain parallel 1D you know\n244.76s: column atmosphere model if you really\n247.439s: want to be more sophisticated you use\n249.959s: like 3D Monte Carlo calculations and\n253.159s: whatnot but in any case uh we stick to\n256.6s: the 1D framework so that's the upshot\n259.639s: here so one thing I really want to\n262.24s: emphasize on and this will become quite\n264.199s: important later is that when we do\n267.08s: radiative transfer in a climate model\n269.36s: speed is very very important cuz\n273.68s: radiation needs to be resolved at a very\n276.4s: high spatial and by this I mean the\n279.039s: vertical stratification in the\n280.479s: atmosphere vertical layers usually you\n282.56s: have like 100 per column 60 to 100 I\n285.84s: guess uh horizontal resolution every\n289.039s: single column right you map the surface\n290.72s: of the Earth you grid it up there are\n292.759s: like many many grids and not to mention\n296.12s: the temporal resolution every time step\n298.199s: you'll try and resolve your radiation\n300.759s: and finally spectral resolution as well\n303.44s: because you long wave short wave and\n305.36s: more than that you will probably want to\n307.199s: split the whole atmosphere into multiple\n308.96s: bands so radiation is you will be\n312.039s: calling the radiation scheme like\n314.639s: Millions I don't know trillions of times\n316.96s: so you really really need it to be fast\n319.96s: how optimized are we talking about well\n323.68s: there are radiation schemes and there\n325.24s: are papers of radiation schemes where\n327.44s: researchers are talking about trying to\n329.24s: minim the number of exponential terms in\n332.6s: the scheme so we are in a world in which\n335.28s: exponential terms are considered\n336.88s: expensive people trying to replace them\n338.4s: with multiplication that's how crazy\n340.4s: optimized we are trying to get\n343.52s: at so the current analytic approach and\n346.96s: this has been done since at least the\n350.0s: 1980s or even earlier is that you assume\n354.8s: angular distribution of the radiation in\n358.0s: each atmospheric layer and if you do\n360.72s: this your flux can then be determined\n363.96s: analytically so you solve everything\n365.68s: analytically compute everything you\n368.52s: that's it you're done no need for any\n371.639s: data um there is some logic to doing\n375.08s: this because did within a cloud the\n378.08s: scattering becomes diffusive and so the\n380.479s: radiation field becomes approximately\n383.479s: isotropic so basically the old schemes\n387.08s: the analytic methods usually you either\n389.599s: assume that your radiation field is\n392.16s: isotropic or you will assume not quite\n395.72s: isotropic there's some Nuance but yeah\n397.84s: so approximately isotropic or you assume\n400.28s: that it is very an isotropic so it's\n403.24s: almost a Delta function and in both\n405.8s: those cases you can get some nice\n408.4s: analytic\n410.199s: Solutions of course the truth is that\n412.599s: you know within uh cloud in between the\n415.4s: two extremes this is not you will\n417.639s: probably get some other\n420.8s: distribution and the problem also is\n424.0s: that even if you can predict perfectly\n427.12s: accurately the angular distribution\n429.52s: throughout the cloud the resultant\n431.8s: Expressions may not even be close form\n433.84s: so it's not just that it's difficult to\n435.639s: predict the angular distribution of the\n437.879s: rad radiation field within the cloud is\n440.08s: also that most angular distributions UK\n442.8s: kind events resolve it in some analytic\n445.72s: analytic close form R anyway\n450.319s: and when I say may not be close on I\n451.879s: actually mean will not because if I use\n455.319s: so we thought about the multi-angle\n457.879s: expression this is the high angular\n460.16s: resolution model we actually know that\n463.08s: the radiative fluxes have this\n465.8s: expression over here where n over here\n468.44s: is just I'm summing over all of the\n470.56s: directions that I resolve in and um\n473.8s: basically when n tends towards Infinity\n475.919s: then you imagine that you resolve\n477.24s: everything like next to perfectly you\n479.0s: get conver if you will um no need to\n482.479s: care too much about the details of the\n486.28s: expression uh the main point I want to\n488.84s: make over here is\n490.919s: that this expression over here relies on\n494.68s: certain ion values Lambda over here\n497.24s: which are the igon values of a\n499.72s: scattering Matrix some very large\n501.96s: scattering Matrix with skilles with the\n503.84s: number of angles you use uh or streams\n507.0s: actually in the literature and this\n510.039s: igon values probably have no close form\n513.2s: solution for those of you are more maing\n516.08s: C you think that you have uh a matrix\n518.839s: that's more than 5x five the igon values\n521.08s: no longer have a close form expression\n523.919s: so you can so from there we really know\n526.24s: that there is no close for expression\n528.16s: for this\n531.16s: actually however using this same\n534.64s: expression we can show that the rad\n537.76s: radiative fluxes are anal\n540.24s: with respect to the optical parameters\n542.24s: the optical parameters are the input\n544.6s: into my radiative transfer solvers uh\n548.32s: either the two sham or the\n550.8s: multi and therefore uh sping\n554.279s: interpolations interpolation in general\n556.04s: tailor series expansions are guaranteed\n558.6s: to converge and you have rapidly\n560.519s: decaying errors so if you don't know\n562.48s: what analytic means don't worry it\n564.44s: doesn't matter the whole point of it is\n566.959s: that your functions are really nice in\n571.0s: some yeah are very very nice and so you\n574.279s: get conversions guarantees you get the\n576.64s: error decays really fast and this will\n579.24s: have some implications for our methods\n581.56s: later\n583.079s: on so I'll be talking about two\n586.32s: technically three that SP into two sets\n589.6s: of data driven two stream methods one is\n593.04s: just SP interpolation pre old pre\n596.68s: traditional I guess but I will tell you\n599.2s: that this is really triy and true and uh\n601.72s: produce some really good results and\n604.079s: then as more advanced methods I'll be\n606.44s: showing you a method using symbolic\n608.279s: regressions using PSR I know like many\n611.44s: many people at all use PSR so hopefully\n613.76s: I can show you something I some\n615.48s: interesting things to say about PSR and\n617.76s: then uh versus symbolic regression\n620.68s: versus using a multi multi-layer neuron\n623.8s: Network so SP interpolation first uh how\n627.519s: we do this somewhat simple where I mean\n630.72s: if you just see sure all of you know\n633.12s: about splines so linear splines you can\n635.519s: do it in 2D you got bilinear by cubic\n638.68s: and what we are doing is basically a 4D\n640.839s: spline so tetr linear Tetra\n644.04s: cubic so what's really nice about using\n648.92s: uh old more traditional method like\n651.12s: spines is that you have some very nice\n654.6s: proven mathematical properties that I\n657.92s: can leverage especially since I know\n660.36s: about the niceness of my flux functions\n663.399s: in particular I get uniform conversions\n666.68s: that is guaranteed by\n668.56s: continuity uh I'll show you the\n670.48s: implication of that later and I get fast\n673.6s: conversions because of the smoothness of\n676.12s: the functions which are\n678.12s: interpolating and very importantly\n680.32s: remember I thought about how it's very\n682.36s: important that you resolve your\n685.16s: radiation uh very quickly well the\n688.16s: forward evaluation of a spline once you\n690.72s: I guess build that entire spline it's\n692.639s: really fast cuz um in general so how it\n696.48s: works right if you want to evaluate this\n698.24s: is that you just have to find the\n699.68s: correct spine that's just the most\n701.399s: expensive part evaluating a cubic\n703.24s: polinomial is Trivial is dising fast how\n707.32s: you find a correct spine is that you\n709.6s: just do a binary search however in our\n712.6s: case where you will probably want to\n714.2s: evaluate like multiple layers\n716.68s: simultaneously you can basically just\n718.92s: make the evaluation contiguous so it's\n721.72s: kind of a contiguous memory kind concept\n724.639s: for those of you who are more CS in\n726.2s: client but you can make use of that to\n728.24s: do your evaluations for many many layers\n730.639s: many many ordered layers really\n733.72s: fast and yeah so obviously once you find\n736.92s: the correct spine evaluation is very\n739.639s: fast so using 68,000 data points is 20 x\n744.36s: 20 by 17 by 10 um I will\n749.279s: at that our we don't have that many\n753.04s: features so actually 68,000 data points\n757.279s: is actually not quite a lot of memory in\n759.639s: case you are wondering I remember I\n761.44s: computered it before it amounts to\n763.04s: something like just 5\n765.0s: megabytes uh but in any case if you do\n767.399s: that your cubic spline has less than 1%\n770.36s: error linear spline less than 4% and of\n774.079s: course if you want to compare the status\n776.079s: quo we are talking about like huge error\n781.16s: basically and indeed why our clients can\n784.36s: get such low error and percentage error\n786.279s: no less right so it's really because of\n788.8s: uniform conversions right and we we know\n791.72s: that if we add more and more points the\n793.8s: percentage error will just go down and\n795.32s: down and down you can make it\n796.279s: arbitrarily small this is pretty much\n798.519s: guaranteed cubid SP works better that's\n801.56s: not a surprise to\n804.0s: anyone however why we would want to\n806.839s: consider linear sply is because are\n809.639s: thinking about this in a adaptive sense\n812.92s: where if I mean a right we don't know\n815.639s: how many data points we need right let's\n818.12s: say you want to achieve 1% error linear\n820.8s: spine how many data points do you need\n822.8s: hard to say uh in that case you can\n826.24s: basically make it adaptive right you can\n828.56s: try and predict you can do it once\n831.759s: evaluate your error if you have some\n833.8s: sort of validation set I guess and then\n837.0s: add points as you need until you acheve\n839.079s: achieve the error that you want and in\n841.279s: that case that's where linear sline\n843.079s: shines because you see my tiny little\n846.12s: schematic over there adding points to\n848.8s: linear spines is Trivial right you just\n850.759s: add to one point you won't affect the\n853.32s: other spines whereas cubic spine if you\n855.68s: add points you need to reevaluate the\n857.32s: whole thing all over again so linear\n859.639s: spine that's something to consider as a\n861.279s: very generalized method generalized and\n863.759s: adaptive\n865.04s: method I will say that one Nuance I am\n867.959s: sort of skipping over is the\n870.12s: distribution of the points so uh this is\n873.399s: not just oh 20 points lus spacing\n876.72s: everything is great uh some Nuance to\n879.8s: choosing a distribution of points I'm\n881.519s: not even sure I'm doing it optimally but\n884.44s: yeah anyway just details\n886.68s: details uh okay okay so now talking\n890.8s: about symbolic regression and neur\n892.92s: networks show you yeah the results so\n896.04s: PSR what I do is I set my Max complexity\n899.88s: to 80 which is kind of considered pretty\n903.36s: high but for my hidden layer and then so\n907.399s: just two hidden layers right one input\n909.8s: layer output Layer Two hidden layers in\n911.519s: between so my NN has 700 hidden\n915.36s: variables and so complexity because some\n918.8s: of you may not be as familiar with the\n920.519s: term um so X Plus y for example will\n925.12s: have a complexity of three cuz you count\n928.12s: x y and count the uh operator the class\n932.319s: operator right so actually 180 Max\n934.6s: complexity probably amounts to just half\n937.36s: that in the number of variables so you\n939.88s: just so in a way you are comparing\n942.199s: probably something like 40 to 700 hidden\n945.279s: variables in a way right so you can see\n949.199s: some of the results I mean sure your\n952.319s: neuron Network you know absolute error\n955.24s: pretty small that's great uh probably\n957.24s: can bring even smaller if I use more\n960.44s: hidden\n962.56s: variables whereas for p Sr you can see\n965.519s: that accuracy is not that good but we\n968.16s: are in a way using a much sparer model I\n972.199s: follow up on that idea in a bit one\n975.079s: interesting thing I want to point out\n976.92s: over here is that there's this idea do\n979.68s: we use exp put exponentials in the PSR\n983.6s: uh do we allow PSR basically to use\n985.519s: exponentials or do we not you can see\n987.959s: the results are actually\n989.6s: quite similar and the nice and the\n992.56s: reason for that is actually because we\n994.48s: are here making use of the\n996.72s: analytic property of our flux functions\n999.68s: once again because for those of you who\n1001.519s: know exponentials if you do a taor\n1003.68s: expansion of exponential that TAA\n1006.079s: expansion actually converges super polom\n1009.92s: fast very very fast\n1012.279s: basically um I will add that we are so\n1016.399s: you'll notice that previously for the\n1017.92s: STS I thought about percentage error now\n1020.48s: I'm talking about absolute error the\n1023.199s: reason for that is because indeed there\n1025.919s: are certain points where the percentage\n1029.439s: error can be really bad for both of\n1031.679s: these methods and the reason for that is\n1034.28s: because we do not have uh uniform\n1036.919s: conversion guarantee in this methods but\n1039.319s: the spline does so this is where\n1041.4s: actually we use the uniform convergence\n1043.28s: property to get like really nice errors\n1046.36s: really small errors everywhere for the\n1048.28s: spines but you don't really have it here\n1050.48s: so we I think it's more practical to\n1052.919s: talk about absolute\n1055.64s: error\n1057.44s: um because you know to some extent if\n1060.52s: your if the value itself is really small\n1064.08s: then maybe even you have a decent if you\n1067.08s: have a high percentage error practically\n1068.84s: speaking may not be too\n1072.12s: important okay so yes so important point\n1075.84s: I want to make here is that for PSR we\n1079.32s: are just because of the far smaller\n1081.76s: number of terms we have a much it' be\n1085.2s: much faster to evaluate this Expressions\n1087.799s: then to try and evaluate the 700 hidden\n1090.679s: variables in your two hidden layer\n1093.2s: neuron\n1095.679s: Network and so I think one interesting\n1099.28s: point I wanted to bring up over here is\n1101.88s: that very often for PSR people talk\n1105.24s: about it as a trying to get interpret\n1109.08s: expression so we talk about\n1110.039s: interpretability this is uh that's the\n1112.72s: point of this we kind of flip this me on\n1117.2s: its head a bit because we are not really\n1121.0s: searching for Expressions we can\n1123.12s: interpret from Pasar in a way we kind of\n1126.159s: already know what forms we are looking\n1129.24s: at right from the earlier\n1131.2s: analysis instead what we are using pyr\n1135.039s: for is sp for a much faster forward\n1139.84s: evaluation and I wanted to say that\n1142.559s: actually in a way this is s of a I would\n1144.76s: say a lesser\n1146.32s: discuss advantage of actually using PSR\n1149.4s: as compared to I guess a neuron Network\n1152.36s: um is that by its very nature PSR is\n1155.6s: really designed to optimize s spacity in\n1159.12s: comparison neuron networks they are not\n1161.84s: very good at being Spar I know there is\n1164.4s: research on Spar neuron networks but in\n1167.0s: general you are expecting lots of hidden\n1169.559s: variables when you are doing nns and of\n1172.84s: course the fact that PSR you get visible\n1176.24s: Expressions it makes it much easier to\n1179.159s: leverage API knowledge compared to the\n1181.799s: blackbox model of NN so again for many\n1186.52s: of you who do use PSR and for that\n1188.64s: matter you that as well I think that's\n1190.679s: an interesting thing I will actually\n1192.32s: follow up um and discuss with you all\n1195.559s: about but okay so everything I showed be\n1200.0s: so we are in the last part of my\n1201.76s: presentation everything I showed before\n1204.36s: is just for a single layer uh atmosphere\n1209.36s: however realistically you we usually\n1212.0s: want to satisfy the atmosphere into\n1215.96s: multiple layers so there's a nice\n1218.039s: schematic over here to show you how that\n1220.36s: would look\n1222.36s: like and so using the previous work we\n1227.24s: have already address the S stems and is\n1232.559s: this intra atmosphere R and T's that\n1235.159s: still need to be predicted that our\n1236.88s: previous world is doesn't so we can get\n1240.6s: the S very well using everything I've\n1243.24s: showed but this R andt are still a bit\n1246.76s: unknown un\n1248.32s: addressed and the reason why we would\n1250.679s: want to satisfy the atmosphere one is\n1253.32s: realism of course the second is because\n1256.72s: we often want to compute things things\n1258.799s: like heating rates and that will re rely\n1261.48s: quite a lot on what is happening within\n1263.6s: the atmosphere within the clouds rather\n1265.48s: than just carrying what is coming up at\n1267.72s: the top or what is going down at the\n1271.159s: bottom so One S of like a easy way out I\n1275.039s: will say is okay let's improve what we\n1278.44s: can improve which are this asems we just\n1281.32s: use the old method for this uh the intra\n1284.88s: atmosphere\n1286.52s: rentes which are much easier to try and\n1290.64s: determine um so some results over here\n1293.72s: let's say we try that and so over here\n1296.159s: what I'm doing is that I'm using a real\n1298.919s: estate and real estate of course by its\n1301.52s: nature is a multi-layer\n1304.159s: cloud and so in this case you can see\n1307.6s: that uh if I set a low Zen enough angle\n1311.08s: the errors are reduced quite a bit so\n1313.32s: the blue is uh my new methods the Orange\n1317.159s: is the old status quore method\n1319.36s: but the problem is that in some cases\n1321.84s: improving just one part of the model\n1324.159s: will actually result in worse error so\n1326.76s: this is really just a result of\n1328.559s: compensating errors um and I have tried\n1331.72s: if you can indeed determine the perfect\n1334.2s: intra osphere RS and TS you would\n1336.679s: actually have perfect error everywhere\n1338.64s: I've tested just as a sanity chat but\n1341.36s: the two big\n1342.76s: takeaways is one that the accuracy of\n1345.919s: various T methods is case dependent it's\n1349.12s: nothing new or interesting over here\n1352.24s: because this has kind of always been the\n1354.24s: case and if you're wondering like what\n1357.48s: method is put into say CSM for example\n1361.159s: it is actually a method that works\n1363.08s: really really well for clouds and it's\n1365.0s: well known that it works poorly for say\n1367.559s: for example Arctic aerosols but what\n1370.88s: people think and say is that clouds are\n1372.919s: the things that we want to get right so\n1374.32s: we just use a method that's really good\n1375.72s: for clouds even it's terrible in some\n1378.039s: other cases us so in a way this is s of\n1381.52s: fundamental but we are still hoping to\n1384.679s: make our model more accurate\n1387.72s: Everywhere by trying to determine the\n1390.44s: int osphere RS ands more accurately and\n1393.679s: in fact we have I mean I have already\n1396.76s: been working on this for months this is\n1398.36s: not a surprise uh and we do have some\n1400.96s: methods to do that though for time\n1402.72s: constraints I will not go into that\n1405.279s: final thing to say on just that first\n1407.799s: part\n1408.96s: is to say that the data that we use to\n1412.44s: test our model on is really important as\n1415.32s: well right because we cannot\n1417.08s: comprehensively say that our method\n1418.559s: works better everywhere but we will want\n1420.64s: to show that it works better for the\n1422.52s: things that we are interested in us\n1424.919s: cloud and Aros\n1426.24s: source and yeah that is all from me any\n1429.2s: questions thank\n1431.679s: you thanks for the presentation um I was\n1435.0s: wondering if if you can kind of mix the\n1437.12s: two approaches of neural networks and\n1439.919s: symbolic regression by once a neural\n1442.679s: network is trained integrating it in the\n1445.4s: library of symbolic functions you're\n1447.48s: searching on is that an approach that uh\n1450.44s: can be\n1452.679s: used okay oh okay I've heard a similar\n1456.36s: idea from Jatan actually he's not here\n1458.88s: but yeah where you train a neuron\n1461.159s: Network first and you use the neuron\n1463.08s: Network outputs to train your PSR\n1466.679s: algorithm he tells me that work much\n1468.84s: better because you s of like Smooth out\n1471.0s: the data but is that kind of the idea\n1473.159s: you're getting it yeah probably yeah uh\n1477.12s: so I guess I have it\n1479.48s: on uh I am told that that works better\n1483.12s: don't quite know why but maybe I guess\n1486.24s: in our\n1488.2s: case but I think in that case people are\n1492.52s: working with expression you're working\n1495.76s: in a case where they know less about the\n1498.399s: true form of the Expressions so you\n1500.679s: might want to do things like that and\n1502.159s: you might have noise that you have to\n1503.44s: deal with right whereas we are dealing\n1504.72s: with synthetic data in my case I think\n1507.48s: PSR on its own is already works much\n1511.12s: better in than in the typical case\n1513.159s: because we do know quite a bit about the\n1516.52s: true\n1518.64s: Expressions thanks great talk to I'm how\n1522.279s: did you arrive at 80 for Max complexity\n1524.88s: did you test a bunch of different\n1526.44s: numbers or you just chose that and so I\n1529.64s: did test for many different numbers but\n1532.48s: I think a interesting point to make here\n1534.76s: is that I believe that I can actually\n1538.76s: scale up the max complexity even more\n1541.52s: and get even less accuracy so in a way\n1544.48s: there's a tradeoff between complexity\n1546.159s: and accuracy as you might expect and I\n1549.48s: guess 80 is pseudo arbitrary in a way so\n1553.44s: in a way I guess it depends on what sort\n1555.0s: of Errors you want to bring it down to\n1558.08s: and um I guess I kind just stop at a\n1561.12s: also the training time increases\n1563.76s: exponentially with your complexity so\n1565.76s: that's a consideration\n1570.039s: too hello oh yeah um so just one small\n1575.12s: comment on what we had before this\n1576.76s: question regarding using I guess some of\n1579.36s: the symbolic regression on top of the\n1580.679s: neuron networks yeah um maybe from what\n1583.559s: Jatan proposed said I know that there is\n1587.32s: kind of a technique osed as an\n1588.919s: interpretable AI technique which\n1590.799s: basically builds a symbolic regression\n1593.64s: emulator of a neural network so I I know\n1596.399s: that this has been sort of explored and\n1598.72s: proposed in case you're interested I can\n1601.2s: show you through the paper yeah thank\n1602.84s: you um but besides that I think like one\n1606.399s: question that I had is because you said\n1609.0s: we have a lot of knowledge also about\n1610.52s: the problem or or the the Dynamics were\n1614.24s: you able to um introduce this somehow\n1617.76s: into the PSR are there certain physical\n1620.08s: constraints that you were not able or\n1622.6s: you were interested in getting into the\n1624.919s: symbolic regression algorithms ah thank\n1627.36s: you for that question great question uh\n1629.88s: so to answer you yes uh in PSR just by\n1633.679s: the library of forms I have actually\n1636.279s: imposed certain oh wait sorry that's PSR\n1640.24s: okay sorry uh I correct myself\n1644.799s: me uh okay in PSR I would say that the\n1647.799s: con are SOL soft constraints in the\n1651.36s: sense that just by transforming my data\n1653.52s: a bit I try and push it towards\n1655.64s: fulfilling certain\n1657.08s: constraints um if we are talking\n1659.919s: symbolic regression in general so not\n1662.6s: genetic programming which is PSR but\n1664.88s: using SP\n1667.519s: regression in that case I can impose the\n1670.519s: constraints quite easily by just\n1672.84s: choosing my library of forms and\n1675.48s: actually that is the approach I'm sort\n1677.559s: of in to so I actually do hope for SP\n1679.96s: regression to replace PSR PSR is just a\n1682.44s: bit explanatory so they use Cindy\n1685.48s: something like\n1686.76s: Cindy well is Cindy is optimized for\n1691.44s: learning uh the Dynamics of Odes I don't\n1695.039s: need something quite so complicated so I\n1697.559s: actually do have my own Spar\n1700.08s: regression um so yeah my SP own Spar\n1703.32s: regression code that I've been using\n1705.919s: okay thanks so much\n1708.6s: hello good presentation I have a very\n1711.2s: basic question is about currently um\n1714.799s: because in the modeling simulations\n1716.399s: cloud is one of the key points that\n1719.6s: needs to solve because some model cannot\n1721.919s: will resolve the cloud effect so uh in\n1725.96s: your simulations I have two questions\n1728.279s: the first is which data set you use you\n1730.64s: use the observation data set of CLA or\n1733.36s: you use the model result the second\n1736.12s: question is uh can you give me a reason\n1739.08s: why a higher resolution Cloud simulation\n1742.919s: is need oh okay one clarification your\n1748.039s: second question resol dat site yeah I\n1751.799s: just wanted to clarify what sort of\n1753.6s: resolution are you talking about you\n1755.519s: talking about vertical stratification\n1757.24s: are you talking about angular resolution\n1759.44s: what kind of resolution so for your\n1762.039s: training your uh for your training your\n1764.6s: method so which data set you use for the\n1766.88s: training the model is or\n1769.159s: observation okay uh so for your first\n1772.12s: question we are using synthetic data so\n1774.84s: it's actually the outputs of my high\n1777.039s: angular resolution model da for those of\n1780.799s: you don't know that is my that is what\n1783.84s: I'm trying to match that's my ground\n1785.12s: truth so it's synthetic data not\n1787.72s: observational okay so does this model\n1791.44s: can have a ve resolve the reality of the\n1795.559s: cloud uh kind of also not quite uh so we\n1800.96s: are still stuck in the 1D plane parallel\n1804.039s: framework so if you want something that\n1806.44s: is much closer to reality you need to\n1808.48s: use a 3D result but\n1811.6s: for I always say various reasons I mean\n1814.48s: this is independent column model right\n1818.159s: um because of that I guess we consider\n1821.24s: the multi-angle but ond solver to kind\n1825.279s: of be good enough in a way okay thank\n1828.399s: you I guess in general if we can get d\n1831.48s: results using the two stream we are\n1833.64s: sufficiently happy we don't even want to\n1835.44s: think about Tre yet thank you my next\n1838.6s: project though anyway that's let\n1840.519s: separate"
    },
    {
        "class": "YouTubeVideo",
        "title": "Using Observations and Machine Learning to Constrain Ice Microphysical Processes with Joseph Ko",
        "videoId": "FRY9HOEms6w",
        "url": "https://www.youtube.com/watch?v=FRY9HOEms6w",
        "publishedAt": "2023-09-20T14:01:12Z",
        "transcript": "3.78s: so Joseph Koh is a also postdoc athlete\n7.56s: he is working on ice microphysics and\n10.62s: applied machine learning he's interested\n13.2s: in air quality urban climate and climate\n15.839s: adaptation uh and uh he is\n19.8s: um uh working on uh a project here\n24.539s: called using observations and machine\n26.16s: learning to constrain ice microphysical\n27.84s: processes Joe got his uh PhD in 2022\n32.04s: from USC in environmental engineering so\n34.559s: welcome uh Joe and we look forward to\n36.899s: hearing what you have to say hi thank\n39.0s: you\n39.84s: um is this Mike good\n41.579s: okay\n46.14s: okay sorry\n49.68s: um that better\n51.78s: Okay so\n53.579s: um yeah so I'll try to keep under time I\n56.28s: might skip some slides here and there\n57.899s: but basically um yeah I'm going to be\n59.76s: talking about if microphysics I work\n61.86s: with Kara Lam and Marcus van Vier walkie\n64.92s: and\n66.6s: oh uh I don't know if this is working oh\n70.92s: yeah the outline is going to give just\n73.5s: motivate why ice microphysics is\n75.9s: important and then give a brief update\n78.36s: um in Parts one and two of some active\n80.04s: work that I've been um doing and then\n83.52s: um follow up with some other work that\n85.619s: other people are doing within the\n87.119s: microphysics world and also some planned\n89.34s: work that's um in queue and then wrap up\n92.159s: with the bigger picture of um you know\n94.92s: how all these moving pieces fit together\n98.46s: so um so to take a step back\n101.759s: um why are clouds important and relevant\n104.04s: is because they have a strong impact on\n105.659s: the climate namely they strongly impact\n108.659s: Earth energy balance and also the\n110.939s: hydrologic cycle\n112.38s: for example they'll reflect shortly a\n115.02s: shortwave radiation but also depending\n118.32s: on where they are in the atmosphere they\n119.82s: might also have a greenhouse effect so\n121.32s: there's kind of this trade-off depending\n122.759s: on what type of cloud as um shown in\n125.759s: this figure and where they are in the\n127.439s: atmosphere and it's a matter of\n129.56s: scopic properties which are determined\n133.08s: um ultimately by these microphysical\n134.819s: processes processes that are happening\n137.16s: at much smaller scales\n139.2s: and we're concerned about this for\n140.94s: climate projections because I mean we\n142.98s: want to know in a future climate what's\n144.959s: going to happen to the clouds and\n146.76s: there's uncertainty\n148.26s: um with regards to how we model clouds\n150.06s: that's going to propagate to how we do\n152.22s: these projections for how clouds might\n154.14s: change in the future and for\n157.2s: um us and the ice microphysics we're\n159.36s: concerned with these high clouds\n161.64s: um these clouds that are essentially\n163.62s: composed of tiny ice crystals\n166.26s: so um in general ice clouds are poorly\n169.08s: understood\n170.58s: um and what I mean by that is the\n171.84s: fundamental physics determining the\n174.3s: microphysical processes are not fully\n176.519s: understood I'll just read this quote\n178.14s: from the latest oh or the ipcc ar5 uh\n181.86s: physical\n182.879s: um basis report so the role of then\n185.099s: serous clouds For Thought feedback is\n187.44s: not known and remains a source of\n189.54s: possible systematic bias the\n191.94s: representation of Cirrus and gcms\n194.04s: appears to be poor and such clouds are\n195.84s: microphysically complex\n197.94s: so\n199.62s: just to give you a picture of what I\n202.319s: mean when I say microphysics basically\n204.0s: all these processes that are going on\n206.22s: inside the cloud from these warm\n209.28s: processes going happening down here in\n212.04s: red to the cold ice processes that are\n215.159s: happening here they need to be\n216.06s: represented somehow within the planet\n217.86s: model and these obviously these are some\n220.379s: good processes happening at you know\n222.06s: nanometer to micro scales and you have\n224.819s: to simplify that somehow into some kind\n226.92s: of scheme and for example here on this\n229.62s: right it's a traditional what we call a\n231.659s: bulk theme where there's different types\n233.34s: of cloud particles classified into into\n237.36s: like for example ice or snow or rain and\n241.56s: there's all these different interactions\n243.299s: between processes dictating how these\n245.58s: clouds will form and how they evolve or\n249.06s: ultimately dissipate or precipitate\n252.12s: so obviously there's a lot going on\n257.28s: um and just to give an overview of how\n259.38s: how these microphysics are represented\n261.84s: there's kind of uh you know a spectrum\n264.72s: of varying levels of complexity so\n267.18s: starting off with the bulk\n268.5s: representation on the left or there\n270.9s: might be a functional analytical form of\n273.36s: something like a size distribution with\n275.639s: a few parameters and then\n278.52s: um going up in complexity to something\n280.74s: like a bin where we have a spectrum a\n282.78s: spectral representation of a size\n284.58s: distribution where the number of\n286.74s: parameters now increases proportionally\n288.66s: to the number of bins and finally to the\n291.36s: more complex the most complex\n292.979s: representation which is the particle\n294.54s: representation where we track individual\n296.759s: particles in a lagrangian fashion and\n299.22s: those individual particles are evolving\n301.32s: and obviously this is not\n303.08s: computationally trackable for a climate\n305.639s: model so most climate models will use\n308.1s: something like this book uh model but\n311.94s: then obviously there's only a couple\n313.979s: parameters that you can tweak and\n315.479s: there's a trade-off between complexity\n318.3s: um and and how realistic that is\n322.08s: and to add on top of that for ice clouds\n324.539s: there's a special issue of crystal shape\n326.58s: because Chris um you know for a warm\n329.4s: Cloud you might have droplets that you\n330.78s: can represent as a sphere but for ice\n333.0s: ice clouds um you can't really do that\n334.86s: there's a thing called habit or ice\n336.36s: shake it's a function of its\n338.1s: environmental variables like temperature\n339.84s: or humidity that changes with regards to\n343.32s: like how it's transported in the\n345.0s: atmosphere because it's not going to\n346.32s: stay within you know one temperature or\n348.9s: one specific humidity so it's it's\n352.82s: complicated to predict the habit and the\n355.8s: evolution of that habit and have it\n358.199s: important because it influences its\n360.84s: process race it's fall speeds and\n363.6s: Optical properties and therefore you\n365.58s: know ultimately things like\n367.56s: precipitation and it's radiative impact\n370.56s: of the clouds at a larger scale so and\n373.08s: just to give you an example a recent\n374.52s: study found that the ice complexity May\n377.039s: induce additional cooling effect of\n378.78s: negative 1.1 watt per meter squared and\n381.3s: to put that into account\n383.1s: um the CO2 forcing is about 2 watts per\n385.259s: meter squared so that's a pretty large\n387.12s: uncertainty that you got there just from\n389.039s: particle habit one\n391.02s: so now it just kind of leads into one of\n394.62s: the projects that I've been working on\n395.819s: is reconstruct explicitly reconstructing\n398.759s: 3D crystals from in-stitching\n401.22s: measurements of seed of crystals and\n404.639s: this is um some work we've been\n406.38s: collaborating with um you Albany folks\n408.72s: where they've compiled a large database\n411.62s: essentially Cloud particle images from\n415.56s: about 13 campaigns over the span of\n417.66s: about 16 years so there's millions of\n420.18s: these single particle images and the pro\n423.66s: to this data set is that there's a lot\n425.4s: of data but we're limited to its 2D\n427.259s: geometric features but ideally in a\n429.78s: parameterization we want to know you\n431.699s: know it's 3D\n433.52s: properties because we want to basically\n436.259s: constrain a parameterization with\n437.819s: something like a mass size relationship\n440.099s: so the basic idea is that we wanted to\n442.56s: try is can we train some kind of machine\n444.419s: learning model that can extract the 2D\n447.06s: features from these images and um and by\n450.9s: doing so I have like you know a large\n453.419s: observational basis to constrain the\n455.58s: parameterizations\n458.94s: um and obviously there's no real world\n460.319s: data to do that so we synthesize our own\n462.84s: so basically we generated a bunch of\n464.58s: crystals uh randomly and I'll just show\n467.22s: you how we do that so we have some a\n469.02s: priori knowledge of what a crystal might\n471.3s: look like for example a bullet Rose kind\n473.16s: of looks like this it's kind of spiky\n474.78s: with the ball in the middle so that we\n476.94s: could generate a bunch of different\n478.56s: crystals with randomly perturbed aspect\n480.9s: ratios or bullet arms and then use this\n484.139s: as a means to train a machine a machine\n486.72s: learning model so um we have this bullet\n489.539s: reset prototype or we can also expand to\n492.3s: other types of habits\n494.52s: um and we have a preliminary data set of\n496.259s: about 10 000 crystals but we're going to\n498.3s: expand that if necessary and ultimately\n501.599s: um yeah we'll make this data set open\n503.34s: source and the code available as well so\n505.02s: other people can reproduce it\n506.879s: so just to show you how this might look\n508.919s: like in some kind of pipeline\n511.199s: um we wanted a test can we predict\n512.76s: effective density\n514.62s: um just from the images alone and\n517.02s: um this was done training on like a\n518.94s: couple hundred rose that synthetically\n521.039s: generated results so what you would\n522.539s: first do is extract some 2D features\n525.839s: um from random projections of these\n527.519s: crystals and then put it in a tabular\n530.16s: form so you can\n532.38s: imagine the inputs on these 2D features\n534.839s: and you want to predict something like\n536.1s: effective density so then we'll train a\n538.44s: bunch of these you know traditional ml\n540.18s: models these low-handing proof see if\n542.04s: they have any kind of\n544.14s: um you know effectiveness at all and\n546.48s: when tested on unseen data\n549.36s: um you can see that for a random Force\n551.459s: for example it has r squared 0.9 which\n553.98s: is pretty decent so this kind of gave us\n555.839s: confidence that\n557.64s: um you know there's there's something\n558.72s: going on here in the and this gave us\n561.18s: like\n562.08s: some incentive to move forward with some\n564.48s: more advanced methods which I can talk\n566.94s: about next\n568.14s: so what we want to do next is do\n570.12s: explicit reconstruction so in the world\n572.16s: of computer vision this is kind of a hot\n575.04s: has been a hot topic for the last decade\n577.019s: for example if you have an image of like\n579.48s: a car can you make a 3D model out of it\n582.899s: so I've been kind of doing a little\n584.64s: digging into that literature and I found\n587.22s: this paper in 2016 so this is kind of\n589.62s: ancient in the world of computer science\n591.3s: but but I wanted to you know see but it\n595.32s: was kind of digestible for me so I\n596.82s: wanted to see if I can use this model\n598.14s: right and I wanted to have like an\n601.019s: explicitly reconstructed Crystal for\n602.76s: today but I ran into technical issues so\n605.16s: I'll just show you the pipeline of\n606.839s: houses\n608.04s: so essentially you're going to train\n609.66s: with multiple views of crystals and this\n613.2s: um 3D r2n2 network is a pre-trained\n616.56s: network on a bunch of random um everyday\n619.38s: objects but we need to fine tune it\n621.3s: which means you need to train on our\n622.86s: specific object of Interest which is\n625.14s: crystals\n626.279s: and it's an autoencoder structure with\n628.32s: the recurrence module in the middle and\n631.14s: we trained that with its known blockful\n633.48s: representation and then once we have\n635.519s: this fine-tuned model you can basically\n637.92s: test it with unseen synthetic data and\n642.12s: then ultimately you want to infer the\n644.16s: voxlies model from CPI images and then\n647.04s: the reason why this is beneficial is now\n649.68s: that we can have distributions of of\n652.32s: relevant 3D features such as effective\n654.48s: density or um you know even surface area\n657.36s: or aspect ratio or anything you really\n659.88s: want to calculate and then that can be\n662.76s: used in future parameterizations so this\n665.88s: is kind of groundwork and it seems maybe\n667.86s: a little abstract but it does have\n669.72s: connections to parameterizations\n672.18s: um in the future\n674.459s: um so now jumping into kind of part two\n677.1s: so I mentioned the CPI data set and I\n680.7s: mentioned how they're categorized into\n682.56s: different classes and that was done with\n684.24s: these supervised CNN that was done by\n686.94s: Vanessa prisibolo from University of\n689.04s: Albany but then we thought can we super\n692.22s: can we cluster them in an unsupervised\n694.74s: manner or you know moving forward even\n697.98s: more like can we learn something about a\n699.839s: shape in the later space so this is just\n702.54s: a really simplified test case\n704.82s: um basically train a variational\n706.62s: autoencoder with CPI images and then we\n710.279s: can we cluster in the latent space\n713.279s: um and I'll show you a very simple\n715.68s: example of the equivalent of a dog\n717.66s: versus cat but in a crystal rosette\n719.76s: world so we are you know we want to\n722.82s: Cluster\n725.18s: so we used a hundred images each\n728.82s: um and you can see they're pretty\n729.839s: distinct and we wanted to make this easy\n732.3s: as a proof of concept right so we\n735.18s: train different variational Auto\n736.68s: encoders from vanilla to implementing\n739.62s: different forms of invariance or class\n741.66s: conditions but I'll just show you the\n743.579s: results from the vanilla here and we use\n746.76s: two latent variables and we down sample\n749.1s: to 28 by 28 for the computational\n750.899s: efficiency\n752.82s: um and you can see here on the left this\n754.8s: is a visual representation of the latent\n756.66s: space and you can see it clear\n757.74s: separation between the Spheres and the\n760.62s: bullets all kind of you know on the\n762.839s: bottom left to the top right and here in\n765.839s: the scatter in the scatter form you can\n767.639s: see this even better with the separation\n769.26s: between the bullets and the sphere so we\n771.0s: know\n771.899s: just visually like this is working\n773.579s: pretty well right with only 100 samples\n775.74s: each\n777.18s: uh uh next yeah so then we compared to\n780.42s: the the true labels to something\n783.54s: um that's done with unsupervised\n785.04s: labeling for example with Canadian's\n786.779s: clustering and in the middle is with\n789.36s: unsupervised learning the left is with\n791.519s: the supervised CNN and we see it\n793.98s: identified 100 of the the bullets and\n796.8s: about 80 of the Spheres with the false\n800.339s: um false positives uh bullets with\n802.44s: spheres but this is kind of a proof of\n804.42s: concept just to show like this actually\n806.04s: works and\n808.26s: um and I just want to know this is done\n810.3s: without any convolutional layers this is\n812.1s: what fully connected layers so moving\n814.56s: forward we want to use even different\n815.94s: architectures in the vae but this is um\n819.72s: was kind of an encouraging sign and just\n821.88s: to\n823.32s: um give you some context so it's like 28\n825.48s: by 28 that's almost like 100 feet or 800\n828.36s: features but then to condense that down\n830.7s: to two latent features and to be able to\n832.74s: separate out that's pretty amazing so we\n835.079s: think that there's something\n836.519s: um something going on here\n838.86s: um so just for fun now we included nine\n842.04s: classes though of particles see what\n843.839s: happens right same startup obviously not\n846.54s: gonna work so next steps are gonna you\n849.779s: know like I mentioned change the vae\n851.88s: architecture play around with that\n853.38s: increase the number of latent variables\n855.48s: and even moving beyond uh just\n858.3s: clustering thinking about how we can use\n860.339s: latent variables potentially in\n862.92s: parameterizations or to inform\n864.48s: parameterizations\n866.339s: um because it's not just about\n867.42s: classifying like classifying is a kind\n869.7s: of artificial thing and there's lots of\n871.2s: crystals that fall that are in this gray\n873.48s: area so how am I doing on time by the\n876.06s: way\n880.04s: so some work that's in the pipeline so\n883.74s: um we're also working on some pertured\n885.24s: parameter ensembles\n887.279s: um similar to what Lydia mentioned but\n889.74s: in the ice microphysics world and here\n892.38s: on the left is just um Les simulations\n894.839s: where we have four categories of\n896.639s: crystals and essentially what we're\n898.62s: doing just to remind you\n902.399s: um oh yeah sorry but just to remind you\n904.139s: the different\n905.24s: levels of complexity and the way you can\n907.86s: represent the microphysics we're\n909.72s: comparing the bulk which is the simplest\n911.579s: type of representation or the simplest\n913.56s: game and now we're going to compare that\n915.36s: to the lagrangian particle\n917.04s: representation as a ground truth and\n919.32s: then doing that comparison we're gonna\n922.8s: um essentially constrain the the\n924.72s: parameters within the bulk microphysics\n927.42s: scheme and we're using a case study of a\n929.699s: ice wall field campaign that was done in\n931.68s: 2022.\n933.42s: um so that is going to be starting soon\n935.54s: and just to give you an idea of what\n938.22s: some other people are working on so\n939.72s: Carolina for example has been doing some\n942.36s: work using Cloud chamber data so opposed\n945.24s: to you know aircraft data she's using\n947.76s: data from this chamber where they\n949.86s: essentially stimulate a cloud and then\n952.26s: fitting uh constraining parameters\n956.04s: um for a parking model\n958.199s: um using the the\n959.88s: um the observations from the chamber and\n962.399s: and what Carol is showing here is kind\n964.68s: of there's like a spectrum of physics of\n967.019s: models driven by physical knowledge to\n968.76s: purely data-driven models and everything\n970.5s: in between and we also had a PhD student\n973.32s: Jonas mckayley who's coming from a stats\n977.04s: background so he had been\n980.94s: um also doing some work constraining\n982.8s: depositional ice group models with the\n984.839s: cloud chamber data but in a more\n986.76s: rigorous Bayesian workflow type of way\n989.1s: so um you can reach out to him if you're\n991.38s: interested in that and he's I believe\n993.12s: he's working on a manuscript for that\n995.1s: so to pick fit this into the bigger\n997.56s: picture well we ultimately want to do is\n999.6s: incorporate all these different\n1000.74s: observations from aircraft from balloon\n1003.38s: measurements lab measurements and\n1006.5s: basically iterate with machine learning\n1008.72s: and Bayesian statistics to constrain the\n1011.06s: parameters of existing parametizations\n1012.92s: or and also I'm looking forward to\n1015.8s: improving parameterizations overall so\n1019.1s: um hopefully I gave you a little\n1021.019s: picture of what's going on\n1023.959s: um microphysics world because there's a\n1025.88s: lot going on but um yeah so it's been\n1029.24s: really interesting\n1030.559s: um this past year and hopefully make\n1032.839s: more progress going forward and thanks\n1034.939s: to my advisors and collaborators and\n1037.4s: just end with this nice scanning\n1039.319s: electron microscopy image of ice\n1041.66s: crystals uh yeah\n1048.679s: thanks so much Joe are there any\n1051.02s: questions here in the audience starting\n1053.36s: with the audience and\n1055.28s: at the innovation\n1057.86s: I I have one question uh with respect to\n1061.039s: the 3D\n1062.72s: um from the 2D is the goal there more\n1065.48s: about interpreting this large the large\n1067.7s: body of information is sort of\n1069.86s: distributions more generally or is the\n1072.86s: goal they are about constraining your\n1074.78s: ppes or whatever or how does that what\n1078.02s: is the final goal there yeah uh so I\n1080.48s: think there's kind of different\n1081.919s: directions you can go with that so as\n1083.6s: you mentioned yeah understanding the\n1085.039s: distributions of the 3D features is\n1086.72s: definitely a first step but then to also\n1089.12s: incorporate like for example something\n1090.98s: like a three-dimensional Mass size\n1092.96s: relationship into a type of\n1095.66s: parameterization that incorporates ice\n1097.46s: habit would be like definitely something\n1099.86s: we want to work towards\n1101.419s: and\n1108.02s: thanks that was amazing and I feel like\n1110.66s: okay enough for this year you know I get\n1112.34s: to ask all the newbies questions so you\n1114.559s: know I I'm definitely gonna take\n1115.94s: advantage of this I was really\n1117.559s: fascinated by the work that you did with\n1119.419s: that simple like other encoding\n1121.1s: procedure and you know like how well you\n1123.559s: get to separate things in the studio\n1125.299s: space especially I kind of implement\n1126.679s: field where we've been trying to\n1127.88s: distinguish between spiral analytical\n1130.22s: Galaxies for like decades and I don't\n1132.74s: think we are as far as you are so and so\n1135.919s: did you mention Disney a\n1138.679s: a really that you have is not rotational\n1142.28s: invariant yeah yeah so I tried okay\n1146.26s: it's because I was imagining it this is\n1148.52s: something that you have to use and so I\n1150.26s: was just uh Curious you know why like if\n1153.02s: that's your next step or if you think\n1154.52s: that the convolutional aspect will help\n1156.38s: more just\n1157.94s: yeah so there's I did try to\n1160.16s: rotationally invariant version of that\n1162.02s: but I guess maybe for that simple case\n1163.7s: it didn't really change anything\n1166.22s: um but yeah there are different\n1167.62s: invariances that we are can also try\n1170.72s: yeah\n1177.32s: if you have any questions online\n1188.84s: okay all right\n1191.78s: um\n1195.74s: I I guess I have another question about\n1198.14s: the 3D uh the synthesis synthesis model\n1202.12s: is seems like you did that for the\n1204.799s: bullet did is that like a challenging\n1207.38s: thing to do or do we know how to do that\n1208.88s: is this one it's kind of like we've\n1210.86s: talked about and leap a lot about that\n1212.48s: if we can just get the resolution down\n1214.1s: we kind of know how that works\n1216.559s: um do we do we have that down it's just\n1218.419s: a matter of we don't have enough\n1219.5s: computational space to run it in a real\n1221.6s: and a big model or is that another\n1224.0s: challenge you have to overcome\n1227.24s: um sorry just to make sure I understand\n1229.1s: so we're talking about the\n1230.419s: Reconstruction aspect like the synthesis\n1232.52s: of the different uh of the different ice\n1235.82s: crystals that you're using to infer the\n1238.34s: 3D structures is that hard hard\n1241.34s: challenge also or is that like kind of\n1243.38s: an easy thing you just want to implement\n1245.0s: it is hard for me because I'm sure I'm\n1248.539s: sure it probably gives a software\n1249.74s: engineer like you know it would be\n1252.32s: really easy to implement but it's just\n1254.12s: like these these um you know models are\n1256.039s: new to me and just even finding the\n1258.08s: appropriate model to do that\n1260.66s: um was a little challenging yeah but\n1262.76s: Jerry has a uh sorry\n1266.12s: Jerry uh Harrington has already\n1268.22s: implemented that my isometric physics\n1270.559s: model that uses that geometric model of\n1273.38s: the budding rosette as a\n1276.32s: um to parametrize how the ice crystals\n1278.419s: will grow so it's kind of ready there to\n1281.0s: incorporate any information that might\n1283.039s: come from analyzing those uh in situ\n1285.679s: data so it's it sort of that was one of\n1288.62s: the reasons I think why Kara and Joe\n1290.78s: went with that is because it's already\n1292.7s: sitting there ready to sort of ingest\n1294.559s: the data yes that's a great\n1297.2s: clarification\n1302.059s: yeah I see your picture has shown up\n1304.64s: here did you have something you want to\n1305.96s: say or yeah I'm just going to add that\n1308.179s: is also related to the PPE work that we\n1310.82s: are planning is that that is now\n1312.919s: implemented in the super droplet\n1315.08s: um code so like but there's there's this\n1318.02s: complication of um part of the\n1319.76s: depositional ice the problem with um\n1321.62s: particularly depositional ice growth is\n1323.419s: that it is not that well understood and\n1327.26s: um like especially how to like\n1328.76s: incorporate all these different Ice\n1330.08s: Crystal habits when they're like growing\n1331.4s: in competition with each other\n1333.799s: um\n1338.419s: okay another question here\n1342.98s: very cool Joe I was wondering I guess\n1345.32s: also going back to those 3D\n1347.679s: reconstructions what fraction of that is\n1351.919s: being influenced by the CPI images and\n1356.12s: what fraction is being taken from those\n1358.34s: like kind of geometric expectations\n1364.12s: maybe I can read the how do you\n1367.46s: incorporate those geometric expectations\n1370.039s: into the 3D\n1373.34s: reconstruction uh can you clarify what\n1375.98s: you mean by geometric expectations uh\n1378.679s: just the way that the crystals will form\n1380.6s: like you should you showed some of the\n1382.94s: like\n1383.9s: the geometry sketches from maybe one of\n1387.799s: Jerry's students\n1391.159s: yeah\n1392.62s: oh I see yeah so\n1396.38s: yeah I guess I guess it is since we're\n1398.78s: training on this a priority assumption\n1401.12s: it'll be 100 reliant on that we're\n1403.52s: assuming wrote that look like that so if\n1406.94s: there's some deviation from that like\n1408.559s: for example if there's a weird rosette\n1410.179s: then it might not do so well yeah oh so\n1413.12s: this part doesn't have any input from\n1415.4s: the CPA no we're completely training on\n1417.799s: synthetic data yeah\n1421.22s: but we you could I guess you could do\n1422.96s: data augmentation too maybe improve that\n1430.22s: okay well thank you again Joe for your\n1432.98s: presentation it was great\n1435.14s: um"
    },
    {
        "class": "YouTubeVideo",
        "title": "Cross-validation Strategy Impacts the Performance and Interpretation of Machine Learning Models",
        "videoId": "NALCGrQHMKg",
        "url": "https://www.youtube.com/watch?v=NALCGrQHMKg",
        "publishedAt": "2023-09-29T15:08:13Z",
        "transcript": "3.959s: foreign\n10.46s: we have Lily Bell sweet presenting today\n13.799s: for the girl club and so yeah before I\n18.18s: go in the title a little bell is a PhD\n20.34s: student at the Hamlet Center for\n22.619s: Environmental Research and light switch\n25.019s: and she was she also collaborates or she\n28.859s: used to I don't know what the I think\n30.599s: she still collaborates with Folks at\n31.92s: Nasa I guess on the adword project\n34.76s: uh and so she's been to New York\n37.38s: hopefully we can you know have her visit\n39.78s: here again uh and so today she'll talk\n43.02s: to us about uh her recent work that\n45.84s: appeared in uh how what's the acronym\n50.16s: for the journal\n51.379s: a-i-e-s I think a-i-e-s uh this is this\n55.44s: new AI Journal by uh from AMS\n59.76s: so deploy with yours\n61.92s: hi hi\n63.96s: um yeah so basically yeah cross\n65.939s: validation strategy impacts the\n68.04s: interpretation and performance of\n69.42s: machine learning models and my first PhD\n72.479s: paper so very exciting\n74.939s: um and it's been online for a little\n76.14s: while now but literally like yesterday I\n78.42s: think the official typeset version is\n81.42s: now online so I'm feeling very very like\n84.299s: a real scientist now it's very nice\n87.36s: um but yeah I've been collaborating with\n89.159s: Christoph Muller and Jacob my supervisor\n93.06s: um I'm in Leipzig and you said\n96.479s: um where I work in the compound weather\n98.82s: and climate events group\n100.68s: um led by Jacob Joshua that's us on our\n102.84s: Retreat which was yesterday on a boat in\n106.619s: uh sexy schweitz and we have about half\n110.579s: the group does kind of machine learning\n112.439s: approaches the other half more\n114.0s: statistical\n115.68s: um we are basically interested in\n119.399s: um compounding climate extremes\n122.82s: um and their impacts or how they will be\n125.52s: impacted by climate change but also on a\n129.42s: similar note\n130.679s: um the idea that extreme impacts can\n132.84s: arise from compounding less extreme\n135.42s: climate drivers so we work on different\n138.36s: kinds of impacts like floods crop\n140.94s: failures wildfires Forest mortality\n144.06s: events all kinds of different stuff\n147.959s: yeah so the motivation for this work I\n151.62s: should say I am the crop yield\n154.2s: um\n155.22s: failure event person in the group that's\n157.379s: my disaster of choice\n159.18s: um and the motivation for my PhD and\n162.78s: overall project was\n164.819s: um that basically the future projections\n167.819s: of global agricultural yields are really\n169.92s: uncertain\n171.54s: um and this paper by Jonas um in\n174.54s: Colombia at Nasa showed that most of\n178.019s: that uncertainty was actually from\n179.819s: variation between the crop models\n182.58s: um obviously a portion also from the\n184.14s: climate models but for these future\n185.519s: projections a lot of it is actually from\n187.019s: the crop models which is not really\n188.879s: surprising because we also know that the\n192.12s: current crop models that are in use the\n194.28s: process-based crop models\n195.98s: underestimate the impacts of extreme\n198.18s: climate events like droughts and heat\n200.04s: waves\n201.48s: um I mean sometimes they capture it\n203.519s: reasonably well but they always do kind\n205.86s: of underestimate and no one's really\n208.14s: surprised by this because there's a lot\n209.64s: of processes that just aren't in the\n211.14s: models a lot of pests and diseases for\n213.84s: example flooding Events maybe a not so\n216.599s: much well captured Frost events I think\n219.36s: also\n220.739s: um but also again I work in the compound\n223.08s: events group and a big kind of push\n227.34s: forward it seems in the last years it's\n229.14s: been\n230.22s: um showing with kind of quite simple\n232.2s: models that you can get really extreme\n234.84s: impacts not just from extreme climate\n237.36s: events but also from the compounding\n239.099s: effects of more moderate climate events\n241.799s: and one example for this in in crops is\n244.56s: this false spring phenomenon where you\n247.26s: can get a huge crop failure if you get\n250.08s: uh you know a warmer winter enough that\n252.48s: the crop enters a vulnerable\n254.76s: phonological stage\n256.739s: um too early and then there's this Frost\n259.979s: which kills it all off too early\n262.139s: basically and this can be really\n263.699s: devastating this led to this huge\n265.68s: Vineyards failures in France and there's\n268.259s: things you can do you can light fires in\n271.08s: the in the fields to try and warm them\n273.72s: up but it can be really devastating and\n276.18s: these events by themselves\n278.28s: um are not so extreme but the\n280.199s: compounding effect of them is what's\n281.52s: really the problem but this is really\n283.08s: hard to study and it's really hard to\n284.699s: study with crops too because there so\n286.44s: much interaction from genetics and\n288.24s: management\n289.38s: so the idea really with um yeah how to\n294.18s: proceed with that is that we know\n295.979s: machine learning models are really good\n297.3s: at capturing these kind of super complex\n299.04s: interacting\n300.3s: um relationships and there's been a lot\n303.84s: of success recently in using machine\n306.9s: learning to predict crop yields from\n309.36s: climate and other drivers but of course\n312.9s: Black Box blah blah blah\n315.3s: um how do we then actually learn about\n317.82s: these relationships\n319.5s: um and it really there's this kind of\n321.419s: yeah this idea which was the motivation\n323.82s: between from my PhD project can we use\n325.979s: these explainable methods to get these\n328.5s: relationships out and there's been a few\n330.539s: papers trying to do this\n332.34s: um this one was from ganellashid at Al\n334.86s: from last year and where they used a few\n338.1s: different machine learning models I\n339.419s: think they had a random forest and an\n341.22s: svm yeah kind of I think maybe one other\n344.94s: or maybe not and they try to predict uh\n348.24s: German yields from climate and then they\n350.88s: use partial dependence pull out to try\n352.56s: and extract these relationships after\n353.94s: and you see that you're able to get\n356.28s: these nice long linear relationships\n359.1s: um but\n360.72s: Unfortunately they weren't really happy\n363.24s: um actually the paper is called machine\n364.74s: learning something like no replacement\n366.66s: for science\n368.699s: because they found their results to be\n370.56s: pretty ambiguous and they found that\n372.539s: models with\n374.039s: very very different sets of features and\n377.52s: would give very similar predictive\n379.74s: performance which is no surprise if you\n381.9s: work with machine learning\n383.52s: um but also the interpretation they got\n386.52s: out were also very different\n388.38s: and then um in other papers doing\n390.539s: similar things for example this other\n392.34s: one which is also in the same Journal\n393.72s: that I went for and where they were\n395.94s: using lstm to predict the U.S Maize\n398.34s: yields and got a very high predictive\n400.38s: performance they also found that when\n402.539s: they tried to use some interpretation\n404.28s: methods uh wind direction was identified\n407.22s: as the most important feature and but\n409.919s: then removing wind direction from the\n411.9s: input didn't reduce the prediction\n413.639s: accuracy which is a bit confusing I\n416.46s: would say that seems like\n418.38s: um something is a bit wrong there\n420.96s: um but the thing is when you put loads\n423.96s: of uh features in that you think might\n426.66s: be causal it's very easy to justify\n429.0s: whatever interpretation you get out\n430.8s: there's it's not so easy to falsify this\n435.72s: at the same time\n438.0s: um there's been a lot of papers recently\n440.16s: discussing how people are evaluating\n442.259s: these machine learning global maps that\n444.3s: are made for example of soils and so on\n446.28s: and discussing better ways of validating\n449.4s: model performance\n452.28s: and again this is super super not\n456.36s: um surprising for machine learning\n458.099s: because machine learning assumes IID\n460.08s: samples\n461.66s: participants in the meeting this meeting\n464.16s: sorry uh hold on could folks mute\n467.28s: themselves please we are getting some uh\n473.099s: you might go to meet them if you're the\n474.9s: organizer okay\n478.56s: next room next to more\n480.66s: I'm sorry what okay\n483.18s: okay cool sorry sorry about that no\n486.24s: worries yeah there is\n489.24s: um so yeah I mean a lot of machine\n490.74s: learning assumes IID which is obviously\n492.66s: not the case when you have space your\n494.039s: temporal climate data with all this\n495.9s: spatial and temporal autocorrelation\n498.539s: um so\n500.34s: I was wondering if\n502.44s: this might have something to do with\n504.539s: some of these ambiguous results or if\n506.819s: the way because a lot of these\n508.319s: interpretation methods you have to\n509.819s: select your test set that you want to\n511.5s: apply them on I wondered what imp what\n514.08s: implication this had for interpretation\n515.52s: methods and this seemed like a really\n518.88s: um obvious question or something that\n521.64s: there had obviously must be known or had\n524.58s: been found before but after quite a lot\n527.16s: of reading I I didn't manage to find\n529.32s: someone\n530.339s: um some clear results on this so I\n532.86s: decided to just test it myself on my\n534.54s: data\n535.44s: um to see what happened basically which\n537.899s: is what I did\n540.12s: um so then this ended up becoming a\n541.74s: study in its own right because it was\n543.72s: kind of interesting\n544.98s: um and the questions for this were then\n546.6s: yeah it does the cross-validation the\n548.7s: evaluation strategy have an impact on\n550.74s: the interpretation you get and is there\n553.019s: a way that we can find out what the most\n554.82s: plausible explanations are and which\n557.399s: strategy uh gives us those\n560.16s: so the idea is very simple\n562.32s: um a lot of similar papers um that I\n564.72s: read basically they take uh all the\n567.54s: growing season climate indices and they\n569.94s: try to predict the yield anomaly\n572.279s: um this is then a machine learning model\n573.839s: so it's usually a random forest for\n576.72s: agricultural studies that's definitely\n578.16s: the most popular but lstms have also\n580.74s: been used and then they Chuck on a\n584.279s: post-hoc interpretation method feature\n586.68s: importances sharply values partial\n588.48s: dependence plots Etc all have been used\n591.42s: um future importance is the most common\n592.8s: of uh because they're the most simple\n595.74s: and then what I\n598.5s: do is first I want to\n601.08s: um yeah do a sanity check and uh show\n603.959s: that the evaluation is\n606.839s: needs to consider the spatial temporal\n609.18s: autocorrelation because a lot of a lot\n611.279s: of studies\n612.3s: um doing this just use random K fold for\n614.94s: example which ignores this correlation\n616.5s: and but then more interestingly\n620.04s: um because I try to\n621.899s: I get this uh climate indices and yield\n624.779s: anomaly from a from a crop model so I\n627.06s: take the input and output of a\n628.56s: process-based model\n629.82s: but so I'm basically trying to then\n631.62s: emulate this model and then that allows\n634.44s: us to comment on whether the\n636.06s: interpretations we get out are really\n638.16s: plausible based on our knowledge of how\n640.32s: the model works\n642.72s: so there's a lot of information here too\n644.82s: much information\n646.2s: um but basically I kind of run two\n649.44s: different experiments so one where I\n651.959s: really I kept the model the same I use\n654.72s: random first because it's the most\n656.1s: commonly used for this study type of\n658.2s: study and I don't change any hyper\n660.42s: parameters I don't do any feature\n661.98s: selection I use a standard set of\n664.44s: climate indices and the only thing that\n666.899s: I vary is the cross-validation method\n669.3s: and for the interpretation and the\n671.579s: evaluation and then in a second\n673.8s: experiment I also use nested\n675.839s: cross-validation of the same type to\n678.48s: tune hyper parameters and to select\n680.1s: features and so on so this can then\n682.019s: affect the generalization performance on\n685.32s: held out years and regions\n688.14s: but yeah very complicated we moved to\n690.779s: the results basically and also I should\n692.82s: explain the cross-validation methods\n694.32s: that I tested\n696.06s: um so Brandon k-fold just take a random\n698.339s: sample of all my data points my data\n701.399s: points are in space and in time I use\n704.04s: global data at a 0.5 degree resolution\n707.06s: and it's model data so I have a whole\n710.16s: load of it but it's driven by reanalysis\n712.92s: for 60 years so quite a lot of data\n715.38s: points and I pull them all together in\n717.42s: space and time\n718.68s: um I ignore that and so in random\n720.899s: keyfold I just take a completely random\n722.519s: sample of this and then I do temporal\n725.64s: cross validation which is again commonly\n727.8s: used I try some spatial methods and some\n730.44s: spatial temporal methods\n732.6s: um but the more interesting one is this\n734.579s: idea of future space clusters where I\n737.7s: take all my\n739.92s: um\n741.0s: all my input all my data points and I\n744.6s: clustered them very simply using k-means\n746.64s: in the future space so in the climate\n749.04s: space in my 37 dimensional future input\n754.38s: yeah set of features I clustered this\n758.339s: um so the idea would be that for example\n760.74s: one cluster might be particularly hot or\n762.899s: particularly dry it could be anywhere in\n765.899s: space and time and so the model would\n768.0s: never have encountered uh points that\n770.16s: are that hot are that dry so it kind of\n772.139s: forces the model into an extrapolation\n773.82s: regime\n776.82s: this is kind of what the police clusters\n778.8s: might look like so this is just two out\n780.54s: of my 37 features and it's colored by\n783.3s: the cluster here so you can see that\n785.16s: they're they're yeah they're in this\n786.899s: feature space\n789.839s: so first of all the sanity check like I\n792.36s: said\n793.26s: um looking at the performance scores\n796.56s: um so this is again the model is kept\n798.72s: the same I'm just trying to predict\n800.579s: yield anomaly\n802.74s: um from 37 growing season climate\n805.26s: indices\n806.339s: and when I measure performance using\n808.38s: random K fold I get above 0.8 which is\n812.339s: pretty good pretty pretty good\n815.04s: um unfortunately when I then evaluate\n816.899s: the model skill\n818.579s: um on unseen years or unseen regions\n820.74s: that plummets on unseen regions in years\n822.839s: that goes to now 0.4\n825.6s: um\n826.56s: and then when I use a different kind of\n828.36s: cross-validation strategy this is a more\n829.98s: close but you get a lot more variation\n831.779s: and so this is not particularly exciting\n834.36s: there's been studies like this before\n835.8s: and this comes from the autocorrelation\n838.5s: in the spacesuit temporal data that is\n840.3s: ignored the model overfits the model is\n842.399s: able to cheat bitmodel learn some\n844.8s: shortcuts some spurious correlations\n847.56s: that it then can't exploit when you take\n850.079s: it into a new regime\n852.24s: uh Elizabeth I have a question yeah the\n855.0s: same model here is this I'm assuming\n857.339s: this is a statistical model and not the\n858.779s: process-based model right so this is so\n860.76s: basically what I'm doing is the data\n863.1s: um that I'm trying to predict is from a\n864.72s: process-based model so it's kind of a\n866.339s: model experiment there's no\n867.839s: observational data here so in theory the\n871.5s: model is completely driven by this\n873.42s: climate data there aren't any um other\n876.18s: effects that I'm ignoring really so it\n878.76s: should be possible to get really really\n881.279s: good performance\n882.66s: theoretically and this the model I then\n885.779s: trained to emulate that model is a\n888.24s: random Forest\n889.56s: okay good good so you're comparing a\n891.779s: random for a statistical model on just\n893.699s: model outputs and exactly yeah\n896.579s: yeah the thing is\n898.68s: um\n899.459s: yeah the thing is that if I did this\n901.56s: with observational data I wouldn't be\n903.42s: able to have a yeah I wouldn't be able\n905.519s: to comment on the interpretations\n906.899s: whether they're you know plausible or\n908.699s: not because we yeah there's just too\n910.26s: much complication there that was the\n912.12s: motivation between using this model data\n914.76s: yeah\n917.699s: so maybe I'd move on to the\n919.92s: interpretations where I looked at the\n922.26s: future importances which is the\n924.24s: permutation feature importances which is\n926.1s: uh yeah the most common possible and\n928.019s: most simple I think way to interpret a\n930.12s: model\n931.32s: um and a bit complicated graphs here but\n934.38s: as you see along the along the left here\n937.199s: you see the different types of\n938.82s: cross-validation that I used along the\n941.1s: right are the different climate indices\n942.72s: that I used so I use a monthly\n945.899s: temperature averages radiation averages\n948.3s: and precipitation averages for three\n950.699s: months before sewing and then seven\n954.0s: months after sewing and then on the\n956.399s: bottom right some hand-picked extreme\n958.56s: indicators like the number of warm days\n960.66s: cool days frost days maximum temperature\n963.48s: in the growing season minimum\n965.279s: temperature in the growing season yeah\n968.399s: these are quite standard ones taken from\n970.62s: literature and the darker the shade here\n973.86s: the most important the more important\n976.139s: that feature is\n977.519s: and the size of these white circles\n979.62s: reflects the variation between the folds\n982.62s: because I do 20-fold cross-validation I\n985.68s: get a different feature important score\n987.839s: in each of those 20 folds so this can\n991.019s: vary or not and that's what the white\n993.36s: circles represent\n995.699s: um and\n996.66s: the first thing the obvious thing is\n999.36s: that they do agree on a lot of things no\n1002.12s: matter what cross-validation method you\n1003.62s: use we see that precipitation for two\n1006.74s: and three months after sewing uh is the\n1009.259s: most is really important and also the\n1011.06s: number of warm days during the growing\n1012.44s: season is really important which makes a\n1014.12s: lot of sense\n1015.44s: um for trying to predict May's yield\n1017.779s: like that makes a lot of sense but\n1020.18s: unfortunately we also see some\n1021.74s: differences and I think this one is the\n1024.86s: one and we're released happy with which\n1026.839s: is the radiation three months before\n1028.939s: sewing which is actually uh if you use a\n1033.199s: random if I use random K fold to\n1035.12s: calculate this this is the most\n1036.86s: important radiation feature of all more\n1039.14s: important than radiation three months\n1040.88s: after sewing\n1042.38s: um when photosynthesis is actually\n1044.36s: occurring\n1046.04s: um which doesn't seem right and\n1049.46s: um there's a huge difference\n1051.98s: and um here's another way of looking at\n1054.799s: this where the the ranked features are\n1059.179s: on both axes using random keyfold is the\n1062.12s: Y and using this feature clusters method\n1064.52s: is on the X and the lower is the most\n1067.76s: important and if they agree they should\n1069.74s: allow on this blue line and you see they\n1071.539s: do agree that frost days is not\n1073.28s: important at all and they do agree that\n1075.919s: warm days is super important in the\n1077.78s: bottom left-hand side and also the\n1079.46s: precipitation two or three months after\n1081.2s: growing but you can see that really\n1083.78s: really far away from all the other\n1085.039s: points is this radiation Point here\n1087.26s: where radiation three months before\n1089.24s: sewing is really really important using\n1092.96s: random keyfold and super unimportant\n1095.12s: using feature clusters\n1099.38s: now\n1100.82s: um\n1101.66s: there's a this is a really really big\n1103.28s: difference\n1104.36s: um and\n1105.58s: this kind of worries me a bit because\n1108.559s: um yeah if you do this type of study and\n1111.679s: these studies are done a lot and you fit\n1114.08s: a model and you use a random use random\n1116.539s: k-fold estimate your performance or a\n1118.52s: random test set you get a you get an R\n1120.559s: square score of like above 0.8\n1123.62s: um and then you take your feature\n1125.6s: importances and you get these some of\n1128.419s: them are very very plausible and there's\n1130.52s: very little variation between the folds\n1132.2s: these white circles are very tiny and\n1134.48s: you think these are really really\n1135.44s: confident and but this score for\n1137.539s: radiation really goes against\n1139.88s: um how the model actually works which is\n1141.62s: lpjml it it really doesn't make sense at\n1144.44s: all this is some kind of spurious\n1146.6s: correlation that is being learned that\n1148.28s: the model is using to cheat basically\n1149.84s: and that's what that's what we think\n1153.38s: um and another reason we think this is\n1155.419s: because when I then do the second\n1157.52s: experiment where I then use nested\n1159.38s: cross-validation to tune and to select\n1161.78s: features and the only the only case for\n1167.12s: which the performance actually increases\n1169.28s: on the Unseen years and region after\n1170.72s: tuning is when I tune using feature\n1174.38s: space clusters again for all others the\n1178.22s: performance stays the same or actually\n1179.96s: decreases the model generalization\n1182.24s: performance which is another reason why\n1184.94s: I think that the\n1186.679s: um features selected and the importances\n1189.26s: you get using this kind of feature\n1191.36s: cluster extrapolation space are more\n1193.34s: likely to be\n1194.84s: um like the the closer to the causal\n1197.9s: drivers\n1200.24s: um but we're really confused why this is\n1202.88s: um we thought maybe there was future\n1204.559s: collinearity when you calculate\n1206.299s: permutation importance you see that you\n1208.46s: can um if you have a highly correlated\n1210.559s: feature and you permute one you can get\n1212.72s: something that's super super unrealistic\n1214.52s: and this has been\n1216.44s: um yeah this has been pointed out by\n1217.82s: many people as maybe a reason for this\n1220.1s: kind of dodgy behavior\n1222.919s: um and so when I looked at my data as\n1225.679s: you see this is uh just two of the\n1227.36s: features and there is this correlation\n1228.86s: right\n1230.059s: um and on the left you see the raw data\n1231.98s: and on the right you see the artificial\n1233.84s: points that are created when you permute\n1235.76s: when you calculate permutation feature\n1237.32s: importance you permute one feature and\n1239.299s: you can see the correlation disappears\n1240.86s: and a lot of these data points are\n1242.48s: probably completely unrealistic on the\n1244.82s: other hand when you use feature clusters\n1246.86s: so you are only permuting over a much\n1250.16s: narrower space\n1252.08s: the correlations are much much more\n1254.6s: preserved so the dead artificial data\n1256.58s: points that you're using to interpret\n1258.32s: your model are much more realistic\n1261.02s: and this this made us get really excited\n1263.299s: and then you can see this kind of holds\n1265.94s: everywhere so the middle is the\n1267.98s: correlation between the original data\n1269.78s: points on the left is the correlation\n1271.64s: between the artificial data points when\n1273.5s: you use this when you just\n1275.299s: um yeah use it do it randomly do it over\n1278.36s: the entire distribution and on the right\n1280.64s: is when you permute using this feature\n1282.919s: space clusters so in inside each cluster\n1285.26s: individually you permute and it's not\n1287.419s: perfect but it preserves a lot of this a\n1289.46s: lot of the multivaric correlation\n1291.679s: and we got really excited but it turns\n1293.659s: out that's not why that's not why it\n1295.88s: doesn't know why the effect is happening\n1297.5s: at all\n1298.34s: um because then we try to use these more\n1300.799s: realistic Community data points but\n1302.84s: still\n1303.799s: um yeah train and test uh using random\n1305.96s: keyfold using random test sets and\n1307.88s: actually the feature importances didn't\n1309.2s: change at all so it would have been cool\n1311.299s: if that was it but it's not so then why\n1313.28s: is it\n1314.539s: um my theory is that it's because when\n1317.72s: I'm when you do this uh so say you\n1320.059s: you're you're testing on this green fold\n1322.4s: and the model has never seen any points\n1325.7s: in the climate like this and it's forced\n1327.98s: to extrapolate\n1329.539s: um so\n1331.22s: the model can learn a whole load of of\n1334.82s: different rules and a whole mess of them\n1337.88s: and only some of them will then apply\n1340.7s: um into different test sets for example\n1342.82s: and I think the idea is that if they\n1347.059s: if they still apply\n1349.28s: um in the extrapolation setting they're\n1351.799s: more likely to be causal so although you\n1353.9s: learn a whole load of different\n1355.159s: relationships when you train on the\n1356.96s: entire entire distribution only a few of\n1359.72s: them will then carry forward into the\n1361.52s: extrapolation so you have a chance of\n1363.08s: kind of stripping away some of these\n1364.7s: shortcuts\n1365.78s: but this is really just a hypothesis\n1367.76s: another thing I quickly want to say is\n1369.74s: that about the circles and the variation\n1371.72s: between folds a lot of the time and this\n1374.78s: variation\n1376.159s: um in future importance is seen as\n1377.96s: uncertainty\n1379.52s: um like an error\n1381.32s: um but while working on this\n1383.96s: um I we we kind of found that actually\n1386.78s: and this might be more interesting than\n1389.9s: this\n1391.28s: um because the different clusters are in\n1394.039s: different climate regions we can then\n1397.039s: find relationships between the climate\n1400.82s: characteristic of a fold and the\n1402.74s: importance in that fold so you can then\n1404.659s: have a look at the interactions here and\n1407.539s: what we found for example was that um\n1409.64s: warm days uh gets slightly more\n1412.159s: important\n1413.539s: um depending on how warm that cluster is\n1417.44s: and so it's only when you get to about\n1419.6s: 40 warm days on average over the growing\n1422.0s: season and that suddenly it doesn't get\n1425.24s: yeah it's then it then it can get um\n1427.64s: more important but maybe due to an\n1429.44s: interaction with another feature for\n1430.88s: example\n1432.14s: um so we hope this could be used maybe\n1433.58s: to try to find some interacting or some\n1435.44s: preconditioning effects\n1437.12s: so instead of being seen as uncertainty\n1439.52s: as you might see here is more actually\n1442.72s: representing these complex relationships\n1445.64s: that you're trying to compress into a\n1447.44s: very very low dimensional space\n1451.7s: yeah so that's kind of the ongoing work\n1453.679s: now is to try to use this to to find\n1456.2s: interacting interactions between drivers\n1458.72s: and then use this to find compounding\n1461.299s: drivers of extreme impacts\n1464.0s: so yeah I'm sorry I think I maybe\n1465.679s: overrun a little bit in time but yeah\n1467.48s: basically these were the main\n1468.62s: conclusions from the study\n1470.539s: um it's again it's only like one um case\n1473.36s: study on one data set so it's really\n1475.52s: difficult for me to make any general\n1476.9s: conclusions like yes you should always\n1478.76s: do clustering in future space if you\n1480.62s: want to interpret\n1481.88s: um the underlying process\n1483.919s: um but I I'm hoping to explore I have\n1486.62s: explored this a bit more and I'm hoping\n1487.94s: to continue to explore this a little bit\n1489.5s: more\n1490.58s: um and yeah I hope that was interesting\n1492.679s: thanks\n1501.98s: a lot Lily Bell uh you by the way you're\n1505.4s: not overtime at all uh so if you if you\n1508.82s: wanted to save more you're welcome but\n1511.4s: don't no no pressure\n1514.52s: um\n1515.539s: uh any questions\n1522.26s: yeah if you're looking at me I know I\n1524.96s: know\n1525.76s: that was great I mean you uh you were\n1528.26s: super clear you know that was uh pretty\n1530.12s: awesome the way you presented uh\n1531.98s: actually we've been thinking a lot about\n1533.12s: those things you know so I'm asking the\n1535.1s: question but I think it's like\n1536.0s: reflecting a lot of the discussions we\n1538.22s: had in the past you know especially\n1539.36s: about spatial and Temple uh variability\n1541.7s: you know so Francis\n1543.74s: Aya has been looking at uh phenology\n1545.84s: like year to year availability and it's\n1548.059s: very difficult to capture with those\n1549.62s: models right because\n1551.24s: of course if you use machine learning\n1552.98s: and it's very straightforward you're\n1554.419s: going to get the spatial structure you\n1556.22s: get the signal structure really well but\n1557.9s: then the anomalies which are the\n1559.58s: interesting things right you're getting\n1561.919s: you're doing a terrible job actually yet\n1563.6s: capturing most of that you know and so\n1566.48s: it's complicated to know and and Japan\n1568.22s: had the same issue with fires right well\n1570.38s: fires where\n1571.7s: you know if you build a model you're\n1573.559s: just getting things that are kind of too\n1576.26s: simple right I mean there's no fire it's\n1578.36s: a desert right and you're getting fires\n1580.279s: you know so you know and that's not\n1582.38s: interesting right you want to say that\n1584.059s: when it gets getting drier you're\n1585.74s: getting more fires potentially right so\n1587.6s: the fuel is changing you know so there's\n1589.52s: a lot of that where space and season\n1591.919s: already the drivers you know of a lot of\n1594.44s: the baby and the variants and so I'd be\n1596.539s: curious to hear like because you talked\n1598.1s: about those clusters but in a sense\n1600.26s: they capture some of those spatial and\n1602.96s: seasonal variation potentially so yeah\n1604.64s: just be curious to hear your thoughts on\n1606.2s: that yeah no exactly this is really the\n1608.779s: motivation that's why behind yeah like\n1611.059s: looking into this more\n1612.74s: um exactly\n1614.419s: um yeah maybe I can comment a little bit\n1617.24s: on some of it let me have a think\n1619.279s: um I mean\n1620.96s: yeah it is basically the case that yeah\n1622.7s: these clusters are kind of yeah\n1624.86s: um\n1625.96s: although theoretically they can come\n1628.159s: from anywhere in this huge space-time\n1630.26s: Cube that I have\n1631.88s: um in actuality they tend to be a little\n1633.86s: clustered in space and in time of course\n1635.96s: because you do get you know\n1638.0s: um certain like regions but it's not\n1640.46s: they're not completely classed in space\n1641.779s: they're just is this kind of behavior\n1644.059s: um I think the most the the real key\n1647.24s: behind this working a little bit is the\n1649.4s: fact that the model is having to\n1650.84s: extrapolate climate wise\n1653.48s: um so it's not able to\n1656.14s: to make use of these of any kind of\n1660.559s: um spurious correlations that might have\n1662.539s: might have worked in other regions and\n1664.76s: just doing it in space and in time on\n1666.799s: the other hand didn't really work I\n1668.9s: think it really needs to be that the\n1671.72s: distribution of the set of the test set\n1674.0s: or the set that you're using for\n1675.38s: interpretation\n1676.88s: um has to be kind of uh kind of as as\n1680.659s: far away as possible almost in the\n1682.88s: future space and there's some a recent\n1687.02s: paper this year from Hana Maya's group\n1689.659s: um in Munster where they also looked at\n1693.26s: yeah in parallel also\n1695.419s: um using a kind of feature space\n1697.84s: method of doing this too and found that\n1701.0s: in comparison to doing a spatial\n1702.679s: cross-validation doing a feature space\n1704.659s: cross validation also led to better\n1706.48s: generalizability better generalization\n1708.62s: performance\n1710.6s: um in terms of the interpretations I\n1713.299s: feel like a real big issue with a lot of\n1716.6s: research that's using interpretable\n1718.64s: machine learning methods is that you put\n1720.32s: in a lot of calls or drivers and\n1722.179s: anything you get out either you you can\n1725.419s: kind of come up with a story and you\n1728.12s: tend to pick out the things that you\n1729.38s: know to be true and say oh you know I\n1731.779s: found some interesting stuff but when\n1733.7s: you see something that doesn't really\n1735.14s: make sense to you I don't think these\n1737.179s: methods are really validated enough that\n1738.74s: we can really believe necessarily that\n1740.539s: this is actually some causal driver that\n1743.24s: you've found and so I really hope that I\n1746.299s: mean this causal Discovery methods of\n1747.799s: course but then trying to actually get\n1749.539s: them to work on spacesuit temporal or\n1752.12s: real data is really challenging and we\n1754.76s: have a couple people in our group who\n1755.96s: work with causal Discovery methods and\n1757.76s: it's very difficult and doesn't always\n1760.76s: work\n1761.779s: so yeah I mean I'm hoping that something\n1763.94s: like this could maybe be something kind\n1765.44s: of in the middle and maybe we can do\n1767.059s: similar studies and with toy data with\n1769.7s: simulated data where we can kind of\n1771.26s: validate that these work and under what\n1773.24s: situations they work so that then when\n1775.64s: we move into the observational data we\n1778.399s: can have a little bit more trust that\n1779.899s: they are they are real I'm not sure if\n1781.76s: that answers are a point exactly\n1785.659s: yeah I mean to the gospel point like I\n1787.88s: think the point that you mentioned about\n1789.32s: like oh it doesn't work in extrapolation\n1791.12s: and a good cause of the model should\n1792.98s: work in extrapolation I think yeah like\n1795.44s: Jonas Peter started with this at one\n1797.779s: point and then went and wrote like like\n1800.179s: a hundred page paper which is like yeah\n1803.84s: yeah exactly actually so um I I do think\n1807.38s: that this is connected to this idea that\n1809.419s: he put forward of the environmental and\n1811.34s: variants um for causal Discovery I\n1813.98s: actually had a really long discussion\n1815.48s: with nicolon yako who was his postdoc\n1818.84s: um but I'm not sure who's this post talk\n1820.88s: anymore because now he's moving to\n1823.159s: different Institute but anyway um and\n1825.799s: yeah we're kind of exploring the\n1827.899s: connection there\n1829.399s: um and I also had a quick chat with\n1831.2s: Jacob ringer about this too\n1833.059s: um what I think is I think it could\n1835.1s: easily this could be the connected and\n1837.08s: the thing is that with for environmental\n1838.82s: invariance you assume that you have some\n1841.76s: yeah some environmental variable which\n1844.039s: is\n1844.94s: um having a Cause influence on your\n1846.799s: features on your predictors but they're\n1848.96s: not\n1849.74s: um on your target uh so and\n1853.7s: I think in in a lot of and that seems\n1856.159s: like a that seems like a big assumption\n1857.659s: but actually I think for a lot of things\n1859.1s: this this does hold maybe in climate for\n1861.799s: example here these Callisters must be\n1864.559s: caused by some uh yeah some climatey\n1868.1s: thing going on I don't know\n1871.659s: but it's not um\n1873.98s: I think it could be reasonable to assume\n1877.039s: that that's not actually\n1878.779s: um\n1879.5s: affecting the day-to-day crop growth in\n1882.799s: comparison but it's a difficult\n1884.419s: assumption and there's not I don't think\n1885.919s: there will be a data driven way to\n1887.12s: validate if the Clusters you get out are\n1888.98s: actually caused by some environmental\n1890.48s: variable\n1896.539s: it's a very good discussion\n1899.799s: sorry of course\n1903.5s: so so in your experiment you have um you\n1906.62s: have a crop model right in the back\n1908.0s: right so you can poke that right you\n1910.7s: know the causal stuff right uh but\n1914.539s: to some extent you know when we build\n1916.82s: those models you know I think there's a\n1918.58s: bunch of\n1920.539s: um\n1921.26s: like confounders you could say I don't\n1923.36s: know if that's the right word but\n1924.26s: whatever you know but there's basically\n1926.36s: a spatial and temporal correlation in\n1928.88s: the in the input features right uh so\n1931.82s: it's a mess you know you could get and\n1933.44s: maybe you're under sampling that as well\n1935.0s: you know so you're not really getting\n1936.5s: the diversity you need\n1938.919s: internally uh you could have like\n1941.6s: epistemic errors right the structure of\n1943.88s: your model is incorrect as well right I\n1945.679s: mean or you're struggling to get that\n1948.02s: right and then on the other output\n1950.12s: because you're trying to build those\n1951.2s: correlations so you have those\n1953.12s: confounders there maybe the dimension of\n1955.7s: the this how can I see the dimension of\n1958.46s: the observation is too small right so\n1960.98s: you're not really sampling your your\n1963.08s: face space the right way right and I can\n1965.72s: feel that if you have a model in the\n1967.52s: back you could test all those all of\n1969.08s: those different hypotheses like is it\n1970.58s: the input is it internal or is it or is\n1972.919s: it just a you know yeah\n1976.399s: yeah the thing is um yeah I thought\n1978.5s: about this as well um and um also this\n1981.2s: is a topic in my group a little bit too\n1983.419s: um we actually had a bit of discussion\n1985.52s: in this in the retreat but then the\n1986.96s: question is how to generate the forcing\n1988.88s: data to produce\n1991.039s: um because you still want to have\n1992.84s: realistic climate data that has these\n1995.299s: drivers that identify\n1997.159s: um it's difficult to to generate this\n1999.38s: kind of multivariate\n2001.36s: um realistic climate data that has these\n2004.24s: bigger features that they put for\n2005.559s: example one of these indices is number\n2007.0s: of warm days yeah I can increase the\n2009.64s: number of warm days but how to increase\n2011.559s: the number of warm days in in a way that\n2014.44s: kind of makes sense and then when I run\n2016.779s: the crop model I also need to keep it\n2018.46s: they run uh steadily for many many years\n2021.7s: you don't just like run them for a year\n2023.38s: and then stop they need spin-up period\n2025.36s: and so on so it's a little bit difficult\n2026.74s: actually to kind of do this um do this\n2028.84s: prodding and really and really and\n2030.22s: really look at this\n2032.019s: um which is why maybe now we move on to\n2033.88s: we move on to some toy data some\n2035.559s: simulated data so that we can produce it\n2037.96s: a bit easier that's um yeah part of the\n2040.659s: part of the plan now I think\n2043.36s: um\n2044.08s: but yeah the other thing is I think um\n2046.24s: one of the things with causal Discovery\n2048.28s: is\n2049.359s: um because yeah now I try to relate this\n2050.919s: a bit to causal Discovery and\n2052.119s: environmental invariance and I guess the\n2054.099s: thing there is that\n2055.599s: um\n2056.619s: what I do here is a bit different\n2058.179s: somehow because\n2059.5s: um I'm looking for\n2062.2s: I look for relationships that you learn\n2064.3s: in the training set that still apply in\n2066.639s: the test set\n2068.02s: um so I will I will not get any\n2070.899s: relationships that are lost from\n2073.839s: um from mispecification for example\n2076.839s: um but I should try to it's more that I\n2080.02s: want to reduce the spurious stuff reduce\n2082.78s: the um the shortcuts that are able to\n2085.899s: learn so yeah I think I can't I can't um\n2088.24s: I don't see this working as in this is\n2090.52s: definitely going to to to give you back\n2092.8s: the causal structure because yeah\n2094.119s: completely these problems will emerge\n2095.619s: but maybe this is more of a strategy to\n2098.08s: get rid of some Spirits get rid of a few\n2100.78s: Spirits correlations or some of the\n2102.4s: shortcuts\n2104.5s: but it's not as rigorous as causal\n2106.119s: Discovery at all\n2114.359s: very interesting I'm wondering if you\n2116.92s: can maybe walk through in a little bit\n2119.14s: more detail how\n2121.42s: um you use the different validation\n2123.76s: methods in the feature selection and\n2126.4s: tuning part like that second set of\n2128.619s: experiments you did yeah sure\n2131.44s: um so basically\n2133.42s: um I take my entire Big Data Cube test\n2136.359s: set in space and in time\n2138.16s: um and then I do 20-fold\n2139.72s: cross-validation but then um so then I\n2142.359s: have 19 now for my training set\n2144.94s: um and then inside this 19 I then do\n2147.579s: another another cross validation\n2150.76s: um while I do tuning and feature\n2153.04s: selection so\n2155.26s: um so I ended up doing that 20 times in\n2157.96s: these different uh 20 outer folds so I\n2160.599s: end up with 20 complete 20 different\n2162.52s: models because they have different\n2163.78s: feature sets and different hyper\n2165.52s: parameters actually\n2168.04s: um and\n2169.839s: yeah the features selected are also\n2171.94s: interesting\n2172.839s: um because they barely vary at all for K\n2176.2s: fold you get basically the same features\n2177.76s: being selected in every single fold and\n2179.8s: whereas for future clusters you do get a\n2181.42s: lot of variation\n2183.04s: um but for example the this this\n2185.98s: radiation feature this radiation three\n2187.839s: months before sewing that's never\n2189.46s: selected at all uh that's never picked\n2191.98s: up I think\n2193.42s: um whereas of course it's picked up\n2194.68s: every single time for k-fold\n2196.78s: um so anyway yeah you end up with\n2197.98s: different models with um different\n2199.359s: features and different\n2200.859s: um yeah the tuning is different so the\n2202.72s: structure of the model is different and\n2204.4s: which leads to the difference in\n2206.2s: performance when I take it to the Unseen\n2208.0s: years and regions\n2217.18s: yeah so do you use all those models\n2221.2s: together to characterize or like or with\n2224.8s: each of those individual points a\n2226.24s: different model\n2228.46s: um yeah let me go back so um I think the\n2230.98s: only plot I showed from this was this\n2232.48s: one\n2234.099s: um and this one you can see that you get\n2236.26s: 20 different points which is the\n2238.54s: performance from the 20 different models\n2241.3s: I see okay the other results I showed\n2244.18s: were from um where the model was the\n2246.339s: same in all cases it was really yeah\n2248.44s: this is the only one I show I think\n2249.7s: where I after the tuning in the future\n2251.68s: selection the thing is that once I've\n2253.54s: done the future selection\n2255.099s: um it's no longer easy to compare the\n2256.72s: interpretations because they all have\n2258.22s: different features in um so yeah not so\n2261.46s: easy anymore\n2268.96s: Alto Forks online if you have a question\n2271.06s: and please\n2272.44s: um jump in\n2279.16s: I mean I can also mention um because I\n2281.14s: also I didn't put this in the paper but\n2282.88s: I did also do this a partial dependence\n2284.74s: plus and I get a similar effect\n2288.04s: um so\n2289.0s: um the partial dependence plots\n2291.099s: um using keyfold were\n2294.099s: very different to the ones I get using\n2296.74s: feature clusters\n2298.359s: um but in this case if so when you do\n2300.4s: permutation and future importance you\n2302.68s: compare against the real data right\n2305.32s: um whereas in partial dependence plus\n2306.7s: you don't you're just showing the model\n2308.44s: performance how it would be you're not\n2310.0s: comparing against you know what it\n2311.56s: should be\n2312.94s: um but you do but still I get that the\n2316.42s: um\n2317.38s: yeah but the the permutation is super\n2320.74s: different\n2321.88s: um I think that more comes from the\n2324.22s: thing I showed um how the the generated\n2327.64s: features are more realistic\n2330.579s: um because simulated permutation\n2331.839s: performance when you calculate partial\n2333.22s: dependence plus you're obviously\n2334.42s: creating these artificial data points\n2336.04s: that could be completely unrealistic\n2337.96s: based on these correlations and so I\n2340.06s: think when I when you do this uh about\n2343.3s: restrict it into these feature clusters\n2345.82s: um you restrict it to more realistic\n2348.28s: points yeah so I got different\n2351.16s: um relationships coming from each from\n2353.619s: each cluster\n2355.119s: um but actually\n2356.079s: um I think you can get more information\n2357.16s: out of that I think it's actually more\n2360.099s: representative of the way the model\n2361.9s: works\n2363.579s: yeah this is another paper because it\n2365.2s: just got too too long\n2369.76s: I mean can I can ask about the paper\n2371.8s: like from uh from uh\n2374.02s: like how was the refereeing Etc like\n2376.48s: because it's a new journal and I I\n2378.28s: wonder like how they were how they\n2379.96s: received this paper given that I think\n2381.76s: this is extremely important but like I\n2384.94s: can imagine you know the community being\n2386.859s: a little like ah yeah\n2389.56s: I've actually been so surprised because\n2391.96s: um so I I mean I started doing this\n2394.54s: because I wanted to know the answer for\n2396.22s: my own research it wasn't like I planned\n2398.26s: for this to become a paper I really just\n2399.94s: needed to know the answer\n2401.5s: um just for myself\n2403.96s: um and you know it's not it's not the\n2407.32s: most exciting topic to say people like\n2409.3s: what are you working on I'm like\n2410.38s: cross-validation people get a bit bored\n2413.38s: so I I know I was really and also it it\n2416.099s: seems like a very basic thing that um\n2419.14s: should have been that should be done I I\n2422.14s: was really convinced there must be some\n2423.7s: huge body of work that I just hadn't\n2425.2s: found where this was already explored\n2427.06s: and already you know existing and I\n2429.22s: really I spent a lot of time hunting\n2430.96s: through different things\n2432.64s: um and if someone did does find\n2434.02s: something please send it to me because I\n2435.339s: still believe it could be out there\n2437.5s: um\n2438.099s: yeah so I really expected it to be you\n2440.56s: know oh great would this paper sounds\n2442.0s: boring um yeah I'm not really\n2443.56s: interesting but no I had a great\n2444.76s: experience with the journal actually and\n2446.38s: the review period was it was super fast\n2448.24s: and also I got three reviewers and all\n2451.06s: of the comments were really on point\n2452.74s: they really got what I was trying to do\n2454.3s: and they were really interested as well\n2457.599s: um yeah they had a lot of ideas\n2460.48s: um I think one of them was like I know\n2461.8s: you can't do all of this in the paper\n2462.94s: but it's really but it's interesting and\n2466.06s: yeah I had a great experience like\n2467.44s: really it was super super nice and I'm\n2470.02s: actually surprised as well and when I've\n2471.52s: been to conferences or like I presented\n2473.44s: this a little bit I've had a lot of\n2475.24s: people being engaged or like wanting to\n2477.339s: talk about it more or like follow up a\n2479.38s: little bit so I feel like yeah I also\n2481.839s: thought this was like a boring topic\n2483.94s: somehow people were gonna not really\n2485.38s: want to know about it but I think\n2487.48s: actually\n2488.38s: um people are starting to get really\n2490.359s: interested in model evaluation in\n2491.8s: general\n2492.82s: um\n2493.54s: and also interpretation is really taking\n2495.46s: off so maybe somehow\n2497.859s: this is all kind of\n2499.48s: becoming more interesting\n2505.72s: I had a quick question actually thank\n2507.46s: you for the time um so I was just\n2509.32s: wondering if you did a similar type of\n2511.359s: analysis about using like shapley values\n2513.7s: and more broadly okay\n2522.4s: um so I think it would still hold\n2523.54s: basically\n2524.56s: um that's what I think but I don't know\n2525.94s: so I did um actually one of my\n2528.04s: colleagues uses shapley values um for\n2529.839s: another experiment and I did send in my\n2532.96s: future clusters because it's just a tiny\n2535.119s: little code it's like a it just it fits\n2537.4s: with cycle learn you know it's nothing I\n2538.96s: just sent it to him was like just try\n2540.82s: just try\n2542.74s: um\n2544.68s: and he did\n2547.0s: um and actually yeah there was some\n2548.2s: there was some difference\n2549.579s: um in what he got out but it was quite\n2551.2s: small\n2552.339s: um and\n2553.48s: um it was also difficult to say because\n2555.46s: this was trained on observation data it\n2557.68s: was a different field so it was\n2559.18s: difficult to say you know\n2560.68s: um what's right what's wrong I don't\n2562.599s: know but um I I think that it yeah I\n2566.68s: think that it was um and the model was\n2568.48s: actually really really excellent and he\n2570.22s: did test it very thoroughly um in like\n2572.98s: um different catchments and it was a\n2574.78s: hydrological one um but there was there\n2577.0s: was a bit of a difference\n2578.619s: um and I do think the same thing would\n2580.96s: happen and also I have to say since I\n2583.599s: finished the paper I got really into\n2586.119s: um adversarial robustness reading\n2587.98s: because this is also connected\n2589.78s: um it's just that in adversarial\n2591.52s: robustness it's not enough to say that\n2593.92s: the interpretation is affected by the\n2595.66s: data input you have to say I found the\n2597.88s: most worst possible I found an algorithm\n2600.28s: that can find the worst possible data\n2601.96s: input\n2602.8s: um so you have to put this kind of spin\n2604.119s: on it but there is a couple of papers\n2605.859s: showing that also shapley values are\n2609.0s: adversarially vulnerable to adversarial\n2611.38s: attacks by which selective data Choice\n2615.04s: um to to kind of perturb what you get\n2617.98s: which I think means this would also\n2620.02s: happen\n2620.859s: um but I really want to extend because\n2622.48s: the thing is I have all the code\n2624.339s: um for this whole experiment it would be\n2626.079s: very easy to just plug in the chapty\n2627.579s: values and kind of do it\n2629.2s: um but I guess I wasn't sure the paper\n2631.0s: was already so long just with feature\n2632.619s: importances\n2634.0s: um and now I feel like if I do another\n2637.54s: if I do it for partial dependent Sports\n2639.64s: and shapley values that's kind of it's I\n2642.099s: already you know I already did this\n2643.48s: paper is it is it novel is it enough but\n2646.9s: I also feel like this information should\n2648.22s: be out there or like these results\n2649.42s: should be should be published somewhere\n2651.28s: that people can see\n2653.02s: I don't know\n2655.18s: thank you thank you\n2658.3s: what is the reference for the\n2659.68s: adversarial uh robustness\n2662.26s: um like could you could you like I don't\n2664.66s: know email it to me or something yeah I\n2666.819s: can email it to you definitely yeah\n2668.98s: um yeah I really only got down this\n2670.66s: Rabbit Hole the last few weeks actually\n2672.28s: because I always was like you know\n2674.8s: I mean I read a couple of adversary bus\n2677.02s: newspapers a while ago because I wanted\n2678.7s: to have citations for\n2681.46s: um machine learning isn't always perfect\n2684.22s: um\n2686.74s: but I didn't um get really into the\n2688.9s: rabbit hole and then the last couple\n2690.099s: weeks\n2691.06s: a week into it and I I really see a lot\n2692.74s: of similarities there's another there's\n2694.24s: another paper I read\n2695.92s: um about partial dependence plus MSO\n2698.319s: robustness where they um they actually\n2700.18s: train a genetic algorithm that they use\n2701.8s: a genetic algorithm to um find the most\n2705.52s: different possible\n2707.619s: um yeah the data points that can give\n2709.48s: you the most different possible and\n2711.4s: partial dependence plot um and it's kind\n2715.06s: of nice but also I feel like um\n2719.38s: yeah I mean for us um where we're not\n2722.8s: worried about you know uh people trying\n2724.96s: to hack into our models and uh or like\n2728.92s: pretend that the models are not uh\n2731.44s: sexist or something\n2733.0s: um it's enough to say that the\n2735.339s: interpretation is affected by the data\n2737.14s: set Choice\n2738.4s: um so\n2740.02s: it's like um\n2741.819s: if you think so so I think there's a lot\n2743.98s: of papers probably in this adversary\n2745.54s: robustness space that can also apply for\n2747.76s: what we do\n2749.02s: um I I just personally wasn't aware that\n2751.3s: it that it did apply um for the framing\n2765.22s: um\n2766.359s: yeah since they're I guess there are no\n2768.099s: more questions at least online so I\n2770.079s: think we can wrap this up officially but\n2772.24s: if you want to stay on like yeah\n2776.56s: um\n2778.02s: in Germany I guess ah yeah\n2782.14s: yeah it's like 25 it's like 20 past 10\n2785.26s: but I mean I've got no plans now\n2789.78s: and yeah yeah that reminds me thank you\n2792.819s: again Lily Bell for like taking out the\n2794.74s: time\n2795.819s: no worries thanks for inviting me\n2799.24s: thanks so much\n2805.599s: foreign"
    },
    {
        "class": "YouTubeVideo",
        "title": "Navigating the Academic Search Process with LEAP PIs",
        "videoId": "_1iEl_nOk7A",
        "url": "https://www.youtube.com/watch?v=_1iEl_nOk7A",
        "publishedAt": "2024-04-03T15:35:03Z",
        "transcript": "6.52s: right well great to see so many people\n9.36s: uh and thanks to Molly uh for organizing\n12.28s: and putting the panel together um so\n15.519s: it's definitely kind of you know\n17.119s: exciting and also you know stressful\n19.64s: when you're on the other side right kind\n21.24s: of applying for jobs uh so what we're\n23.599s: going to try to do is give you you know\n25.16s: our perspective on you know how to\n28.32s: navigate the job market I guess an\n30.56s: emphasis on faculty jobs uh which is\n32.8s: where we have most experience the first\n35.0s: thing I always say is that you know we\n37.04s: are one data point each even though you\n39.6s: know we might have a lot of years of\n41.44s: experience and things like that so you\n42.8s: know take that with those are you know\n45.44s: data points not necessarily the you know\n48.0s: the blueprint to everything so kind of a\n50.64s: little bit of a world of caution but\n52.8s: thir thing is you know you need to apply\n54.92s: right to uh to get a job in a way um and\n58.16s: you know when when you put your\n59.559s: application\n60.519s: together um you know the first thing I\n62.96s: guess we all want to see is you know\n65.84s: you're telling a story so we want to see\n67.96s: your story your academic story in a way\n70.68s: uh and it's more than just bullet point\n72.159s: I've done X Y and Z but it's you know\n75.04s: what are you excited about what are the\n76.92s: big questions you're trying to solve how\n78.759s: you're trying to solve it and this is\n80.799s: very much kind of the approach that I\n82.96s: guess will be reflected when you give a\n84.56s: talk when you write your statement it's\n86.439s: it's really kind of telling your story\n88.04s: why you know why you're doing what\n89.52s: you're doing how you're doing it and why\n92.0s: it's you know it's so exciting and so\n93.88s: important and why you're the good\n95.24s: candidate in a way so you know it all\n98.04s: comes by putting documents together uh\n101.32s: and you know the first thing you have to\n103.36s: do is of course making sure that you\n105.6s: know you fit the department the\n107.159s: requirements that you have and so on and\n109.04s: so forth so you know that would be kind\n111.04s: of the basic advice right so you look\n114.0s: for a job try to see how you fit best\n117.399s: you know the requirements again and\n119.159s: requirements in quot it's tell your\n121.159s: scientific story uh in a way you're\n123.32s: trying to\n124.439s: tell\n127.039s: um P you know panels review or\n129.52s: committees review a lot of applications\n131.879s: right and so always kind of keep that in\n133.64s: mind you putting a lot of time and\n135.519s: effort in it but there are lot of things\n138.879s: that have to be read so you know make\n141.12s: sure you're suent and again you're\n142.72s: telling your story as quickly as\n144.36s: possible so usually what we like to see\n146.4s: in the first kind of paragraph of a of a\n148.76s: research statement is you know again\n150.68s: kind of the the story who you are what\n154.16s: you're trying to solve how you're trying\n155.519s: to solve it and telling us why you're so\n158.239s: excited about this so that's something\n160.4s: that kind of you know we kind of enjoy\n162.68s: you know seeing right right at the start\n165.36s: and then going into you know what you've\n167.159s: done in the past what is your big vision\n169.76s: for the next you know five years or so\n171.879s: people you know are looking for what\n174.319s: other the big problem you're going to\n175.44s: solve you know how you're going to you\n176.92s: know advise PhD students pstu and so on\n179.599s: and so forth so so this is kind of you\n181.64s: know one of the big piece of the\n182.92s: research statement I would say I think\n184.599s: my colleagues will talk more about you\n186.12s: know how how to write this uh together\n189.0s: there are a lot of documents to prepare\n191.48s: don't underestimate how long it takes it\n194.4s: yeah so I can see everybody nodding\n196.36s: takes a lot of time to prepare and again\n198.64s: takes a lot of effort uh but they are\n201.04s: important again you know each piece of\n203.4s: your application give some information\n206.4s: to the panel so you also don't need to\n208.4s: repeat yourself many times you each\n210.4s: document wisely in a way right so your\n213.12s: cover letter is a little bit of a way to\n214.92s: introduce yourself and you know telling\n216.84s: the committee you know why this\n218.92s: application why this place why how\n221.2s: you're going to collaborate with people\n223.239s: how you know how do you see yourself in\n224.84s: the department in the university and\n227.64s: actually in the community as a whole\n229.599s: then your CV is a little bit more bullet\n231.36s: point you know there my PhD is what I\n233.879s: done as my publication your research\n236.48s: statement what you've done in the past\n238.64s: your vision how you know you're going to\n241.079s: change the world uh in a way and so\n243.48s: really each document gives a little bit\n245.959s: of something um and so that's important\n248.2s: to use the documents again in a way that\n250.319s: is useful\n253.239s: um as I mentioned you know the opening\n255.48s: of your statement is important the the\n257.68s: closing is as important when I you know\n260.199s: when we start reading application we\n261.56s: want to be excited about a candidate so\n263.479s: understanding what they want to solve\n265.16s: how then we go through the detail so\n267.88s: people are telling us their story I've\n269.52s: done X I've done y this is why it\n272.0s: matters and then at the end you know we\n273.6s: want to invite them for interview so the\n275.68s: closing has to be you know something\n277.52s: exciting the vision the\n279.72s: future um in the little warning I always\n282.84s: say be careful with the kitchen sink\n284.88s: approach where you list everything\n287.039s: you've\n287.88s: done without tying the story together\n291.4s: and so you know again we all have this\n293.56s: kind of attitude that we're excited\n295.199s: about what we do right so we want to\n297.0s: tell people about it but there's always\n299.36s: this of balance making sure that you\n301.6s: know you balance the detail with the\n303.24s: vision so that that would be my little\n305.8s: kind of two cents since I'm first and I\n308.039s: know a lot of things will come up I I'll\n310.08s: stop here just again because I think a\n313.12s: lot of the things will come through uh\n315.4s: and then I can come back uh a little bit\n317.6s: more or take questions now\n321.68s: or that's open up for question okay so\n324.28s: it's not too exactly I like to not talk\n326.56s: for 10 minutes yeah so happy to take\n328.88s: questions on kind of the first part on\n330.44s: you know how you put your applications\n332.039s: and and things like this if there are\n334.4s: any yeah how long does it take to to\n337.88s: prepare everything oh boy it's h I think\n341.28s: the first one you know it will take many\n344.039s: weeks I I have to be honest I think you\n346.52s: know it the CV is usually something that\n348.759s: you have already and so it's just\n350.639s: polishing it the research statement\n352.919s: takes several iteration and and I think\n355.919s: my suggestion as well is you know the\n357.52s: earlier you start the better the advice\n360.44s: I give my you know students and PC when\n362.8s: they go for the faculty job is you know\n365.199s: try to write the first paragraph you\n367.4s: know if you were telling your story you\n369.56s: know this is what I work on this is how\n372.479s: I do it and you know and this is what\n374.919s: I'm going to solve in the next five\n376.199s: years and spend a fair bit of time on\n378.199s: that and write I usually say you know\n380.919s: write three bullet points of the big\n382.919s: questions that you're trying to solve\n385.08s: just bullet points and then start you\n388.0s: know kind of filling in the blanks\n390.319s: um get feedback you know you get your\n394.08s: mentors friends all of that to actually\n396.68s: go through and it you know iterating\n399.199s: helps a lot it gets easier the more you\n402.12s: do it but definitely get you know get\n407.0s: feedback any other questions comments\n410.12s: yes uh maybe on\n413.52s: that yeah sorry yeah I just say yeah\n418.0s: just maybe on that you know um it takes\n420.12s: time for the initial stage I very much\n421.84s: agree with what L uh I think it's very\n424.08s: good strategy to think about the\n425.52s: storyline you know what you want to\n426.96s: present how you want to present yourself\n428.599s: for that particular place and uh you\n432.28s: could say you could just like submit a\n434.16s: ton of uh the same research statements\n436.68s: that's the wrong thing to do right I\n437.96s: mean there needs to be something that's\n439.28s: a bit tailored to the particular place\n440.919s: you're looking at you know what's\n442.599s: specific about that department what's\n444.199s: specific about that job so it does take\n446.44s: even more time right because for each of\n448.24s: them you need to taor that maybe some of\n450.199s: the structure or some of things can\n452.0s: remain the same but you know you would\n453.199s: hope that people would fine tune that to\n455.56s: really fit to uh to to to De to that\n460.199s: department yeah definitely very\n462.4s: important to make sure that the\n463.759s: application doesn't read as the one I\n465.879s: submitted everywhere and I would love to\n468.319s: work with all faculty members so you\n470.4s: know make sure you tailor it yeah I was\n473.159s: just wondering if you could if we had a\n474.8s: sense of like how much time you should\n476.56s: spend talking about what you have done\n478.12s: versus what you want to do the\n480.52s: future yeah that's an excellent question\n482.759s: so you know how much the past versus how\n485.159s: much the future um so obviously depends\n487.879s: on Career stage right so the you know if\n490.919s: it's your first you know faculty job\n492.56s: application couple of years out of your\n494.759s: PST deck so you want to you know you\n496.36s: want to build up you know to your future\n498.96s: so so it's you know it's going to be\n500.52s: more about the past in a way which kind\n502.52s: of makes sense right what you've done in\n504.28s: your PhD in your P deck but what's very\n506.28s: important to kind of emphasize in a way\n508.639s: is also you know what you've done that\n511.4s: is a little bit different than your PhD\n513.0s: advisers and your Mentor without saying\n515.32s: it explicitly but the more you can show\n517.76s: that you know this is yours and this is\n520.0s: you know your growth through the science\n523.159s: and through the vision that that's quite\n525.64s: important right and so again it's always\n527.279s: hard to tell the balance but usually we\n529.44s: expect someone to work on something over\n531.399s: the next five 10 years based on what\n533.04s: they've done in the past and it's not\n535.32s: necessarily the topic but it's more on\n537.12s: you know how they push things forward\n539.56s: and so you know in general the\n542.04s: statements are about I would say you\n544.519s: know two3 past onethird future again\n547.88s: roughly spread in a in a different\n550.64s: fashion in a way um but you\n553.48s: know what you're going to do in the next\n555.56s: five years you can use what you've done\n557.2s: in the past and show how you\n559.519s: demonstrated that you can push those\n561.32s: things much further on your own we your\n564.72s: own team any a\n568.36s: way\n570.279s: any other\n574.88s: questions oh uh will Gregory hey\n579.36s: Will H thanks for that intro um I was\n583.16s: just curious about whether you might\n585.36s: have any perspective on kind of putting\n587.88s: your proposal together or your cover\n589.24s: letter and talking about um how you'll\n591.6s: collaborate with people in the\n592.68s: department there um\n595.48s: specifically do you have a sense of like\n598.56s: obviously you can refer to people who\n600.32s: will help you facilitate your own\n602.0s: research goals but is there a preference\n604.16s: to showing like I don't know I work on\n606.44s: CIS I can work with this other person\n608.399s: who does atmospheric aerosols because\n610.2s: they're interested in machine learning\n611.32s: or something like that you know or is\n612.88s: that is it better to kind of focus on\n615.16s: how how you'll collaborate in terms of\n617.48s: that facilitating your own\n619.279s: research I think a little bit of both\n621.6s: right so you want to show that you're\n623.72s: going to be excited to be in a\n624.959s: department and that means you can talk\n627.079s: to people who work on similar topic as\n628.88s: yours or things that you want to push\n631.32s: forward then that place is the place to\n633.36s: do it because you know those people are\n635.92s: interested in things you haven't done\n638.2s: yet for example so it's it's very much\n640.639s: about both what you're doing now but\n642.519s: also the growth overall and again when\n645.279s: you go to a place you're not working by\n646.959s: yourself the environment the talks right\n649.12s: I mean for those of us here in leap and\n651.12s: you know you at M Square line there is a\n653.079s: big community and all the people you\n654.8s: interact with you never even thought\n656.36s: about so you know showing that you have\n658.399s: this kind of willingness\n659.76s: in a way and and being open-minded I\n662.04s: think I think that's kind of almost the\n664.079s: you know one of the most important thing\n666.24s: so all of it works thanks on want to\n670.44s: follow up and maybe just an additional\n672.839s: comment on this an advice I received in\n674.639s: the past is not to mention specific\n677.399s: people in your application but rather\n679.399s: talk in terms of research areas because\n681.519s: those you don't mention maybe might\n683.279s: might take it personal\n685.44s: so that's the\n687.519s: ne that's a good point\n693.519s: anyone\n695.2s: else all right\n703.12s: U okay I think I'm gonna continue on\n705.839s: what uh lore mentioned already related\n707.959s: to writing research proposal so it took\n711.24s: me maybe like two three months to have\n713.72s: something that I feel a little bit\n714.92s: satisfied with and uh I could say that I\n717.92s: write more than 10 times and for each\n720.04s: job that I applied I wrote a new version\n722.519s: of it and sometimes it was also a\n724.6s: practice to say okay forget about what I\n726.92s: have and I write it from scratch again\n729.079s: to see like if I can make something\n731.24s: better or like if I can phrase the um\n733.56s: the research that I'm doing differently\n735.399s: and I read a lot of stuff I try to like\n737.44s: summarize what I have read and what was\n739.8s: like the major um suggestions so you\n742.76s: have to have a first paragraph that you\n745.12s: say what you're doing or like what is\n746.76s: your research goal in general what is\n748.76s: the big questions that you're trying to\n750.92s: address and then you continue around\n753.199s: that you start with your what you have\n754.92s: done already what you are doing and your\n756.8s: what you're planning to do and um so one\n760.519s: thing that I read that was interesting\n761.88s: is that it shouldn't sound it shouldn't\n763.68s: seem like you've been assigned different\n766.0s: projects and you were good in in in\n768.399s: finalizing them and getting some results\n770.88s: but it should show some story like you\n773.16s: were interested or you decided to go to\n775.36s: this department and do that specific\n777.519s: project or you had some contribution in\n780.04s: redefining your um your research topic\n782.48s: as well um so that should all come in\n785.519s: like the way that you phrase your um\n787.68s: your state your your written\n790.32s: proposal and um so when when you write\n793.04s: about the future research you have to\n795.16s: have short-term plans and long-term\n796.72s: plans short-term plans are usually\n798.639s: considered as let's say you write a a\n801.519s: you you apply for a grant and then those\n803.639s: short-term plans tells the the title of\n807.199s: the grants that you're going to write um\n809.399s: so that's going to be something for two\n811.079s: years ahead three years ahead to five\n812.639s: years ahead and then you have to have\n814.32s: like long-term plans as well let's say\n816.519s: in 10 years what you want to be doing or\n819.6s: like what big question you have already\n821.88s: answered and then beyond that you have\n823.88s: to also say where you want to be as a\n826.0s: researcher in long term but that's\n828.519s: that's kind of like that was probably\n830.16s: the hardest part for me to like imagine\n832.24s: okay where my research might go but then\n835.16s: a simple way to to think about it is\n837.32s: that okay you're working on a subject\n838.88s: and there's this big problem that exists\n841.24s: in the field well one one way to phrase\n844.04s: it is that okay I want my research to\n845.72s: address that issue let's say if you're\n847.88s: working on um microphysics for example\n850.839s: you want your your research to address\n852.639s: the problem of um modeling\n855.519s: microphysics or um I don't know you\n857.88s: could also say you want to be the best\n859.199s: researcher and then you can also go like\n862.0s: be more creative in term of methodology\n864.12s: I remember I talked to pier and he was\n865.68s: like yeah so you're think you know that\n867.44s: now people are using machine learning\n869.199s: could you like imagine in five years\n870.88s: what would be the new tool that someone\n873.12s: might want to use in order to to address\n875.48s: some of the problems I thought that was\n877.399s: very helpful um so that in term of like\n880.6s: what to write and then you also have to\n882.839s: read really carefully through the job um\n885.279s: job announcement what they want what\n887.32s: kind of job they're doing there and what\n889.399s: are the gaps that they actually have\n891.079s: like job announcement are typically very\n893.56s: general so they say we're looking for\n895.759s: some climate scientists some atmospheric\n897.639s: scientists if they want to be really\n899.079s: detail then they sort of like separate\n900.759s: between atmosphere and ocean but\n902.399s: typically it's only someone from a\n905.079s: relevant background that won that wants\n907.519s: to work on um a collaborative\n909.759s: environment something related to the to\n912.04s: the climate so that's typically the no\n914.68s: my note is\n916.12s: gone um yeah so um it would be then\n919.72s: difficult to kind of tailor your uh\n921.8s: proposal to what to to something that is\n924.72s: more relevant to that specific\n926.36s: department so one way that you can um go\n929.56s: around this problem is to reach out to\n931.56s: someone that you may know in the\n933.519s: department or if you don't know just to\n935.0s: the search committee get a little bit of\n936.8s: more information like what they're\n938.319s: actually looking for do they have like\n940.319s: more specific requirement and if that is\n943.36s: something that is aligned for your with\n945.04s: B your research you can maybe tailor a\n946.959s: little bit to that specific um\n949.839s: requirement um read samples I think I\n952.72s: read many samples the problem is that\n954.68s: samples that are relevant to my field\n956.279s: doesn't exist so like it's it's like\n958.12s: atmospheric scien ocean scientists they\n960.079s: don't share their samples that much but\n962.959s: I read more than 20 computer scientist\n965.48s: samples which I had no idea what they're\n967.92s: doing but then it was interesting\n969.72s: because you you also get the idea that\n972.399s: okay some of the audience that are\n973.88s: reading my research proposal they don't\n975.759s: know exactly what I'm doing so I had to\n977.759s: be able to communicate with them give\n979.399s: them a big picture but also some of the\n981.959s: details of things that are important and\n984.0s: I have done um I think you have to like\n986.36s: Clearly say if you address some big\n988.68s: problem problem you have to Clearly say\n990.8s: that okay that was a challenge and my\n992.8s: research addressed that using this um\n995.959s: this method and if there is a\n997.319s: shortcoming and you plan to like go\n999.6s: ahead and address that shortcoming you\n1001.319s: have to also say that I think that's\n1002.92s: kind of like make it a stronger to not\n1005.56s: just say um what have worked but also\n1008.36s: what haven't hasn't worked and you plan\n1010.24s: to um work on\n1012.24s: that um get feedback from people that\n1015.24s: you know share your your statement with\n1018.12s: your pis your colleagues and ask for\n1020.399s: very critical feedback so like if it's\n1022.48s: an appealing one if if me as an let's\n1025.72s: say um search comedy member read the\n1027.799s: first paragraph would I want to read the\n1030.72s: rest of it or or would I say okay this\n1033.319s: looks like other one so I'm not that\n1035.6s: much interested in reading the rest of\n1037.319s: it so I I read that like\n1039.919s: research comedy members are kind of busy\n1043.4s: they have more than 200 applications and\n1045.76s: they look for any excuse not to read\n1048.24s: your application\n1053.919s: I haven't been in search com but that's\n1056.559s: a joke but this means like yeah you have\n1058.919s: to stand out among 200\n1063.0s: applications no no offense\n1066.32s: sorry\n1068.4s: um yeah I think that's uh that's all I\n1071.2s: have here if someone wants to add\n1077.84s: anything\n1080.76s: yeah maybe just on the last comment uh I\n1083.919s: would frame it the other way around like\n1085.76s: uh it's uh I mean you see so many CVS or\n1089.88s: like statements that are just messy\n1092.159s: right so it's I mean just give people an\n1094.559s: easy time right I mean it has to be very\n1096.44s: polished it has to be very like it has\n1099.4s: to look clean and nice right I mean you\n1101.08s: just want to want to be willing to get\n1103.08s: into it and you can have figures and all\n1105.28s: that you know like CVS has to be like\n1107.039s: easy to read now like all over the place\n1109.2s: and you can't imagine that I would say\n1111.76s: like 80% of like statements and CVS are\n1114.52s: still very difficult to read you know it\n1116.4s: blows my mind like just this polishing\n1118.6s: piece you're already part of a small\n1120.76s: fraction you know and then you're in\n1122.12s: good hands right so that extra m is\n1125.159s: actually very important so you don't get\n1127.28s: in that\n1130.64s: portion here don't mind so actually\n1135.799s: I thanks so actually I wondered like\n1140.4s: this research proposal how important it\n1143.039s: would be because if you're working in\n1145.32s: one field and then there is a faculty\n1148.0s: position and you look at the CV of\n1150.52s: everyone more or less you will come up\n1152.559s: with the same questions I imagine and\n1156.2s: the same methodology so does this will\n1160.64s: take you to the short list and that's it\n1163.76s: or does it is something that also will\n1166.36s: take you further and if it takes you Al\n1169.039s: further than what makes that specific\n1173.08s: person to stand out from the\n1177.88s: rest is they\n1187.08s: clear I can also\n1189.76s: add um yeah I think that's a great\n1191.96s: question um I think all documents do\n1194.28s: matter actually I I think the research\n1196.24s: statement is definitely a it's a big one\n1199.08s: because your CV is you know something\n1201.28s: you can Google and as you said you know\n1202.88s: a lot of people have similar CVS you\n1205.159s: know everybody has a PHD and you know\n1207.24s: has done interesting stuff and people\n1209.24s: have published in general uh but the\n1211.88s: research statement is is again is your\n1213.679s: story and and your story is what matters\n1215.919s: because we're not hiring someone just\n1218.2s: based on a few Publications but we\n1220.52s: really hiring people who want to solve\n1222.799s: big problems with certain methodologies\n1225.2s: and we're going to push the field\n1227.2s: further so so I do think yeah the\n1229.72s: research statement is is clearly very\n1231.84s: important and you know again like Pier\n1234.4s: said I think there are we do have\n1236.2s: hundreds of applications and we we\n1239.12s: actually do read it all by the way but\n1241.52s: it's true that it it does make a\n1243.36s: difference right when when I understand\n1245.52s: what are the big questions and even if\n1247.84s: it's someone who is not in my field then\n1249.6s: they convince me that this is what to do\n1252.039s: and how to do it because you convince\n1254.039s: people who are not in your field as well\n1255.76s: and so that's important what gets you\n1258.0s: the job if only I knew um I think there\n1261.08s: is you know there are amazing people who\n1263.919s: apply and don't get jobs right so I\n1265.919s: think you know we have to be honest\n1267.32s: about this I think people who have jobs\n1268.88s: deserve it but there are tons of\n1270.12s: deserving people who have to apply many\n1272.32s: times and unfortunately it depends on\n1274.2s: the fit of the department as Sarah\n1275.96s: mentioned you know the gaps or what\n1277.84s: people are looking for or the tradition\n1280.279s: or a new area that the department want\n1283.0s: to go in and and that's you could say\n1286.24s: it's a little bit random but that's also\n1287.76s: why it's important to read you know the\n1289.679s: requirement and to talk to people in the\n1291.559s: in the department that you go in because\n1293.679s: there it becomes super specific on the\n1296.24s: needs in a way and so yeah I'm afraid\n1299.4s: that's harder to find a a proper answer\n1301.88s: to but hopefully add to that yeah um I\n1304.799s: think there's also one point which is\n1306.4s: the ad that you see out you know is\n1308.08s: really the emerged part of the iceberg\n1309.88s: right there's a lot of story and what is\n1312.6s: actually the the focus area that you\n1314.64s: have no idea about right and I feel that\n1317.52s: sometimes especially uh talking to like\n1319.799s: female scientist please apply because\n1322.12s: there's I mean lots of studies showing\n1323.679s: that there are some self screening and\n1325.2s: and typically female scientists would\n1327.52s: not want to apply because they feel they\n1328.919s: do not fit and if you see that it's and\n1331.799s: was talking to a friend and she got the\n1333.279s: job and she felt that she she was like\n1334.96s: feeling on only 60% of the job ad you\n1337.6s: know so you have to realize that this ad\n1340.24s: is just a fraction of of the whole thing\n1341.96s: there's going to be a lot of internal\n1344.08s: discussion and politics you know that\n1346.0s: goes with that so please apply even if\n1348.52s: if you don't feel it's a full fit and\n1350.32s: talk to people like if maybe that's a\n1352.039s: good thing to do earlier right to talk\n1354.08s: to the if you know people in the\n1355.6s: especially in the department or get in\n1356.84s: touch with them to see if that would be\n1358.84s: a good match you know but I think you\n1361.64s: should not underestimate like all of the\n1363.6s: background that there is you know in uh\n1365.48s: behind you know\n1366.919s: so and going back to your original\n1369.84s: question I think you know this is uh\n1372.039s: your playing at the edge because if you\n1374.48s: arrive second then it's like as if you\n1377.12s: were a number at 100 so every single\n1379.64s: piece you submitting that matters\n1382.0s: because once you get towards you know\n1384.4s: the last three p people that were\n1386.84s: shortlisted then every single piece of\n1389.72s: material is scrutinized line by line um\n1394.2s: maybe there are some priori some\n1395.6s: screening initial screening strategies\n1397.64s: you know maybe they look first at the CV\n1399.96s: and then at the proposal but once you\n1402.559s: get to the final three everything is\n1404.279s: really analyzed into the the detail and\n1408.559s: I totally agree with also what Pierre\n1410.44s: mentioned that often times you know the\n1413.2s: call is General but look at the\n1414.679s: department what they're doing getting\n1416.559s: contact with someone to get a better\n1419.799s: understanding of what they might be\n1421.08s: looking for um yeah often times there's\n1423.84s: a lot more that you don't know and that\n1425.279s: makes you potentially a very good\n1427.52s: candidate for for that position um and\n1431.4s: also uh that's a much better way to\n1433.64s: actually frame your talk right because\n1435.279s: if you know the audience like know your\n1436.76s: audience that's the number one one piece\n1439.84s: of advice right if you don't know the\n1441.679s: audience you'll be off right but if you\n1443.24s: know that's going to be much more\n1444.48s: targeted so much better\n1452.679s: right more\n1458.96s: questions okay if not I can probably\n1461.559s: take it from here have another question\n1464.64s: but I didn't want to monopolize the\n1467.32s: discussion so\n1469.32s: just\n1472.36s: another like another thing that I've\n1475.12s: heard like from another random date you\n1480.32s: say yeah so is that sometimes it's more\n1483.84s: easily Justified if you have like\n1486.76s: background study in a certain field and\n1489.44s: then you are applying to a department or\n1492.399s: advertisement that potentially is like\n1494.76s: you describe 50% fit to what you have\n1499.799s: and then it's it's more easy uh it's\n1502.799s: easier to convince people that you will\n1504.919s: be having added value but but but is it\n1507.919s: something you have seen that the\n1509.799s: department you end up getting hired and\n1512.399s: a start of your position is different\n1515.679s: from what you've done before or\n1523.76s: not I can answer some of that so what\n1526.279s: I've seen is um\n1529.039s: people flipping the the initial\n1531.08s: perspective right so sometimes you take\n1533.159s: people you will have five or six uh\n1535.159s: interviews uh like candidates that come\n1538.24s: for an interview and in your mind you\n1540.36s: have the ranking like one two four based\n1542.279s: on CVS and then the fifths might be\n1544.12s: there you know or whatever and then you\n1546.0s: see the talk right and that person is\n1548.64s: really flipping your your mindset right\n1551.08s: and saying okay that's transformative\n1552.679s: right that seems to be very novel and\n1554.72s: that that that happens right so your\n1556.72s: case where that person's might be\n1558.32s: bringing something new uh New\n1560.399s: Perspective completely Innovative type\n1562.36s: of work and you we not appreciative of\n1564.32s: that right and again when you define the\n1566.48s: search right you have a very narrow view\n1568.76s: of the world right you might not know\n1570.24s: everything that's going on and like some\n1571.6s: of the especially because that that\n1573.799s: might not be exactly your area right\n1575.64s: it's connected to your area but you\n1577.32s: might not be knowing exactly the the new\n1579.799s: things uh in that particular field so\n1582.0s: yeah so that I've seen that couple of\n1583.48s: times and that's exciting I would say\n1585.279s: and and you see that you know at the end\n1586.919s: of the talks people really typically\n1589.0s: agree that that's very Innovative that's\n1590.72s: where we should go\n1592.48s: in and sometimes some universities are\n1595.84s: really ready to take big bets I've seen\n1599.6s: electrical engineers being hired in a\n1601.559s: department for a flu Dynamics position\n1604.039s: because this person was the best in\n1606.52s: control for example so yeah you you have\n1610.559s: these situations happening very\n1613.32s: often yeah I I think yeah I think all of\n1615.84s: us have seen some of that we've all have\n1617.44s: been also in Department ments that you\n1619.0s: know are not necessarily the one where\n1620.6s: we were trained in um so I think yeah\n1622.919s: some departments are more open to new\n1624.84s: areas and new research so I think it can\n1627.44s: definitely be a plus you know Pier\n1629.2s: mentioned the talk so you can definitely\n1630.679s: convince people in a talk but I don't\n1632.44s: think we've talked about the one-on-one\n1633.88s: chats those are also really important\n1636.76s: because you know the talk will be tell\n1638.32s: you to an audience but when you talk\n1639.76s: oneon-one to people um and again you\n1642.08s: know they can have many different\n1643.44s: backgrounds and you know you have a very\n1645.279s: different type of conversation and so\n1647.36s: seeing you know how open-minded you are\n1650.0s: how creative and so on and so forth all\n1652.039s: of that is a pretty good way to convince\n1655.559s: members as well of your creativity okay\n1658.6s: I could jump back on that uh I remember\n1661.159s: that time when I was applying for jobs\n1662.6s: like going across colleague Tommy you\n1665.159s: know we um we're hiring a colleague but\n1667.519s: I'm hiring my neighbor right no but but\n1670.2s: I thought it was it made a a whole lot\n1671.799s: of sense right that's a very important\n1673.2s: comment right there's the science piece\n1675.96s: right but you also want someone\n1677.559s: collegial right that's going to be a\n1678.84s: good citizen in the department because\n1680.919s: running a department is not just about\n1682.88s: giving talks and writing papers right\n1684.88s: you need to actually uh handle classes\n1687.559s: there might be some Comm Community or\n1690.159s: service you know that you need to so you\n1692.159s: want to make sure that the person will\n1693.6s: contribute as well right so those pieces\n1696.0s: are also important I\n1703.96s: feel um a bit on the uh teaching and\n1708.48s: stuff how there there are teaching\n1711.44s: statements right that have to be\n1713.6s: submitted how important are those\n1716.12s: statements in comparison to say the\n1719.6s: research proposal\n1722.2s: CD so I think it'll depend on the type\n1724.36s: of job you apply for right so if it's a\n1726.64s: you know regular faculty position I mean\n1728.88s: again it's always hard to tell you know\n1730.48s: which one is more important but you are\n1732.76s: mostly focusing on Research uh but the\n1735.36s: teaching statement is also an important\n1737.399s: part of it you know as PR mentioned you\n1739.36s: know we technically our salaries are you\n1742.159s: know for teaching in a way so you know\n1744.24s: if you are in a place where you do have\n1745.76s: a lot of undergraduate students so they\n1747.799s: want to see that you can teach you know\n1749.6s: a large cohort say you know in whatever\n1752.0s: discipline you end up in um you know\n1754.919s: understanding how you will interact with\n1756.24s: the student graduate and undergraduate\n1758.44s: it's also very important because all of\n1760.76s: us right we're scientist and we need to\n1762.24s: communicate our science and so you know\n1764.6s: communication through teaching is is\n1766.76s: really critical this is you know it's\n1768.88s: going to be the next generation of\n1770.159s: scientists you know wherever they end up\n1772.84s: um so so definitely you know put also\n1775.48s: you know uh time in in your teaching\n1777.519s: statement it's definitely been part of\n1779.519s: it if you apply for more liberal art\n1781.72s: colleges then they the way is even\n1784.24s: higher uh for teaching it's very very\n1786.679s: important because a lot of that is is\n1789.24s: the a lot of emphasis is placed on it\n1791.799s: yeah it's a great\n1797.039s: question\n1801.679s: um and\n1803.88s: if have any of you seen where someone\n1807.44s: who may not have formal teaching\n1809.72s: experience like how how would you write\n1812.12s: a teaching statement that is um\n1815.72s: exemplifying the skills that you might\n1817.32s: have to be a good teacher even if you've\n1819.799s: not actually taught a class and how how\n1823.0s: does one approach approach that if\n1824.96s: you're mostly\n1826.96s: research\n1837.44s: um so I would say for that yeah that's a\n1838.96s: very tricky thing but and that's I would\n1841.2s: say also depends on the career stage\n1842.919s: right so when you're applying to say\n1844.32s: anant Professor position that's almost\n1846.96s: to be expected right but that's a place\n1849.48s: I think where you could actually play\n1851.64s: make that play in your favor right try\n1853.32s: to get some experience you know there\n1855.159s: might be OPP opportunities from time to\n1856.88s: time to teach one or two classes right\n1858.679s: to get some experience there might be a\n1860.639s: summer school or some event where you\n1862.399s: could be having some you know of that\n1864.76s: experience uh you could uh showcase also\n1867.559s: because teaching typically also includes\n1869.639s: mentorship as well so showcasing some\n1872.2s: mentorship opportunities uh we're trying\n1874.24s: to have some of that as part of leap so\n1876.48s: as much as you can showing a little bit\n1878.08s: of that early leadership would be\n1879.72s: actually very important you know and\n1881.08s: they are try to look around you know\n1882.88s: there always opportunities or for\n1884.88s: instance um uh research experience for\n1887.639s: under grads are us you know so that's\n1889.32s: another experience where you could have\n1891.12s: it's quazite teaching you know but that\n1892.76s: would show some mentorship you\n1898.159s: know yeah so the teaching statement\n1900.559s: again should be seen very broadly as\n1902.519s: mentoring teaching Outreach so even if\n1905.159s: you give you know you know public\n1906.76s: Outreach talk if you Mentor you know\n1909.919s: high school students all of this is\n1911.96s: actually part of your engagement with if\n1914.76s: you want people who are not in your\n1916.039s: field in a way in you know and educating\n1919.32s: the community so that's more this kind\n1920.76s: of mindset rather than the proper\n1922.919s: teaching in the way that you just go\n1924.44s: into the classroom so think about it\n1926.559s: very broadly as broadly as\n1931.36s: possible yeah I think we we're going to\n1933.279s: do talks\n1935.159s: now okay so I can take it that from here\n1938.76s: all right so now you prepare all your\n1941.159s: material the cover letter The Proposal\n1944.039s: teaching statement and you got an\n1947.48s: interview you made it through the zoom\n1949.96s: screening and you were invited to give a\n1952.84s: talk now that talk is a very very very\n1956.24s: important part of getting the job\n1959.2s: especially here in the US I like to\n1961.32s: think that uh you know once the\n1963.519s: candidates are invited for the talk all\n1966.88s: the rest of the material doesn't matter\n1968.559s: almost compared to that performance\n1971.76s: because that's it's a full day where you\n1974.039s: know you give a presentation you\n1975.48s: interact with colleagues and they'll\n1977.399s: prob your knowledge they'll ask you\n1979.399s: questions you'll get to interact they\n1981.279s: get to really know both what you've done\n1983.0s: in terms of research but also how you\n1984.84s: are as a person how you could be as a\n1987.039s: colleague and as a teacher um so that\n1991.24s: part is really really important and the\n1993.36s: the talk especially and some of us are\n1995.44s: just better presenting than others but I\n1998.039s: think that you know with sufficient\n2000.0s: practice and having some guidelines that\n2003.279s: that uh that can be uh the bar can be\n2006.36s: brought pretty high for the for the talk\n2009.159s: uh and so today I'm just going to give\n2010.639s: you some some guidelines based on my\n2012.32s: experience and and yeah then we'll open\n2014.039s: it to to Q&A so in terms of structure\n2017.48s: you want to start by giving a background\n2020.36s: about yourself who you are what your uh\n2024.12s: yeah background is your research team\n2027.159s: this will help kind of set the stage\n2030.0s: then you want to invest some slides in\n2033.159s: really motivating your research like\n2036.159s: what is your research area what are the\n2037.799s: current knowledge gaps this will help\n2040.279s: the audience understand that you\n2042.159s: actually know what you're talking about\n2044.44s: and how it fits within the bigger scheme\n2046.72s: of things and here is also where if you\n2049.96s: have numbers dollar numbers for example\n2053.159s: it's where you want to put them say\n2055.0s: you're working on tropical Cyclones it's\n2056.96s: always good to put a you know USD amount\n2060.399s: on the cost of inaction for example of\n2062.52s: not doing your\n2063.679s: research because your audience can be\n2066.24s: very diverse and some may not be\n2068.96s: specifically expert in your field so I\n2071.96s: think numbers are always good or any\n2073.8s: other factual you know uh implication of\n2076.359s: not doing that that research um after\n2080.52s: you've done this and you have your stage\n2082.399s: ready then you want to provide an\n2083.8s: overview on your past research this is\n2086.04s: really the meat of the talk you want to\n2089.119s: describe methodologies you've used or\n2091.079s: introduced the key findings explain very\n2094.599s: clearly what is novel and how these\n2096.96s: addresses the the knowledge Gap you had\n2098.96s: identified it's always good to have an\n2100.8s: organic presentation so always refer\n2103.56s: back when you have a finding to your to\n2106.0s: the to the knowledge gaps you had\n2108.04s: identified um after this is done now you\n2111.72s: want to talk about your current and\n2113.44s: future research and we've talked a bit\n2115.44s: about this this is where you discuss\n2117.32s: your your ongoing projects but also\n2119.079s: where you project where your research is\n2120.88s: going and that is very very important\n2123.839s: and um one piece of advice I got in the\n2126.4s: past was okay oppose you know a number\n2129.0s: of directions but some will build from\n2131.2s: your expertise so that you you know you\n2133.119s: show that there is a low risk on this\n2134.8s: one and productivity potentially is\n2137.48s: going to be high but then also Venture\n2139.48s: into some more ambitious uh Avenue of\n2142.96s: research and that is where you want to\n2145.16s: basically show that you're not just a\n2146.92s: satellite uh uh you know group of your\n2149.8s: former advisor group but you're an\n2152.0s: independent researcher you can do your\n2153.839s: own uh you can drive your own research\n2157.0s: program\n2158.16s: uh here is also very good to be\n2160.44s: ambitious because the department sees\n2163.04s: you as their next Superstar so you\n2165.119s: really want to behave like one you don't\n2167.04s: want to be you know shy or oh maybe this\n2169.04s: will not work just there a bit more than\n2172.16s: than you would on a normal you know\n2173.88s: conference\n2175.04s: presentation uh and get them excited\n2177.359s: about the research um you might also\n2181.04s: want to mention then have maybe one\n2183.079s: slide or two on potential funding for\n2185.24s: your research you're an independent Pi\n2188.24s: you need to bring in funds to to support\n2190.76s: your student and post doogs and so that\n2193.4s: they can do their research and showing\n2195.96s: that you have especially at the early\n2197.44s: stage I think most of us don't have a\n2199.28s: lot of experience with with this but\n2201.48s: it's good to show that you have at least\n2202.88s: an idea where you know where to go uh\n2206.28s: fish\n2208.0s: um you might want to include some slides\n2210.4s: on collaborate potential collaborations\n2213.2s: but like I said before I wouldn't make\n2214.96s: any specific name just because times you\n2218.56s: don't even know of collaborators that\n2221.599s: are within the potential collaborators\n2223.319s: that are within the department uh maybe\n2225.72s: just talk in terms of research areas and\n2227.839s: show how your research can really\n2229.64s: benefit from the ecosystem of the\n2231.92s: University of the institution but also\n2233.8s: is bringing new uh new capabilities new\n2236.72s: new Talent\n2239.119s: um some slides on teaching philosophy\n2242.76s: also should go in the presentation so\n2244.88s: the presentation essentially will run\n2247.28s: through through all the things you've\n2249.4s: written in your proposal teachy\n2251.28s: statement cover letter Etc it just gives\n2253.24s: you more time to explain where with nice\n2255.96s: infographics you know um and and and\n2259.0s: text um this I would say from a covers I\n2263.88s: would say all the elements of of a good\n2265.68s: presentation and then you'll have to\n2267.44s: modulate Things based on your uh on your\n2269.92s: specific\n2271.04s: research in terms of General advices for\n2274.24s: for the talk um first is uh as Pier said\n2278.2s: before know your audience it's good if\n2281.839s: you make your talk resonate with the\n2284.64s: research or some of the teams or that\n2287.04s: the institution is interested in that\n2289.24s: will give you point read the job\n2291.56s: description sometimes through the lines\n2294.48s: and uh then make sure that your\n2296.48s: presentation somehow addresses those\n2299.2s: points that were brought up and in terms\n2301.319s: of focus areas um make the talk\n2304.48s: accessible maybe only one or two people\n2306.92s: in your audience\n2308.48s: really know the specifics of your\n2310.48s: research field and to maximize your your\n2314.28s: chances you really need to keep the\n2315.96s: juron low except perhaps when in a\n2319.079s: couple of slides where you want to\n2320.64s: really Target those two people that know\n2322.88s: very well you know your research area\n2324.48s: and then if you lose the audience every\n2326.4s: now and then it's probably fine but that\n2327.88s: shouldn't be the throughout the talk\n2330.119s: otherwise um the impact that those two\n2332.599s: people that know your research area will\n2334.079s: have on convincing the other might be\n2336.599s: ultimately small if everyone else didn't\n2338.68s: understand\n2339.52s: anything\n2341.16s: um be confident be enthusiastic um one\n2345.52s: advice I received in the past also was\n2347.4s: uh you know when you go for an interview\n2349.079s: behave like a faculty don't behave like\n2351.359s: a PhD or a postd you're already passed\n2353.44s: that stage they want to see that you are\n2355.4s: the perfect colleague for that\n2357.0s: department and so uh yeah be confident\n2360.44s: and and show\n2362.56s: enthusiasm um also one advice I give to\n2366.359s: my students typically when um this Cas\n2369.68s: is be open-minded right now you have an\n2371.599s: idea of what your future research plan\n2374.119s: is but uh you know once you join the\n2376.76s: department you're going to interact with\n2378.24s: new people you're going to be exposed to\n2379.8s: new ideas and inputs and so your\n2381.48s: research might change so be mention that\n2385.119s: I would say it's a very good uh it's a\n2387.0s: very good thing uh to do um and then\n2391.079s: practice practice practice get you know\n2394.4s: for my presentation here at Colombia I\n2397.119s: think I had four rehearsals with my\n2399.96s: advisor two rehearsal with colleagues at\n2403.079s: the University of British Columbia and\n2406.0s: uh then I practice many times on my own\n2409.28s: and uh this is something that uh I think\n2411.599s: it's it's important uh and different\n2414.079s: people have different strategies but I\n2416.0s: think practice really helps um and uh\n2420.359s: yeah so I'll be happy to take any any\n2426.319s: question\n2434.4s: okay I have two\n2436.52s: questions maybe the first what is like\n2440.16s: the general advice about how a job talk\n2442.96s: should be different from just if you got\n2446.04s: invited to give the department seminar\n2448.68s: kind of how to distinguish those um and\n2451.359s: then the second question is all of the\n2454.92s: things that you described that you\n2456.44s: should include it sounds like the talk\n2458.56s: is going to be like three hours long how\n2461.88s: how do you keep it in like 40\n2464.319s: minutes yeah that's a good point I think\n2466.88s: I mean I think you should touch on all\n2468.8s: these points and if you put a couple of\n2471.44s: slides I think the the core of the\n2473.92s: presentation is your your research past\n2476.8s: and future I think that is the main part\n2479.52s: on which you'll be\n2481.079s: evaluated um but uh going to your first\n2484.72s: question when you give a talk or job\n2488.24s: you're not just showcasing a specific\n2490.52s: research project that you worked on or\n2492.76s: two you are selling yourself and the\n2495.52s: research and that you want to make the\n2498.599s: audience aware of the you know the what\n2501.359s: you bring to the table and how you're\n2503.48s: going to be as a colleague so that's why\n2506.64s: it has to be structured slightly\n2508.8s: different than a classical seminar\n2511.0s: presentation when you present your\n2512.8s: research you potentially identify a\n2514.839s: number of key areas you don't want to\n2518.0s: adopt the K the kitchen Sinker you know\n2520.52s: approach where you have a project per\n2522.079s: slide focus on some key area key\n2525.56s: projects maybe and highlight your\n2528.319s: contributions um and yeah keep it sucin\n2532.56s: but I like why it's not maybe avoid\n2535.4s: technicalities you don't go to you need\n2537.16s: to go too technical because you know\n2540.079s: most likely 80% of the audience will not\n2542.8s: be able to absorb that technical part\n2545.28s: instead highlight what is novel what it\n2547.4s: is\n2548.4s: impactful that way you know avoiding the\n2550.599s: technicalities I think you can go\n2552.04s: through the the research um overview\n2555.8s: much faster then yeah I hope these\n2558.16s: answers\n2561.16s: both um and maybe to add to that it's\n2563.64s: because we have some searches going on\n2565.559s: these days um I feel I see that just too\n2568.839s: frequently that this K kitchen sys\n2570.92s: approach you know where you know I think\n2573.16s: the whole point is like what's the story\n2575.079s: right and again the audience is going to\n2576.359s: be very Broad because it's a department\n2578.24s: so avoiding technicality that's spot on\n2581.559s: right I mean there are times you can\n2582.839s: have a few slides you know some people\n2584.76s: say you can lose your audience or most\n2586.839s: of the audience except for a few folks\n2589.079s: for like two to three slides right but\n2591.2s: the rest you should have a compelling\n2593.2s: story uh people should really Envision\n2595.72s: like how that's going to fit within the\n2597.319s: department and it takes time to build\n2599.24s: that story as opposed to just having\n2600.8s: again like a series of slides it just\n2603.2s: doesn't fit very well doesn't and the\n2606.04s: the audience is lost very very quickly\n2607.88s: yeah so I think that's super important\n2609.319s: and just sorry very quickly on that\n2611.04s: story so it build I mean that's my\n2613.76s: strategy people might have different\n2615.079s: strategies but it take I take weeks\n2617.72s: sometimes to think about the story and I\n2620.0s: just write you know that's going to be\n2621.96s: the the frame you know and then I say\n2623.559s: okay this I move and here and and then I\n2625.44s: start populating that basically the\n2626.96s: bullet points that La was talking about\n2628.8s: and then at the end I feel I have the\n2630.359s: the the the full story and then I\n2632.0s: populate that with different things and\n2633.92s: at the end I remove some sides because I\n2636.359s: always know that I have too much so I\n2638.359s: remove 10 to 20% because I and I I don't\n2641.04s: want to do it but I do it and I feel\n2643.559s: really good after the talk that I did\n2645.96s: it\n2650.68s: wa so I think we always come back to no\n2653.48s: kchen SN approach not for the research\n2655.72s: proposal not for the and I think this is\n2657.599s: usually kind of really that could be the\n2660.04s: you know we don't know what will\n2661.8s: guarantee a job but we know what can\n2663.96s: kill applications very quickly and the\n2665.599s: same for the job talk your story is\n2668.04s: important no need for all details uh and\n2671.0s: you know as Pier mentioned removing\n2672.48s: slide do not run over like do\n2679.079s: not um there's a question on the chat\n2681.4s: from bahador bahamani could you comment\n2683.839s: on the vision talk as well apart from\n2686.04s: the technical\n2691.4s: talk could you comment on the vision\n2693.839s: talk as well um apart from the technical\n2696.8s: talk\n2702.28s: yeah I'm not I\n2706.599s: guess um yeah so I think not all places\n2709.8s: have the same kind of setup so in some\n2712.68s: places you will be asked to give only\n2714.319s: one talk right and the one talk you give\n2717.119s: is exactly the way Marco described it\n2719.4s: you know which is more of a high level\n2721.359s: story Vision with you know again where\n2724.88s: you're going to go and all this kind of\n2726.28s: stuff some places will ask you for two\n2728.4s: different talks one that is more Vision\n2731.079s: like so again that will still be a\n2733.28s: little bit like Marco described but even\n2735.119s: more high level um so you even have\n2738.64s: almost no technical in a way kind if\n2740.72s: it's very much about this is the\n2742.559s: problems that I'm going to solve and one\n2744.319s: that is actually technical where you\n2746.76s: will be asked specifically to discuss\n2749.559s: you know one project that you've gone\n2751.92s: through can be on the board sometimes\n2754.28s: again depending on the department you go\n2755.72s: for or could be on the methodologies so\n2758.319s: there that would look a little bit more\n2759.96s: like you know regular seminar if you\n2762.119s: want but still you still need to you\n2764.599s: know convince your audience and you know\n2766.24s: keep it up so that would be a little bit\n2767.92s: of the separation again different\n2770.119s: institutions are very different and also\n2771.96s: different department within each\n2773.64s: institutions are different um so Sarah I\n2776.359s: think you add some some of the\n2778.0s: experiences yeah I wanted to add a\n2780.04s: little bit on the on the technical talk\n2782.28s: of Chu talk so the idea is that you're\n2785.04s: supposed to know all the details of the\n2787.28s: of the tech of the work that you have\n2788.88s: done and there might be like any\n2790.28s: question related to that just\n2792.88s: not yeah I mean like you you could\n2795.24s: expect like anything related to the work\n2797.72s: and the detail that you have done and\n2800.16s: you should be able to write it down so\n2802.319s: besid like um evaluating you in term of\n2805.8s: methodology that you have done they are\n2807.68s: also evaluating you in term of like\n2809.359s: explaining and teaching how well you can\n2811.72s: explain what you have done to some\n2813.16s: audience that now they are mostly like\n2815.4s: faculty expert but probably not within\n2817.96s: your\n2830.96s: field so actually I would I would like\n2834.359s: to ask you like you talk about how to\n2837.88s: get chosen so I would ask you how to\n2841.68s: choose what kind of questions the next\n2845.48s: oh okay okay okay so I I can't wait\n2854.16s: transition thanks for the\n2857.72s: transition afterwards for the check um\n2861.16s: so yes so the was to talk about the\n2864.079s: being on the other side you know so we I\n2865.68s: think we covered a lot of things like\n2867.4s: what people are expecting in terms of\n2869.559s: you know application and um in terms of\n2872.96s: talk uh I mentioned that earlier but\n2875.359s: it's very important again that\n2877.559s: uh selft skills are important right I\n2879.48s: mean we are I mean talking and uh being\n2882.559s: enthusiastic and energetic that day like\n2884.559s: if you're tired just get get a coffee\n2886.44s: you know like get some vitamins or\n2888.24s: whatever but get I I just sometimes see\n2891.359s: people say come on just wake up you know\n2893.839s: like that's you the day you should you\n2896.119s: should be awake anyways um so yeah it's\n2900.839s: amazing um and so that's actually an\n2903.559s: important point right just uh be look\n2906.2s: good you know so people feel that they\n2907.72s: are energetic again talk about potential\n2910.599s: connections when you meet on a onetoone\n2912.76s: basis you know uh so that you can\n2915.52s: understand you know also the setup of\n2917.64s: the of the department you will get some\n2921.24s: very typical questions not every place\n2923.16s: has those questions it feels very much\n2924.96s: like HR type questions you know like uh\n2927.8s: where do you see yourself in five years\n2929.559s: or 10 years from now U that's a very\n2931.88s: standard question and it sounds a bit um\n2935.64s: generic but it's not a bad idea to think\n2937.799s: about that because I mean Marco\n2939.599s: mentioned some of that I think also\n2941.28s: Sarah and La earlier is that it gives\n2943.839s: you some perspective as to where you\n2945.839s: want your research to be right so it\n2947.88s: doesn't need to be perfect things will\n2949.4s: evolve as Marco mentioned uh but that's\n2951.96s: actually important like five years it\n2953.319s: give me a sense you know I will have a\n2954.44s: few proposals you know so that it's good\n2957.4s: to actually have a plan 10 years that's\n2959.599s: basically where you want to be in terms\n2962.24s: of your field right I mean where do you\n2964.2s: want to Define yourself in that\n2965.88s: particular field\n2968.04s: um yeah so those were some of the uh so\n2971.4s: those are some of the standard questions\n2973.559s: people typically ask about fit within\n2975.52s: the department you know like uh\n2977.88s: collaborations uh within the department\n2980.4s: within the school across different\n2983.119s: schools and within the university so\n2985.04s: those are very typical things uh service\n2989.28s: sometimes people ask you know what type\n2990.72s: of service will you want to do some and\n2992.839s: it depends on the University some places\n2994.88s: really shelter faculty so that they have\n2997.839s: very minimal service but some places\n2999.72s: have more service you also depends on\n3001.44s: the scale of the so having a sense as to\n3004.119s: you know i' be interest in graduate\n3005.68s: comedy or undergraduate comedy you know\n3007.68s: it's good to actually have a a sense of\n3010.0s: that early on um again that's related to\n3014.92s: the talk but thinking about the fact\n3017.599s: that U people are again looking for a\n3019.76s: colleague right so it has to be a fit\n3022.559s: and they have to also understand broadly\n3024.599s: speaking the research and can they see\n3026.28s: connection does it help the department\n3028.68s: can they see potential connections with\n3030.52s: them you know that's actually very\n3032.599s: important um yeah and I don't know what\n3035.96s: else I had let me just check my\n3039.119s: notes um I think those were the main\n3043.88s: points um oh yeah uh another typical\n3047.0s: questions you're going to hear about is\n3049.2s: funding uh so it tends to be very\n3051.4s: generic so where will you get uh funded\n3053.76s: you know and where will you be funding\n3055.72s: your research group on and so of course\n3058.359s: you will respond NSF and National\n3060.599s: Science Foundation Department of energy\n3062.92s: NASA if you work on modeling or remote\n3065.28s: sensing Noah as well so those are very\n3068.079s: typical ones um Department of Defense\n3071.559s: could be another one and I think in our\n3073.839s: field so people that are working on AI\n3076.16s: you could also think about some things\n3078.079s: that are a bit more like philanthropic\n3080.24s: right so that can be something a bit you\n3082.359s: know a bit different from the other\n3083.76s: candidate so think about some other\n3085.839s: potential for\n3087.24s: we have some funing M Square lines from\n3089.04s: Schmid used to be called Schmid future\n3091.44s: not Schmid science so it's good to\n3093.559s: actually know that those exist right and\n3095.119s: to be actually part part of those as\n3097.76s: well and I think that's um yeah pretty\n3100.64s: much all I wanted to talk about yeah and\n3103.88s: again I think a very important piece of\n3106.119s: advice is that um really we are looking\n3109.44s: for a colleague right and it's more than\n3111.4s: just a scientist great science is great\n3113.4s: but we also want someone that's going to\n3114.88s: be collegial helping the development of\n3117.28s: the department and you know helping with\n3119.359s: the all of the service because at the\n3121.359s: end of the day we never talk about that\n3123.0s: but we're always looking for a unicorn\n3124.839s: you know and we are we want someone that\n3127.04s: does everything well like research\n3128.839s: teaching service mentoring and of course\n3131.76s: that doesn't exist right but you need to\n3133.44s: appear as if you were that person and\n3135.2s: that unicor\n3144.28s: right I don't know you want to you want\n3146.24s: to continue on hiring being hiring\n3148.96s: side well I think we had question on the\n3151.2s: other side how do we choose how do we\n3154.319s: choose be as applicant right yeah your\n3157.72s: question about applicant yeah I think\n3159.839s: that's really important question so the\n3161.64s: way that I used to think about it is\n3163.16s: like where I want to be like do I want\n3165.319s: to live in this city do I want to work\n3167.04s: in this University and it's like a\n3169.0s: decision that you make for like six\n3170.76s: seven years of your life um I think one\n3173.76s: way to maybe um approach that is to get\n3176.64s: more more information for example you\n3178.359s: see a job announcement they um ask for\n3180.92s: some specific um skill that you need to\n3183.4s: have do you have them and then you can\n3185.44s: get information about them uh what is\n3187.68s: the culture of the University what is\n3189.64s: the specific thing that they're looking\n3191.359s: for would you love to be colleague with\n3193.92s: the people that are living there or like\n3196.04s: working there and uh what are the\n3198.599s: responsibilities that you have like for\n3200.4s: example are you supposed to teach um I\n3203.28s: don't know undergrad courses four times\n3205.079s: a year or is it only two times a year I\n3207.4s: think that that's really important like\n3209.48s: how much responsibility you have and\n3211.799s: then what they offer and for example\n3214.4s: would they support you for the first two\n3216.559s: three years or are you supposed to like\n3218.52s: get ground right away\n3221.079s: um I think that's uh that's what I what\n3224.16s: I can think\n3227.28s: of I think just to follow up on Sarah I\n3230.119s: think you know a lot of the choices are\n3232.28s: very personal so I think you know it's\n3235.0s: great to get offers and it's super super\n3236.72s: exciting kind of making sure you take a\n3238.799s: step back and decide what is it that you\n3240.88s: value you know what's important to you\n3243.72s: for your research how you know you'll be\n3246.0s: supported as s mentioned how your\n3247.64s: students P duck you know will be\n3250.0s: supported they again you know it's kind\n3251.44s: of people you're going to work with and\n3253.04s: you want them to be in a department\n3254.559s: where they'll grow where they be able to\n3256.599s: actually do all the things they want to\n3257.88s: do and of course where do you want to be\n3260.2s: you know in the city or somewhere else\n3262.599s: so I think really always like it's super\n3264.44s: exciting when you get you know offers\n3266.64s: which I hope you know all of you will\n3268.48s: get then always take a little step back\n3271.079s: try to think this is not just the\n3273.559s: excitement and the money and the salary\n3275.48s: and so on but really this is it this is\n3277.559s: going to be the next X number of years\n3279.88s: and that's where you start your academic\n3281.599s: career and that is a big influence on\n3284.16s: many things so always take that step\n3285.88s: back and think about what is it you know\n3287.599s: you value and you want\n3290.4s: so and just one thing to add is you have\n3293.16s: an advisor so ask a consult with or her\n3297.28s: because they have more experience and I\n3299.16s: might be able to help you you know make\n3301.92s: a the decision that is best for you\n3303.96s: because often time you you don't know\n3305.839s: what you don't know and the advisor can\n3308.2s: help in that\n3311.359s: case maybe just to add like um in terms\n3314.24s: of selection so you select and how\n3316.76s: you're being selected you know so on the\n3318.839s: other the the the other side you know um\n3322.039s: I think it's important to remember that\n3323.4s: once you're passed or you go to the\n3325.0s: interview stage you know it's it will\n3327.48s: appear to be pretty random to you right\n3329.24s: so it's not always the people that will\n3331.119s: have the best CV that will be selected\n3333.52s: at the end and it's a combination of\n3335.76s: multiple factors right so including fit\n3339.16s: uh in terms of research within the\n3340.72s: department uh the direction of the\n3342.92s: department so it's also not a bad idea\n3345.039s: to talk and ask the chair about the\n3346.839s: vision for the department when you meet\n3349.24s: with him or her um and of course all of\n3352.839s: the service so once you're in that small\n3355.559s: pool okay you made it so it's you're\n3357.599s: great candidate and beyond that is a bit\n3360.359s: a lot of things Beyond The Talk which is\n3362.48s: really crucial like if you done a great\n3364.0s: job on on the on the talk beyond that is\n3367.96s: basically it's outside of your control I\n3369.72s: would say and and often times it can be\n3372.0s: disappointing it feels like a failure\n3373.76s: but don't take it personal a lot of that\n3376.28s: is actually not due to you it's um\n3378.799s: multiple fits you know and uh yeah\n3381.76s: there's just so much you can control so\n3383.24s: don't be disappointed of course easier\n3385.359s: said than done but that but that don't\n3388.119s: you can ask for feedback but typically\n3390.079s: the feedback is not super useful past\n3392.039s: that\n3393.319s: stage so I I just want to be mindful of\n3395.76s: time we're at four o'clock that hour\n3397.119s: went by very fast um so I think some\n3400.48s: parts of our um topics got woven in\n3403.079s: between um but if the panelists want to\n3406.119s: anything else you would like to say um\n3407.88s: that you didn't quite get\n3410.72s: to good\n3415.24s: luck\n3417.68s: yeah indeed I mean as everyone mentioned\n3419.599s: right it is a tough Market out there so\n3421.64s: don't get disappointed but also use you\n3423.96s: know your peers and use the communities\n3426.039s: that you have around you kind of to help\n3428.0s: you and kind of guide you through the\n3429.48s: process as well so you know you're still\n3431.92s: part of a good community so hopefully uh\n3434.16s: you know we can help and that's a great\n3436.28s: Point like uh don't also we we we\n3438.28s: haven't talked too much about that but\n3439.559s: don't underestimate the value of\n3441.16s: recommendation letters uh there's\n3443.359s: nothing worse than a v generic\n3445.079s: recommendation letter a specific\n3447.079s: recommendation letter if it even if it's\n3448.92s: coming from someone less well known has\n3451.119s: a lot more value you know so being\n3452.88s: specific someone that really knows you\n3454.52s: well we'll talk about your quality and\n3457.559s: um at least for leap and mare Alliance\n3459.2s: you know there's a pretty big community\n3461.16s: so we're here to help like when you need\n3463.48s: need recommendation letters we hope we\n3465.24s: can help you know that's really really\n3466.72s: critical and that's a benefit of being\n3468.359s: part of a committee as opposed to having\n3470.359s: just a single\n3475.119s: advisor\n3477.039s: if others don't\n3488.599s: have sorry actually yeah sorry uh you\n3491.72s: know this is really more of a comment\n3493.4s: than a question but hopefully it's not\n3494.839s: that type uh and I just wanted to say\n3497.96s: you know I think many of you know but\n3499.92s: you know I'm a faculty member in cuni\n3502.2s: which is like you know mostly teaching\n3503.92s: institution so it'll be closer to you\n3505.96s: know know a small Liber college or you\n3508.039s: know a teaching institution and I think\n3509.839s: the process this is amazing content the\n3512.319s: process in those type of places a bit\n3514.28s: different so I just want to say if any\n3516.119s: of you is interested also in thinking\n3518.359s: about applying to these places I'm very\n3520.2s: happy to be a resource for you and uh\n3522.92s: you know and give you maybe additional\n3524.4s: advice that can you know can cover a\n3526.44s: slightly different\n3530.96s: area hello uh I just wanted to ask about\n3535.079s: I feel like uh all touched on funding at\n3537.24s: some point um I had a question that\n3539.48s: pertained through the the writing\n3541.799s: process and the oral presentation uh and\n3544.48s: this may not have an answer or a direct\n3546.16s: answer um or an easy answer but my\n3548.72s: question is um how do you present\n3550.2s: yourself with someone who's capable of\n3552.44s: getting funding right because that's\n3554.359s: kind of the elephant in the room I guess\n3555.92s: and that's something that I think about\n3557.96s: all the time that's the first thing that\n3558.96s: comes to mind when I'm thinking about\n3560.079s: this kind of thing so thank\n3563.319s: you well I think uh that when\n3566.559s: you apply uh\n3568.359s: for assistant professor say if you don't\n3570.839s: have a lot of experience the expectation\n3573.559s: is that you have an idea of what funding\n3576.72s: agencies are interested or might be\n3578.64s: interested in your research often times\n3580.88s: though the research you do you know you\n3583.48s: can often times some research is very\n3587.16s: well funded and the department knows\n3589.64s: other research is less well funded maybe\n3592.039s: some more theoretical you know I don't\n3594.72s: know turbulence research\n3596.64s: very hard to get funding\n3598.839s: nowadays um and uh so I think it's not\n3603.28s: as\n3605.4s: critical is not a critical element for\n3608.0s: you to sell yourself as a good\n3609.64s: entrepreneur it's going to be important\n3611.559s: ultimately because if you bring in\n3613.359s: funding then you can sustain your\n3615.2s: research group but for the job talk I\n3618.119s: think it's not the most critical element\n3620.64s: I I think your research the past\n3622.559s: research and your research plan for the\n3624.96s: future and your potential as a colleague\n3628.4s: count a lot more than than the\n3631.079s: funding don't know\n3634.44s: if sure that you have awareness but\n3637.48s: that's\n3638.4s: it that's very comforting ask yeah don't\n3641.559s: worry too much about\n3643.68s: that so I asked the last question so I\n3648.319s: wonder I can speak\n3650.44s: now I wonder if um so some people would\n3654.559s: say it's like a frost\n3656.44s: like it's better if you want to aim for\n3658.48s: a faculty position you don't think that\n3662.079s: okay this is the this is this year by\n3664.88s: the fourth year I want to make this\n3667.079s: transition start in advance like one\n3669.76s: year two year before it because you have\n3672.48s: to get like the position open up yearly\n3675.24s: and then you have to get rejected a few\n3677.68s: times before you start to succeed and I\n3681.24s: wonder what what's what are your\n3683.079s: thoughts like I think that uh yeah it is\n3686.599s: a a process like I I wouldn't um a lot\n3690.599s: of things have to align for you to get\n3692.64s: the job because maybe you are the best\n3695.359s: person for that topic but that year\n3697.48s: there is no opening for that specific\n3699.64s: area next year a lot of openings and so\n3702.48s: even if you're not the best person now\n3704.44s: you get a job so I think persevering in\n3709.16s: this case it's uh it's important like\n3711.799s: don't give up apply apply and uh with\n3716.24s: time you know you also learn as you go\n3718.88s: through the interview process you maybe\n3720.48s: make you know one two three\n3722.96s: interviews your your old package will\n3725.839s: improve a lot because now every time you\n3728.68s: get tested you you have elements to\n3731.359s: refine and you know you learn how to\n3732.96s: sell yourself better and so it slowly\n3735.92s: becomes a very good uh yeah very good uh\n3740.039s: overall package and the probability now\n3742.359s: is much\n3744.48s: higher so that definitely I mean we keep\n3746.72s: hearing perseverance but sometimes also\n3748.96s: the star aligns you know they might be a\n3751.76s: job and you might feel you maybe a\n3753.88s: little too early but who knows you know\n3757.16s: you might be only one or two years and\n3758.799s: your P deck and again it's the job that\n3761.319s: you want and you know the qualification\n3763.44s: and a good fit then you know give it all\n3766.0s: you've got right because if you don't\n3767.48s: apply you don't get it as well but of\n3770.039s: course ego hurts if you don't but so you\n3773.24s: know it's a little bit\n3774.839s: of\n3779.039s: okay thank you all so much for joining\n3780.52s: thank you so much to the panelists for\n3783.16s: all your inside and\n3786.079s: advice and we'll have more professional\n3788.24s: development events coming up if you have\n3790.279s: any suggestions or any feedback there's\n3791.799s: a QR code on that back table um they'll\n3794.039s: take you to a form where you can share\n3795.88s: your ideas thank you\n3802.799s: again"
    },
    {
        "class": "YouTubeVideo",
        "title": "Transfer Neyman Pearson Algorithm for Outlier Detection",
        "videoId": "n0u5ToC9ors",
        "url": "https://www.youtube.com/watch?v=n0u5ToC9ors",
        "publishedAt": "2025-01-13T18:26:57Z",
        "transcript": "4.2s: hi everyone um we're going to start part\n7.319s: two so we have Muhammad dza Colin um\n12.639s: he's a post-doctoral researcher in the\n15.16s: statistics department at Columbia\n17.6s: previously he earned his PhD in\n20.0s: electrical engineering from USC um as\n23.32s: well as um an Ma and Applied Mathematics\n27.48s: um his research focuses on statistical\n29.599s: learning Theory with a particular\n31.32s: interest in transfer learning and domain\n33.8s: adaptation specifically he studies\n36.8s: methods for transferring knowledge and\n38.28s: information from tasks with abundant\n40.239s: data to those with limited\n44.28s: data hello everyone I'm very happy to be\n47.28s: here to talk about my search on transfer\n51.32s: Lear sorry to interrupt you can you\n53.48s: press the button on the screen oh yeah\n61.96s: okay hello everyone I'm happy to be here\n63.64s: to talk about uh I\n66.6s: think to\n70.439s: talk\n73.14s: [Music]\n76.52s: sorry my research on transfer learning\n78.88s: in outli detection this is Joint for\n81.88s: with Samar Po from statistics Department\n90.96s: yeah so the problem of outlier\n93.68s: detection uh happens uh in many\n96.399s: scenarios like in climate uh\n99.28s: applications for example we we are\n102.159s: interested in uh detecting uh rare\n105.64s: events like heavy rain or Wildfire\n108.88s: detection so in this problems uh we have\n111.68s: two classes from one one class is very\n115.24s: common uh but the other one is very rare\n118.119s: and it's not likely to happen\n120.56s: and uh we are interested in to detect\n123.56s: the rare event and you see uh we have\n127.2s: two types of Errors one type of error is\n130.599s: that for example we have a heavy rain\n133.239s: but we fail to detect but the other type\n136.08s: of the error is that uh we do not have a\n138.879s: heavy rain but we flag like a heavy rain\n141.48s: and you see that these types of errors\n143.08s: are very\n147.0s: different so if I want to compare the\n150.36s: traditional balanced classification with\n153.36s: outlier detection or you can call\n155.319s: imbalanced classification in traditional\n158.2s: classification in both of them we have\n160.12s: two classes but in traditional one uh we\n163.239s: have enough number of samples from both\n165.159s: classes but in the outlier detection\n168.56s: from one class we have a bant of data\n171.0s: but from the other one we have a few\n173.28s: data and sometimes we do not have any\n176.12s: data so the challenge is that it\n179.84s: traditional classification Balan\n181.92s: classification we can just minimize the\n184.68s: total loss or total error uh if the\n188.239s: number of the samples from two classes\n190.0s: are kind of the same but if you do it in\n192.959s: the outl detection in the imbalanced\n195.519s: classification setting uh if we minimize\n199.0s: the total loss we can find a function we\n201.04s: can find a classifier that achieves a\n203.64s: low error on the total loss uh however\n206.519s: the error with respect to the class from\n209.84s: which we we have a few data could be\n212.319s: very high and it's not good because we\n215.12s: want to have a classifier achieves low\n216.92s: error on both\n221.04s: classes so there are some popular\n223.4s: approaches to uh this\n226.0s: problem uh one of them is called cost\n228.879s: sensitive learning in the literature so\n231.799s: what people do is uh they minimize uh\n235.159s: weighted loss so one they assign a c a\n239.84s: weight to one of the loss and one minus\n242.319s: C to the other loss uh there's a\n246.159s: challenge in this approach uh how should\n249.12s: we assign this C because it requires a a\n252.2s: prior class probabilities and we have a\n254.84s: few samples from one of the classes and\n256.799s: we cannot estimate the a prior class\n260.12s: probabilities the other approach uh less\n264.36s: uh studied in the literature it's called\n267.08s: name on person classification it has uh\n270.56s: uh it's related to the also hypothesis\n273.12s: testing problem so in this setting uh we\n276.56s: have two types of Errors we want to\n278.639s: minimize one type of the error subject\n281.759s: to the constraint that the other type of\n284.08s: the error is less than\n286.919s: Alpha and here the the objective one is\n290.4s: called type to error and the constraint\n293.36s: is called type one error and this Alpha\n296.08s: is user specified threshold uh for\n298.88s: example if I want to give you an example\n301.919s: um for example the rain detection\n304.44s: problem uh one trivial classifier is\n308.96s: that always you can say that oh today we\n311.28s: are going to have a heavy rain so if you\n314.6s: do that the objective uh loss is zero\n318.4s: but uh the type one error is huge and\n321.919s: that also reflects the cost for example\n324.56s: if you say that we are going to have we\n327.039s: are we are going to have a heavy rain uh\n329.28s: today then we have to take some\n330.919s: emergency measures uh if we if we we're\n335.199s: wrong then we have to pay some cost so\n337.919s: that Alpha reflects the cost in most of\n340.08s: the\n340.88s: applications also in this uh example so\n343.919s: in this framework first of all there's a\n345.68s: asymmetry between errors one type of the\n348.4s: error is much more important than the\n350.199s: other type of the error so see that in\n352.56s: the Wildfire detection type two error is\n354.84s: that the Wildfire occurs but we fail to\n357.52s: detect the other one is that uh Wildfire\n360.639s: does not occur but uh we fail to we flag\n364.28s: a\n366.68s: wildfire so again this problem has been\n369.88s: studied a lot in the statistics\n372.56s: literature uh when we have access to the\n375.72s: underlying distributions so there's a\n378.319s: famous Lemo it's called Deon Pearson\n380.16s: Lemo it characterizes the optimal\n382.24s: solution of this problem uh when we know\n385.44s: the probability distribution of the\n387.96s: classes uh and the optimal solution is\n391.72s: uh simple if you have distributions then\n395.08s: if you plot if you plot the density\n397.639s: ratios of one class to the other class\n399.52s: then you just need to find a threshold\n401.639s: then the optimal function optimal\n403.28s: classifier has the following form if\n404.96s: it's if the density ratio is larger than\n407.039s: sub threshold you say it's class one if\n409.319s: it's less than a threshold then it's a\n411.16s: class the other class but the challenge\n413.479s: is that we only have some samples spe\n416.36s: specifically in from the outlier class\n419.639s: have a few data and it's not possible to\n422.319s: estimate the probability uh\n426.599s: densities so the the problem become\n428.759s: challenging when there's a scarcity of\n430.12s: data in the outl\n432.16s: class uh now uh one uh approach uh to\n438.4s: mitigate this uh challenge is uh use is\n442.72s: using trans learning\n444.759s: technique so this is our problem we we\n448.759s: also call it Target this is our goal we\n450.72s: have two classes class zero class one\n452.68s: from one class we have many data from\n454.319s: the other class we have a few data uh\n457.759s: it's hard it's challenging to find a\n459.639s: good classifier so the challenge is the\n462.039s: scarcity of the outlier data so\n465.56s: one natural approach is to get help from\n469.08s: some other related data sets so we we\n473.72s: can call it source so in the source\n476.36s: also it's another outlier detection\n479.56s: problem however from the other class we\n482.159s: have uh from class one we have uh more\n485.0s: data and uh we also assume that the the\n488.72s: class zero which we can call normal\n492.159s: distributions are the same in to Target\n495.039s: and Source but the distribution of the\n497.08s: outo classes could be related also could\n500.0s: be different uh from each\n502.199s: other and the problem is that how can we\n505.08s: get help from The Source in order to\n507.919s: improve the accur accuracy in the Target\n511.159s: uh\n512.76s: problem uh also let me give you an\n515.399s: concrete example in the applic climate\n517.599s: data let's say Target is uh one location\n520.76s: in a specific location we want to detect\n522.88s: heavy rain but we do not have a data\n525.68s: from that specific location uh but\n528.519s: Source could be other locations but from\n531.399s: some other locations we have enough data\n533.92s: and it's it's fair to assume that the\n536.48s: normal distribution of the rain not\n538.68s: heavy rain it's kind of the same between\n541.0s: two locations but the distribution of\n543.839s: the Heavy Rain could be different from\n547.88s: one location to other\n551.079s: location so it depends how you define\n553.92s: the source and Target source and Target\n555.6s: could be different to different\n556.76s: locations could be time for example\n559.2s: Target could be the current year Source\n561.0s: could be the past years from past years\n563.76s: you have gathered many data from for\n565.959s: example in the current year you do not\n567.36s: have enough data so there are some\n569.16s: question questions here how should we\n570.36s: leverage Source samples to improve\n573.04s: accuracy in the Target task can we just\n575.56s: combine them naively uh or we should uh\n579.6s: combine them in an effective way so\n582.24s: that's one question uh what if this the\n585.04s: second question is very important what\n586.279s: if the source distribution is unrelated\n588.2s: to the Target so sometimes because we\n591.079s: have some samples we do not know the\n593.36s: distributions uh we cannot also estimate\n595.64s: the distributions because we have a few\n597.48s: samples sometimes the distributions\n599.56s: could be very different from each other\n601.16s: then the phenomenon of negative transfer\n604.48s: happens so negative transfer it means\n606.76s: that it's better not to use Source\n608.279s: because it it sometimes it can mislead\n611.519s: you and the third question is that do we\n614.32s: need to have a higher knowledge of the\n616.24s: relatedness between source and Target\n618.079s: distributions do we need first to know\n620.44s: that source and Target related to each\n622.72s: other then perform transfer learning or\n625.0s: we can uh come up with a approach\n628.04s: automatically detect\n629.92s: when we should use a source when we\n631.839s: should avoid or ignore\n635.279s: source so here we are proposing a metod\n639.6s: procedure uh it's it's a very generic uh\n642.839s: procedure and in the later we are going\n644.839s: to implement this procedure so this is\n647.12s: an constraint optimization problem it\n650.6s: has a objective function and two\n653.32s: constraints uh so let's uh understand\n657.079s: line by line\n660.399s: so the last line which is one of the\n663.44s: constraints ensures that the type one\n666.519s: error of the function we want to obtain\n669.6s: is below the pre-specified threshold so\n673.0s: here it this this line filter out the\n675.639s: functions whose type one error is as\n681.32s: large then the second line uh first of\n685.24s: all this H hat uh on the right hand side\n689.639s: is the function obtained using only\n692.12s: target so first you uh ignore the source\n695.44s: you do classification you find find the\n698.12s: function uh from the target uh so that's\n701.519s: that's h t the the second line uh\n704.24s: retains functions with performance is\n707.16s: close to this uh the the function\n710.12s: obtained on the target uh plus uh\n713.399s: additional term so if you consider that\n716.2s: additional term if the number of Target\n718.279s: samples is large then H hatti is\n721.44s: reliable because it has train on a\n724.68s: enough number of samples so H Hatt is\n726.88s: good so that term uh goes down so we\n730.76s: only retain the function that are very\n732.72s: close to the that HT but when the number\n735.56s: of Target sample is uh low meaning that\n739.079s: that h t has uh has been trained on a\n743.92s: few number of Target samples so it's\n746.199s: it's not reliable so we have to retain\n748.76s: more\n749.76s: functions so that uh ensures that uh our\n753.6s: function would not very far from the\n755.839s: function uh train on the Target and then\n760.199s: on on on this class of uh functions uh\n764.24s: we are minimizing The Source uh we are\n766.959s: utilizing the source data and we are\n769.32s: minimizing the type to error uh on the\n771.68s: source data which utilizes The Source\n773.639s: samples so you see that this uh approach\n777.0s: uh guarantees that we will never have\n779.72s: negative transfer uh because we are\n782.8s: minimizing Source error on the function\n785.839s: that are close to the function uh\n788.44s: trained on the\n792.6s: target so first we derive the\n795.16s: theoretical guarantee for this approach\n797.839s: so that uh procedure is on training data\n801.399s: but we have to make sure that if when we\n804.16s: get a final when we get a function uh H\n808.0s: how how how is how is his performance on\n811.92s: the test data or generalization error so\n815.48s: we Pro this uh first of all it\n817.68s: guarantees that the on the test data the\n820.6s: type one error on the Target in the\n822.6s: Target domain uh is less than Alpha uh\n826.519s: and uh type two error is less than\n829.48s: minimum of two terms so let me explain\n831.959s: that two terms it consists of two terms\n835.0s: one of them depends on the so that one\n838.04s: is the number of targets samples and the\n840.0s: other one uh number of the source\n841.959s: samples uh so if you pay attention to\n844.36s: the second term it first of all it\n846.6s: ensures that Source doesn't hurt you uh\n850.519s: at least you can get the rate uh can be\n853.88s: obtained by using only target\n857.12s: samples and the the the other term is\n860.519s: that if source is helpful if source is\n862.639s: informative about the target you can\n864.68s: Leverage The the information from the uh\n867.56s: stores there also some other uh\n870.079s: parameters here so that row I'm not\n873.12s: going to into the details of these\n875.399s: parameters it kind of captures the\n877.24s: transfer distance it captur the value of\n879.72s: source samples if row is a small like if\n881.88s: row is one then Source sample is more\n884.36s: valuable if a row is large like 10 20\n887.68s: then the source sers are less valuable\n889.68s: so it captures the distance between\n891.839s: source and Target also that Delta is\n895.48s: the let's say you have obtained a\n897.88s: function using only source and then you\n900.959s: evaluate that function obtained on The\n902.6s: Source on the Target that Delta is the a\n905.56s: Target ER of the best source function uh\n908.44s: in the Target domain so that that's the\n910.639s: theoretical guarantee uh next we want to\n914.36s: implement uh this uh\n918.16s: procedure so let me use these notations\n921.88s: uh R vp0 is uh the risk the risk of H uh\n928.12s: on\n929.519s: normal distribution we call it P0 that\n931.72s: why it reflects the loss function we are\n934.04s: using could be logistic loss exponential\n937.319s: loss and then we have a Target type to\n940.839s: error uh sorry it should be Source type\n943.8s: to error is PS and the other one is\n946.24s: Target type\n947.88s: to so this this procedure is a\n952.12s: optimization a con optimization\n954.399s: procedure so we are using log Gran if\n956.639s: you write down the logran uh it will\n959.079s: have this format so here two tuning\n961.8s: parameters appear uh Lambda s uh is the\n965.639s: tuning parameter for the source risk and\n967.959s: Lambda T is the tuning parameter for the\n970.319s: Target risk\n972.88s: uh so we are not doing Brute Force\n976.199s: search we have developed a smart way how\n978.6s: to uh find these tuning parameters so\n981.68s: first you fix Lambda s and you find and\n985.639s: you've changeed the Lambda t uh so that\n989.079s: to in order to get some functions whose\n991.56s: type one error uh is close to the alpha\n994.279s: so for each pair of Lambda lambda zero\n996.319s: you have to train it and you get a\n997.959s: function so using this smart way you get\n1001.279s: a bunch of functions so the initial\n1004.0s: class of functions for example let's say\n1005.68s: it's a class of neuron networks uh can\n1008.399s: be reduced uh to H hat so all the\n1011.199s: functions in the H hat satisfy the type\n1014.04s: one error\n1016.04s: constraint and then uh it requires\n1019.959s: another filteration step so you use\n1022.56s: Target samples to uh filter some of\n1026.039s: these functions and in order to get\n1028.16s: another reduced uh hypothesis class or\n1031.199s: class of functions uh again also that\n1034.439s: depends on the number of the target\n1035.839s: samples if the number of Target samples\n1038.12s: is low then you retain more functions if\n1040.88s: the number of Target samples is large\n1043.079s: then you R fewer\n1046.28s: functions finally uh you use the source\n1049.76s: samples you minimize the source error uh\n1052.32s: on this reduced class of\n1059.96s: functions so properties of this this\n1063.48s: proposed algorithm is that first of all\n1065.679s: it doesn't require prior knowledge about\n1068.24s: relatedness between source and Target\n1070.559s: you know we can have source and Target\n1073.08s: are very close to each other their\n1075.0s: distribution and we can have source and\n1077.24s: Target that are very far from each other\n1080.799s: uh and so if the source contains\n1083.96s: information uh relevant to Target we\n1086.799s: will on the experiments also you you\n1088.84s: will you will see that the algorithm\n1090.44s: leverages the information if the source\n1093.159s: is irrelevant to the Target the\n1095.0s: algorithm uh avoids negative transfer so\n1098.48s: automatically if source is useful it\n1100.84s: exploits Source if source is not useful\n1103.039s: it avoid source and also the algorithm\n1105.919s: is model free meaning that you can\n1108.96s: consider class of neural networks kernel\n1111.32s: machines we do not have any assumption\n1113.36s: on the architecture of the neural\n1115.44s: network like could be CNN\n1118.679s: Etc so here we have conduct we have\n1122.36s: conducted some experiments on uh uh\n1125.2s: climate data so we are using the data\n1127.72s: set clim u large multi scale data set\n1132.2s: with hybrid physics ml climate emulation\n1135.6s: so in this data set from each location\n1138.24s: we have some uh data it uh depends on\n1141.64s: longitude and latitude of the location\n1144.679s: uh so we have mered this some\n1147.2s: neighboring locations and we have uh uh\n1149.919s: created some clusters uh so the data has\n1152.919s: 124 numerical features like temperature\n1155.96s: humidity Etc and it has many outputs so\n1159.679s: we have extracted only the output of the\n1161.88s: rain the original problem is a\n1163.4s: regression problem so we used the 95\n1166.24s: percentile to uh create a binary problem\n1170.48s: uh so one of one class is heavy rain the\n1172.36s: other class is non heavy rain we want to\n1174.32s: predict the heavy rain using this input\n1180.88s: features um so here is the result uh we\n1185.2s: have implemented our algorithm and some\n1188.4s: other approaches existing in the\n1191.0s: literature so here type one error which\n1193.64s: is Alpha is 5% uh and we are measuring\n1197.96s: the test\n1199.36s: Target type to error and here we are\n1202.159s: increasing the number of the source\n1203.6s: samples from 100 to 2,000 number of\n1206.76s: Target outlier you see is 25 the other\n1209.88s: CL 3,000 is heavily\n1213.2s: imbalanced uh first look at these two\n1215.72s: plots the on the top so one\n1220.12s: uh common approach in the literature is\n1222.88s: that uh you do a classification you find\n1226.36s: a function they call it score function\n1228.84s: function uh but for example you get a\n1232.039s: score function and in traditional\n1233.64s: classification if the score is above\n1236.88s: half you classify to one class if it's\n1239.6s: less than half you classify to the other\n1242.159s: class then uh you can change that\n1244.72s: threshold in order to satisfy the type\n1246.96s: one error so you first you get the score\n1248.799s: function and by changing the threshold\n1251.559s: you can satisfy the conern on the type\n1253.64s: one error so if you do that uh the\n1256.44s: dashed line is just using\n1259.24s: only target thresholding approach you\n1261.679s: see that's very large and this one uh is\n1266.0s: pull source and Target you just combine\n1268.08s: source and Target data and then you use\n1270.64s: that thresholding method you see that\n1272.4s: it's not good these methods all of them\n1275.0s: are name on Pearson approach based on uh\n1277.799s: our implementation and I'm comparing the\n1280.44s: black one is the full version of the\n1282.039s: name on pieron and I'm comparing with\n1284.08s: the other variants for example the blue\n1286.44s: one is that you just use Target\n1289.559s: and the other is that you just use\n1291.36s: Source uh and the other one is that you\n1293.919s: just naively combine source and Target\n1297.279s: and you run the algorithm but the black\n1299.44s: one is not uh naively combin source and\n1302.039s: Target it effectively combin source and\n1304.44s: Target so first of all you see that we\n1306.76s: have a for example gain with respect to\n1308.96s: the Baseline of only target it shows\n1311.44s: that source is helpful we can reduce the\n1314.64s: target error using the source uh however\n1317.4s: you see that the only source or just\n1320.279s: pool source and Target also they work\n1322.279s: well when we have more samples so\n1325.08s: they're kind of close to each\n1327.44s: other so you may ask us so why we you\n1331.0s: should use this uh a little bit\n1333.12s: complicated way to combine source and\n1334.72s: Target we can just combine them naively\n1337.279s: and run the algorithm uh the problem is\n1342.36s: that we don't know source is close or\n1345.0s: far so here you see that in the previous\n1348.0s: one source is informative so because\n1350.24s: source is good source is close to the\n1352.08s: Target only source method or pull source\n1355.159s: and Target perform well but when source\n1358.279s: is not good they suffer from a negative\n1361.4s: transfer so we ensure that our approach\n1364.84s: is close to the only target uh approach\n1368.84s: uh meaning that source is not helpful\n1370.679s: and we want to just ignore the source so\n1373.679s: we can uh be close to the base law but\n1377.48s: the other approaches uh suffer from\n1379.559s: negative transfer uh because they're\n1381.48s: just navely combined source and Target\n1383.36s: and they're not adaptive to the data uh\n1386.12s: meaning that they cannot detect whether\n1388.88s: source is helpful or is not helpful uh\n1392.32s: so that that's the message of the\n1393.559s: algorithm is that is adaptive if it's if\n1396.08s: source is helpful it exploits if source\n1398.24s: is not helpful automatically ignores the\n1401.48s: source so if I want to summary the talk\n1404.919s: uh we propose a meta algorithm as a\n1407.919s: constraint optimization procedure uh\n1410.679s: with a theoretical guarantee on the\n1412.44s: generalization error uh we implemented\n1416.32s: uh an in instantiation of the that meta\n1420.039s: procedure using log rer method there\n1423.12s: could be another inst instantiations of\n1425.44s: the uh procedure we conducted some\n1428.679s: experiments the experiments show that\n1431.559s: the algorithm uiz a source when source\n1434.36s: is related and avoid negative transfer\n1438.0s: when uh the source is not\n1442.6s: related also we submitted this board to\n1444.96s: AI stats\n1446.72s: 20125 uh transfer name on Pi algorithm\n1450.08s: for outlier detection uh the reviews\n1452.84s: were posit the reviews were positive I\n1454.6s: think it will be appear on that also we\n1457.919s: have conducted additional experiments in\n1460.12s: the paper not just climate data you know\n1462.88s: the approach is very generic it could be\n1464.799s: applied to financial data to climate\n1467.36s: data and\n1470.2s: uh thank\n1475.24s: you any\n1486.36s: question very interesting talk I'm\n1488.48s: wondering when you were uh\n1491.08s: showing\n1493.52s: um maybe I'll just ask the the transfer\n1496.76s: distance uh row value oh yeah yeah so in\n1501.52s: order to do this proof do you have to\n1503.2s: like be able to Define that analytically\n1506.2s: could you maybe explain yeah good\n1508.24s: question it's a very U\n1511.799s: um I mean people have defined um\n1515.2s: different notion of transfer how to\n1517.52s: define the how to quantify the notion of\n1519.72s: transfer between source and Target this\n1521.96s: row uh reflects the following fact you\n1524.679s: have a function in the source uh you\n1526.84s: want to measure how well this fun if a\n1529.6s: function works well in the source is it\n1532.32s: also good in the Target or not so this\n1534.44s: row captures that phenomenon that\n1536.399s: translates the performance of function\n1538.679s: in the source uh to the Target domain so\n1541.919s: that's uh one\n1544.44s: definition uh why this is important we\n1547.2s: have derived also optimality Minimax\n1549.36s: rate so it shows that this row appears\n1552.52s: in the lower bound meaning that it\n1554.559s: really it's a fundamental parameter and\n1557.72s: the beauty of the theorum is that\n1559.96s: without knowing the rule uh without\n1562.32s: knowing the transfer distance which is\n1563.88s: not estimable using finite samples uh we\n1566.88s: can get the optimal rate so meaning that\n1570.44s: uh we don't know row it could be large\n1572.44s: it could be small we don't know uh but\n1574.84s: always we are getting the optimal\n1577.279s: possible achievable rate\n1597.08s: hey uh thanks for the talk um yeah so in\n1600.24s: this talk you kind of like focus on\n1602.36s: outlier detention uh detection which is\n1604.399s: like a binary classification like you\n1606.159s: mentioned can this be extended to like\n1608.88s: heavily imbalanced multiclass\n1610.6s: classification yeah yeah good question\n1612.96s: uh so actually V are we are also working\n1614.919s: on extending this framework to\n1616.84s: multiclass uh I think only I remember\n1620.039s: only one or two papers have been\n1621.48s: published regarding multiclass dma\n1623.6s: Pearson uh we we are not sure if we can\n1626.44s: trivially extend this problem to multic\n1628.84s: class classification problem uh yeah but\n1633.32s: still we are working how to extend this\n1634.96s: problem yeah I don't know if you can\n1637.64s: trivially extend it to multi class or\n1639.52s: not\n1649.799s: thank you muhammeda and thank you Joe um\n1653.6s: at this point you are welcome to join us\n1656.2s: for a light lunch as always Greg\n1658.12s: students you get first dip so you can go\n1660.0s: to class thank you everyone and this was\n1662.36s: our last fall 2024 lecture in climate\n1666.519s: data science so thank you all and thank\n1668.24s: you online for joining us um throughout\n1670.84s: the term and we welcome you back I think\n1672.84s: we kick off\n1675.36s: January 23rd\n1679.0s: that's a Thursday so uh yes after the\n1681.76s: semester begins January 23rd I think is\n1683.96s: our first Thursday back so we look\n1685.919s: forward to seeing you back then thank\n1687.44s: you everyone"
    }
]